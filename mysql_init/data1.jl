{"id": "0704.0002", "submitter": "Louis Theran", "authors": "Ileana Streinu and Louis Theran", "title": "Sparsity-certifying Graph Decompositions", "comments": "To appear in Graphs and Combinatorics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new algorithm, the $(k,\\ell)$-pebble game with colors, and use\nit obtain a characterization of the family of $(k,\\ell)$-sparse graphs and\nalgorithmic solutions to a family of problems concerning tree decompositions of\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\nreceived increased attention in recent years. In particular, our colored\npebbles generalize and strengthen the previous results of Lee and Streinu and\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\nalso present a new decomposition that certifies sparsity based on the\n$(k,\\ell)$-pebble game with colors. Our work also exposes connections between\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\nWestermann and Hendrickson.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2007 02:26:18 GMT"}, {"version": "v2", "created": "Sat, 13 Dec 2008 17:26:00 GMT"}], "update_date": "2008-12-13", "authors_parsed": [["Streinu", "Ileana", ""], ["Theran", "Louis", ""]]}
{"id": "0704.0047", "submitter": "Igor Grabec", "authors": "T. Kosel and I. Grabec", "title": "Intelligent location of simultaneously active acoustic emission sources:\n  Part I", "comments": "5 pages, 5 eps figures, uses IEEEtran.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  The intelligent acoustic emission locator is described in Part I, while Part\nII discusses blind source separation, time delay estimation and location of two\nsimultaneously active continuous acoustic emission sources.\n  The location of acoustic emission on complicated aircraft frame structures is\na difficult problem of non-destructive testing. This article describes an\nintelligent acoustic emission source locator. The intelligent locator comprises\na sensor antenna and a general regression neural network, which solves the\nlocation problem based on learning from examples. Locator performance was\ntested on different test specimens. Tests have shown that the accuracy of\nlocation depends on sound velocity and attenuation in the specimen, the\ndimensions of the tested area, and the properties of stored data. The location\naccuracy achieved by the intelligent locator is comparable to that obtained by\nthe conventional triangulation method, while the applicability of the\nintelligent locator is more general since analysis of sonic ray paths is\navoided. This is a promising method for non-destructive testing of aircraft\nframe structures by the acoustic emission method.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2007 13:06:50 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Kosel", "T.", ""], ["Grabec", "I.", ""]]}
{"id": "0704.0050", "submitter": "Igor Grabec", "authors": "T. Kosel and I. Grabec", "title": "Intelligent location of simultaneously active acoustic emission sources:\n  Part II", "comments": "5 pages, 7 eps figures, uses IEEEtran.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  Part I describes an intelligent acoustic emission locator, while Part II\ndiscusses blind source separation, time delay estimation and location of two\ncontinuous acoustic emission sources.\n  Acoustic emission (AE) analysis is used for characterization and location of\ndeveloping defects in materials. AE sources often generate a mixture of various\nstatistically independent signals. A difficult problem of AE analysis is\nseparation and characterization of signal components when the signals from\nvarious sources and the mode of mixing are unknown. Recently, blind source\nseparation (BSS) by independent component analysis (ICA) has been used to solve\nthese problems. The purpose of this paper is to demonstrate the applicability\nof ICA to locate two independent simultaneously active acoustic emission\nsources on an aluminum band specimen. The method is promising for\nnon-destructive testing of aircraft frame structures by acoustic emission\nanalysis.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2007 18:53:13 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Kosel", "T.", ""], ["Grabec", "I.", ""]]}
{"id": "0704.0090", "submitter": "Lester Ingber", "authors": "Lester Ingber", "title": "Real Options for Project Schedules (ROPS)", "comments": null, "journal-ref": null, "doi": null, "report-no": "Report 2007:ROPS", "categories": "cs.CE cond-mat.stat-mech cs.MS cs.NA physics.data-an", "license": null, "abstract": "  Real Options for Project Schedules (ROPS) has three recursive\nsampling/optimization shells. An outer Adaptive Simulated Annealing (ASA)\noptimization shell optimizes parameters of strategic Plans containing multiple\nProjects containing ordered Tasks. A middle shell samples probability\ndistributions of durations of Tasks. An inner shell samples probability\ndistributions of costs of Tasks. PATHTREE is used to develop options on\nschedules.. Algorithms used for Trading in Risk Dimensions (TRD) are applied to\ndevelop a relative risk analysis among projects.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2007 14:35:40 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Ingber", "Lester", ""]]}
{"id": "0704.0108", "submitter": "Sergey Gubin", "authors": "Sergey Gubin", "title": "Reducing SAT to 2-SAT", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  Description of a polynomial time reduction of SAT to 2-SAT of polynomial\nsize.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2007 23:16:27 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Gubin", "Sergey", ""]]}
{"id": "0704.0213", "submitter": "Ketan Mulmuley D", "authors": "Ketan D. Mulmuley Hariharan Narayanan", "title": "Geometric Complexity Theory V: On deciding nonvanishing of a generalized\n  Littlewood-Richardson coefficient", "comments": "This article has been withdrawn because it has been merged with the\n  earlier article (GCT3) in the series, and a new article appears in this GCT5\n  slot now as shown in the abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  This article has been withdrawn because it has been merged with the earlier\narticle GCT3 (arXiv: CS/0501076 [cs.CC]) in the series. The merged article is\nnow available as:\n  Geometric Complexity Theory III: on deciding nonvanishing of a\nLittlewood-Richardson Coefficient, Journal of Algebraic Combinatorics, vol. 36,\nissue 1, 2012, pp. 103-110. (Authors: Ketan Mulmuley, Hari Narayanan and Milind\nSohoni)\n  The new article in this GCT5 slot in the series is:\n  Geometric Complexity Theory V: Equivalence between blackbox derandomization\nof polynomial identity testing and derandomization of Noether's Normalization\nLemma, in the Proceedings of FOCS 2012 (abstract), arXiv:1209.5993 [cs.CC]\n(full version) (Author: Ketan Mulmuley)\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2007 15:13:27 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2012 15:23:39 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Narayanan", "Ketan D. Mulmuley Hariharan", ""]]}
{"id": "0704.0229", "submitter": "Ketan Mulmuley D", "authors": "Ketan D. Mulmuley", "title": "Geometric Complexity Theory VI: the flip via saturated and positive\n  integer programming in representation theory and algebraic geometry", "comments": "139 pages. Corrects error in the conjectural saturation hypothesis\n  (SH) in the earlier version, which was pointed out in a recent paper of\n  Briand et al (arXIv:0810.3163v1 [math.CO])", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article belongs to a series on geometric complexity theory (GCT), an\napproach to the P vs. NP and related problems through algebraic geometry and\nrepresentation theory. The basic principle behind this approach is called the\nflip. In essence, it reduces the negative hypothesis in complexity theory (the\nlower bound problems), such as the P vs. NP problem in characteristic zero, to\nthe positive hypothesis in complexity theory (the upper bound problems):\nspecifically, to showing that the problems of deciding nonvanishing of the\nfundamental structural constants in representation theory and algebraic\ngeometry, such as the well known plethysm constants--or rather certain relaxed\nforms of these decision probelms--belong to the complexity class P. In this\narticle, we suggest a plan for implementing the flip, i.e., for showing that\nthese relaxed decision problems belong to P. This is based on the reduction of\nthe preceding complexity-theoretic positive hypotheses to mathematical\npositivity hypotheses: specifically, to showing that there exist positive\nformulae--i.e. formulae with nonnegative coefficients--for the structural\nconstants under consideration and certain functions associated with them. These\nturn out be intimately related to the similar positivity properties of the\nKazhdan-Lusztig polynomials and the multiplicative structural constants of the\ncanonical (global crystal) bases in the theory of Drinfeld-Jimbo quantum\ngroups. The known proofs of these positivity properties depend on the Riemann\nhypothesis over finite fields and the related results. Thus the reduction here,\nin conjunction with the flip, in essence, says that the validity of the P vs.\nNP conjecture in characteristic zero is intimately linked to the Riemann\nhypothesis over finite fields and related problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2007 16:41:38 GMT"}, {"version": "v2", "created": "Fri, 18 May 2007 19:55:46 GMT"}, {"version": "v3", "created": "Mon, 28 Apr 2008 19:49:27 GMT"}, {"version": "v4", "created": "Thu, 22 Jan 2009 15:25:24 GMT"}], "update_date": "2009-01-22", "authors_parsed": [["Mulmuley", "Ketan D.", ""]]}
{"id": "0704.0282", "submitter": "Samuele Bandi", "authors": "Samuele Bandi, Luca Stabellini, Andrea Conti and Velio Tralli", "title": "On Punctured Pragmatic Space-Time Codes in Block Fading Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": null, "abstract": "  This paper considers the use of punctured convolutional codes to obtain\npragmatic space-time trellis codes over block-fading channel. We show that good\nperformance can be achieved even when puncturation is adopted and that we can\nstill employ the same Viterbi decoder of the convolutional mother code by using\napproximated metrics without increasing the complexity of the decoding\noperations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2007 22:44:17 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Bandi", "Samuele", ""], ["Stabellini", "Luca", ""], ["Conti", "Andrea", ""], ["Tralli", "Velio", ""]]}
{"id": "0704.0301", "submitter": "Akitoshi Kawamura", "authors": "Akitoshi Kawamura", "title": "Differential Recursion and Differentially Algebraic Functions", "comments": "14 pages, 3 figures", "journal-ref": "Revised and published in ACM Trans. Comput. Logic 10, Article 22,\n  2009, under the title \"Differential Recursion\".", "doi": "10.1145/1507244.1507252", "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  Moore introduced a class of real-valued \"recursive\" functions by analogy with\nKleene's formulation of the standard recursive functions. While his concise\ndefinition inspired a new line of research on analog computation, it contains\nsome technical inaccuracies. Focusing on his \"primitive recursive\" functions,\nwe pin down what is problematic and discuss possible attempts to remove the\nambiguity regarding the behavior of the differential recursion operator on\npartial functions. It turns out that in any case the purported relation to\ndifferentially algebraic functions, and hence to Shannon's model of analog\ncomputation, fails.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2007 19:50:14 GMT"}], "update_date": "2009-04-19", "authors_parsed": [["Kawamura", "Akitoshi", ""]]}
{"id": "0704.0304", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson", "title": "The World as Evolving Information", "comments": "16 pages. Extended version, three more laws of information, two\n  classifications, and discussion added. To be published (soon) in\n  International Conference on Complex Systems 2007 Proceedings", "journal-ref": "Minai, A., Braha, D., and Bar-Yam, Y., eds. Unifying Themes in\n  Complex Systems VII, pp. 100-115. Springer, Berlin Heidelberg, 2012", "doi": "10.1007/978-3-642-18003-3_10", "report-no": null, "categories": "cs.IT cs.AI math.IT q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the benefits of describing the world as information,\nespecially in the study of the evolution of life and cognition. Traditional\nstudies encounter problems because it is difficult to describe life and\ncognition in terms of matter and energy, since their laws are valid only at the\nphysical scale. However, if matter and energy, as well as life and cognition,\nare described in terms of information, evolution can be described consistently\nas information becoming more complex.\n  The paper presents eight tentative laws of information, valid at multiple\nscales, which are generalizations of Darwinian, cybernetic, thermodynamic,\npsychological, philosophical, and complexity principles. These are further used\nto discuss the notions of life, cognition and their evolution.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2007 02:08:48 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2007 20:03:59 GMT"}, {"version": "v3", "created": "Wed, 13 Oct 2010 19:49:16 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Gershenson", "Carlos", ""]]}
{"id": "0704.0309", "submitter": "Guohun Zhu", "authors": "Guohun Zhu", "title": "The Complexity of HCP in Digraps with Degree Bound Two", "comments": "10 pages, 4 figures, had been submitted to a Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": null, "abstract": "  The Hamiltonian cycle problem (HCP) in digraphs D with degree bound two is\nsolved by two mappings in this paper. The first bijection is between an\nincidence matrix C_{nm} of simple digraph and an incidence matrix F of balanced\nbipartite undirected graph G; The second mapping is from a perfect matching of\nG to a cycle of D. It proves that the complexity of HCP in D is polynomial, and\nfinding a second non-isomorphism Hamiltonian cycle from a given Hamiltonian\ndigraph with degree bound two is also polynomial. Lastly it deduces P=NP base\non the results.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2007 03:50:43 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2007 15:42:14 GMT"}, {"version": "v3", "created": "Fri, 13 Jul 2007 01:38:24 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Zhu", "Guohun", ""]]}
{"id": "0704.0468", "submitter": "Jinsong Tan", "authors": "Jinsong Tan", "title": "Inapproximability of Maximum Weighted Edge Biclique and Its Applications", "comments": null, "journal-ref": "LNCS 4978, TAMC 2008, pp 282-293", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a bipartite graph $G = (V_1,V_2,E)$ where edges take on {\\it both}\npositive and negative weights from set $\\mathcal{S}$, the {\\it maximum weighted\nedge biclique} problem, or $\\mathcal{S}$-MWEB for short, asks to find a\nbipartite subgraph whose sum of edge weights is maximized. This problem has\nvarious applications in bioinformatics, machine learning and databases and its\n(in)approximability remains open. In this paper, we show that for a wide range\nof choices of $\\mathcal{S}$, specifically when $| \\frac{\\min\\mathcal{S}} {\\max\n\\mathcal{S}} | \\in \\Omega(\\eta^{\\delta-1/2}) \\cap O(\\eta^{1/2-\\delta})$ (where\n$\\eta = \\max\\{|V_1|, |V_2|\\}$, and $\\delta \\in (0,1/2]$), no polynomial time\nalgorithm can approximate $\\mathcal{S}$-MWEB within a factor of $n^{\\epsilon}$\nfor some $\\epsilon > 0$ unless $\\mathsf{RP = NP}$. This hardness result gives\njustification of the heuristic approaches adopted for various applied problems\nin the aforementioned areas, and indicates that good approximation algorithms\nare unlikely to exist. Specifically, we give two applications by showing that:\n1) finding statistically significant biclusters in the SAMBA model, proposed in\n\\cite{Tan02} for the analysis of microarray data, is\n$n^{\\epsilon}$-inapproximable; and 2) no polynomial time algorithm exists for\nthe Minimum Description Length with Holes problem \\cite{Bu05} unless\n$\\mathsf{RP=NP}$.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2007 21:39:11 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2009 02:50:29 GMT"}], "update_date": "2009-03-23", "authors_parsed": [["Tan", "Jinsong", ""]]}
{"id": "0704.0967", "submitter": "Jia Liu", "authors": "Jia Liu and Y. Thomas Hou", "title": "Cross-Layer Optimization of MIMO-Based Mesh Networks with Gaussian\n  Vector Broadcast Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AR math.IT", "license": null, "abstract": "  MIMO technology is one of the most significant advances in the past decade to\nincrease channel capacity and has a great potential to improve network capacity\nfor mesh networks. In a MIMO-based mesh network, the links outgoing from each\nnode sharing the common communication spectrum can be modeled as a Gaussian\nvector broadcast channel. Recently, researchers showed that ``dirty paper\ncoding'' (DPC) is the optimal transmission strategy for Gaussian vector\nbroadcast channels. So far, there has been little study on how this fundamental\nresult will impact the cross-layer design for MIMO-based mesh networks. To fill\nthis gap, we consider the problem of jointly optimizing DPC power allocation in\nthe link layer at each node and multihop/multipath routing in a MIMO-based mesh\nnetworks. It turns out that this optimization problem is a very challenging\nnon-convex problem. To address this difficulty, we transform the original\nproblem to an equivalent problem by exploiting the channel duality. For the\ntransformed problem, we develop an efficient solution procedure that integrates\nLagrangian dual decomposition method, conjugate gradient projection method\nbased on matrix differential calculus, cutting-plane method, and subgradient\nmethod. In our numerical example, it is shown that we can achieve a network\nperformance gain of 34.4% by using DPC.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2007 03:18:46 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Liu", "Jia", ""], ["Hou", "Y. Thomas", ""]]}
{"id": "0704.0985", "submitter": "Mohd Abubakr", "authors": "Mohd Abubakr, R.M.Vinay", "title": "Architecture for Pseudo Acausal Evolvable Embedded Systems", "comments": "4 pages, 2 figures. Submitted to SASO 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  Advances in semiconductor technology are contributing to the increasing\ncomplexity in the design of embedded systems. Architectures with novel\ntechniques such as evolvable nature and autonomous behavior have engrossed lot\nof attention. This paper demonstrates conceptually evolvable embedded systems\ncan be characterized basing on acausal nature. It is noted that in acausal\nsystems, future input needs to be known, here we make a mechanism such that the\nsystem predicts the future inputs and exhibits pseudo acausal nature. An\nembedded system that uses theoretical framework of acausality is proposed. Our\nmethod aims at a novel architecture that features the hardware evolability and\nautonomous behavior alongside pseudo acausality. Various aspects of this\narchitecture are discussed in detail along with the limitations.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2007 13:40:49 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Abubakr", "Mohd", ""], ["Vinay", "R. M.", ""]]}
{"id": "0704.1028", "submitter": "Jianlin Cheng", "authors": "Jianlin Cheng", "title": "A neural network approach to ordinal regression", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": null, "abstract": "  Ordinal regression is an important type of learning, which has properties of\nboth classification and regression. Here we describe a simple and effective\napproach to adapt a traditional neural network to learn ordinal categories. Our\napproach is a generalization of the perceptron method for ordinal regression.\nOn several benchmark datasets, our method (NNRank) outperforms a neural network\nclassification method. Compared with the ordinal regression methods using\nGaussian processes and support vector machines, NNRank achieves comparable\nperformance. Moreover, NNRank has the advantages of traditional neural\nnetworks: learning in both online and batch modes, handling very large training\ndatasets, and making rapid predictions. These features make NNRank a useful and\ncomplementary tool for large-scale data processing tasks such as information\nretrieval, web page ranking, collaborative filtering, and protein ranking in\nBioinformatics.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2007 17:36:00 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Cheng", "Jianlin", ""]]}
{"id": "0704.1043", "submitter": "Hector Zenil", "authors": "Jean-Paul Delahaye and Hector Zenil", "title": "On the Kolmogorov-Chaitin Complexity for short sequences", "comments": "21 pages. Paper webpage: http://www.mathrix.org/experimentalAIT/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A drawback of Kolmogorov-Chaitin complexity (K) as a function from s to the\nshortest program producing s is its noncomputability which limits its range of\napplicability. Moreover, when strings are short, the dependence of K on a\nparticular universal Turing machine U can be arbitrary. In practice one can\napproximate it by computable compression methods. However, such compression\nmethods do not always provide meaningful approximations--for strings shorter,\nfor example, than typical compiler lengths. In this paper we suggest an\nempirical approach to overcome this difficulty and to obtain a stable\ndefinition of the Kolmogorov-Chaitin complexity for short sequences.\nAdditionally, a correlation in terms of distribution frequencies was found\nacross the output of two models of abstract machines, namely unidimensional\ncellular automata and deterministic Turing machine.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2007 20:01:47 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2007 13:00:55 GMT"}, {"version": "v3", "created": "Wed, 30 May 2007 10:16:36 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2010 20:03:20 GMT"}, {"version": "v5", "created": "Fri, 17 Dec 2010 01:36:26 GMT"}], "update_date": "2010-12-20", "authors_parsed": [["Delahaye", "Jean-Paul", ""], ["Zenil", "Hector", ""]]}
{"id": "0704.1196", "submitter": "Shengchao Ding", "authors": "Qing Yang and Shengchao Ding", "title": "Novel algorithm to calculate hypervolume indicator of Pareto\n  approximation set", "comments": "9 pages, 2 figures. Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NE", "license": null, "abstract": "  Hypervolume indicator is a commonly accepted quality measure for comparing\nPareto approximation set generated by multi-objective optimizers. The best\nknown algorithm to calculate it for $n$ points in $d$-dimensional space has a\nrun time of $O(n^{d/2})$ with special data structures. This paper presents a\nrecursive, vertex-splitting algorithm for calculating the hypervolume indicator\nof a set of $n$ non-comparable points in $d>2$ dimensions. It splits out\nmultiple child hyper-cuboids which can not be dominated by a splitting\nreference point. In special, the splitting reference point is carefully chosen\nto minimize the number of points in the child hyper-cuboids. The complexity\nanalysis shows that the proposed algorithm achieves $O((\\frac{d}{2})^n)$ time\nand $O(dn^2)$ space complexity in the worst case.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2007 07:21:02 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Yang", "Qing", ""], ["Ding", "Shengchao", ""]]}
{"id": "0704.1269", "submitter": "Lenka Zdeborova", "authors": "Lenka Zdeborov\\'a, Florent Krzakala", "title": "Phase Transitions in the Coloring of Random Graphs", "comments": "36 pages, 15 figures", "journal-ref": "Phys. Rev. E 76, 031131 (2007)", "doi": "10.1103/PhysRevE.76.031131", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC", "license": null, "abstract": "  We consider the problem of coloring the vertices of a large sparse random\ngraph with a given number of colors so that no adjacent vertices have the same\ncolor. Using the cavity method, we present a detailed and systematic analytical\nstudy of the space of proper colorings (solutions).\n  We show that for a fixed number of colors and as the average vertex degree\n(number of constraints) increases, the set of solutions undergoes several phase\ntransitions similar to those observed in the mean field theory of glasses.\nFirst, at the clustering transition, the entropically dominant part of the\nphase space decomposes into an exponential number of pure states so that beyond\nthis transition a uniform sampling of solutions becomes hard. Afterward, the\nspace of solutions condenses over a finite number of the largest states and\nconsequently the total entropy of solutions becomes smaller than the annealed\none. Another transition takes place when in all the entropically dominant\nstates a finite fraction of nodes freezes so that each of these nodes is\nallowed a single color in all the solutions inside the state. Eventually, above\nthe coloring threshold, no more solutions are available. We compute all the\ncritical connectivities for Erdos-Renyi and regular random graphs and determine\ntheir asymptotic values for large number of colors.\n  Finally, we discuss the algorithmic consequences of our findings. We argue\nthat the onset of computational hardness is not associated with the clustering\ntransition and we suggest instead that the freezing transition might be the\nrelevant phenomenon. We also discuss the performance of a simple local Walk-COL\nalgorithm and of the belief propagation algorithm in the light of our results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2007 16:42:15 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2007 15:26:20 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Zdeborová", "Lenka", ""], ["Krzakala", "Florent", ""]]}
{"id": "0704.1394", "submitter": "Tarik Had\\v{z}i\\'c", "authors": "Tarik Hadzic, Rune Moller Jensen, Henrik Reif Andersen", "title": "Calculating Valid Domains for BDD-Based Interactive Configuration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  In these notes we formally describe the functionality of Calculating Valid\nDomains from the BDD representing the solution space of valid configurations.\nThe formalization is largely based on the CLab configuration framework.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2007 10:59:56 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Hadzic", "Tarik", ""], ["Jensen", "Rune Moller", ""], ["Andersen", "Henrik Reif", ""]]}
{"id": "0704.1409", "submitter": "Yao Hengshuai", "authors": "Yao HengShuai", "title": "Preconditioned Temporal Difference Learning", "comments": "This paper has been withdrawn by the author. Look at the ICML version\n  instead: http://icml2008.cs.helsinki.fi/papers/111.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": null, "abstract": "  This paper has been withdrawn by the author. This draft is withdrawn for its\npoor quality in english, unfortunately produced by the author when he was just\nstarting his science route. Look at the ICML version instead:\nhttp://icml2008.cs.helsinki.fi/papers/111.pdf\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2007 13:17:01 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2007 03:33:26 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2012 14:08:19 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["HengShuai", "Yao", ""]]}
{"id": "0704.1675", "submitter": "Kristina Lerman", "authors": "Anon Plangprasopchok and Kristina Lerman", "title": "Exploiting Social Annotation for Automatic Resource Discovery", "comments": "6 pages, submitted to AAAI07 workshop on Information Integration on\n  the Web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DL", "license": null, "abstract": "  Information integration applications, such as mediators or mashups, that\nrequire access to information resources currently rely on users manually\ndiscovering and integrating them in the application. Manual resource discovery\nis a slow process, requiring the user to sift through results obtained via\nkeyword-based search. Although search methods have advanced to include evidence\nfrom document contents, its metadata and the contents and link structure of the\nreferring pages, they still do not adequately cover information sources --\noften called ``the hidden Web''-- that dynamically generate documents in\nresponse to a query. The recently popular social bookmarking sites, which allow\nusers to annotate and share metadata about various information sources, provide\nrich evidence for resource discovery. In this paper, we describe a\nprobabilistic model of the user annotation process in a social bookmarking\nsystem del.icio.us. We then use the model to automatically find resources\nrelevant to a particular information domain. Our experimental results on data\nobtained from \\emph{del.icio.us} show this approach as a promising method for\nhelping automate the resource discovery task.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2007 23:24:19 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Plangprasopchok", "Anon", ""], ["Lerman", "Kristina", ""]]}
{"id": "0704.1676", "submitter": "Kristina Lerman", "authors": "Kristina Lerman, Anon Plangprasopchok and Chio Wong", "title": "Personalizing Image Search Results on Flickr", "comments": "12 pages, submitted to AAAI07 workshop on Intelligent Information\n  Personalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CY cs.DL cs.HC", "license": null, "abstract": "  The social media site Flickr allows users to upload their photos, annotate\nthem with tags, submit them to groups, and also to form social networks by\nadding other users as contacts. Flickr offers multiple ways of browsing or\nsearching it. One option is tag search, which returns all images tagged with a\nspecific keyword. If the keyword is ambiguous, e.g., ``beetle'' could mean an\ninsect or a car, tag search results will include many images that are not\nrelevant to the sense the user had in mind when executing the query. We claim\nthat users express their photography interests through the metadata they add in\nthe form of contacts and image annotations. We show how to exploit this\nmetadata to personalize search results for the user, thereby improving search\nperformance. First, we show that we can significantly improve search precision\nby filtering tag search results by user's contacts or a larger social network\nthat includes those contact's contacts. Secondly, we describe a probabilistic\nmodel that takes advantage of tag information to discover latent topics\ncontained in the search results. The users' interests can similarly be\ndescribed by the tags they used for annotating their images. The latent topics\nfound by the model are then used to personalize search results by finding\nimages on topics that are of interest to the user.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2007 23:31:04 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Lerman", "Kristina", ""], ["Plangprasopchok", "Anon", ""], ["Wong", "Chio", ""]]}
{"id": "0704.1678", "submitter": "Shanghua Teng", "authors": "Xi Chen, Xiaotie Deng, Shang-Hua Teng", "title": "Settling the Complexity of Computing Two-Player Nash Equilibria", "comments": "53 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": null, "abstract": "  We settle a long-standing open question in algorithmic game theory. We prove\nthat Bimatrix, the problem of finding a Nash equilibrium in a two-player game,\nis complete for the complexity class PPAD Polynomial Parity Argument, Directed\nversion) introduced by Papadimitriou in 1991.\n  This is the first of a series of results concerning the complexity of Nash\nequilibria. In particular, we prove the following theorems:\n  Bimatrix does not have a fully polynomial-time approximation scheme unless\nevery problem in PPAD is solvable in polynomial time. The smoothed complexity\nof the classic Lemke-Howson algorithm and, in fact, of any algorithm for\nBimatrix is not polynomial unless every problem in PPAD is solvable in\nrandomized polynomial time. Our results demonstrate that, even in the simplest\nform of non-cooperative games, equilibrium computation and approximation are\npolynomial-time equivalent to fixed point computation. Our results also have\ntwo broad complexity implications in mathematical economics and operations\nresearch: Arrow-Debreu market equilibria are PPAD-hard to compute. The P-Matrix\nLinear Complementary Problem is computationally harder than convex programming\nunless every problem in PPAD is solvable in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2007 23:54:30 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Chen", "Xi", ""], ["Deng", "Xiaotie", ""], ["Teng", "Shang-Hua", ""]]}
{"id": "0704.1694", "submitter": "Sergey Yekhanin", "authors": "Kiran S. Kedlaya, Sergey Yekhanin", "title": "Locally Decodable Codes From Nice Subsets of Finite Fields and Prime\n  Factors of Mersenne Numbers", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.NT", "license": null, "abstract": "  A k-query Locally Decodable Code (LDC) encodes an n-bit message x as an N-bit\ncodeword C(x), such that one can probabilistically recover any bit x_i of the\nmessage by querying only k bits of the codeword C(x), even after some constant\nfraction of codeword bits has been corrupted. The major goal of LDC related\nresearch is to establish the optimal trade-off between length and query\ncomplexity of such codes.\n  Recently [Y] introduced a novel technique for constructing locally decodable\ncodes and vastly improved the upper bounds for code length. The technique is\nbased on Mersenne primes. In this paper we extend the work of [Y] and argue\nthat further progress via these methods is tied to progress on an old number\ntheory question regarding the size of the largest prime factors of Mersenne\nnumbers.\n  Specifically, we show that every Mersenne number m=2^t-1 that has a prime\nfactor p>m^\\gamma yields a family of k(\\gamma)-query locally decodable codes of\nlength Exp(n^{1/t}). Conversely, if for some fixed k and all \\epsilon > 0 one\ncan use the technique of [Y] to obtain a family of k-query LDCs of length\nExp(n^\\epsilon); then infinitely many Mersenne numbers have prime factors arger\nthan known currently.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2007 04:18:19 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Kedlaya", "Kiran S.", ""], ["Yekhanin", "Sergey", ""]]}
{"id": "0704.1768", "submitter": "Enrique ter Horst A", "authors": "Henryk Gzyl, German Molina, Enrique ter Horst", "title": "Assessment and Propagation of Input Uncertainty in Tree-based Option\n  Pricing Models", "comments": "39 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.GT", "license": null, "abstract": "  This paper aims to provide a practical example on the assessment and\npropagation of input uncertainty for option pricing when using tree-based\nmethods. Input uncertainty is propagated into output uncertainty, reflecting\nthat option prices are as unknown as the inputs they are based on. Option\npricing formulas are tools whose validity is conditional not only on how close\nthe model represents reality, but also on the quality of the inputs they use,\nand those inputs are usually not observable. We provide three alternative\nframeworks to calibrate option pricing tree models, propagating parameter\nuncertainty into the resulting option prices. We finally compare our methods\nwith classical calibration-based results assuming that there is no options\nmarket established. These methods can be applied to pricing of instruments for\nwhich there is not an options market, as well as a methodological tool to\naccount for parameter and model uncertainty in theoretical option pricing.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2007 14:48:41 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Gzyl", "Henryk", ""], ["Molina", "German", ""], ["ter Horst", "Enrique", ""]]}
{"id": "0704.1783", "submitter": "Francesco Santini", "authors": "Stefano Bistarelli, Ugo Montanari, Francesca Rossi, Francesco Santini", "title": "Unicast and Multicast Qos Routing with Soft Constraint Logic Programming", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.NI", "license": null, "abstract": "  We present a formal model to represent and solve the unicast/multicast\nrouting problem in networks with Quality of Service (QoS) requirements. To\nattain this, first we translate the network adapting it to a weighted graph\n(unicast) or and-or graph (multicast), where the weight on a connector\ncorresponds to the multidimensional cost of sending a packet on the related\nnetwork link: each component of the weights vector represents a different QoS\nmetric value (e.g. bandwidth, cost, delay, packet loss). The second step\nconsists in writing this graph as a program in Soft Constraint Logic\nProgramming (SCLP): the engine of this framework is then able to find the best\npaths/trees by optimizing their costs and solving the constraints imposed on\nthem (e.g. delay < 40msec), thus finding a solution to QoS routing problems.\nMoreover, c-semiring structures are a convenient tool to model QoS metrics. At\nlast, we provide an implementation of the framework over scale-free networks\nand we suggest how the performance can be improved.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2007 15:53:44 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2007 15:40:10 GMT"}, {"version": "v3", "created": "Mon, 21 Apr 2008 17:25:06 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Bistarelli", "Stefano", ""], ["Montanari", "Ugo", ""], ["Rossi", "Francesca", ""], ["Santini", "Francesco", ""]]}
{"id": "0704.2010", "submitter": "Juliana Bernardes", "authors": "Juliana S Bernardes, Alberto Davila, Vitor Santos Costa, Gerson\n  Zaverucha", "title": "A study of structural properties on profiles HMMs", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Profile hidden Markov Models (pHMMs) are a popular and very\nuseful tool in the detection of the remote homologue protein families.\nUnfortunately, their performance is not always satisfactory when proteins are\nin the 'twilight zone'. We present HMMER-STRUCT, a model construction algorithm\nand tool that tries to improve pHMM performance by using structural information\nwhile training pHMMs. As a first step, HMMER-STRUCT constructs a set of pHMMs.\nEach pHMM is constructed by weighting each residue in an aligned protein\naccording to a specific structural property of the residue. Properties used\nwere primary, secondary and tertiary structures, accessibility and packing.\nHMMER-STRUCT then prioritizes the results by voting. Results: We used the SCOP\ndatabase to perform our experiments. Throughout, we apply leave-one-family-out\ncross-validation over protein superfamilies. First, we used the MAMMOTH-mult\nstructural aligner to align the training set proteins. Then, we performed two\nsets of experiments. In a first experiment, we compared structure weighted\nmodels against standard pHMMs and against each other. In a second experiment,\nwe compared the voting model against individual pHMMs. We compare method\nperformance through ROC curves and through Precision/Recall curves, and assess\nsignificance through the paired two tailed t-test. Our results show significant\nperformance improvements of all structurally weighted models over default\nHMMER, and a significant improvement in sensitivity of the combined models over\nboth the original model and the structurally weighted models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2007 13:10:35 GMT"}, {"version": "v2", "created": "Thu, 11 Dec 2008 18:47:26 GMT"}], "update_date": "2008-12-11", "authors_parsed": [["Bernardes", "Juliana S", ""], ["Davila", "Alberto", ""], ["Costa", "Vitor Santos", ""], ["Zaverucha", "Gerson", ""]]}
{"id": "0704.2083", "submitter": "Hassan Satori", "authors": "H. Satori, M. Harti and N. Chenfour", "title": "Introduction to Arabic Speech Recognition Using CMUSphinx System", "comments": "4 pages, 3 figures and 2 tables, was in Information and Communication\n  Technologies International Symposium proceeding ICTIS07 Fes (2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": null, "abstract": "  In this paper Arabic was investigated from the speech recognition problem\npoint of view. We propose a novel approach to build an Arabic Automated Speech\nRecognition System (ASR). This system is based on the open source CMU Sphinx-4,\nfrom the Carnegie Mellon University. CMU Sphinx is a large-vocabulary;\nspeaker-independent, continuous speech recognition system based on discrete\nHidden Markov Models (HMMs). We build a model using utilities from the\nOpenSource CMU Sphinx. We will demonstrate the possible adaptability of this\nsystem to Arabic voice recognition.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2007 01:04:01 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Satori", "H.", ""], ["Harti", "M.", ""], ["Chenfour", "N.", ""]]}
{"id": "0704.2201", "submitter": "Hassan Satori", "authors": "H. Satori, M. Harti and N. Chenfour", "title": "Arabic Speech Recognition System using CMU-Sphinx4", "comments": "5 pages, 3 figures and 2 tables, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": null, "abstract": "  In this paper we present the creation of an Arabic version of Automated\nSpeech Recognition System (ASR). This system is based on the open source\nSphinx-4, from the Carnegie Mellon University. Which is a speech recognition\nsystem based on discrete hidden Markov models (HMMs). We investigate the\nchanges that must be made to the model to adapt Arabic voice recognition.\n  Keywords: Speech recognition, Acoustic model, Arabic language, HMMs,\nCMUSphinx-4, Artificial intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2007 17:04:26 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Satori", "H.", ""], ["Harti", "M.", ""], ["Chenfour", "N.", ""]]}
{"id": "0704.2386", "submitter": "Pilar Albert", "authors": "Pilar Albert, Elvira Mayordomo, and Philippe Moser", "title": "Bounded Pushdown dimension vs Lempel Ziv information density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": null, "abstract": "  In this paper we introduce a variant of pushdown dimension called bounded\npushdown (BPD) dimension, that measures the density of information contained in\na sequence, relative to a BPD automata, i.e. a finite state machine equipped\nwith an extra infinite memory stack, with the additional requirement that every\ninput symbol only allows a bounded number of stack movements. BPD automata are\na natural real-time restriction of pushdown automata. We show that BPD\ndimension is a robust notion by giving an equivalent characterization of BPD\ndimension in terms of BPD compressors. We then study the relationships between\nBPD compression, and the standard Lempel-Ziv (LZ) compression algorithm, and\nshow that in contrast to the finite-state compressor case, LZ is not universal\nfor bounded pushdown compressors in a strong sense: we construct a sequence\nthat LZ fails to compress signicantly, but that is compressed by at least a\nfactor 2 by a BPD compressor. As a corollary we obtain a strong separation\nbetween finite-state and BPD dimension.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2007 16:49:48 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Albert", "Pilar", ""], ["Mayordomo", "Elvira", ""], ["Moser", "Philippe", ""]]}
{"id": "0704.2779", "submitter": "J D", "authors": "Jonas Dieckelmann", "title": "The Complexity of Simple Stochastic Games", "comments": "Hi, while reading through literature i noticed that it has not yet\n  been proved that computing the value vector of simple stochastic games is a\n  Problem in FNP. This is why i came up with a prove in this seminar work of\n  mine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": null, "abstract": "  In this paper we survey the computational time complexity of assorted simple\nstochastic game problems, and we give an overview of the best known algorithms\nassociated with each problem.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2007 19:51:36 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Dieckelmann", "Jonas", ""]]}
{"id": "0704.2852", "submitter": "Christof Teuscher", "authors": "Christof Teuscher", "title": "Nature-Inspired Interconnects for Self-Assembled Large-Scale\n  Network-on-Chip Designs", "comments": null, "journal-ref": "Chaos, 17(2):026106, 2007", "doi": "10.1063/1.2740566", "report-no": "LA-UR-07-0204", "categories": "cs.AR cond-mat.dis-nn nlin.AO", "license": null, "abstract": "  Future nano-scale electronics built up from an Avogadro number of components\nneeds efficient, highly scalable, and robust means of communication in order to\nbe competitive with traditional silicon approaches. In recent years, the\nNetworks-on-Chip (NoC) paradigm emerged as a promising solution to interconnect\nchallenges in silicon-based electronics. Current NoC architectures are either\nhighly regular or fully customized, both of which represent implausible\nassumptions for emerging bottom-up self-assembled molecular electronics that\nare generally assumed to have a high degree of irregularity and imperfection.\nHere, we pragmatically and experimentally investigate important design\ntrade-offs and properties of an irregular, abstract, yet physically plausible\n3D small-world interconnect fabric that is inspired by modern network-on-chip\nparadigms. We vary the framework's key parameters, such as the connectivity,\nthe number of switch nodes, the distribution of long- versus short-range\nconnections, and measure the network's relevant communication characteristics.\nWe further explore the robustness against link failures and the ability and\nefficiency to solve a simple toy problem, the synchronization task. The results\nconfirm that (1) computation in irregular assemblies is a promising and\ndisruptive computing paradigm for self-assembled nano-scale electronics and (2)\nthat 3D small-world interconnect fabrics with a power-law decaying distribution\nof shortcut lengths are physically plausible and have major advantages over\nlocal 2D and 3D regular topologies.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2007 21:26:03 GMT"}], "update_date": "2007-07-01", "authors_parsed": [["Teuscher", "Christof", ""]]}
{"id": "0704.3157", "submitter": "Giorgio Terracina", "authors": "Giorgio Terracina, Nicola Leone, Vincenzino Lio, Claudio Panetta", "title": "Experimenting with recursive queries in database and logic programming\n  systems", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": null, "abstract": "  This paper considers the problem of reasoning on massive amounts of (possibly\ndistributed) data. Presently, existing proposals show some limitations: {\\em\n(i)} the quantity of data that can be handled contemporarily is limited, due to\nthe fact that reasoning is generally carried out in main-memory; {\\em (ii)} the\ninteraction with external (and independent) DBMSs is not trivial and, in\nseveral cases, not allowed at all; {\\em (iii)} the efficiency of present\nimplementations is still not sufficient for their utilization in complex\nreasoning tasks involving massive amounts of data. This paper provides a\ncontribution in this setting; it presents a new system, called DLV$^{DB}$,\nwhich aims to solve these problems. Moreover, the paper reports the results of\na thorough experimental analysis we have carried out for comparing our system\nwith several state-of-the-art systems (both logic and databases) on some\nclassical deductive problems; the other tested systems are: LDL++, XSB, Smodels\nand three top-level commercial DBMSs. DLV$^{DB}$ significantly outperforms even\nthe commercial Database Systems on recursive queries. To appear in Theory and\nPractice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2007 10:58:40 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Terracina", "Giorgio", ""], ["Leone", "Nicola", ""], ["Lio", "Vincenzino", ""], ["Panetta", "Claudio", ""]]}
{"id": "0704.3177", "submitter": "Andreas Enge", "authors": "Andreas Enge (INRIA Futurs)", "title": "Computing modular polynomials in quasi-linear time", "comments": null, "journal-ref": "Mathematics of Computation 78, 267 (2009) 1809-1824", "doi": null, "report-no": null, "categories": "math.NT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse and compare the complexity of several algorithms for computing\nmodular polynomials. We show that an algorithm relying on floating point\nevaluation of modular functions and on interpolation, which has received little\nattention in the literature, has a complexity that is essentially (up to\nlogarithmic factors) linear in the size of the computed polynomials. In\nparticular, it obtains the classical modular polynomials $\\Phi_\\ell$ of prime\nlevel $\\ell$ in time O (\\ell^3 \\log^4 \\ell \\log \\log \\ell). Besides treating\nmodular polynomials for $\\Gamma^0 (\\ell)$, which are an important ingredient in\nmany algorithms dealing with isogenies of elliptic curves, the algorithm is\neasily adapted to more general situations. Composite levels are handled just as\neasily as prime levels, as well as polynomials between a modular function and\nits transform of prime level, such as the Schl\\\"afli polynomials and their\ngeneralisations. Our distributed implementation of the algorithm confirms the\ntheoretical analysis by computing modular equations of record level around\n10000 in less than two weeks on ten processors.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2007 12:27:39 GMT"}, {"version": "v2", "created": "Wed, 23 Jul 2008 12:33:49 GMT"}], "update_date": "2009-05-08", "authors_parsed": [["Enge", "Andreas", "", "INRIA Futurs"]]}
{"id": "0704.3197", "submitter": "Reinhard Klette", "authors": "Fajie Li and Reinhard Klette", "title": "Euclidean Shortest Paths in Simple Cube Curves at a Glance", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": "CITR-TR-198", "categories": "cs.CG cs.DM", "license": null, "abstract": "  This paper reports about the development of two provably correct approximate\nalgorithms which calculate the Euclidean shortest path (ESP) within a given\ncube-curve with arbitrary accuracy, defined by $\\epsilon >0$, and in time\ncomplexity $\\kappa(\\epsilon) \\cdot {\\cal O}(n)$, where $\\kappa(\\epsilon)$ is\nthe length difference between the path used for initialization and the\nminimum-length path, divided by $\\epsilon$. A run-time diagram also illustrates\nthis linear-time behavior of the implemented ESP algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2007 03:54:51 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Li", "Fajie", ""], ["Klette", "Reinhard", ""]]}
{"id": "0704.3359", "submitter": "Alex Smola J", "authors": "Quoc Le and Alexander Smola", "title": "Direct Optimization of Ranking Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": null, "abstract": "  Web page ranking and collaborative filtering require the optimization of\nsophisticated performance measures. Current Support Vector approaches are\nunable to optimize them directly and focus on pairwise comparisons instead. We\npresent a new approach which allows direct optimization of the relevant loss\nfunctions. This is achieved via structured estimation in Hilbert spaces. It is\nmost related to Max-Margin-Markov networks optimization of multivariate\nperformance measures. Key to our approach is that during training the ranking\nproblem can be viewed as a linear assignment problem, which can be solved by\nthe Hungarian Marriage algorithm. At test time, a sort operation is sufficient,\nas our algorithm assigns a relevance score to every (document, query) pair.\nExperiments show that the our algorithm is fast and that it works very well.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2007 12:36:55 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Le", "Quoc", ""], ["Smola", "Alexander", ""]]}
{"id": "0704.3395", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez", "title": "General-Purpose Computing on a Semantic Network Substrate", "comments": null, "journal-ref": "Emergent Web Intelligence: Advanced Semantic Technologies,\n  Advanced Information and Knowledge Processing series, Springer-Verlag, pages\n  57-104, ISBN:978-1-84996-076-2, June 2010", "doi": null, "report-no": "LA-UR-07-2885", "categories": "cs.AI cs.PL", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  This article presents a model of general-purpose computing on a semantic\nnetwork substrate. The concepts presented are applicable to any semantic\nnetwork representation. However, due to the standards and technological\ninfrastructure devoted to the Semantic Web effort, this article is presented\nfrom this point of view. In the proposed model of computing, the application\nprogramming interface, the run-time program, and the state of the computing\nvirtual machine are all represented in the Resource Description Framework\n(RDF). The implementation of the concepts presented provides a practical\ncomputing paradigm that leverages the highly-distributed and standardized\nrepresentational-layer of the Semantic Web.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2007 15:37:52 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2007 20:08:21 GMT"}, {"version": "v3", "created": "Sun, 7 Oct 2007 21:44:01 GMT"}, {"version": "v4", "created": "Sun, 6 Jun 2010 05:29:22 GMT"}], "update_date": "2010-06-08", "authors_parsed": [["Rodriguez", "Marko A.", ""]]}
{"id": "0704.3433", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala and Bodie Crossingham", "title": "Bayesian approach to rough set", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper proposes an approach to training rough set models using Bayesian\nframework trained using Markov Chain Monte Carlo (MCMC) method. The prior\nprobabilities are constructed from the prior knowledge that good rough set\nmodels have fewer rules. Markov Chain Monte Carlo sampling is conducted through\nsampling in the rough set granule space and Metropolis algorithm is used as an\nacceptance criteria. The proposed method is tested to estimate the risk of HIV\ngiven demographic data. The results obtained shows that the proposed approach\nis able to achieve an average accuracy of 58% with the accuracy varying up to\n66%. In addition the Bayesian rough set give the probabilities of the estimated\nHIV status as well as the linguistic rules describing how the demographic\nparameters drive the risk of HIV.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2007 19:50:59 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""], ["Crossingham", "Bodie", ""]]}
{"id": "0704.3453", "submitter": "Tshilidzi Marwala", "authors": "S. Mohamed, D. Rubin, and T. Marwala", "title": "An Adaptive Strategy for the Classification of G-Protein Coupled\n  Receptors", "comments": "9 pages, 5 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.QM", "license": null, "abstract": "  One of the major problems in computational biology is the inability of\nexisting classification models to incorporate expanding and new domain\nknowledge. This problem of static classification models is addressed in this\npaper by the introduction of incremental learning for problems in\nbioinformatics. Many machine learning tools have been applied to this problem\nusing static machine learning structures such as neural networks or support\nvector machines that are unable to accommodate new information into their\nexisting models. We utilize the fuzzy ARTMAP as an alternate machine learning\nsystem that has the ability of incrementally learning new data as it becomes\navailable. The fuzzy ARTMAP is found to be comparable to many of the widespread\nmachine learning systems. The use of an evolutionary strategy in the selection\nand combination of individual classifiers into an ensemble system, coupled with\nthe incremental learning ability of the fuzzy ARTMAP is proven to be suitable\nas a pattern classifier. The algorithm presented is tested using data from the\nG-Coupled Protein Receptors Database and shows good accuracy of 83%. The system\npresented is also generally applicable, and can be used in problems in genomics\nand proteomics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2007 21:23:31 GMT"}], "update_date": "2007-06-25", "authors_parsed": [["Mohamed", "S.", ""], ["Rubin", "D.", ""], ["Marwala", "T.", ""]]}
{"id": "0704.3496", "submitter": "Frank Gurski", "authors": "Frank Gurski", "title": "Polynomial algorithms for protein similarity search for restricted mRNA\n  structures", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  In this paper we consider the problem of computing an mRNA sequence of\nmaximal similarity for a given mRNA of secondary structure constraints,\nintroduced by Backofen et al. in [BNS02] denoted as the MRSO problem. The\nproblem is known to be NP-complete for planar associated implied structure\ngraphs of vertex degree at most 3. In [BFHV05] a first polynomial dynamic\nprogramming algorithms for MRSO on implied structure graphs with maximum vertex\ndegree 3 of bounded cut-width is shown. We give a simple but more general\npolynomial dynamic programming solution for the MRSO problem for associated\nimplied structure graphs of bounded clique-width. Our result implies that MRSO\nis polynomial for graphs of bounded tree-width, co-graphs, $P_4$-sparse graphs,\nand distance hereditary graphs. Further we conclude that the problem of\ncomparing two solutions for MRSO is hard for the class of problems which can be\nsolved in polynomial time with a number of parallel queries to an oracle in NP.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2007 08:30:14 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Gurski", "Frank", ""]]}
{"id": "0704.3515", "submitter": "Jegor Uglov Mr", "authors": "J. Uglov, V. Schetinin, C. Maple", "title": "Comparing Robustness of Pairwise and Multiclass Neural-Network Systems\n  for Face Recognition", "comments": null, "journal-ref": null, "doi": "10.1155/2008/468693", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Noise, corruptions and variations in face images can seriously hurt the\nperformance of face recognition systems. To make such systems robust,\nmulticlass neuralnetwork classifiers capable of learning from noisy data have\nbeen suggested. However on large face data sets such systems cannot provide the\nrobustness at a high level. In this paper we explore a pairwise neural-network\nsystem as an alternative approach to improving the robustness of face\nrecognition. In our experiments this approach is shown to outperform the\nmulticlass neural-network system in terms of the predictive accuracy on the\nface images corrupted by noise.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2007 11:29:19 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Uglov", "J.", ""], ["Schetinin", "V.", ""], ["Maple", "C.", ""]]}
{"id": "0704.3573", "submitter": "Andrea Maiorano", "authors": "F. Belletti, M. Cotallo, A. Cruz, L. A. Fern\\'andez, A. Gordillo, A.\n  Maiorano, F. Mantovani, E. Marinari, V. Mart\\'in-Mayor, A. Mu\\~noz-Sudupe, D.\n  Navarro, S. P\\'erez-Gaviro, J. J. Ruiz-Lorenzo, S. F. Schifano, D. Sciretti,\n  A. Taranc\\'on, R. Tripiccione, J. L. Velasco", "title": "Simulating spin systems on IANUS, an FPGA-based computer", "comments": "19 pages, 8 figures; submitted to Computer Physics Communications", "journal-ref": "Computer Physics Communications, 178 (3), p.208-216, (2008)", "doi": "10.1016/j.cpc.2007.09.006", "report-no": null, "categories": "cond-mat.dis-nn cs.AR", "license": null, "abstract": "  We describe the hardwired implementation of algorithms for Monte Carlo\nsimulations of a large class of spin models. We have implemented these\nalgorithms as VHDL codes and we have mapped them onto a dedicated processor\nbased on a large FPGA device. The measured performance on one such processor is\ncomparable to O(100) carefully programmed high-end PCs: it turns out to be even\nbetter for some selected spin models. We describe here codes that we are\ncurrently executing on the IANUS massively parallel FPGA-based system.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2007 15:49:47 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Belletti", "F.", ""], ["Cotallo", "M.", ""], ["Cruz", "A.", ""], ["Fernández", "L. A.", ""], ["Gordillo", "A.", ""], ["Maiorano", "A.", ""], ["Mantovani", "F.", ""], ["Marinari", "E.", ""], ["Martín-Mayor", "V.", ""], ["Muñoz-Sudupe", "A.", ""], ["Navarro", "D.", ""], ["Pérez-Gaviro", "S.", ""], ["Ruiz-Lorenzo", "J. J.", ""], ["Schifano", "S. F.", ""], ["Sciretti", "D.", ""], ["Tarancón", "A.", ""], ["Tripiccione", "R.", ""], ["Velasco", "J. L.", ""]]}
{"id": "0704.3683", "submitter": "Mark Jerrum", "authors": "Martin Dyer, Leslie Ann Goldberg and Mark Jerrum", "title": "The Complexity of Weighted Boolean #CSP", "comments": "Minor revision", "journal-ref": "SIAM J. Comput. 38(5), 1970-1986", "doi": "10.1137/070690201", "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a dichotomy theorem for the complexity of computing the\npartition function of an instance of a weighted Boolean constraint satisfaction\nproblem. The problem is parameterised by a finite set F of non-negative\nfunctions that may be used to assign weights to the configurations (feasible\nsolutions) of a problem instance. Classical constraint satisfaction problems\ncorrespond to the special case of 0,1-valued functions. We show that the\npartition function, i.e. the sum of the weights of all configurations, can be\ncomputed in polynomial time if either (1) every function in F is of ``product\ntype'', or (2) every function in F is ``pure affine''. For every other fixed\nset F, computing the partition function is FP^{#P}-complete.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2007 13:19:32 GMT"}, {"version": "v2", "created": "Thu, 19 Jun 2008 08:00:54 GMT"}], "update_date": "2009-02-23", "authors_parsed": [["Dyer", "Martin", ""], ["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}
{"id": "0704.3835", "submitter": "K. Y. Michael Wong", "authors": "K. Y. Michael Wong and David Saad", "title": "Minimizing Unsatisfaction in Colourful Neighbourhoods", "comments": "28 pages, 12 figures, substantially revised with additional\n  explanation", "journal-ref": "J. Phys. A: Math. Theor. 41, 324023 (2008).", "doi": "10.1088/1751-8113/41/32/324023", "report-no": null, "categories": "cs.DS cond-mat.dis-nn cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colouring sparse graphs under various restrictions is a theoretical problem\nof significant practical relevance. Here we consider the problem of maximizing\nthe number of different colours available at the nodes and their\nneighbourhoods, given a predetermined number of colours. In the analytical\nframework of a tree approximation, carried out at both zero and finite\ntemperatures, solutions obtained by population dynamics give rise to estimates\nof the threshold connectivity for the incomplete to complete transition, which\nare consistent with those of existing algorithms. The nature of the transition\nas well as the validity of the tree approximation are investigated.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2007 10:03:00 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2007 04:18:58 GMT"}, {"version": "v3", "created": "Tue, 1 Jul 2008 17:43:32 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Wong", "K. Y. Michael", ""], ["Saad", "David", ""]]}
{"id": "0704.3886", "submitter": "W Saba", "authors": "Walid S. Saba", "title": "A Note on Ontology and Ordinary Language", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": null, "abstract": "  We argue for a compositional semantics grounded in a strongly typed ontology\nthat reflects our commonsense view of the world and the way we talk about it.\nAssuming such a structure we show that the semantics of various natural\nlanguage phenomena may become nearly trivial.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2007 17:55:39 GMT"}, {"version": "v2", "created": "Tue, 1 May 2007 13:43:32 GMT"}, {"version": "v3", "created": "Wed, 2 May 2007 18:13:22 GMT"}, {"version": "v4", "created": "Thu, 3 May 2007 08:34:47 GMT"}, {"version": "v5", "created": "Fri, 4 May 2007 17:49:03 GMT"}, {"version": "v6", "created": "Mon, 7 May 2007 16:04:50 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Saba", "Walid S.", ""]]}
{"id": "0704.3905", "submitter": "Marc Schoenauer", "authors": "Christian Gagn\\'e (INFORMATIQUE WGZ INC.), Mich\\`ele Sebag (INRIA\n  Futurs), Marc Schoenauer (INRIA Futurs), Marco Tomassini (ISI)", "title": "Ensemble Learning for Free with Evolutionary Algorithms ?", "comments": null, "journal-ref": "Dans GECCO (2007)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Evolutionary Learning proceeds by evolving a population of classifiers, from\nwhich it generally returns (with some notable exceptions) the single\nbest-of-run classifier as final result. In the meanwhile, Ensemble Learning,\none of the most efficient approaches in supervised Machine Learning for the\nlast decade, proceeds by building a population of diverse classifiers. Ensemble\nLearning with Evolutionary Computation thus receives increasing attention. The\nEvolutionary Ensemble Learning (EEL) approach presented in this paper features\ntwo contributions. First, a new fitness function, inspired by co-evolution and\nenforcing the classifier diversity, is presented. Further, a new selection\ncriterion based on the classification margin is proposed. This criterion is\nused to extract the classifier ensemble from the final population only\n(Off-line) or incrementally along evolution (On-line). Experiments on a set of\nbenchmark problems show that Off-line outperforms single-hypothesis\nevolutionary learning and state-of-art Boosting and generates smaller\nclassifier ensembles.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2007 09:29:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Gagné", "Christian", "", "INFORMATIQUE WGZ INC."], ["Sebag", "Michèle", "", "INRIA\n  Futurs"], ["Schoenauer", "Marc", "", "INRIA Futurs"], ["Tomassini", "Marco", "", "ISI"]]}
{"id": "0705.0025", "submitter": "Andreas Martin Lisewski", "authors": "Andreas Martin Lisewski", "title": "Can the Internet cope with stress?", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": null, "abstract": "  When will the Internet become aware of itself? In this note the problem is\napproached by asking an alternative question: Can the Internet cope with\nstress? By extrapolating the psychological difference between coping and\ndefense mechanisms a distributed software experiment is outlined which could\nreject the hypothesis that the Internet is not a conscious entity.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2007 15:44:17 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Lisewski", "Andreas Martin", ""]]}
{"id": "0705.0086", "submitter": "Maurice Margenstern", "authors": "Maurice Margenstern", "title": "About the domino problem in the hyperbolic plane, a new solution:\n  complement", "comments": "20 pages", "journal-ref": "M. Margenstern, \"The domino problem of the hyperbolic plane is\n  undecidable\", Theoretical Computer Science, vol. 407, (2008), 29-84", "doi": "10.1016/j.tcs.2008.04.038", "report-no": null, "categories": "cs.CG cs.DM", "license": null, "abstract": "  In this paper, we complete the construction of paper arXiv:cs.CG/0701096v2.\nTogether with the proof contained in arXiv:cs.CG/0701096v2, this paper\ndefinitely proves that the general problem of tiling the hyperbolic plane with\n{\\it \\`a la} Wang tiles is undecidable.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2007 09:29:59 GMT"}, {"version": "v2", "created": "Tue, 1 May 2007 20:09:36 GMT"}, {"version": "v3", "created": "Wed, 9 May 2007 06:25:50 GMT"}, {"version": "v4", "created": "Fri, 18 May 2007 15:14:52 GMT"}], "update_date": "2009-07-06", "authors_parsed": [["Margenstern", "Maurice", ""]]}
{"id": "0705.0150", "submitter": "Myung-Sin Song", "authors": "Palle E. T. Jorgensen, Myung-Sin Song", "title": "Comparison of Discrete and Continuous Wavelet Transforms", "comments": "22 pages, Springer Encyclopedia of Complexity and Systems Science,\n  the full version with figures is available at\n  http://www.siue.edu/~msong/Research/ency.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  In this paper we outline several points of view on the interplay between\ndiscrete and continuous wavelet transforms; stressing both pure and applied\naspects of both. We outline some new links between the two transform\ntechnologies based on the theory of representations of generators and\nrelations. By this we mean a finite system of generators which are represented\nby operators in Hilbert space. We further outline how these representations\nyield sub-band filter banks for signal and image processing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2007 18:24:52 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2007 17:53:30 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Jorgensen", "Palle E. T.", ""], ["Song", "Myung-Sin", ""]]}
{"id": "0705.0197", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala, Unathi Mahola and Snehashish Chakraverty", "title": "Fault Classification in Cylinders Using Multilayer Perceptrons, Support\n  Vector Machines and Guassian Mixture Models", "comments": "10 pages, 2 figures, 4 tables", "journal-ref": "Computer Assisted Mechanics and Engineering Sciences, Vol. 14, No.\n  2, 2007.", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Gaussian mixture models (GMM) and support vector machines (SVM) are\nintroduced to classify faults in a population of cylindrical shells. The\nproposed procedures are tested on a population of 20 cylindrical shells and\ntheir performance is compared to the procedure, which uses multi-layer\nperceptrons (MLP). The modal properties extracted from vibration data are used\nto train the GMM, SVM and MLP. It is observed that the GMM produces 98%, SVM\nproduces 94% classification accuracy while the MLP produces 88% classification\nrates.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2007 03:13:28 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""], ["Mahola", "Unathi", ""], ["Chakraverty", "Snehashish", ""]]}
{"id": "0705.0199", "submitter": "Erik Berglund", "authors": "Erik Berglund, Joaquin Sitte", "title": "The Parameter-Less Self-Organizing Map algorithm", "comments": "29 pages, 27 figures. Based on publication in IEEE Trans. on Neural\n  Networks", "journal-ref": "IEEE Transactions on Neural Networks, 2006 v.17, n.2, pp.305-316", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": null, "abstract": "  The Parameter-Less Self-Organizing Map (PLSOM) is a new neural network\nalgorithm based on the Self-Organizing Map (SOM). It eliminates the need for a\nlearning rate and annealing schemes for learning rate and neighbourhood size.\nWe discuss the relative performance of the PLSOM and the SOM and demonstrate\nsome tasks in which the SOM fails but the PLSOM performs satisfactory. Finally\nwe discuss some example applications of the PLSOM and present a proof of\nordering under certain limited conditions.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2007 04:04:51 GMT"}, {"version": "v2", "created": "Tue, 8 May 2007 01:06:10 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Berglund", "Erik", ""], ["Sitte", "Joaquin", ""]]}
{"id": "0705.0350", "submitter": "Ruslan Sharipov", "authors": "Ruslan Sharipov", "title": "Algorithms for laying points optimally on a plane and a circle", "comments": "AmSTeX, 6 pages, amsppt style", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.OC", "license": null, "abstract": "  Two averaging algorithms are considered which are intended for choosing an\noptimal plane and an optimal circle approximating a group of points in\nthree-dimensional Euclidean space.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2007 19:41:44 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Sharipov", "Ruslan", ""]]}
{"id": "0705.0413", "submitter": "David Eppstein", "authors": "David Eppstein, Marc van Kreveld, Elena Mumford, and Bettina Speckmann", "title": "Edges and Switches, Tunnels and Bridges", "comments": "15 pages, 11 figures. To appear in 10th Worksh. Algorithms and Data\n  Structures, Halifax, Nova Scotia, 2007. This version includes three pages of\n  appendices that will not be included in the conference proceedings version", "journal-ref": "Computational Geometry Theory & Applications 42(8): 790-802, 2009", "doi": "10.1016/j.comgeo.2008.05.005", "report-no": null, "categories": "cs.DS cs.CG", "license": null, "abstract": "  Edge casing is a well-known method to improve the readability of drawings of\nnon-planar graphs. A cased drawing orders the edges of each edge crossing and\ninterrupts the lower edge in an appropriate neighborhood of the crossing.\nCertain orders will lead to a more readable drawing than others. We formulate\nseveral optimization criteria that try to capture the concept of a \"good\" cased\ndrawing. Further, we address the algorithmic question of how to turn a given\ndrawing into an optimal cased drawing. For many of the resulting optimization\nproblems, we either find polynomial time algorithms or NP-hardness results.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2007 06:33:04 GMT"}], "update_date": "2009-07-09", "authors_parsed": [["Eppstein", "David", ""], ["van Kreveld", "Marc", ""], ["Mumford", "Elena", ""], ["Speckmann", "Bettina", ""]]}
{"id": "0705.0561", "submitter": "Jingchao Chen", "authors": "Jing-Chao Chen", "title": "Iterative Rounding for the Closest String Problem", "comments": "This paper has been published in abstract Booklet of CiE09", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The closest string problem is an NP-hard problem, whose task is to find a\nstring that minimizes maximum Hamming distance to a given set of strings. This\ncan be reduced to an integer program (IP). However, to date, there exists no\nknown polynomial-time algorithm for IP. In 2004, Meneses et al. introduced a\nbranch-and-bound (B & B) method for solving the IP problem. Their algorithm is\nnot always efficient and has the exponential time complexity. In the paper, we\nattempt to solve efficiently the IP problem by a greedy iterative rounding\ntechnique. The proposed algorithm is polynomial time and much faster than the\nexisting B & B IP for the CSP. If the number of strings is limited to 3, the\nalgorithm is provably at most 1 away from the optimum. The empirical results\nshow that in many cases we can find an exact solution. Even though we fail to\nfind an exact solution, the solution found is very close to exact solution.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2007 03:01:42 GMT"}, {"version": "v2", "created": "Wed, 11 May 2011 00:18:55 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Chen", "Jing-Chao", ""]]}
{"id": "0705.0588", "submitter": "Edgar Graaf de", "authors": "Edgar H. de Graaf, Joost N. Kok, Walter A. Kosters", "title": "Clustering Co-occurrence of Maximal Frequent Patterns in Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": null, "abstract": "  One way of getting a better view of data is using frequent patterns. In this\npaper frequent patterns are subsets that occur a minimal number of times in a\nstream of itemsets. However, the discovery of frequent patterns in streams has\nalways been problematic. Because streams are potentially endless it is in\nprinciple impossible to say if a pattern is often occurring or not. Furthermore\nthe number of patterns can be huge and a good overview of the structure of the\nstream is lost quickly. The proposed approach will use clustering to facilitate\nthe analysis of the structure of the stream.\n  A clustering on the co-occurrence of patterns will give the user an improved\nview on the structure of the stream. Some patterns might occur so much together\nthat they should form a combined pattern. In this way the patterns in the\nclustering will be the largest frequent patterns: maximal frequent patterns.\n  Our approach to decide if patterns occur often together will be based on a\nmethod of clustering when only the distance between pairs is known. The number\nof maximal frequent patterns is much smaller and combined with clustering\nmethods these patterns provide a good view on the structure of the stream.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2007 10:36:53 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["de Graaf", "Edgar H.", ""], ["Kok", "Joost N.", ""], ["Kosters", "Walter A.", ""]]}
{"id": "0705.0593", "submitter": "Edgar Graaf de", "authors": "Edgar H. de Graaf, Joost N. Kok, Walter A. Kosters", "title": "Clustering with Lattices in the Analysis of Graph Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": null, "abstract": "  Mining frequent subgraphs is an area of research where we have a given set of\ngraphs (each graph can be seen as a transaction), and we search for (connected)\nsubgraphs contained in many of these graphs. In this work we will discuss\ntechniques used in our framework Lattice2SAR for mining and analysing frequent\nsubgraph data and their corresponding lattice information. Lattice information\nis provided by the graph mining algorithm gSpan; it contains all\nsupergraph-subgraph relations of the frequent subgraph patterns -- and their\nsupports.\n  Lattice2SAR is in particular used in the analysis of frequent graph patterns\nwhere the graphs are molecules and the frequent subgraphs are fragments. In the\nanalysis of fragments one is interested in the molecules where patterns occur.\nThis data can be very extensive and in this paper we focus on a technique of\nmaking it better available by using the lattice information in our clustering.\nNow we can reduce the number of times the highly compressed occurrence data\nneeds to be accessed by the user. The user does not have to browse all the\noccurrence data in search of patterns occurring in the same molecules. Instead\none can directly see which frequent subgraphs are of interest.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2007 10:52:28 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["de Graaf", "Edgar H.", ""], ["Kok", "Joost N.", ""], ["Kosters", "Walter A.", ""]]}
{"id": "0705.0635", "submitter": "Jean Cardinal", "authors": "J. Cardinal, S. Collette, F. Hurtado, S. Langerman and B. Palop", "title": "Moving Walkways, Escalators, and Elevators", "comments": "16 pages. Presented at XII Encuentros de Geometria Computacional,\n  Valladolid, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  We study a simple geometric model of transportation facility that consists of\ntwo points between which the travel speed is high. This elementary definition\ncan model shuttle services, tunnels, bridges, teleportation devices, escalators\nor moving walkways. The travel time between a pair of points is defined as a\ntime distance, in such a way that a customer uses the transportation facility\nonly if it is helpful.\n  We give algorithms for finding the optimal location of such a transportation\nfacility, where optimality is defined with respect to the maximum travel time\nbetween two points in a given set.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2007 14:52:06 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2007 11:30:09 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Cardinal", "J.", ""], ["Collette", "S.", ""], ["Hurtado", "F.", ""], ["Langerman", "S.", ""], ["Palop", "B.", ""]]}
{"id": "0705.0693", "submitter": "Tshilidzi Marwala", "authors": "Evan Hurwitz and Tshilidzi Marwala", "title": "Learning to Bluff", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  The act of bluffing confounds game designers to this day. The very nature of\nbluffing is even open for debate, adding further complication to the process of\ncreating intelligent virtual players that can bluff, and hence play,\nrealistically. Through the use of intelligent, learning agents, and carefully\ndesigned agent outlooks, an agent can in fact learn to predict its opponents\nreactions based not only on its own cards, but on the actions of those around\nit. With this wider scope of understanding, an agent can in learn to bluff its\nopponents, with the action representing not an illogical action, as bluffing is\noften viewed, but rather as an act of maximising returns through an effective\nstatistical optimisation. By using a tee dee lambda learning algorithm to\ncontinuously adapt neural network agent intelligence, agents have been shown to\nbe able to learn to bluff without outside prompting, and even to learn to call\neach others bluffs in free, competitive play.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2007 19:15:24 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Hurwitz", "Evan", ""], ["Marwala", "Tshilidzi", ""]]}
{"id": "0705.0734", "submitter": "Sanjiang Li", "authors": "Sanjiang Li and Mingsheng Ying", "title": "Soft constraint abstraction based on semiring homomorphism", "comments": "18 pages, 1 figure", "journal-ref": "Theoretical Computer Science 403(2-3) 192-201, 2008", "doi": "10.1016/j.tcs.2008.03.029", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  The semiring-based constraint satisfaction problems (semiring CSPs), proposed\nby Bistarelli, Montanari and Rossi \\cite{BMR97}, is a very general framework of\nsoft constraints. In this paper we propose an abstraction scheme for soft\nconstraints that uses semiring homomorphism. To find optimal solutions of the\nconcrete problem, the idea is, first working in the abstract problem and\nfinding its optimal solutions, then using them to solve the concrete problem.\n  In particular, we show that a mapping preserves optimal solutions if and only\nif it is an order-reflecting semiring homomorphism. Moreover, for a semiring\nhomomorphism $\\alpha$ and a problem $P$ over $S$, if $t$ is optimal in\n$\\alpha(P)$, then there is an optimal solution $\\bar{t}$ of $P$ such that\n$\\bar{t}$ has the same value as $t$ in $\\alpha(P)$.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2007 08:47:31 GMT"}], "update_date": "2010-07-01", "authors_parsed": [["Li", "Sanjiang", ""], ["Ying", "Mingsheng", ""]]}
{"id": "0705.0760", "submitter": "Sujay Sanghavi", "authors": "Sujay Sanghavi", "title": "Equivalence of LP Relaxation and Max-Product for Weighted Matching in\n  General Graphs", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG cs.NI math.IT", "license": null, "abstract": "  Max-product belief propagation is a local, iterative algorithm to find the\nmode/MAP estimate of a probability distribution. While it has been successfully\nemployed in a wide variety of applications, there are relatively few\ntheoretical guarantees of convergence and correctness for general loopy graphs\nthat may have many short cycles. Of these, even fewer provide exact ``necessary\nand sufficient'' characterizations.\n  In this paper we investigate the problem of using max-product to find the\nmaximum weight matching in an arbitrary graph with edge weights. This is done\nby first constructing a probability distribution whose mode corresponds to the\noptimal matching, and then running max-product. Weighted matching can also be\nposed as an integer program, for which there is an LP relaxation. This\nrelaxation is not always tight. In this paper we show that \\begin{enumerate}\n\\item If the LP relaxation is tight, then max-product always converges, and\nthat too to the correct answer. \\item If the LP relaxation is loose, then\nmax-product does not converge. \\end{enumerate} This provides an exact,\ndata-dependent characterization of max-product performance, and a precise\nconnection to LP relaxation, which is a well-studied optimization technique.\nAlso, since LP relaxation is known to be tight for bipartite graphs, our\nresults generalize other recent results on using max-product to find weighted\nmatchings in bipartite graphs.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2007 18:57:47 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Sanghavi", "Sujay", ""]]}
{"id": "0705.0761", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala and Bodie Crossingham", "title": "Bayesian Approach to Neuro-Rough Models", "comments": "24 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper proposes a neuro-rough model based on multi-layered perceptron and\nrough set. The neuro-rough model is then tested on modelling the risk of HIV\nfrom demographic data. The model is formulated using Bayesian framework and\ntrained using Monte Carlo method and Metropolis criterion. When the model was\ntested to estimate the risk of HIV infection given the demographic data it was\nfound to give the accuracy of 62%. The proposed model is able to combine the\naccuracy of the Bayesian MLP model and the transparency of Bayesian rough set\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2007 22:55:58 GMT"}, {"version": "v2", "created": "Wed, 9 May 2007 04:13:04 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2007 09:24:46 GMT"}], "update_date": "2007-08-28", "authors_parsed": [["Marwala", "Tshilidzi", ""], ["Crossingham", "Bodie", ""]]}
{"id": "0705.0895", "submitter": "Chazottes", "authors": "C. Bonanno, J.-R. Chazottes, P. Collet", "title": "Epsilon-Distortion Complexity for Cantor Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.CC math.MG", "license": null, "abstract": "  We define the epsilon-distortion complexity of a set as the shortest program,\nrunning on a universal Turing machine, which produces this set at the precision\nepsilon in the sense of Hausdorff distance. Then, we estimate the\nepsilon-distortion complexity of various central Cantor sets on the line\ngenerated by iterated function systems (IFS's). In particular, the\nepsilon-distortion complexity of a C^k Cantor set depends, in general, on k and\non its box counting dimension, contrarily to Cantor sets generated by\npolynomial IFS or random affine Cantor sets.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2007 12:16:57 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Bonanno", "C.", ""], ["Chazottes", "J. -R.", ""], ["Collet", "P.", ""]]}
{"id": "0705.0915", "submitter": "Joerg Rothe", "authors": "Dorothea Baumeister and Joerg Rothe", "title": "Satisfiability Parsimoniously Reduces to the Tantrix(TM) Rotation Puzzle\n  Problem", "comments": "19 pages, 16 figures, appears in the Proceedings of \"Machines,\n  Computations and Universality\" (MCU 2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Holzer and Holzer (Discrete Applied Mathematics 144(3):345--358, 2004) proved\nthat the Tantrix(TM) rotation puzzle problem is NP-complete. They also showed\nthat for infinite rotation puzzles, this problem becomes undecidable. We study\nthe counting version and the unique version of this problem. We prove that the\nsatisfiability problem parsimoniously reduces to the Tantrix(TM) rotation\npuzzle problem. In particular, this reduction preserves the uniqueness of the\nsolution, which implies that the unique Tantrix(TM) rotation puzzle problem is\nas hard as the unique satisfiability problem, and so is DP-complete under\npolynomial-time randomized reductions, where DP is the second level of the\nboolean hierarchy over NP.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2007 14:23:20 GMT"}, {"version": "v2", "created": "Mon, 9 Jun 2008 11:28:24 GMT"}], "update_date": "2008-06-09", "authors_parsed": [["Baumeister", "Dorothea", ""], ["Rothe", "Joerg", ""]]}
{"id": "0705.0965", "submitter": "Guillaume Hanrot", "authors": "Guillaume Hanrot (INRIA Lorraine - LORIA), Damien Stehl\\'e (INRIA\n  Rh\\^one-Alpes)", "title": "Improved Analysis of Kannan's Shortest Lattice Vector Algorithm", "comments": null, "journal-ref": "Dans Advances in Cryptology - Crypto'07 4622 (2007) 170-186", "doi": "10.1007/978-3-540-74143-5_10", "report-no": null, "categories": "cs.CR cs.CC", "license": null, "abstract": "  The security of lattice-based cryptosystems such as NTRU, GGH and Ajtai-Dwork\nessentially relies upon the intractability of computing a shortest non-zero\nlattice vector and a closest lattice vector to a given target vector in high\ndimensions. The best algorithms for these tasks are due to Kannan, and, though\nremarkably simple, their complexity estimates have not been improved since more\nthan twenty years. Kannan's algorithm for solving the shortest vector problem\nis in particular crucial in Schnorr's celebrated block reduction algorithm, on\nwhich are based the best known attacks against the lattice-based encryption\nschemes mentioned above. Understanding precisely Kannan's algorithm is of prime\nimportance for providing meaningful key-sizes. In this paper we improve the\ncomplexity analyses of Kannan's algorithms and discuss the possibility of\nimproving the underlying enumeration strategy.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2007 18:44:05 GMT"}, {"version": "v2", "created": "Wed, 9 May 2007 15:32:57 GMT"}], "update_date": "2009-04-16", "authors_parsed": [["Hanrot", "Guillaume", "", "INRIA Lorraine - LORIA"], ["Stehlé", "Damien", "", "INRIA\n  Rhône-Alpes"]]}
{"id": "0705.0969", "submitter": "Tshilidzi Marwala", "authors": "Ishmael S. Msiza, Fulufhelo V. Nelwamondo and Tshilidzi Marwala", "title": "Artificial Neural Networks and Support Vector Machines for Water Demand\n  Time Series Forecasting", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Water plays a pivotal role in many physical processes, and most importantly\nin sustaining human life, animal life and plant life. Water supply entities\ntherefore have the responsibility to supply clean and safe water at the rate\nrequired by the consumer. It is therefore necessary to implement mechanisms and\nsystems that can be employed to predict both short-term and long-term water\ndemands. The increasingly growing field of computational intelligence\ntechniques has been proposed as an efficient tool in the modelling of dynamic\nphenomena. The primary objective of this paper is to compare the efficiency of\ntwo computational intelligence techniques in water demand forecasting. The\ntechniques under comparison are the Artificial Neural Networks (ANNs) and the\nSupport Vector Machines (SVMs). In this study it was observed that the ANNs\nperform better than the SVMs. This performance is measured against the\ngeneralisation ability of the two.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2007 19:00:28 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Msiza", "Ishmael S.", ""], ["Nelwamondo", "Fulufhelo V.", ""], ["Marwala", "Tshilidzi", ""]]}
{"id": "0705.1031", "submitter": "Tshilidzi Marwala", "authors": "F.V. Nelwamondo and T. Marwala", "title": "Fuzzy Artmap and Neural Network Approach to Online Processing of Inputs\n  with Missing Values", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  An ensemble based approach for dealing with missing data, without predicting\nor imputing the missing values is proposed. This technique is suitable for\nonline operations of neural networks and as a result, is used for online\ncondition monitoring. The proposed technique is tested in both classification\nand regression problems. An ensemble of Fuzzy-ARTMAPs is used for\nclassification whereas an ensemble of multi-layer perceptrons is used for the\nregression problem. Results obtained using this ensemble-based technique are\ncompared to those obtained using a combination of auto-associative neural\nnetworks and genetic algorithms and findings show that this method can perform\nup to 9% better in regression problems. Another advantage of the proposed\ntechnique is that it eliminates the need for finding the best estimate of the\ndata, and hence, saves time.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2007 05:12:01 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Nelwamondo", "F. V.", ""], ["Marwala", "T.", ""]]}
{"id": "0705.1033", "submitter": "Kebin Wang", "authors": "Michael A. Bender, Bradley C. Kuszmaul, Shang-Hua Teng, Kebin Wang", "title": "Optimal Cache-Oblivious Mesh Layouts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mesh is a graph that divides physical space into regularly-shaped regions.\nMeshes computations form the basis of many applications, e.g. finite-element\nmethods, image rendering, and collision detection. In one important mesh\nprimitive, called a mesh update, each mesh vertex stores a value and repeatedly\nupdates this value based on the values stored in all neighboring vertices. The\nperformance of a mesh update depends on the layout of the mesh in memory.\n  This paper shows how to find a memory layout that guarantees that the mesh\nupdate has asymptotically optimal memory performance for any set of memory\nparameters. Such a memory layout is called cache-oblivious. Formally, for a\n$d$-dimensional mesh $G$, block size $B$, and cache size $M$ (where\n$M=\\Omega(B^d)$), the mesh update of $G$ uses $O(1+|G|/B)$ memory transfers.\nThe paper also shows how the mesh-update performance degrades for smaller\ncaches, where $M=o(B^d)$.\n  The paper then gives two algorithms for finding cache-oblivious mesh layouts.\nThe first layout algorithm runs in time $O(|G|\\log^2|G|)$ both in expectation\nand with high probability on a RAM. It uses $O(1+|G|\\log^2(|G|/M)/B)$ memory\ntransfers in expectation and $O(1+(|G|/B)(\\log^2(|G|/M) + \\log|G|))$ memory\ntransfers with high probability in the cache-oblivious and disk-access machine\n(DAM) models. The layout is obtained by finding a fully balanced decomposition\ntree of $G$ and then performing an in-order traversal of the leaves of the\ntree. The second algorithm runs faster by almost a $\\log|G|/\\log\\log|G|$ factor\nin all three memory models, both in expectation and with high probability. The\nlayout obtained by finding a relax-balanced decomposition tree of $G$ and then\nperforming an in-order traversal of the leaves of the tree.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2007 05:59:55 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2009 18:45:25 GMT"}], "update_date": "2009-10-05", "authors_parsed": [["Bender", "Michael A.", ""], ["Kuszmaul", "Bradley C.", ""], ["Teng", "Shang-Hua", ""], ["Wang", "Kebin", ""]]}
{"id": "0705.1110", "submitter": "Edgar Graaf de", "authors": "Edgar de Graaf Joost Kok Walter Kosters", "title": "Mining Patterns with a Balanced Interval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": null, "abstract": "  In many applications it will be useful to know those patterns that occur with\na balanced interval, e.g., a certain combination of phone numbers are called\nalmost every Friday or a group of products are sold a lot on Tuesday and\nThursday.\n  In previous work we proposed a new measure of support (the number of\noccurrences of a pattern in a dataset), where we count the number of times a\npattern occurs (nearly) in the middle between two other occurrences. If the\nnumber of non-occurrences between two occurrences of a pattern stays almost the\nsame then we call the pattern balanced.\n  It was noticed that some very frequent patterns obviously also occur with a\nbalanced interval, meaning in every transaction. However more interesting\npatterns might occur, e.g., every three transactions. Here we discuss a\nsolution using standard deviation and average. Furthermore we propose a simpler\napproach for pruning patterns with a balanced interval, making estimating the\npruning threshold more intuitive.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2007 15:22:38 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Kosters", "Edgar de Graaf Joost Kok Walter", ""]]}
{"id": "0705.1209", "submitter": "Tshilidzi Marwala", "authors": "E. Habtemariam, T. Marwala and M. Lagazio", "title": "Artificial Intelligence for Conflict Management", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Militarised conflict is one of the risks that have a significant impact on\nsociety. Militarised Interstate Dispute (MID) is defined as an outcome of\ninterstate interactions, which result on either peace or conflict. Effective\nprediction of the possibility of conflict between states is an important\ndecision support tool for policy makers. In a previous research, neural\nnetworks (NNs) have been implemented to predict the MID. Support Vector\nMachines (SVMs) have proven to be very good prediction techniques and are\nintroduced for the prediction of MIDs in this study and compared to neural\nnetworks. The results show that SVMs predict MID better than NNs while NNs give\nmore consistent and easy to interpret sensitivity analysis than SVMs.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2007 05:53:30 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Habtemariam", "E.", ""], ["Marwala", "T.", ""], ["Lagazio", "M.", ""]]}
{"id": "0705.1214", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Control of Complex Systems Using Bayesian Networks and Genetic Algorithm", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  A method based on Bayesian neural networks and genetic algorithm is proposed\nto control the fermentation process. The relationship between input and output\nvariables is modelled using Bayesian neural network that is trained using\nhybrid Monte Carlo method. A feedback loop based on genetic algorithm is used\nto change input variables so that the output variables are as close to the\ndesired target as possible without the loss of confidence level on the\nprediction that the neural network gives. The proposed procedure is found to\nreduce the distance between the desired target and measured outputs\nsignificantly.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2007 07:08:58 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}
{"id": "0705.1244", "submitter": "Marc Schoenauer", "authors": "Nicolas Godzik (INRIA Futurs, INRIA Rocquencourt), Marc Schoenauer\n  (INRIA Futurs, INRIA Rocquencourt), Mich\\`ele Sebag (INRIA Futurs, LRI)", "title": "Evolving Symbolic Controllers", "comments": null, "journal-ref": "Dans 4th European Workshop on Evolutionary Robotics, 2611 (2003)\n  638-650", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  The idea of symbolic controllers tries to bridge the gap between the top-down\nmanual design of the controller architecture, as advocated in Brooks'\nsubsumption architecture, and the bottom-up designer-free approach that is now\nstandard within the Evolutionary Robotics community. The designer provides a\nset of elementary behavior, and evolution is given the goal of assembling them\nto solve complex tasks. Two experiments are presented, demonstrating the\nefficiency and showing the recursiveness of this approach. In particular, the\nsensitivity with respect to the proposed elementary behaviors, and the\nrobustness w.r.t. generalization of the resulting controllers are studied in\ndetail.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2007 09:53:31 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Godzik", "Nicolas", "", "INRIA Futurs, INRIA Rocquencourt"], ["Schoenauer", "Marc", "", "INRIA Futurs, INRIA Rocquencourt"], ["Sebag", "Michèle", "", "INRIA Futurs, LRI"]]}
{"id": "0705.1309", "submitter": "Marc Schoenauer", "authors": "Alexandre Devert (INRIA Futurs), Nicolas Bred\\`eche (INRIA Futurs),\n  Marc Schoenauer (INRIA Futurs)", "title": "Robust Multi-Cellular Developmental Design", "comments": null, "journal-ref": "Dans Genetic and Evolutionary Computation COnference (2007)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper introduces a continuous model for Multi-cellular Developmental\nDesign. The cells are fixed on a 2D grid and exchange \"chemicals\" with their\nneighbors during the growth process. The quantity of chemicals that a cell\nproduces, as well as the differentiation value of the cell in the phenotype,\nare controlled by a Neural Network (the genotype) that takes as inputs the\nchemicals produced by the neighboring cells at the previous time step. In the\nproposed model, the number of iterations of the growth process is not\npre-determined, but emerges during evolution: only organisms for which the\ngrowth process stabilizes give a phenotype (the stable state), others are\ndeclared nonviable. The optimization of the controller is done using the NEAT\nalgorithm, that optimizes both the topology and the weights of the Neural\nNetworks. Though each cell only receives local information from its neighbors,\nthe experimental results of the proposed approach on the 'flags' problems (the\nphenotype must match a given 2D pattern) are almost as good as those of a\ndirect regression approach using the same model with global information.\nMoreover, the resulting multi-cellular organisms exhibit almost perfect\nself-healing characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2007 15:33:34 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Devert", "Alexandre", "", "INRIA Futurs"], ["Bredèche", "Nicolas", "", "INRIA Futurs"], ["Schoenauer", "Marc", "", "INRIA Futurs"]]}
{"id": "0705.1364", "submitter": "Mustaq Ahmed", "authors": "Mustaq Ahmed and Anna Lubiw", "title": "An Approximation Algorithm for Shortest Descending Paths", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "CS-2007-14", "categories": "cs.CG cs.DS", "license": null, "abstract": "  A path from s to t on a polyhedral terrain is descending if the height of a\npoint p never increases while we move p along the path from s to t. No\nefficient algorithm is known to find a shortest descending path (SDP) from s to\nt in a polyhedral terrain. We give a simple approximation algorithm that solves\nthe SDP problem on general terrains. Our algorithm discretizes the terrain with\nO(n^2 X / e) Steiner points so that after an O(n^2 X / e * log(n X /e))-time\npreprocessing phase for a given vertex s, we can determine a (1+e)-approximate\nSDP from s to any point v in O(n) time if v is either a vertex of the terrain\nor a Steiner point, and in O(n X /e) time otherwise. Here n is the size of the\nterrain, and X is a parameter of the geometry of the terrain.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2007 22:02:28 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Ahmed", "Mustaq", ""], ["Lubiw", "Anna", ""]]}
{"id": "0705.1390", "submitter": "Tshilidzi Marwala", "authors": "M.A. Herzog, T. Marwala and P.S. Heyns", "title": "Machine and Component Residual Life Estimation through the Application\n  of Neural Networks", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  This paper concerns the use of neural networks for predicting the residual\nlife of machines and components. In addition, the advantage of using\ncondition-monitoring data to enhance the predictive capability of these neural\nnetworks was also investigated. A number of neural network variations were\ntrained and tested with the data of two different reliability-related datasets.\nThe first dataset represents the renewal case where the failed unit is repaired\nand restored to a good-as-new condition. Data was collected in the laboratory\nby subjecting a series of similar test pieces to fatigue loading with a\nhydraulic actuator. The average prediction error of the various neural networks\nbeing compared varied from 431 to 841 seconds on this dataset, where test\npieces had a characteristic life of 8,971 seconds. The second dataset was\ncollected from a group of pumps used to circulate a water and magnetite\nsolution within a plant. The data therefore originated from a repaired system\naffected by reliability degradation. When optimized, the multi-layer perceptron\nneural networks trained with the Levenberg-Marquardt algorithm and the general\nregression neural network produced a sum-of-squares error within 11.1% of each\nother. The potential for using neural networks for residual life prediction and\nthe advantage of incorporating condition-based data into the model were proven\nfor both examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2007 05:52:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Herzog", "M. A.", ""], ["Marwala", "T.", ""], ["Heyns", "P. S.", ""]]}
{"id": "0705.1442", "submitter": "Karlen Gharibyan", "authors": "Karlen Garnik Gharibyan", "title": "Does P=NP?", "comments": null, "journal-ref": "Karlen Gharibyan, Does P=NP?, in Proceedings of the first\n  international Arm Tech Congress 2007", "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  This paper has been withdrawn Abstract: This paper has been withdrawn by the\nauthor due to the publication.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2007 11:41:26 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2007 03:41:18 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Gharibyan", "Karlen Garnik", ""]]}
{"id": "0705.1541", "submitter": "Joseph O'Rourke", "authors": "Mirela Damian, Robin Flatland, Joseph O'Rourke", "title": "Unfolding Manhattan Towers", "comments": "Full version of abstract that appeared in: Proc. 17th Canad. Conf.\n  Comput. Geom., 2005, pp. 204--207", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": null, "abstract": "  We provide an algorithm for unfolding the surface of any orthogonal\npolyhedron that falls into a particular shape class we call Manhattan Towers,\nto a nonoverlapping planar orthogonal polygon. The algorithm cuts along edges\nof a 4x5x1 refinement of the vertex grid.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2007 19:50:48 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Damian", "Mirela", ""], ["Flatland", "Robin", ""], ["O'Rourke", "Joseph", ""]]}
{"id": "0705.1617", "submitter": "Daegene Song", "authors": "Daegene Song", "title": "Non-Computability of Consciousness", "comments": "10 pages, 2 figures, 1 table", "journal-ref": "NeuroQuantology 5, 382 (2007).", "doi": null, "report-no": null, "categories": "quant-ph astro-ph cs.AI", "license": null, "abstract": "  With the great success in simulating many intelligent behaviors using\ncomputing devices, there has been an ongoing debate whether all conscious\nactivities are computational processes. In this paper, the answer to this\nquestion is shown to be no. A certain phenomenon of consciousness is\ndemonstrated to be fully represented as a computational process using a quantum\ncomputer. Based on the computability criterion discussed with Turing machines,\nthe model constructed is shown to necessarily involve a non-computable element.\nThe concept that this is solely a quantum effect and does not work for a\nclassical case is also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 10:16:48 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Song", "Daegene", ""]]}
{"id": "0705.1672", "submitter": "Tshilidzi Marwala", "authors": "L. Mdlazi, T. Marwala, C.J. Stander, C. Scheffer and P.S. Heyns", "title": "Principal Component Analysis and Automatic Relevance Determination in\n  Damage Identification", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  This paper compares two neural network input selection schemes, the Principal\nComponent Analysis (PCA) and the Automatic Relevance Determination (ARD) based\non Mac-Kay's evidence framework. The PCA takes all the input data and projects\nit onto a lower dimension space, thereby reduc-ing the dimension of the input\nspace. This input reduction method often results with parameters that have\nsignificant influence on the dynamics of the data being diluted by those that\ndo not influence the dynamics of the data. The ARD selects the most relevant\ninput parameters and discards those that do not contribute significantly to the\ndynamics of the data being modelled. The ARD sometimes results with important\ninput parameters being discarded thereby compromising the dynamics of the data.\nThe PCA and ARD methods are implemented together with a Multi-Layer-Perceptron\n(MLP) network for fault identification in structures and the performance of the\ntwo methods is as-sessed. It is observed that ARD and PCA give similar\naccu-racy levels when used as input-selection schemes. There-fore, the choice\nof input-selection scheme is dependent on the nature of the data being\nprocessed.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 15:35:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Mdlazi", "L.", ""], ["Marwala", "T.", ""], ["Stander", "C. J.", ""], ["Scheffer", "C.", ""], ["Heyns", "P. S.", ""]]}
{"id": "0705.1673", "submitter": "Tshilidzi Marwala", "authors": "L. Mdlazi, C.J. Stander, P.S. Heyns and T. Marwala", "title": "Using artificial intelligence for data reduction in mechanical\n  engineering", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI cs.NE", "license": null, "abstract": "  In this paper artificial neural networks and support vector machines are used\nto reduce the amount of vibration data that is required to estimate the Time\nDomain Average of a gear vibration signal. Two models for estimating the time\ndomain average of a gear vibration signal are proposed. The models are tested\non data from an accelerated gear life test rig. Experimental results indicate\nthat the required data for calculating the Time Domain Average of a gear\nvibration signal can be reduced by up to 75% when the proposed models are\nimplemented.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 15:49:40 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Mdlazi", "L.", ""], ["Stander", "C. J.", ""], ["Heyns", "P. S.", ""], ["Marwala", "T.", ""]]}
{"id": "0705.1673", "submitter": "Tshilidzi Marwala", "authors": "L. Mdlazi, C.J. Stander, P.S. Heyns and T. Marwala", "title": "Using artificial intelligence for data reduction in mechanical\n  engineering", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI cs.NE", "license": null, "abstract": "  In this paper artificial neural networks and support vector machines are used\nto reduce the amount of vibration data that is required to estimate the Time\nDomain Average of a gear vibration signal. Two models for estimating the time\ndomain average of a gear vibration signal are proposed. The models are tested\non data from an accelerated gear life test rig. Experimental results indicate\nthat the required data for calculating the Time Domain Average of a gear\nvibration signal can be reduced by up to 75% when the proposed models are\nimplemented.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 15:49:40 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Mdlazi", "L.", ""], ["Stander", "C. J.", ""], ["Heyns", "P. S.", ""], ["Marwala", "T.", ""]]}
{"id": "0705.1674", "submitter": "Tshilidzi Marwala", "authors": "Lukasz A Machowski, Tshilidzi Marwala", "title": "Evolutionary Optimisation Methods for Template Based Image Registration", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CV", "license": null, "abstract": "  This paper investigates the use of evolutionary optimisation techniques to\nregister a template with a scene image. An error function is created to measure\nthe correspondence of the template to the image. The problem presented here is\nto optimise the horizontal, vertical and scaling parameters that register the\ntemplate with the scene. The Genetic Algorithm, Simulated Annealing and\nParticle Swarm Optimisations are compared to a Nelder-Mead Simplex optimisation\nwith starting points chosen in a pre-processing stage. The paper investigates\nthe precision and accuracy of each method and shows that all four methods\nperform favourably for image registration. SA is the most precise, GA is the\nmost accurate. PSO is a good mix of both and the Simplex method returns local\nminima the most. A pre-processing stage should be investigated for the\nevolutionary methods in order to improve performance. Discrete versions of the\noptimisation methods should be investigated to further improve computational\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 15:51:36 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Machowski", "Lukasz A", ""], ["Marwala", "Tshilidzi", ""]]}
{"id": "0705.1680", "submitter": "Tshilidzi Marwala", "authors": "Michael Maio Pires, Tshilidzi Marwala", "title": "Option Pricing Using Bayesian Neural Networks", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  Options have provided a field of much study because of the complexity\ninvolved in pricing them. The Black-Scholes equations were developed to price\noptions but they are only valid for European styled options. There is added\ncomplexity when trying to price American styled options and this is why the use\nof neural networks has been proposed. Neural Networks are able to predict\noutcomes based on past data. The inputs to the networks here are stock\nvolatility, strike price and time to maturity with the output of the network\nbeing the call option price. There are two techniques for Bayesian neural\nnetworks used. One is Automatic Relevance Determination (for Gaussian\nApproximation) and one is a Hybrid Monte Carlo method, both used with\nMulti-Layer Perceptrons.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 15:55:31 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Pires", "Michael Maio", ""], ["Marwala", "Tshilidzi", ""]]}
{"id": "0705.1759", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Finite Element Model Updating Using Response Surface Method", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  This paper proposes the response surface method for finite element model\nupdating. The response surface method is implemented by approximating the\nfinite element model surface response equation by a multi-layer perceptron. The\nupdated parameters of the finite element model were calculated using genetic\nalgorithm by optimizing the surface response equation. The proposed method was\ncompared to the existing methods that use simulated annealing or genetic\nalgorithm together with a full finite element model for finite element model\nupdating. The proposed method was tested on an unsymmetri-cal H-shaped\nstructure. It was observed that the proposed method gave the updated natural\nfrequen-cies and mode shapes that were of the same order of accuracy as those\ngiven by simulated annealing and genetic algorithm. Furthermore, it was\nobserved that the response surface method achieved these results at a\ncomputational speed that was more than 2.5 times as fast as the genetic\nalgorithm and a full finite element model and 24 times faster than the\nsimulated annealing.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2007 10:25:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}
{"id": "0705.1760", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Dynamic Model Updating Using Particle Swarm Optimization Method", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  This paper proposes the use of particle swarm optimization method (PSO) for\nfinite element (FE) model updating. The PSO method is compared to the existing\nmethods that use simulated annealing (SA) or genetic algorithms (GA) for FE\nmodel for model updating. The proposed method is tested on an unsymmetrical\nH-shaped structure. It is observed that the proposed method gives updated\nnatural frequencies the most accurate and followed by those given by an updated\nmodel that was obtained using the GA and a full FE model. It is also observed\nthat the proposed method gives updated mode shapes that are best correlated to\nthe measured ones, followed by those given by an updated model that was\nobtained using the SA and a full FE model. Furthermore, it is observed that the\nPSO achieves this accuracy at a computational speed that is faster than that by\nthe GA and a full FE model which is faster than the SA and a full FE model.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2007 10:27:07 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}
{"id": "0705.1956", "submitter": "Dan Chen", "authors": "Dan Chen", "title": "A Branch and Cut Algorithm for the Halfspace Depth Problem", "comments": "110 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  The concept of data depth in non-parametric multivariate descriptive\nstatistics is the generalization of the univariate rank method to multivariate\ndata. Halfspace depth is a measure of data depth. Given a set S of points and a\npoint p, the halfspace depth (or rank) k of p is defined as the minimum number\nof points of S contained in any closed halfspace with p on its boundary.\nComputing halfspace depth is NP-hard, and it is equivalent to the Maximum\nFeasible Subsystem problem. In this thesis a mixed integer program is\nformulated with the big-M method for the halfspace depth problem. We suggest a\nbranch and cut algorithm. In this algorithm, Chinneck's heuristic algorithm is\nused to find an upper bound and a related technique based on sensitivity\nanalysis is used for branching. Irreducible Infeasible Subsystem (IIS) hitting\nset cuts are applied. We also suggest a binary search algorithm which may be\nmore stable numerically. The algorithms are implemented with the BCP framework\nfrom the COIN-OR project.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2007 15:31:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Chen", "Dan", ""]]}
{"id": "0705.1999", "submitter": "Camilla Schwind", "authors": "Camilla Schwind (LIF)", "title": "A first-order Temporal Logic for Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  We present a multi-modal action logic with first-order modalities, which\ncontain terms which can be unified with the terms inside the subsequent\nformulas and which can be quantified. This makes it possible to handle\nsimultaneously time and states. We discuss applications of this language to\naction theory where it is possible to express many temporal aspects of actions,\nas for example, beginning, end, time points, delayed preconditions and results,\nduration and many others. We present tableaux rules for a decidable fragment of\nthis logic.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2007 18:36:25 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Schwind", "Camilla", "", "LIF"]]}
{"id": "0705.2011", "submitter": "Alex Graves", "authors": "Alex Graves, Santiago Fernandez, Juergen Schmidhuber", "title": "Multi-Dimensional Recurrent Neural Networks", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": "04-07", "categories": "cs.AI cs.CV", "license": null, "abstract": "  Recurrent neural networks (RNNs) have proved effective at one dimensional\nsequence learning tasks, such as speech and online handwriting recognition.\nSome of the properties that make RNNs suitable for such tasks, for example\nrobustness to input warping, and the ability to access contextual information,\nare also desirable in multidimensional domains. However, there has so far been\nno direct way of applying RNNs to data with more than one spatio-temporal\ndimension. This paper introduces multi-dimensional recurrent neural networks\n(MDRNNs), thereby extending the potential applicability of RNNs to vision,\nvideo processing, medical imaging and many other areas, while avoiding the\nscaling problems that have plagued other multi-dimensional models. Experimental\nresults are provided for two image segmentation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2007 19:49:56 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Graves", "Alex", ""], ["Fernandez", "Santiago", ""], ["Schmidhuber", "Juergen", ""]]}
{"id": "0705.2125", "submitter": "Ching-Lueh Chang", "authors": "Ching-Lueh Chang, Yuh-Dauh Lyuu", "title": "Parallelized approximation algorithms for minimum routing cost spanning\n  trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  We parallelize several previously proposed algorithms for the minimum routing\ncost spanning tree problem and some related problems.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2007 17:48:42 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2007 20:10:22 GMT"}], "update_date": "2007-07-04", "authors_parsed": [["Chang", "Ching-Lueh", ""], ["Lyuu", "Yuh-Dauh", ""]]}
{"id": "0705.2147", "submitter": "Guilhem Semerjian", "authors": "Guilhem Semerjian", "title": "On the freezing of variables in random constraint satisfaction problems", "comments": "32 pages, 7 figures", "journal-ref": "J. Stat. Phys. 130, 251 (2008)", "doi": "10.1007/s10955-007-9417-7", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.CC math.PR", "license": null, "abstract": "  The set of solutions of random constraint satisfaction problems (zero energy\ngroundstates of mean-field diluted spin glasses) undergoes several structural\nphase transitions as the amount of constraints is increased. This set first\nbreaks down into a large number of well separated clusters. At the freezing\ntransition, which is in general distinct from the clustering one, some\nvariables (spins) take the same value in all solutions of a given cluster. In\nthis paper we study the critical behavior around the freezing transition, which\nappears in the unfrozen phase as the divergence of the sizes of the\nrearrangements induced in response to the modification of a variable. The\nformalism is developed on generic constraint satisfaction problems and applied\nin particular to the random satisfiability of boolean formulas and to the\ncoloring of random graphs. The computation is first performed in random tree\nensembles, for which we underline a connection with percolation models and with\nthe reconstruction problem of information theory. The validity of these results\nfor the original random ensembles is then discussed in the framework of the\ncavity method.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2007 13:53:10 GMT"}], "update_date": "2007-12-19", "authors_parsed": [["Semerjian", "Guilhem", ""]]}
{"id": "0705.2229", "submitter": "Matthew Valeriote Dr.", "authors": "Emil Kiss, Matthew Valeriote", "title": "On tractability and congruence distributivity", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 3, Issue 2 (June 8,\n  2007) lmcs:1005", "doi": "10.2168/LMCS-3(2:6)2007", "report-no": null, "categories": "cs.CC cs.LO", "license": null, "abstract": "  Constraint languages that arise from finite algebras have recently been the\nobject of study, especially in connection with the Dichotomy Conjecture of\nFeder and Vardi. An important class of algebras are those that generate\ncongruence distributive varieties and included among this class are lattices,\nand more generally, those algebras that have near-unanimity term operations. An\nalgebra will generate a congruence distributive variety if and only if it has a\nsequence of ternary term operations, called Jonsson terms, that satisfy certain\nequations.\n  We prove that constraint languages consisting of relations that are invariant\nunder a short sequence of Jonsson terms are tractable by showing that such\nlanguages have bounded relational width.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2007 20:01:32 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2007 12:26:50 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kiss", "Emil", ""], ["Valeriote", "Matthew", ""]]}
{"id": "0705.2235", "submitter": "Tshilidzi Marwala", "authors": "S. Chakraverty, T. Marwala, Pallavi Gupta and Thando Tettey", "title": "Response Prediction of Structural System Subject to Earthquake Motions\n  using Artificial Neural Network", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper uses Artificial Neural Network (ANN) models to compute response of\nstructural system subject to Indian earthquakes at Chamoli and Uttarkashi\nground motion data. The system is first trained for a single real earthquake\ndata. The trained ANN architecture is then used to simulate earthquakes with\nvarious intensities and it was found that the predicted responses given by ANN\nmodel are accurate for practical purposes. When the ANN is trained by a part of\nthe ground motion data, it can also identify the responses of the structural\nsystem well. In this way the safeness of the structural systems may be\npredicted in case of future earthquakes without waiting for the earthquake to\noccur for the lessons. Time period and the corresponding maximum response of\nthe building for an earthquake has been evaluated, which is again trained to\npredict the maximum response of the building at different time periods. The\ntrained time period versus maximum response ANN model is also tested for real\nearthquake data of other place, which was not used in the training and was\nfound to be in good agreement.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2007 20:29:06 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Chakraverty", "S.", ""], ["Marwala", "T.", ""], ["Gupta", "Pallavi", ""], ["Tettey", "Thando", ""]]}
{"id": "0705.2236", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala, Thando Tettey and Snehashish Chakraverty", "title": "Fault Classification using Pseudomodal Energies and Neuro-fuzzy\n  modelling", "comments": "8 pages, In Proceedings of the Asia-Pacific Workshop on Structural\n  Health Monitoring, Yokohama, Japan, 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper presents a fault classification method which makes use of a\nTakagi-Sugeno neuro-fuzzy model and Pseudomodal energies calculated from the\nvibration signals of cylindrical shells. The calculation of Pseudomodal\nEnergies, for the purposes of condition monitoring, has previously been found\nto be an accurate method of extracting features from vibration signals. This\ncalculation is therefore used to extract features from vibration signals\nobtained from a diverse population of cylindrical shells. Some of the cylinders\nin the population have faults in different substructures. The pseudomodal\nenergies calculated from the vibration signals are then used as inputs to a\nneuro-fuzzy model. A leave-one-out cross-validation process is used to test the\nperformance of the model. It is found that the neuro-fuzzy model is able to\nclassify faults with an accuracy of 91.62%, which is higher than the previously\nused multilayer perceptron.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2007 20:34:05 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""], ["Tettey", "Thando", ""], ["Chakraverty", "Snehashish", ""]]}
{"id": "0705.2305", "submitter": "Tshilidzi Marwala", "authors": "Sizwe M. Dhlamini, Tshilidzi Marwala, and Thokozani Majozi", "title": "Fuzzy and Multilayer Perceptron for Evaluation of HV Bushings", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": null, "abstract": "  The work proposes the application of fuzzy set theory (FST) to diagnose the\ncondition of high voltage bushings. The diagnosis uses dissolved gas analysis\n(DGA) data from bushings based on IEC60599 and IEEE C57-104 criteria for oil\nimpregnated paper (OIP) bushings. FST and neural networks are compared in terms\nof accuracy and computational efficiency. Both FST and NN simulations were able\nto diagnose the bushings condition with 10% error. By using fuzzy theory, the\nmaintenance department can classify bushings and know the extent of degradation\nin the component.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2007 09:06:19 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Dhlamini", "Sizwe M.", ""], ["Marwala", "Tshilidzi", ""], ["Majozi", "Thokozani", ""]]}
{"id": "0705.2307", "submitter": "Tshilidzi Marwala", "authors": "Bradley van Aardt, Tshilidzi Marwala", "title": "A Study in a Hybrid Centralised-Swarm Agent Community", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  This paper describes a systems architecture for a hybrid Centralised/Swarm\nbased multi-agent system. The issue of local goal assignment for agents is\ninvestigated through the use of a global agent which teaches the agents\nresponses to given situations. We implement a test problem in the form of a\nPursuit game, where the Multi-Agent system is a set of captor agents. The\nagents learn solutions to certain board positions from the global agent if they\nare unable to find a solution. The captor agents learn through the use of\nmulti-layer perceptron neural networks. The global agent is able to solve board\npositions through the use of a Genetic Algorithm. The cooperation between\nagents and the results of the simulation are discussed here. .\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2007 09:12:09 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["van Aardt", "Bradley", ""], ["Marwala", "Tshilidzi", ""]]}
{"id": "0705.2310", "submitter": "Tshilidzi Marwala", "authors": "C.B. Vilakazi, T. Marwala, P. Mautla and E. Moloto", "title": "On-Line Condition Monitoring using Computational Intelligence", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper presents bushing condition monitoring frameworks that use\nmulti-layer perceptrons (MLP), radial basis functions (RBF) and support vector\nmachines (SVM) classifiers. The first level of the framework determines if the\nbushing is faulty or not while the second level determines the type of fault.\nThe diagnostic gases in the bushings are analyzed using the dissolve gas\nanalysis. MLP gives superior performance in terms of accuracy and training time\nthan SVM and RBF. In addition, an on-line bushing condition monitoring\napproach, which is able to adapt to newly acquired data are introduced. This\napproach is able to accommodate new classes that are introduced by incoming\ndata and is implemented using an incremental learning algorithm that uses MLP.\nThe testing results improved from 67.5% to 95.8% as new data were introduced\nand the testing results improved from 60% to 95.3% as new conditions were\nintroduced. On average the confidence value of the framework on its decision\nwas 0.92.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2007 09:19:00 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Vilakazi", "C. B.", ""], ["Marwala", "T.", ""], ["Mautla", "P.", ""], ["Moloto", "E.", ""]]}
{"id": "0705.2485", "submitter": "Bodie Crossingham", "authors": "Bodie Crossingham and Tshilidzi Marwala", "title": "Using Genetic Algorithms to Optimise Rough Set Partition Sizes for HIV\n  Data Analysis", "comments": "10 pages, 1 figure, Update Bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.QM", "license": null, "abstract": "  In this paper, we present a method to optimise rough set partition sizes, to\nwhich rule extraction is performed on HIV data. The genetic algorithm\noptimisation technique is used to determine the partition sizes of a rough set\nin order to maximise the rough sets prediction accuracy. The proposed method is\ntested on a set of demographic properties of individuals obtained from the\nSouth African antenatal survey. Six demographic variables were used in the\nanalysis, these variables are; race, age of mother, education, gravidity,\nparity, and age of father, with the outcome or decision being either HIV\npositive or negative. Rough set theory is chosen based on the fact that it is\neasy to interpret the extracted rules. The prediction accuracy of equal width\nbin partitioning is 57.7% while the accuracy achieved after optimising the\npartitions is 72.8%. Several other methods have been used to analyse the HIV\ndata and their results are stated and compared to that of rough set theory\n(RST).\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2007 07:02:23 GMT"}], "update_date": "2007-06-25", "authors_parsed": [["Crossingham", "Bodie", ""], ["Marwala", "Tshilidzi", ""]]}
{"id": "0705.2503", "submitter": "Peng Cui", "authors": "Peng Cui", "title": "Improved Approximability Result for Test Set with Small Redundancy", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  Test set with redundancy is one of the focuses in recent bioinformatics\nresearch. Set cover greedy algorithm (SGA for short) is a commonly used\nalgorithm for test set with redundancy. This paper proves that the\napproximation ratio of SGA can be $(2-\\frac{1}{2r})\\ln n+{3/2}\\ln r+O(\\ln\\ln\nn)$ by using the potential function technique. This result is better than the\napproximation ratio $2\\ln n$ which directly derives from set multicover, when\n$r=o(\\frac{\\ln n}{\\ln\\ln n})$, and is an extension of the approximability\nresults for plain test set.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2007 09:53:20 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2007 09:11:18 GMT"}, {"version": "v3", "created": "Tue, 11 Sep 2007 09:21:21 GMT"}, {"version": "v4", "created": "Thu, 27 Sep 2007 14:58:21 GMT"}], "update_date": "2007-09-27", "authors_parsed": [["Cui", "Peng", ""]]}
{"id": "0705.2516", "submitter": "Tshilidzi Marwala", "authors": "Sizwe M. Dhlamini*, Fulufhelo V. Nelwamondo**, Tshilidzi Marwala**", "title": "Condition Monitoring of HV Bushings in the Presence of Missing Data\n  Using Evolutionary Computing", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  The work proposes the application of neural networks with particle swarm\noptimisation (PSO) and genetic algorithms (GA) to compensate for missing data\nin classifying high voltage bushings. The classification is done using DGA data\nfrom 60966 bushings based on IEEEc57.104, IEC599 and IEEE production rates\nmethods for oil impregnated paper (OIP) bushings. PSO and GA were compared in\nterms of accuracy and computational efficiency. Both GA and PSO simulations\nwere able to estimate missing data values to an average 95% accuracy when only\none variable was missing. However PSO rapidly deteriorated to 66% accuracy with\ntwo variables missing simultaneously, compared to 84% for GA. The data\nestimated using GA was found to classify the conditions of bushings than the\nPSO.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2007 11:33:34 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Dhlamini*", "Sizwe M.", ""], ["Nelwamondo**", "Fulufhelo V.", ""], ["Marwala**", "Tshilidzi", ""]]}
{"id": "0705.2604", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala and Christina Busisiwe Vilakazi", "title": "Computational Intelligence for Condition Monitoring", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  Condition monitoring techniques are described in this chapter. Two aspects of\ncondition monitoring process are considered: (1) feature extraction; and (2)\ncondition classification. Feature extraction methods described and implemented\nare fractals, Kurtosis and Mel-frequency Cepstral Coefficients. Classification\nmethods described and implemented are support vector machines (SVM), hidden\nMarkov models (HMM), Gaussian mixture models (GMM) and extension neural\nnetworks (ENN). The effectiveness of these features were tested using SVM, HMM,\nGMM and ENN on condition monitoring of bearings and are found to give good\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2007 21:20:58 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""], ["Vilakazi", "Christina Busisiwe", ""]]}
{"id": "0705.2765", "submitter": "Rustem Takhanov", "authors": "Rustem Takhanov", "title": "On the monotonization of the training set", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": null, "abstract": "  We consider the problem of minimal correction of the training set to make it\nconsistent with monotonic constraints. This problem arises during analysis of\ndata sets via techniques that require monotone data. We show that this problem\nis NP-hard in general and is equivalent to finding a maximal independent set in\nspecial orgraphs. Practically important cases of that problem considered in\ndetail. These are the cases when a partial order given on the replies set is a\ntotal order or has a dimension 2. We show that the second case can be reduced\nto maximization of a quadratic convex function on a convex set. For this case\nwe construct an approximate polynomial algorithm based on convex optimization.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2007 19:44:19 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Takhanov", "Rustem", ""]]}
{"id": "0705.2835", "submitter": "Binhai Zhu", "authors": "Sergey Bereg, Marina Gavrilova and Binhai Zhu", "title": "Voronoi Diagram of Polygonal Chains under the Discrete Fr\\'echet\n  Distance", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": null, "abstract": "  Polygonal chains are fundamental objects in many applications like pattern\nrecognition and protein structure alignment. A well-known measure to\ncharacterize the similarity of two polygonal chains is the famous Fr\\`{e}chet\ndistance. In this paper, for the first time, we consider the Voronoi diagram of\npolygonal chains in $d$-dimension ($d=2,3$) under the discrete Fr\\`{e}chet\ndistance. Given $n$ polygonal chains ${\\cal C}$ in $d$-dimension ($d=2,3$),\neach with at most $k$ vertices, we prove fundamental properties of such a\nVoronoi diagram {\\em VD}$_F({\\cal C})$ by presenting the first known upper and\nlower bounds for {\\em VD}$_F({\\cal C})$.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2007 18:35:18 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Bereg", "Sergey", ""], ["Gavrilova", "Marina", ""], ["Zhu", "Binhai", ""]]}
{"id": "0705.2835", "submitter": "Binhai Zhu", "authors": "Sergey Bereg, Marina Gavrilova and Binhai Zhu", "title": "Voronoi Diagram of Polygonal Chains under the Discrete Fr\\'echet\n  Distance", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": null, "abstract": "  Polygonal chains are fundamental objects in many applications like pattern\nrecognition and protein structure alignment. A well-known measure to\ncharacterize the similarity of two polygonal chains is the famous Fr\\`{e}chet\ndistance. In this paper, for the first time, we consider the Voronoi diagram of\npolygonal chains in $d$-dimension ($d=2,3$) under the discrete Fr\\`{e}chet\ndistance. Given $n$ polygonal chains ${\\cal C}$ in $d$-dimension ($d=2,3$),\neach with at most $k$ vertices, we prove fundamental properties of such a\nVoronoi diagram {\\em VD}$_F({\\cal C})$ by presenting the first known upper and\nlower bounds for {\\em VD}$_F({\\cal C})$.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2007 18:35:18 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Bereg", "Sergey", ""], ["Gavrilova", "Marina", ""], ["Zhu", "Binhai", ""]]}
{"id": "0705.3061", "submitter": "Chao Chen", "authors": "Daniel Freedman and Chao Chen", "title": "Measuring and Localing Homology Classes", "comments": "References 8 and 22 are fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": null, "abstract": "  We develop a method for measuring and localizing homology classes. This\ninvolves two problems. First, we define relevant notions of size for both a\nhomology class and a homology group basis, using ideas from relative homology.\nSecond, we propose an algorithm to compute the optimal homology basis, using\ntechniques from persistent homology and finite field algebra. Classes of the\ncomputed optimal basis are localized with cycles conveying their sizes. The\nalgorithm runs in $O(\\beta^4 n^3 \\log^2 n)$ time, where $n$ is the size of the\nsimplicial complex and $\\beta$ is the Betti number of the homology group.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2007 22:16:20 GMT"}, {"version": "v2", "created": "Thu, 24 May 2007 18:01:33 GMT"}], "update_date": "2007-06-13", "authors_parsed": [["Freedman", "Daniel", ""], ["Chen", "Chao", ""]]}
{"id": "0705.3227", "submitter": "H. Reiju Mihara", "authors": "Masahiro Kumabe, H. Reiju Mihara", "title": "Computability of simple games: A characterization and application to the\n  core", "comments": "35 pages; To appear in Journal of Mathematical Economics; Appendix\n  added, Propositions, Remarks, etc. are renumbered", "journal-ref": "Journal of Mathematical Economics, Volume 44, Issues 3-4, February\n  2008, Pages 348-366", "doi": "10.1016/j.jmateco.2007.05.012", "report-no": null, "categories": "cs.GT cs.CC cs.LO math.LO", "license": null, "abstract": "  The class of algorithmically computable simple games (i) includes the class\nof games that have finite carriers and (ii) is included in the class of games\nthat have finite winning coalitions. This paper characterizes computable games,\nstrengthens the earlier result that computable games violate anonymity, and\ngives examples showing that the above inclusions are strict. It also extends\nNakamura's theorem about the nonemptyness of the core and shows that computable\ngames have a finite Nakamura number, implying that the number of alternatives\nthat the players can deal with rationally is restricted.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2007 17:49:15 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2007 13:57:59 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kumabe", "Masahiro", ""], ["Mihara", "H. Reiju", ""]]}
{"id": "0705.3343", "submitter": "David Coeurjolly", "authors": "David Coeurjolly (LIRIS), Annick Montanvert (GIPSA-lab)", "title": "Optimal Separable Algorithms to Compute the Reverse Euclidean Distance\n  Transformation and Discrete Medial Axis in Arbitrary Dimension", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence 29,\n  3 (01/03/2007) 437-448", "doi": "10.1109/TPAMI.2007.54", "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  In binary images, the distance transformation (DT) and the geometrical\nskeleton extraction are classic tools for shape analysis. In this paper, we\npresent time optimal algorithms to solve the reverse Euclidean distance\ntransformation and the reversible medial axis extraction problems for\n$d$-dimensional images. We also present a $d$-dimensional medial axis filtering\nprocess that allows us to control the quality of the reconstructed shape.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2007 11:29:52 GMT"}], "update_date": "2007-05-24", "authors_parsed": [["Coeurjolly", "David", "", "LIRIS"], ["Montanvert", "Annick", "", "GIPSA-lab"]]}
{"id": "0705.3360", "submitter": "Kyriakos Sgarbas", "authors": "Kyriakos N. Sgarbas", "title": "The Road to Quantum Artificial Intelligence", "comments": "9 pages. Presented at PCI-2007: 11th Panhellenic Conference in\n  Informatics, 18-20 May 2007, Patras, Greece", "journal-ref": "In: T.S.Papatheodorou, D.N.Christodoulakis and N.N.Karanikolas\n  (eds), \"Current Trends in Informatics\", Vol.A, pp.469-477, New Technologies\n  Publications, Athens, 2007 (SET 978-960-89784-0-9)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper overviews the basic principles and recent advances in the emerging\nfield of Quantum Computation (QC), highlighting its potential application to\nArtificial Intelligence (AI). The paper provides a very brief introduction to\nbasic QC issues like quantum registers, quantum gates and quantum algorithms\nand then it presents references, ideas and research guidelines on how QC can be\nused to deal with some basic AI problems, such as search and pattern matching,\nas soon as quantum computers become widely available.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2007 12:31:47 GMT"}], "update_date": "2007-05-24", "authors_parsed": [["Sgarbas", "Kyriakos N.", ""]]}
{"id": "0705.3561", "submitter": "Lucas Bordeaux", "authors": "Lucas Bordeaux, Marco Cadoli, Toni Mancini", "title": "Generalizing Consistency and other Constraint Properties to Quantified\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": null, "abstract": "  Quantified constraints and Quantified Boolean Formulae are typically much\nmore difficult to reason with than classical constraints, because quantifier\nalternation makes the usual notion of solution inappropriate. As a consequence,\nbasic properties of Constraint Satisfaction Problems (CSP), such as consistency\nor substitutability, are not completely understood in the quantified case.\nThese properties are important because they are the basis of most of the\nreasoning methods used to solve classical (existentially quantified)\nconstraints, and one would like to benefit from similar reasoning methods in\nthe resolution of quantified constraints. In this paper, we show that most of\nthe properties that are used by solvers for CSP can be generalized to\nquantified CSP. This requires a re-thinking of a number of basic concepts; in\nparticular, we propose a notion of outcome that generalizes the classical\nnotion of solution and on which all definitions are based. We propose a\nsystematic study of the relations which hold between these properties, as well\nas complexity results regarding the decision of these properties. Finally, and\nsince these problems are typically intractable, we generalize the approach used\nin CSP and propose weaker, easier to check notions based on locality, which\nallow to detect these properties incompletely but in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2007 11:27:55 GMT"}], "update_date": "2007-05-25", "authors_parsed": [["Bordeaux", "Lucas", ""], ["Cadoli", "Marco", ""], ["Mancini", "Toni", ""]]}
{"id": "0705.3748", "submitter": "Oleg Verbitsky", "authors": "Oleg Verbitsky", "title": "On the Obfuscation Complexity of Planar Graphs", "comments": "12 pages, 1 figure. The proof of Theorem 3 is simplified. An overview\n  of a related work is added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": null, "abstract": "  Being motivated by John Tantalo's Planarity Game, we consider straight line\nplane drawings of a planar graph $G$ with edge crossings and wonder how\nobfuscated such drawings can be. We define $obf(G)$, the obfuscation complexity\nof $G$, to be the maximum number of edge crossings in a drawing of $G$.\nRelating $obf(G)$ to the distribution of vertex degrees in $G$, we show an\nefficient way of constructing a drawing of $G$ with at least $obf(G)/3$ edge\ncrossings. We prove bounds $(\\delta(G)^2/24-o(1))n^2 < \\obf G <3 n^2$ for an\n$n$-vertex planar graph $G$ with minimum vertex degree $\\delta(G)\\ge 2$.\n  The shift complexity of $G$, denoted by $shift(G)$, is the minimum number of\nvertex shifts sufficient to eliminate all edge crossings in an arbitrarily\nobfuscated drawing of $G$ (after shifting a vertex, all incident edges are\nsupposed to be redrawn correspondingly). If $\\delta(G)\\ge 3$, then $shift(G)$\nis linear in the number of vertices due to the known fact that the matching\nnumber of $G$ is linear. However, in the case $\\delta(G)\\ge2$ we notice that\n$shift(G)$ can be linear even if the matching number is bounded. As for\ncomputational complexity, we show that, given a drawing $D$ of a planar graph,\nit is NP-hard to find an optimum sequence of shifts making $D$ crossing-free.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2007 11:19:03 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2007 08:50:52 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2007 12:32:42 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Verbitsky", "Oleg", ""]]}
{"id": "0705.3751", "submitter": "Laurent Lyaudet", "authors": "Laurent Lyaudet (LIP), Pascal Koiran (LIP), Uffe Flarup (IMADA)", "title": "On the expressive power of planar perfect matching and permanents of\n  bounded treewidth matrices", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": null, "abstract": "  Valiant introduced some 25 years ago an algebraic model of computation along\nwith the complexity classes VP and VNP, which can be viewed as analogues of the\nclassical classes P and NP. They are defined using non-uniform sequences of\narithmetic circuits and provides a framework to study the complexity for\nsequences of polynomials. Prominent examples of difficult (that is,\nVNP-complete) problems in this model includes the permanent and hamiltonian\npolynomials. While the permanent and hamiltonian polynomials in general are\ndifficult to evaluate, there have been research on which special cases of these\npolynomials admits efficient evaluation. For instance, Barvinok has shown that\nif the underlying matrix has bounded rank, both the permanent and the\nhamiltonian polynomials can be evaluated in polynomial time, and thus are in\nVP. Courcelle, Makowsky and Rotics have shown that for matrices of bounded\ntreewidth several difficult problems (including evaluating the permanent and\nhamiltonian polynomials) can be solved efficiently. An earlier result of this\nflavour is Kasteleyn's theorem which states that the sum of weights of perfect\nmatchings of a planar graph can be computed in polynomial time, and thus is in\nVP also. For general graphs this problem is VNP-complete. In this paper we\ninvestigate the expressive power of the above results. We show that the\npermanent and hamiltonian polynomials for matrices of bounded treewidth both\nare equivalent to arithmetic formulas. Also, arithmetic weakly skew circuits\nare shown to be equivalent to the sum of weights of perfect matchings of planar\ngraphs.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2007 11:34:13 GMT"}], "update_date": "2007-06-13", "authors_parsed": [["Lyaudet", "Laurent", "", "LIP"], ["Koiran", "Pascal", "", "LIP"], ["Flarup", "Uffe", "", "IMADA"]]}
{"id": "0705.3766", "submitter": "Anton Eremeev", "authors": "Anton Eremeev", "title": "On complexity of optimized crossover for binary representations", "comments": "Dagstuhl Seminar 06061 \"Theory of Evolutionary Algorithms\", 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  We consider the computational complexity of producing the best possible\noffspring in a crossover, given two solutions of the parents. The crossover\noperators are studied on the class of Boolean linear programming problems,\nwhere the Boolean vector of variables is used as the solution representation.\nBy means of efficient reductions of the optimized gene transmitting crossover\nproblems (OGTC) we show the polynomial solvability of the OGTC for the maximum\nweight set packing problem, the minimum weight set partition problem and for\none of the versions of the simple plant location problem. We study a connection\nbetween the OGTC for linear Boolean programming problem and the maximum weight\nindependent set problem on 2-colorable hypergraph and prove the NP-hardness of\nseveral special cases of the OGTC problem in Boolean linear programming.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2007 13:07:18 GMT"}], "update_date": "2007-05-28", "authors_parsed": [["Eremeev", "Anton", ""]]}
{"id": "0705.3820", "submitter": "Francisco Santos", "authors": "Oswin Aichholzer, Thomas Hackl, Michael Hoffmann, Clemens Huemer,\n  Attila Por, Francisco Santos, Bettina Speckmann, Birgit Vogtenhuber", "title": "Maximizing Maximal Angles for Plane Straight-Line Graphs", "comments": "15 pages, 14 figures. Apart of minor corrections, some proofs that\n  were omitted in the previous version are now included", "journal-ref": "In \"Algorithms and Data Structures, WADS 2007, Halifax, Canada,\n  August 15-17, 2007\", Frank Dehne et al. (Eds.), LNCS 4619, Springer-Verlag,\n  2007, pp. 458-469", "doi": "10.1007/978-3-540-73951-7_40", "report-no": null, "categories": "cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G=(S, E)$ be a plane straight-line graph on a finite point set\n$S\\subset\\R^2$ in general position. The incident angles of a vertex $p \\in S$\nof $G$ are the angles between any two edges of $G$ that appear consecutively in\nthe circular order of the edges incident to $p$.\n  A plane straight-line graph is called $\\phi$-open if each vertex has an\nincident angle of size at least $\\phi$. In this paper we study the following\ntype of question: What is the maximum angle $\\phi$ such that for any finite set\n$S\\subset\\R^2$ of points in general position we can find a graph from a certain\nclass of graphs on $S$ that is $\\phi$-open? In particular, we consider the\nclasses of triangulations, spanning trees, and paths on $S$ and give tight\nbounds in most cases.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2007 18:10:45 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2009 19:07:20 GMT"}], "update_date": "2010-06-15", "authors_parsed": [["Aichholzer", "Oswin", ""], ["Hackl", "Thomas", ""], ["Hoffmann", "Michael", ""], ["Huemer", "Clemens", ""], ["Por", "Attila", ""], ["Santos", "Francisco", ""], ["Speckmann", "Bettina", ""], ["Vogtenhuber", "Birgit", ""]]}
{"id": "0705.4085", "submitter": "David Wood", "authors": "Erik D. Demaine, Francisco Gomez-Martin, Henk Meijer, David Rappaport,\n  Perouz Taslakian, Godfried T. Toussaint, Terry Winograd, David R. Wood", "title": "The Distance Geometry of Music", "comments": "This is the full version of the paper: \"The distance geometry of deep\n  rhythms and scales.\" 17th Canadian Conference on Computational Geometry (CCCG\n  '05), University of Windsor, Canada, 2005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  We demonstrate relationships between the classic Euclidean algorithm and many\nother fields of study, particularly in the context of music and distance\ngeometry. Specifically, we show how the structure of the Euclidean algorithm\ndefines a family of rhythms which encompass over forty timelines\n(\\emph{ostinatos}) from traditional world music. We prove that these\n\\emph{Euclidean rhythms} have the mathematical property that their onset\npatterns are distributed as evenly as possible: they maximize the sum of the\nEuclidean distances between all pairs of onsets, viewing onsets as points on a\ncircle. Indeed, Euclidean rhythms are the unique rhythms that maximize this\nnotion of \\emph{evenness}. We also show that essentially all Euclidean rhythms\nare \\emph{deep}: each distinct distance between onsets occurs with a unique\nmultiplicity, and these multiplicies form an interval $1,2,...,k-1$. Finally,\nwe characterize all deep rhythms, showing that they form a subclass of\ngenerated rhythms, which in turn proves a useful property called shelling. All\nof our results for musical rhythms apply equally well to musical scales. In\naddition, many of the problems we explore are interesting in their own right as\ndistance geometry problems on the circle; some of the same problems were\nexplored by Erd\\H{o}s in the plane.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2007 18:36:19 GMT"}], "update_date": "2007-05-29", "authors_parsed": [["Demaine", "Erik D.", ""], ["Gomez-Martin", "Francisco", ""], ["Meijer", "Henk", ""], ["Rappaport", "David", ""], ["Taslakian", "Perouz", ""], ["Toussaint", "Godfried T.", ""], ["Winograd", "Terry", ""], ["Wood", "David R.", ""]]}
{"id": "0705.4134", "submitter": "Michael Vielhaber", "authors": "Michael Vielhaber and Monica del Pilar Canales", "title": "The Battery-Discharge-Model: A Class of Stochastic Finite Automata to\n  Simulate Multidimensional Continued Fraction Expansion", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.CR math.IT", "license": null, "abstract": "  We define an infinite stochastic state machine, the Battery-Discharge-Model\n(BDM), which simulates the behaviour of linear and jump complexity of the\ncontinued fraction expansion of multidimensional formal power series, a\nrelevant security measure in the cryptanalysis of stream ciphers.\n  We also obtain finite approximations to the infinite BDM, where polynomially\nmany states suffice to approximate with an exponentially small error the\nprobabilities and averages for linear and jump complexity of M-multisequences\nof length n over the finite field F_q, for any M, n, q.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2007 02:50:42 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Vielhaber", "Michael", ""], ["Canales", "Monica del Pilar", ""]]}
{"id": "0705.4138", "submitter": "Michael Vielhaber", "authors": "Michael Vielhaber and Monica del Pilar Canales", "title": "The Asymptotic Normalized Linear Complexity of Multisequences", "comments": "19 pages, 2 figures, submitted to J. Complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.CR math.IT", "license": null, "abstract": "  We show that the asymptotic linear complexity of a multisequence a in\nF_q^\\infty that is I := liminf L_a(n)/n and S := limsup L_a(n)/n satisfy the\ninequalities M/(M+1) <= S <= 1 and M(1-S) <= I <= 1-S/M, if all M sequences\nhave nonzero discrepancy infinitely often, and all pairs (I,S) satisfying these\nconditions are met by 2^{\\aleph_0} multisequences a.\n  This answers an Open Problem by Dai, Imamura, and Yang.\n  Keywords: Linear complexity, multisequence, Battery Discharge Model,\nisometry.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2007 03:41:21 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Vielhaber", "Michael", ""], ["Canales", "Monica del Pilar", ""]]}
{"id": "0705.4302", "submitter": "Jens Oehlschl\\\"agel", "authors": "Jens Oehlschl\\\"agel", "title": "Truecluster matching", "comments": "15 pages, 2 figures. Details the matching needed for \"Truecluster:\n  robust scalable clustering with model selection\" but can also be used in\n  different contexts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Cluster matching by permuting cluster labels is important in many clustering\ncontexts such as cluster validation and cluster ensemble techniques. The\nclassic approach is to minimize the euclidean distance between two cluster\nsolutions which induces inappropriate stability in certain settings. Therefore,\nwe present the truematch algorithm that introduces two improvements best\nexplained in the crisp case. First, instead of maximizing the trace of the\ncluster crosstable, we propose to maximize a chi-square transformation of this\ncrosstable. Thus, the trace will not be dominated by the cells with the largest\ncounts but by the cells with the most non-random observations, taking into\naccount the marginals. Second, we suggest a probabilistic component in order to\nbreak ties and to make the matching algorithm truly random on random data. The\ntruematch algorithm is designed as a building block of the truecluster\nframework and scales in polynomial time. First simulation results confirm that\nthe truematch algorithm gives more consistent truecluster results for unequal\ncluster sizes. Free R software is available.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2007 21:52:17 GMT"}], "update_date": "2007-05-31", "authors_parsed": [["Oehlschlägel", "Jens", ""]]}
{"id": "0705.4566", "submitter": "Bastian Wemmenhove", "authors": "Bastian Wemmenhove and Bert Kappen", "title": "Loop corrections for message passing algorithms in continuous variable\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": null, "abstract": "  In this paper we derive the equations for Loop Corrected Belief Propagation\non a continuous variable Gaussian model. Using the exactness of the averages\nfor belief propagation for Gaussian models, a different way of obtaining the\ncovariances is found, based on Belief Propagation on cavity graphs. We discuss\nthe relation of this loop correction algorithm to Expectation Propagation\nalgorithms for the case in which the model is no longer Gaussian, but slightly\nperturbed by nonlinear terms.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2007 10:35:07 GMT"}], "update_date": "2007-06-01", "authors_parsed": [["Wemmenhove", "Bastian", ""], ["Kappen", "Bert", ""]]}
{"id": "0705.4584", "submitter": "Stefan Johansson", "authors": "Magnus Boman and Stefan J. Johansson", "title": "Modeling Epidemic Spread in Synthetic Populations - Virtual Plagues in\n  Massively Multiplayer Online Games", "comments": "Accepted for presentation at Digital Games Research Association\n  (DiGRA) conference in Tokyo in September 2007. All comments to the authors\n  (mail addresses are in the paper) are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": null, "abstract": "  A virtual plague is a process in which a behavior-affecting property spreads\namong characters in a Massively Multiplayer Online Game (MMOG). The MMOG\nindividuals constitute a synthetic population, and the game can be seen as a\nform of interactive executable model for studying disease spread, albeit of a\nvery special kind. To a game developer maintaining an MMOG, recognizing,\nmonitoring, and ultimately controlling a virtual plague is important,\nregardless of how it was initiated. The prospect of using tools, methods and\ntheory from the field of epidemiology to do this seems natural and appealing.\nWe will address the feasibility of such a prospect, first by considering some\nbasic measures used in epidemiology, then by pointing out the differences\nbetween real world epidemics and virtual plagues. We also suggest directions\nfor MMOG developer control through epidemiological modeling. Our aim is\nunderstanding the properties of virtual plagues, rather than trying to\neliminate them or mitigate their effects, as would be in the case of real\ninfectious disease.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2007 12:15:05 GMT"}], "update_date": "2007-06-01", "authors_parsed": [["Boman", "Magnus", ""], ["Johansson", "Stefan J.", ""]]}
{"id": "0705.4618", "submitter": "Roberto Bagnara", "authors": "Roberto Bagnara, Patricia M. Hill, Enea Zaffanella", "title": "An Improved Tight Closure Algorithm for Integer Octagonal Constraints", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LO", "license": null, "abstract": "  Integer octagonal constraints (a.k.a. ``Unit Two Variables Per Inequality''\nor ``UTVPI integer constraints'') constitute an interesting class of\nconstraints for the representation and solution of integer problems in the\nfields of constraint programming and formal analysis and verification of\nsoftware and hardware systems, since they couple algorithms having polynomial\ncomplexity with a relatively good expressive power. The main algorithms\nrequired for the manipulation of such constraints are the satisfiability check\nand the computation of the inferential closure of a set of constraints. The\nlatter is called `tight' closure to mark the difference with the (incomplete)\nclosure algorithm that does not exploit the integrality of the variables. In\nthis paper we present and fully justify an O(n^3) algorithm to compute the\ntight closure of a set of UTVPI integer constraints.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2007 14:32:46 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2007 08:17:11 GMT"}], "update_date": "2007-06-01", "authors_parsed": [["Bagnara", "Roberto", ""], ["Hill", "Patricia M.", ""], ["Zaffanella", "Enea", ""]]}
{"id": "0705.4658", "submitter": "Marius Zimand", "authors": "Marius Zimand", "title": "Two sources are better than one for increasing the Kolmogorov complexity\n  of infinite sequences", "comments": "Theorem 4.15 replaced with a weaker version; several other minor\n  changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": null, "abstract": "  The randomness rate of an infinite binary sequence is characterized by the\nsequence of ratios between the Kolmogorov complexity and the length of the\ninitial segments of the sequence. It is known that there is no uniform\neffective procedure that transforms one input sequence into another sequence\nwith higher randomness rate. By contrast, we display such a uniform effective\nprocedure having as input two independent sequences with positive but\narbitrarily small constant randomness rate. Moreover the transformation is a\ntruth-table reduction and the output has randomness rate arbitrarily close to\n1.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2007 17:38:04 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2007 14:12:28 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Zimand", "Marius", ""]]}
{"id": "0706.0022", "submitter": "Marko Antonio Rodriguez", "authors": "Marko A. Rodriguez and Johan Bollen", "title": "Modeling Computations in a Semantic Network", "comments": "project website: http://neno.lanl.gov", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Semantic network research has seen a resurgence from its early history in the\ncognitive sciences with the inception of the Semantic Web initiative. The\nSemantic Web effort has brought forth an array of technologies that support the\nencoding, storage, and querying of the semantic network data structure at the\nworld stage. Currently, the popular conception of the Semantic Web is that of a\ndata modeling medium where real and conceptual entities are related in\nsemantically meaningful ways. However, new models have emerged that explicitly\nencode procedural information within the semantic network substrate. With these\nnew technologies, the Semantic Web has evolved from a data modeling medium to a\ncomputational medium. This article provides a classification of existing\ncomputational modeling efforts and the requirements of supporting technologies\nthat will aid in the further growth of this burgeoning domain.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2007 21:56:25 GMT"}], "update_date": "2021-08-23", "authors_parsed": [["Rodriguez", "Marko A.", ""], ["Bollen", "Johan", ""]]}
{"id": "0706.0465", "submitter": "Donald Sofge", "authors": "D. A. Sofge", "title": "Virtual Sensor Based Fault Detection and Classification on a Plasma Etch\n  Reactor", "comments": "7 pages", "journal-ref": "D. Sofge, \"Virtual Sensor Based Fault Detection and Classification\n  on a Plasma Etch Reactor,\" The 2nd Joint Mexico-US Int'l. Workshop on Neural\n  Networks and Neurocontrol (poster), 1997", "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": null, "abstract": "  The SEMATECH sponsored J-88-E project teaming Texas Instruments with\nNeuroDyne (et al.) focused on Fault Detection and Classification (FDC) on a Lam\n9600 aluminum plasma etch reactor, used in the process of semiconductor\nfabrication. Fault classification was accomplished by implementing a series of\nvirtual sensor models which used data from real sensors (Lam Station sensors,\nOptical Emission Spectroscopy, and RF Monitoring) to predict recipe setpoints\nand wafer state characteristics. Fault detection and classification were\nperformed by comparing predicted recipe and wafer state values with expected\nvalues. Models utilized include linear PLS, Polynomial PLS, and Neural Network\nPLS. Prediction of recipe setpoints based upon sensor data provides a\ncapability for cross-checking that the machine is maintaining the desired\nsetpoints. Wafer state characteristics such as Line Width Reduction and\nRemaining Oxide were estimated on-line using these same process sensors (Lam,\nOES, RFM). Wafer-to-wafer measurement of these characteristics in a production\nsetting (where typically this information may be only sparsely available, if at\nall, after batch processing runs with numerous wafers have been completed)\nwould provide important information to the operator that the process is or is\nnot producing wafers within acceptable bounds of product quality. Production\nyield is increased, and correspondingly per unit cost is reduced, by providing\nthe operator with the opportunity to adjust the process or machine before\netching more wafers.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2007 15:55:27 GMT"}], "update_date": "2007-06-05", "authors_parsed": [["Sofge", "D. A.", ""]]}
{"id": "0706.0585", "submitter": "Zhendong Zhao", "authors": "Zhendong Zhao, Lei Yuan, Yuxuan Wang, Forrest Sheng Bao, Shunyi Zhang\n  Yanfei Sun", "title": "A Novel Model of Working Set Selection for SMO Decomposition Methods", "comments": "8 pages, 12 figures, it was submitted to IEEE International\n  conference of Tools on Artificial Intelligence", "journal-ref": null, "doi": "10.1109/ICTAI.2007.99", "report-no": null, "categories": "cs.LG cs.AI", "license": null, "abstract": "  In the process of training Support Vector Machines (SVMs) by decomposition\nmethods, working set selection is an important technique, and some exciting\nschemes were employed into this field. To improve working set selection, we\npropose a new model for working set selection in sequential minimal\noptimization (SMO) decomposition methods. In this model, it selects B as\nworking set without reselection. Some properties are given by simple proof, and\nexperiments demonstrate that the proposed method is in general faster than\nexisting methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2007 05:55:07 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Zhao", "Zhendong", ""], ["Yuan", "Lei", ""], ["Wang", "Yuxuan", ""], ["Bao", "Forrest Sheng", ""], ["Sun", "Shunyi Zhang Yanfei", ""]]}
{"id": "0706.0870", "submitter": "Nachi Gupta", "authors": "Nachi Gupta, Raphael Hauser, and Neil F. Johnson", "title": "Inferring the Composition of a Trader Population in a Financial Market", "comments": "15 pages, 2 figures, to appear as a chapter in \"Econophysics and\n  Sociophysics of Markets and Networks\", Springer-Verlag", "journal-ref": null, "doi": "10.1007/978-88-470-0665-2_7", "report-no": null, "categories": "cs.CE nlin.AO", "license": null, "abstract": "  We discuss a method for predicting financial movements and finding pockets of\npredictability in the price-series, which is built around inferring the\nheterogeneity of trading strategies in a multi-agent trader population. This\nwork explores extensions to our previous framework (arXiv:physics/0506134).\nHere we allow for more intelligent agents possessing a richer strategy set, and\nwe no longer constrain the estimate for the heterogeneity of the agents to a\nprobability space. We also introduce a scheme which allows the incorporation of\nmodels with a wide variety of agent types, and discuss a mechanism for the\nremoval of bias from relevant parameters.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2007 17:29:42 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Gupta", "Nachi", ""], ["Hauser", "Raphael", ""], ["Johnson", "Neil F.", ""]]}
{"id": "0706.1001", "submitter": "Krzysztof R. Apt", "authors": "Krzysztof R. Apt", "title": "Epistemic Analysis of Strategic Games with Arbitrary Strategy Sets", "comments": "8 pages Proc. of the 11th Conference on Theoretical Aspects of\n  Rationality and Knowledge (TARK XI), 2007. To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": null, "abstract": "  We provide here an epistemic analysis of arbitrary strategic games based on\nthe possibility correspondences. Such an analysis calls for the use of\ntransfinite iterations of the corresponding operators. Our approach is based on\nTarski's Fixpoint Theorem and applies both to the notions of rationalizability\nand the iterated elimination of strictly dominated strategies.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2007 12:57:21 GMT"}], "update_date": "2007-06-08", "authors_parsed": [["Apt", "Krzysztof R.", ""]]}
{"id": "0706.1002", "submitter": "Alexander Wolff", "authors": "Xavier Goaoc, Jan Kratochvil, Yoshio Okamoto, Chan-Su Shin, Alexander\n  Wolff", "title": "Moving Vertices to Make Drawings Plane", "comments": "This paper has been merged with http://arxiv.org/abs/0709.0170", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A straight-line drawing $\\delta$ of a planar graph $G$ need not be plane, but\ncan be made so by moving some of the vertices. Let shift$(G,\\delta)$ denote the\nminimum number of vertices that need to be moved to turn $\\delta$ into a plane\ndrawing of $G$. We show that shift$(G,\\delta)$ is NP-hard to compute and to\napproximate, and we give explicit bounds on shift$(G,\\delta)$ when $G$ is a\ntree or a general planar graph. Our hardness results extend to\n1BendPointSetEmbeddability, a well-known graph-drawing problem.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2007 13:57:52 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2007 13:14:51 GMT"}, {"version": "v3", "created": "Thu, 6 Nov 2008 21:57:09 GMT"}], "update_date": "2008-11-06", "authors_parsed": [["Goaoc", "Xavier", ""], ["Kratochvil", "Jan", ""], ["Okamoto", "Yoshio", ""], ["Shin", "Chan-Su", ""], ["Wolff", "Alexander", ""]]}
{"id": "0706.1002", "submitter": "Alexander Wolff", "authors": "Xavier Goaoc, Jan Kratochvil, Yoshio Okamoto, Chan-Su Shin, Alexander\n  Wolff", "title": "Moving Vertices to Make Drawings Plane", "comments": "This paper has been merged with http://arxiv.org/abs/0709.0170", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A straight-line drawing $\\delta$ of a planar graph $G$ need not be plane, but\ncan be made so by moving some of the vertices. Let shift$(G,\\delta)$ denote the\nminimum number of vertices that need to be moved to turn $\\delta$ into a plane\ndrawing of $G$. We show that shift$(G,\\delta)$ is NP-hard to compute and to\napproximate, and we give explicit bounds on shift$(G,\\delta)$ when $G$ is a\ntree or a general planar graph. Our hardness results extend to\n1BendPointSetEmbeddability, a well-known graph-drawing problem.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2007 13:57:52 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2007 13:14:51 GMT"}, {"version": "v3", "created": "Thu, 6 Nov 2008 21:57:09 GMT"}], "update_date": "2008-11-06", "authors_parsed": [["Goaoc", "Xavier", ""], ["Kratochvil", "Jan", ""], ["Okamoto", "Yoshio", ""], ["Shin", "Chan-Su", ""], ["Wolff", "Alexander", ""]]}
{"id": "0706.1119", "submitter": "Stefan Stefanov Z", "authors": "Stefan Z. Stefanov", "title": "Cointegration of the Daily Electric Power System Load and the Weather", "comments": "8 pages, extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper makes a thermal predictive analysis of the electric power system\nsecurity for a day ahead. This predictive analysis is set as a thermal\ncomputation of the expected security. This computation is obtained by\ncointegrating the daily electric power systen load and the weather, by finding\nthe daily electric power system thermodynamics and by introducing tests for\nthis thermodynamics. The predictive analysis made shows the electricity\nconsumers' wisdom.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2007 07:04:24 GMT"}, {"version": "v2", "created": "Mon, 24 Jan 2011 11:53:45 GMT"}], "update_date": "2011-01-25", "authors_parsed": [["Stefanov", "Stefan Z.", ""]]}
{"id": "0706.1130", "submitter": "Matthias Brust R.", "authors": "Matthias R. Brust, Steffen Rothkugel", "title": "A Communication Model for Adaptive Service Provisioning in Hybrid\n  Wireless Networks", "comments": "WSEAS Transactions on Circuits and Systems 2004", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AR cs.CY cs.HC", "license": null, "abstract": "  Mobile entities with wireless links are able to form a mobile ad-hoc network.\nSuch an infrastructureless network does not have to be administrated. However,\nself-organizing principles have to be applied to deal with upcoming problems,\ne.g. information dissemination. These kinds of problems are not easy to tackle,\nrequiring complex algorithms. Moreover, the usefulness of pure ad-hoc networks\nis arguably limited. Hence, enthusiasm for mobile ad-hoc networks, which could\neliminate the need for any fixed infrastructure, has been damped. The goal is\nto overcome the limitations of pure ad-hoc networks by augmenting them with\ninstant Internet access, e.g. via integration of UMTS respectively GSM links.\nHowever, this raises multiple questions at the technical as well as the\norganizational level. Motivated by characteristics of small-world networks that\ndescribe an efficient network even without central or organized design, this\npaper proposes to combine mobile ad-hoc networks and infrastructured networks\nto form hybrid wireless networks. One main objective is to investigate how this\napproach can reduce the costs of a permanent backbone link and providing in the\nsame way the benefits of useful information from Internet connectivity or\nservice providers. For the purpose of bridging between the different types of\nnetworks, an adequate middleware service is the focus of our investigation.\nThis paper shows our first steps forward to this middleware by introducing the\nInjection Communication paradigm as principal concept.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2007 08:23:14 GMT"}], "update_date": "2007-06-11", "authors_parsed": [["Brust", "Matthias R.", ""], ["Rothkugel", "Steffen", ""]]}
{"id": "0706.1137", "submitter": "Thierry Poibeau", "authors": "Amanda Bouffier (LIPN), Thierry Poibeau (LIPN)", "title": "Automatically Restructuring Practice Guidelines using the GEM DTD", "comments": null, "journal-ref": "Proceedings of Biomedical Natural Language Processing (BioNLP)\n  (2007) -", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper describes a system capable of semi-automatically filling an XML\ntemplate from free texts in the clinical domain (practice guidelines). The XML\ntemplate includes semantic information not explicitly encoded in the text\n(pairs of conditions and actions/recommendations). Therefore, there is a need\nto compute the exact scope of conditions over text sequences expressing the\nrequired actions. We present a system developed for this task. We show that it\nyields good performance when applied to the analysis of French practice\nguidelines.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2007 15:39:49 GMT"}], "update_date": "2007-06-11", "authors_parsed": [["Bouffier", "Amanda", "", "LIPN"], ["Poibeau", "Thierry", "", "LIPN"]]}
{"id": "0706.1290", "submitter": "Sylviane Schwer", "authors": "Sylviane R. Schwer (LIPN)", "title": "Temporal Reasoning without Transitive Tables", "comments": "rapport interne", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Representing and reasoning about qualitative temporal information is an\nessential part of many artificial intelligence tasks. Lots of models have been\nproposed in the litterature for representing such temporal information. All\nderive from a point-based or an interval-based framework. One fundamental\nreasoning task that arises in applications of these frameworks is given by the\nfollowing scheme: given possibly indefinite and incomplete knowledge of the\nbinary relationships between some temporal objects, find the consistent\nscenarii between all these objects. All these models require transitive tables\n-- or similarly inference rules-- for solving such tasks. We have defined an\nalternative model, S-languages - to represent qualitative temporal information,\nbased on the only two relations of \\emph{precedence} and \\emph{simultaneity}.\nIn this paper, we show how this model enables to avoid transitive tables or\ninference rules to handle this kind of problem.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2007 06:57:05 GMT"}], "update_date": "2007-06-12", "authors_parsed": [["Schwer", "Sylviane R.", "", "LIPN"]]}
{"id": "0706.1477", "submitter": "Sylvain Perifel", "authors": "Pascal Koiran (LIP), Sylvain Perifel (LIP)", "title": "VPSPACE and a transfer theorem over the complex field", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  We extend the transfer theorem of [KP2007] to the complex field. That is, we\ninvestigate the links between the class VPSPACE of families of polynomials and\nthe Blum-Shub-Smale model of computation over C. Roughly speaking, a family of\npolynomials is in VPSPACE if its coefficients can be computed in polynomial\nspace. Our main result is that if (uniform, constant-free) VPSPACE families can\nbe evaluated efficiently then the class PAR of decision problems that can be\nsolved in parallel polynomial time over the complex field collapses to P. As a\nresult, one must first be able to show that there are VPSPACE families which\nare hard to evaluate in order to separate P from NP over C, or even from PAR.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2007 13:59:31 GMT"}], "update_date": "2007-06-12", "authors_parsed": [["Koiran", "Pascal", "", "LIP"], ["Perifel", "Sylvain", "", "LIP"]]}
{"id": "0706.1692", "submitter": "Cyrille Chavet", "authors": "Cyrille Chavet (LESTER, STM), Philippe Coussy (LESTER), Pascal Urard\n  (STM), Eric Martin (LESTER)", "title": "A Methodology for Efficient Space-Time Adapter Design Space Exploration:\n  A Case Study of an Ultra Wide Band Interleaver", "comments": "ISBN:1-4244-0921-7", "journal-ref": "Proceedings of the IEEE International Symposium on Circuits and\n  Systems (ISCAS) (28/05/2007) 2946", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents a solution to efficiently explore the design space of\ncommunication adapters. In most digital signal processing (DSP) applications,\nthe overall architecture of the system is significantly affected by\ncommunication architecture, so the designers need specifically optimized\nadapters. By explicitly modeling these communications within an effective\ngraph-theoretic model and analysis framework, we automatically generate an\noptimized architecture, named Space-Time AdapteR (STAR). Our design flow inputs\na C description of Input/Output data scheduling, and user requirements\n(throughput, latency, parallelism...), and formalizes communication constraints\nthrough a Resource Constraints Graph (RCG). The RCG properties enable an\nefficient architecture space exploration in order to synthesize a STAR\ncomponent. The proposed approach has been tested to design an industrial data\nmixing block example: an Ultra-Wideband interleaver.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2007 13:45:50 GMT"}], "update_date": "2007-06-13", "authors_parsed": [["Chavet", "Cyrille", "", "LESTER, STM"], ["Coussy", "Philippe", "", "LESTER"], ["Urard", "Pascal", "", "STM"], ["Martin", "Eric", "", "LESTER"]]}
{"id": "0706.2035", "submitter": "Michael Silverman", "authors": "Kyle Sabo, Ryan Schmitt, Michael Silverman", "title": "Critique of Feinstein's Proof that P is not Equal to NP", "comments": "5 pages, 2 definitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  We examine a proof by Craig Alan Feinstein that P is not equal to NP. We\npresent counterexamples to claims made in his paper and expose a flaw in the\nmethodology he uses to make his assertions. The fault in his argument is the\nincorrect use of reduction. Feinstein makes incorrect assumptions about the\ncomplexity of a problem based on the fact that there is a more complex problem\nthat can be used to solve it. His paper introduces the terminology \"imaginary\nprocessor\" to describe how it is possible to beat the brute force reduction he\noffers to solve the Subset-Sum problem. The claims made in the paper would not\nbe validly established even were imaginary processors to exist.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2007 13:15:39 GMT"}], "update_date": "2007-06-15", "authors_parsed": [["Sabo", "Kyle", ""], ["Schmitt", "Ryan", ""], ["Silverman", "Michael", ""]]}
{"id": "0706.2153", "submitter": "Quentin Merigot", "authors": "Fr\\'ed\\'eric Chazal (INRIA Sophia Antipolis), David Cohen-Steiner\n  (INRIA Sophia Antipolis), Quentin M\\'erigot (INRIA Sophia Antipolis)", "title": "Stability of boundary measures", "comments": null, "journal-ref": "Boundary measures for geometric inference, Found. Comput. Math.,\n  10 (2), pp. 221-240, 2010", "doi": "10.1007/s10208-009-9056-2", "report-no": null, "categories": "cs.CG math.CA math.MG", "license": null, "abstract": "  We introduce the boundary measure at scale r of a compact subset of the\nn-dimensional Euclidean space. We show how it can be computed for point clouds\nand suggest these measures can be used for feature detection. The main\ncontribution of this work is the proof a quantitative stability theorem for\nboundary measures using tools of convex analysis and geometric measure theory.\nAs a corollary we obtain a stability result for Federer's curvature measures of\na compact, allowing to compute them from point-cloud approximations of the\ncompact.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2007 16:03:28 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2007 09:06:56 GMT"}], "update_date": "2010-03-31", "authors_parsed": [["Chazal", "Frédéric", "", "INRIA Sophia Antipolis"], ["Cohen-Steiner", "David", "", "INRIA Sophia Antipolis"], ["Mérigot", "Quentin", "", "INRIA Sophia Antipolis"]]}
{"id": "0706.2155", "submitter": "Greg Sepesi", "authors": "Greg Sepesi", "title": "Dualheap Selection Algorithm: Efficient, Inherently Parallel and\n  Somewhat Mysterious", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC", "license": null, "abstract": "  An inherently parallel algorithm is proposed that efficiently performs\nselection: finding the K-th largest member of a set of N members. Selection is\na common component of many more complex algorithms and therefore is a widely\nstudied problem.\n  Not much is new in the proposed dualheap selection algorithm: the heap data\nstructure is from J.W.J.Williams, the bottom-up heap construction is from R.W.\nFloyd, and the concept of a two heap data structure is from J.W.J. Williams and\nD.E. Knuth. The algorithm's novelty is limited to a few relatively minor\nimplementation twists: 1) the two heaps are oriented with their roots at the\npartition values rather than at the minimum and maximum values, 2)the coding of\none of the heaps (the heap of smaller values) employs negative indexing, and 3)\nthe exchange phase of the algorithm is similar to a bottom-up heap\nconstruction, but navigates the heap with a post-order tree traversal.\n  When run on a single processor, the dualheap selection algorithm's\nperformance is competitive with quickselect with median estimation, a common\nvariant of C.A.R. Hoare's quicksort algorithm. When run on parallel processors,\nthe dualheap selection algorithm is superior due to its subtasks that are\neasily partitioned and innately balanced.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2007 16:11:24 GMT"}], "update_date": "2007-06-15", "authors_parsed": [["Sepesi", "Greg", ""]]}
{"id": "0706.2331", "submitter": "Erhan Bayraktar", "authors": "Erhan Bayraktar, Hao Xing", "title": "Pricing American Options for Jump Diffusions by Iterating Optimal\n  Stopping Problems for Diffusions", "comments": "Key Words: Pricing derivatives, American options, jump diffusions,\n  barrier options, finite difference methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approximate the price of the American put for jump diffusions by a\nsequence of functions, which are computed iteratively. This sequence converges\nto the price function uniformly and exponentially fast. Each element of the\napproximating sequence solves an optimal stopping problem for geometric\nBrownian motion, and can be numerically computed using the classical finite\ndifference methods. We prove the convergence of this numerical scheme and\npresent examples to illustrate its performance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2007 16:43:14 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2007 15:40:41 GMT"}, {"version": "v3", "created": "Sat, 14 Jun 2008 03:46:38 GMT"}, {"version": "v4", "created": "Thu, 31 Jul 2008 03:43:12 GMT"}, {"version": "v5", "created": "Wed, 3 Dec 2008 16:56:17 GMT"}], "update_date": "2008-12-03", "authors_parsed": [["Bayraktar", "Erhan", ""], ["Xing", "Hao", ""]]}
{"id": "0706.2725", "submitter": "Guohun Zhu", "authors": "Guohun Zhu", "title": "The Complexity of Determining Existence a Hamiltonian Cycle is $O(n^3)$", "comments": "6 papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": null, "abstract": "  The Hamiltonian cycle problem in digraph is mapped into a matching cover\nbipartite graph. Based on this mapping, it is proved that determining existence\na Hamiltonian cycle in graph is $O(n^3)$.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2007 07:57:51 GMT"}], "update_date": "2007-06-20", "authors_parsed": [["Zhu", "Guohun", ""]]}
{"id": "0706.2732", "submitter": "Cyrille Chavet", "authors": "Cyrille Chavet (LESTER), Philippe Coussy (LESTER), Pascal Urard (STM),\n  Eric Martin (LESTER)", "title": "A Design Methodology for Space-Time Adapter", "comments": "ISBN : 978-1-59593-606-8", "journal-ref": "Proceedings of the 2007 ACM Great Lakes Symposium on VLSI\n  (12/03/2007) 347", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents a solution to efficiently explore the design space of\ncommunication adapters. In most digital signal processing (DSP) applications,\nthe overall architecture of the system is significantly affected by\ncommunication architecture, so the designers need specifically optimized\nadapters. By explicitly modeling these communications within an effective\ngraph-theoretic model and analysis framework, we automatically generate an\noptimized architecture, named Space-Time AdapteR (STAR). Our design flow inputs\na C description of Input/Output data scheduling, and user requirements\n(throughput, latency, parallelism...), and formalizes communication constraints\nthrough a Resource Constraints Graph (RCG). The RCG properties enable an\nefficient architecture space exploration in order to synthesize a STAR\ncomponent. The proposed approach has been tested to design an industrial data\nmixing block example: an Ultra-Wideband interleaver.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2007 14:18:57 GMT"}], "update_date": "2007-06-20", "authors_parsed": [["Chavet", "Cyrille", "", "LESTER"], ["Coussy", "Philippe", "", "LESTER"], ["Urard", "Pascal", "", "STM"], ["Martin", "Eric", "", "LESTER"]]}
{"id": "0706.2746", "submitter": "Stefano Tessaro", "authors": "Robert Koenig, Ueli Maurer, Stefano Tessaro", "title": "Abstract Storage Devices", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.IT math.IT", "license": null, "abstract": "  A quantum storage device differs radically from a conventional physical\nstorage device. Its state can be set to any value in a certain (infinite) state\nspace, but in general every possible read operation yields only partial\ninformation about the stored state.\n  The purpose of this paper is to initiate the study of a combinatorial\nabstraction, called abstract storage device (ASD), which models deterministic\nstorage devices with the property that only partial information about the state\ncan be read, but that there is a degree of freedom as to which partial\ninformation should be retrieved.\n  This concept leads to a number of interesting problems which we address, like\nthe reduction of one device to another device, the equivalence of devices,\ndirect products of devices, as well as the factorization of a device into\nprimitive devices. We prove that every ASD has an equivalent ASD with minimal\nnumber of states and of possible read operations. Also, we prove that the\nreducibility problem for ASD's is NP-complete, that the equivalence problem is\nat least as hard as the graph isomorphism problem, and that the factorization\ninto binary-output devices (if it exists) is unique.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2007 17:14:24 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Koenig", "Robert", ""], ["Maurer", "Ueli", ""], ["Tessaro", "Stefano", ""]]}
{"id": "0706.2824", "submitter": "Cyrille Chavet", "authors": "Cyrille Chavet (LESTER, STM), Philippe Coussy (LESTER), Pascal Urard\n  (STM), Eric Martin (LESTER)", "title": "M\\'ethodologie de mod\\'elisation et d'impl\\'ementation d'adaptateurs\n  spatio-temporels", "comments": null, "journal-ref": "Actes de la conference MajecSTIC 2005 (16/11/2005) 151", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The re-use of pre-designed blocks is a well-known concept of the software\ndevelopment. This technique has been applied to System-on-Chip (SoC) design\nwhose complexity and heterogeneity are growing. The re-use is made thanks to\nhigh level components, called virtual components (IP), available in more or\nless flexible forms. These components are dedicated blocks: digital signal\nprocessing (DCT, FFT), telecommunications (Viterbi, TurboCodes),... These\nblocks rest on a model of fixed architecture with very few degrees of\npersonalization. This rigidity is particularly true for the communication\ninterface whose orders of acquisition and production of data, the temporal\nbehavior and protocols of exchanges are fixed. The successful integration of\nsuch an IP requires that the designer (1) synchronizes the components (2)\nconverts the protocols between \"incompatible\" blocks (3) temporizes the data to\nguarantee the temporal constraints and the order of the data. This phase\nremains however very manual and source of errors. Our approach proposes a\nformal modeling, based on an original Ressource Compatibility Graph. The\nsynthesis flow is based on a set of transformations of the initial graph to\nlead to an interface architecture allowing the space-time adaptation of the\ndata exchanges between several components.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2007 15:56:43 GMT"}], "update_date": "2007-06-20", "authors_parsed": [["Chavet", "Cyrille", "", "LESTER, STM"], ["Coussy", "Philippe", "", "LESTER"], ["Urard", "Pascal", "", "STM"], ["Martin", "Eric", "", "LESTER"]]}
{"id": "0706.2893", "submitter": "Greg Sepesi", "authors": "Greg Sepesi", "title": "Dualheap Sort Algorithm: An Inherently Parallel Generalization of\n  Heapsort", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC", "license": null, "abstract": "  A generalization of the heapsort algorithm is proposed. At the expense of\nabout 50% more comparison and move operations for typical cases, the dualheap\nsort algorithm offers several advantages over heapsort: improved cache\nperformance, better performance if the input happens to be already sorted, and\neasier parallel implementations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2007 14:42:45 GMT"}], "update_date": "2007-06-21", "authors_parsed": [["Sepesi", "Greg", ""]]}
{"id": "0706.3009", "submitter": "Cyrille Chavet", "authors": "Cyrille Chavet (LESTER, STM), Philippe Coussy (LESTER), Pascal Urard\n  (STM), Eric Martin (LESTER)", "title": "Application of a design space exploration tool to enhance interleaver\n  generation", "comments": null, "journal-ref": "Proceedings of the European Signal Processing Conference\n  (EUSIPCO-2007) (03/09/2007)", "doi": null, "report-no": null, "categories": "cs.AR cs.IT math.IT", "license": null, "abstract": "  This paper presents a methodology to efficiently explore the design space of\ncommunication adapters. In most digital signal processing (DSP) applications,\nthe overall performance of the system is significantly affected by\ncommunication architectures, as a consequence the designers need specifically\noptimized adapters. By explicitly modeling these communications within an\neffective graph-theoretic model and analysis framework, we automatically\ngenerate an optimized architecture, named Space-Time AdapteR (STAR). Our design\nflow inputs a C description of Input/Output data scheduling, and user\nrequirements (throughput, latency, parallelism...), and formalizes\ncommunication constraints through a Resource Constraints Graph (RCG). Design\nspace exploration is then performed through associated tools, to synthesize a\nSTAR component under time-to-market constraints. The proposed approach has been\ntested to design an industrial data mixing block example: an Ultra-Wideband\ninterleaver.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2007 15:19:01 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Chavet", "Cyrille", "", "LESTER, STM"], ["Coussy", "Philippe", "", "LESTER"], ["Urard", "Pascal", "", "STM"], ["Martin", "Eric", "", "LESTER"]]}
{"id": "0706.3060", "submitter": "Eric Darve", "authors": "Erich Elsen, V. Vishal, Mike Houston, Vijay Pande, Pat Hanrahan, Eric\n  Darve", "title": "N-Body Simulations on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC", "license": null, "abstract": "  Commercial graphics processors (GPUs) have high compute capacity at very low\ncost, which makes them attractive for general purpose scientific computing. In\nthis paper we show how graphics processors can be used for N-body simulations\nto obtain improvements in performance over current generation CPUs. We have\ndeveloped a highly optimized algorithm for performing the O(N^2) force\ncalculations that constitute the major part of stellar and molecular dynamics\nsimulations. In some of the calculations, we achieve sustained performance of\nnearly 100 GFlops on an ATI X1900XTX. The performance on GPUs is comparable to\nspecialized processors such as GRAPE-6A and MDGRAPE-3, but at a fraction of the\ncost. Furthermore, the wide availability of GPUs has significant implications\nfor cluster computing and distributed computing efforts like Folding@Home.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2007 21:02:14 GMT"}], "update_date": "2007-06-22", "authors_parsed": [["Elsen", "Erich", ""], ["Vishal", "V.", ""], ["Houston", "Mike", ""], ["Pande", "Vijay", ""], ["Hanrahan", "Pat", ""], ["Darve", "Eric", ""]]}
{"id": "0706.3412", "submitter": "Blai Bonet", "authors": "Nerio Borges, Blai Bonet", "title": "On Canonical Forms of Complete Problems via First-order Projections", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  The class of problems complete for NP via first-order reductions is known to\nbe characterized by existential second-order sentences of a fixed form. All\nsuch sentences are built around the so-called generalized IS-form of the\nsentence that defines Independent-Set. This result can also be understood as\nthat every sentence that defines a NP-complete problem P can be decomposed in\ntwo disjuncts such that the first one characterizes a fragment of P as hard as\nIndependent-Set and the second the rest of P. That is, a decomposition that\ndivides every such sentence into a quotient and residue modulo Independent-Set.\n  In this paper, we show that this result can be generalized over a wide\ncollection of complexity classes, including the so-called nice classes.\nMoreover, we show that such decomposition can be done for any complete problem\nwith respect to the given class, and that two such decompositions are\nnon-equivalent in general. Interestingly, our results are based on simple and\nwell-known properties of first-order reductions.ow that this result can be\ngeneralized over a wide collection of complexity classes, including the\nso-called nice classes. Moreover, we show that such decomposition can be done\nfor any complete problem with respect to the given class, and that two such\ndecompositions are non-equivalent in general. Interestingly, our results are\nbased on simple and well-known properties of first-order reductions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2007 21:27:06 GMT"}], "update_date": "2007-06-26", "authors_parsed": [["Borges", "Nerio", ""], ["Bonet", "Blai", ""]]}
{"id": "0706.3459", "submitter": "Gabor Kun", "authors": "Gabor Kun, Jaroslav Nesetril", "title": "NP by means of lifts and shadows", "comments": "12 pages, conference (MFCS07) version of 0706.1704", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": null, "abstract": "  We show that every NP problem is polynomially equivalent to a simple\ncombinatorial problem: the membership problem for a special class of digraphs.\nThese classes are defined by means of shadows (projections) and by finitely\nmany forbidden colored (lifted) subgraphs. Our characterization is motivated by\nthe analysis of syntactical subclasses with the full computational power of NP,\nwhich were first studied by Feder and Vardi.\n  Our approach applies to many combinatorial problems and it induces the\ncharacterization of coloring problems (CSP) defined by means of shadows. This\nturns out to be related to homomorphism dualities. We prove that a class of\ndigraphs (relational structures) defined by finitely many forbidden colored\nsubgraphs (i.e. lifted substructures) is a CSP class if and only if all the the\nforbidden structures are homomorphically equivalent to trees. We show a\nsurprising richness of coloring problems when restricted to most frequent graph\nclasses. Using results of Ne\\v{s}et\\v{r}il and Ossona de Mendez for bounded\nexpansion classes (which include bounded degree and proper minor closed\nclasses) we prove that the restriction of every class defined as the shadow of\nfinitely many colored subgraphs equals to the restriction of a coloring (CSP)\nclass.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2007 15:40:43 GMT"}], "update_date": "2007-06-27", "authors_parsed": [["Kun", "Gabor", ""], ["Nesetril", "Jaroslav", ""]]}
{"id": "0706.3523", "submitter": "Olivier Finkel", "authors": "Dominique Lecomte (UMR 7586), Olivier Finkel (LIP)", "title": "There Exist some Omega-Powers of Any Borel Rank", "comments": "To appear in the Proceedings of the 16th EACSL Annual Conference on\n  Computer Science and Logic, CSL 2007, Lausanne, Switzerland, September 11-15,\n  2007, Lecture Notes in Computer Science, (c) Springer, 2007", "journal-ref": "Dans Proceedings of the 16th EACSL Annual Conference on Computer\n  Science and Logic, CSL 2007, - 16th EACSL Annual Conference on Computer\n  Science and Logic, CSL 2007, September 11-15, 2007, Lausanne : Suisse", "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": null, "abstract": "  Omega-powers of finitary languages are languages of infinite words\n(omega-languages) in the form V^omega, where V is a finitary language over a\nfinite alphabet X. They appear very naturally in the characterizaton of regular\nor context-free omega-languages. Since the set of infinite words over a finite\nalphabet X can be equipped with the usual Cantor topology, the question of the\ntopological complexity of omega-powers of finitary languages naturally arises\nand has been posed by Niwinski (1990), Simonnet (1992) and Staiger (1997). It\nhas been recently proved that for each integer n > 0, there exist some\nomega-powers of context free languages which are Pi^0_n-complete Borel sets,\nthat there exists a context free language L such that L^omega is analytic but\nnot Borel, and that there exists a finitary language V such that V^omega is a\nBorel set of infinite rank. But it was still unknown which could be the\npossible infinite Borel ranks of omega-powers. We fill this gap here, proving\nthe following very surprising result which shows that omega-powers exhibit a\ngreat topological complexity: for each non-null countable ordinal alpha, there\nexist some Sigma^0_alpha-complete omega-powers, and some Pi^0_alpha-complete\nomega-powers.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2007 16:03:36 GMT"}], "update_date": "2008-03-12", "authors_parsed": [["Lecomte", "Dominique", "", "UMR 7586"], ["Finkel", "Olivier", "", "LIP"]]}
{"id": "0706.3639", "submitter": "Marcus Hutter", "authors": "Shane Legg and Marcus Hutter", "title": "A Collection of Definitions of Intelligence", "comments": "12 LaTeX pages", "journal-ref": "Frontiers in Artificial Intelligence and Applications, Vol.157\n  (2007) 17-24", "doi": null, "report-no": "IDSIA-07-07", "categories": "cs.AI", "license": null, "abstract": "  This paper is a survey of a large number of informal definitions of\n``intelligence'' that the authors have collected over the years. Naturally,\ncompiling a complete list would be impossible as many definitions of\nintelligence are buried deep inside articles and books. Nevertheless, the\n70-odd definitions presented here are, to the authors' knowledge, the largest\nand most well referenced collection there is.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2007 13:40:56 GMT"}], "update_date": "2007-06-26", "authors_parsed": [["Legg", "Shane", ""], ["Hutter", "Marcus", ""]]}
{"id": "0706.4044", "submitter": "Lutz Schr\\\"oder", "authors": "Lutz Schr\\\"oder and Dirk Pattinson", "title": "PSPACE Bounds for Rank-1 Modal Logics", "comments": null, "journal-ref": "ACM Transactions on Computational Logic 10 (2:13), pp. 1-33, 2009", "doi": "10.1145/1462179.1462185", "report-no": "Imperial College TR 2007/4", "categories": "cs.LO cs.CC", "license": null, "abstract": "  For lack of general algorithmic methods that apply to wide classes of logics,\nestablishing a complexity bound for a given modal logic is often a laborious\ntask. The present work is a step towards a general theory of the complexity of\nmodal logics. Our main result is that all rank-1 logics enjoy a shallow model\nproperty and thus are, under mild assumptions on the format of their\naxiomatisation, in PSPACE. This leads to a unified derivation of tight\nPSPACE-bounds for a number of logics including K, KD, coalition logic, graded\nmodal logic, majority logic, and probabilistic modal logic. Our generic\nalgorithm moreover finds tableau proofs that witness pleasant proof-theoretic\nproperties including a weak subformula property. This generality is made\npossible by a coalgebraic semantics, which conveniently abstracts from the\ndetails of a given model class and thus allows covering a broad range of logics\nin a uniform way.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2007 15:15:57 GMT"}], "update_date": "2011-01-18", "authors_parsed": [["Schröder", "Lutz", ""], ["Pattinson", "Dirk", ""]]}
{"id": "0706.4095", "submitter": "Ilya Kapovich", "authors": "Ilya Kapovich and Paul Schupp", "title": "Some Quantitative Aspects of Fractional Computability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC", "license": null, "abstract": "  Motivated by results on generic-case complexity in group theory, we apply the\nideas of effective Baire category and effective measure theory to study\ncomplexity classes of functions which are \"fractionally computable\" by a\npartial algorithm. For this purpose it is crucial to specify an allowable\neffective density, $\\delta$, of convergence for a partial algorithm. The set\n$\\mathcal{FC}(\\delta)$ consists of all total functions $ f: \\Sigma^\\ast \\to\n\\{0,1 \\}$ where $\\Sigma$ is a finite alphabet with $|\\Sigma| \\ge 2$ which are\n\"fractionally computable at density $\\delta$\". The space $\\mathcal{FC}(\\delta)\n$ is effectively of the second category while any fractional complexity class,\ndefined using $\\delta$ and any computable bound $\\beta$ with respect to an\nabstract Blum complexity measure, is effectively meager. A remarkable result of\nKautz and Miltersen shows that relative to an algorithmically random oracle\n$A$, the relativized class $\\mathcal{NP}^A$ does not have effective polynomial\nmeasure zero in $\\mathcal{E}^A$, the relativization of strict exponential time.\nWe define the class $\\mathcal{UFP}^A$ of all languages which are fractionally\ndecidable in polynomial time at ``a uniform rate'' by algorithms with an oracle\nfor $A$. We show that this class does have effective polynomial measure zero in\n$\\mathcal{E}^A$ for every oracle $A$. Thus relaxing the requirement of\npolynomial time decidability to hold only for a fraction of possible inputs\ndoes not compensate for the power of nondeterminism in the case of random\noracles.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2007 20:26:19 GMT"}], "update_date": "2007-06-30", "authors_parsed": [["Kapovich", "Ilya", ""], ["Schupp", "Paul", ""]]}
{"id": "0706.4161", "submitter": "Maurice Margenstern", "authors": "Maurice Margenstern", "title": "The Domino Problem of the Hyperbolic Plane Is Undecidable", "comments": "18 pages, This is a synthesis of previous deposits", "journal-ref": "The Bulletin of EATCS, 93(Oct.), (2007), 220-237", "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": null, "abstract": "  In this paper, we prove that the general tiling problem of the hyperbolic\nplane is undecidable by proving a slightly stronger version using only a\nregular polygon as the basic shape of the tiles. The problem was raised by a\npaper of Raphael Robinson in 1971, in his famous simplified proof that the\ngeneral tiling problem is undecidable for the Euclidean plane, initially proved\nby Robert Berger in 1966.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2007 09:16:19 GMT"}], "update_date": "2008-04-19", "authors_parsed": [["Margenstern", "Maurice", ""]]}
{"id": "0706.4323", "submitter": "Khalil Djelloul", "authors": "Khalil Djelloul, Thi-bich-hanh Dao and Thom Fruehwirth", "title": "Theory of Finite or Infinite Trees Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": null, "abstract": "  We present in this paper a first-order axiomatization of an extended theory\n$T$ of finite or infinite trees, built on a signature containing an infinite\nset of function symbols and a relation $\\fini(t)$ which enables to distinguish\nbetween finite or infinite trees. We show that $T$ has at least one model and\nprove its completeness by giving not only a decision procedure, but a full\nfirst-order constraint solver which gives clear and explicit solutions for any\nfirst-order constraint satisfaction problem in $T$. The solver is given in the\nform of 16 rewriting rules which transform any first-order constraint $\\phi$\ninto an equivalent disjunction $\\phi$ of simple formulas such that $\\phi$ is\neither the formula $\\true$ or the formula $\\false$ or a formula having at least\none free variable, being equivalent neither to $\\true$ nor to $\\false$ and\nwhere the solutions of the free variables are expressed in a clear and explicit\nway. The correctness of our rules implies the completeness of $T$. We also\ndescribe an implementation of our algorithm in CHR (Constraint Handling Rules)\nand compare the performance with an implementation in C++ and that of a recent\ndecision procedure for decomposable theories.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2007 21:18:19 GMT"}], "update_date": "2007-07-02", "authors_parsed": [["Djelloul", "Khalil", ""], ["Dao", "Thi-bich-hanh", ""], ["Fruehwirth", "Thom", ""]]}
{"id": "0706.4375", "submitter": "Thierry Hamon", "authors": "Thierry Hamon (LIPN), Adeline Nazarenko (LIPN), Thierry Poibeau\n  (LIPN), Sophie Aubin (LIPN), Julien Derivi\\`ere (LIPN)", "title": "A Robust Linguistic Platform for Efficient and Domain specific Web\n  Content Analysis", "comments": null, "journal-ref": "Proceedings of RIAO 2007 (30/05/2007)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Web semantic access in specific domains calls for specialized search engines\nwith enhanced semantic querying and indexing capacities, which pertain both to\ninformation retrieval (IR) and to information extraction (IE). A rich\nlinguistic analysis is required either to identify the relevant semantic units\nto index and weight them according to linguistic specific statistical\ndistribution, or as the basis of an information extraction process. Recent\ndevelopments make Natural Language Processing (NLP) techniques reliable enough\nto process large collections of documents and to enrich them with semantic\nannotations. This paper focuses on the design and the development of a text\nprocessing platform, Ogmios, which has been developed in the ALVIS project. The\nOgmios platform exploits existing NLP modules and resources, which may be tuned\nto specific domains and produces linguistically annotated documents. We show\nhow the three constraints of genericity, domain semantic awareness and\nperformance can be handled all together.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2007 08:58:02 GMT"}], "update_date": "2007-07-02", "authors_parsed": [["Hamon", "Thierry", "", "LIPN"], ["Nazarenko", "Adeline", "", "LIPN"], ["Poibeau", "Thierry", "", "LIPN"], ["Aubin", "Sophie", "", "LIPN"], ["Derivière", "Julien", "", "LIPN"]]}
{"id": "0707.0181", "submitter": "Yuriy Bunyak", "authors": "Yu. Bunyak and O. Bunyak", "title": "Location and Spectral Estimation of Weak Wave Packets on Noise\n  Background", "comments": "7 pages, 8 figures. Extended version of presentation in the\n  conferences IMTC-2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  The method of location and spectral estimation of weak signals on a noise\nbackground is being considered. The method is based on the optimized on order\nand noise dispersion autoregressive model of a sought signal. A new approach of\nmodel order determination is being offered. Available estimation of the noise\ndispersion is close to the real one. The optimized model allows to define\nfunction of empirical data spectral and dynamic features changes. The analysis\nof the signal as dynamic invariant in respect of the linear shift\ntransformation yields the function of model consistency. Use of these both\nfunctions enables to detect short-time and nonstationary wave packets at signal\nto noise ratio as from -20 dB and above.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2007 09:47:33 GMT"}], "update_date": "2007-07-03", "authors_parsed": [["Bunyak", "Yu.", ""], ["Bunyak", "O.", ""]]}
{"id": "0707.0282", "submitter": "Igor Razgon", "authors": "Igor Razgon and Barry O'Sullivan", "title": "Directed Feedback Vertex Set is Fixed-Parameter Tractable", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  We resolve positively a long standing open question regarding the\nfixed-parameter tractability of the parameterized Directed Feedback Vertex Set\nproblem. In particular, we propose an algorithm which solves this problem in\n$O(8^kk!*poly(n))$.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2007 17:56:53 GMT"}], "update_date": "2007-07-03", "authors_parsed": [["Razgon", "Igor", ""], ["O'Sullivan", "Barry", ""]]}
{"id": "0707.0336", "submitter": "Erhan Bayraktar", "authors": "Erhan Bayraktar", "title": "Pricing Options on Defaultable Stocks", "comments": "Key Words: Option pricing, multiscale perturbation methods,\n  defaultable stocks, stochastic intensity of default, implied volatility skew", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  In this note, we develop stock option price approximations for a model which\ntakes both the risk o default and the stochastic volatility into account. We\nalso let the intensity of defaults be influenced by the volatility. We show\nthat it might be possible to infer the risk neutral default intensity from the\nstock option prices. Our option price approximation has a rich implied\nvolatility surface structure and fits the data implied volatility well. Our\ncalibration exercise shows that an effective hazard rate from bonds issued by a\ncompany can be used to explain the implied volatility skew of the implied\nvolatility of the option prices issued by the same company.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2007 03:28:35 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2007 01:08:18 GMT"}], "update_date": "2007-12-21", "authors_parsed": [["Bayraktar", "Erhan", ""]]}
{"id": "0707.0421", "submitter": "Riccardo Dondi", "authors": "Paola Bonizzoni, Gianluca Della Vedova, Riccardo Dondi", "title": "The $k$-anonymity Problem is Hard", "comments": "21 pages, A short version of this paper has been accepted in FCT 2009\n  - 17th International Symposium on Fundamentals of Computation Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of publishing personal data without giving up privacy is becoming\nincreasingly important. An interesting formalization recently proposed is the\nk-anonymity. This approach requires that the rows in a table are clustered in\nsets of size at least k and that all the rows in a cluster become the same\ntuple, after the suppression of some records. The natural optimization problem,\nwhere the goal is to minimize the number of suppressed entries, is known to be\nNP-hard when the values are over a ternary alphabet, k = 3 and the rows length\nis unbounded. In this paper we give a lower bound on the approximation factor\nthat any polynomial-time algorithm can achive on two restrictions of the\nproblem,namely (i) when the records values are over a binary alphabet and k =\n3, and (ii) when the records have length at most 8 and k = 4, showing that\nthese restrictions of the problem are APX-hard.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2007 14:17:49 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2009 16:40:37 GMT"}], "update_date": "2009-06-02", "authors_parsed": [["Bonizzoni", "Paola", ""], ["Della Vedova", "Gianluca", ""], ["Dondi", "Riccardo", ""]]}
{"id": "0707.0430", "submitter": "Branislav Rovan", "authors": "Peter Ga\\v{z}i, Branislav Rovan", "title": "Assisted Problem Solving and Decompositions of Finite Automata", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  A study of assisted problem solving formalized via decompositions of\ndeterministic finite automata is initiated. The landscape of new types of\ndecompositions of finite automata this study uncovered is presented. Languages\nwith various degrees of decomposability between undecomposable and perfectly\ndecomposable are shown to exist.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2007 14:54:53 GMT"}], "update_date": "2007-07-04", "authors_parsed": [["Gaži", "Peter", ""], ["Rovan", "Branislav", ""]]}
{"id": "0707.0498", "submitter": "Roy Murphy Dr", "authors": "Roy E. Murphy", "title": "The Role of Time in the Creation of Knowledge", "comments": "Adaptive Processes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": null, "abstract": "  This paper I assume that in humans the creation of knowledge depends on a\ndiscrete time, or stage, sequential decision-making process subjected to a\nstochastic, information transmitting environment. For each time-stage, this\nenvironment randomly transmits Shannon type information-packets to the\ndecision-maker, who examines each of them for relevancy and then determines his\noptimal choices. Using this set of relevant information-packets, the\ndecision-maker adapts, over time, to the stochastic nature of his environment,\nand optimizes the subjective expected rate-of-growth of knowledge. The\ndecision-maker's optimal actions, lead to a decision function that involves,\nover time, his view of the subjective entropy of the environmental process and\nother important parameters at each time-stage of the process. Using this model\nof human behavior, one could create psychometric experiments using computer\nsimulation and real decision-makers, to play programmed games to measure the\nresulting human performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2007 20:43:43 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Murphy", "Roy E.", ""]]}
{"id": "0707.0610", "submitter": "Joseph O'Rourke", "authors": "Joseph O'Rourke", "title": "Unfolding Orthogonal Terrains", "comments": "7 pages, 7 figures, 5 references. First revision adds Figure 7, and\n  improves Figure 6. Second revision further improves Figure 7, and adds one\n  clarifying sentence. Third corrects label in Figure 7. Fourth revision\n  corrects a sentence in the conclusion about the class of shapes now known to\n  be grid-unfoldable", "journal-ref": null, "doi": null, "report-no": "Smith Technical Report 084", "categories": "cs.CG", "license": null, "abstract": "  It is shown that every orthogonal terrain, i.e., an orthogonal (right-angled)\npolyhedron based on a rectangle that meets every vertical line in a segment,\nhas a grid unfolding: its surface may be unfolded to a single non-overlapping\npiece by cutting along grid edges defined by coordinate planes through every\nvertex.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2007 15:04:33 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2007 18:11:20 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2007 12:39:04 GMT"}, {"version": "v4", "created": "Thu, 12 Jul 2007 13:16:38 GMT"}], "update_date": "2007-07-12", "authors_parsed": [["O'Rourke", "Joseph", ""]]}
{"id": "0707.0701", "submitter": "Alexandre d'Aspremont", "authors": "Ronny Luss, Alexandre d'Aspremont", "title": "Clustering and Feature Selection using Sparse Principal Component\n  Analysis", "comments": "More experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the application of sparse principal component\nanalysis (PCA) to clustering and feature selection problems. Sparse PCA seeks\nsparse factors, or linear combinations of the data variables, explaining a\nmaximum amount of variance in the data while having only a limited number of\nnonzero coefficients. PCA is often used as a simple clustering technique and\nsparse factors allow us here to interpret the clusters in terms of a reduced\nset of variables. We begin with a brief introduction and motivation on sparse\nPCA and detail our implementation of the algorithm in d'Aspremont et al.\n(2005). We then apply these results to some classic clustering and feature\nselection problems arising in biology.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2007 21:53:11 GMT"}, {"version": "v2", "created": "Wed, 8 Oct 2008 18:41:53 GMT"}], "update_date": "2008-10-08", "authors_parsed": [["Luss", "Ronny", ""], ["d'Aspremont", "Alexandre", ""]]}
{"id": "0707.0704", "submitter": "Alexandre d'Aspremont", "authors": "Onureena Banerjee, Laurent El Ghaoui, Alexandre d'Aspremont", "title": "Model Selection Through Sparse Maximum Likelihood Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": null, "abstract": "  We consider the problem of estimating the parameters of a Gaussian or binary\ndistribution in such a way that the resulting undirected graphical model is\nsparse. Our approach is to solve a maximum likelihood problem with an added\nl_1-norm penalty term. The problem as formulated is convex but the memory\nrequirements and complexity of existing interior point methods are prohibitive\nfor problems with more than tens of nodes. We present two new algorithms for\nsolving problems with at least a thousand nodes in the Gaussian case. Our first\nalgorithm uses block coordinate descent, and can be interpreted as recursive\nl_1-norm penalized regression. Our second algorithm, based on Nesterov's first\norder method, yields a complexity estimate with a better dependence on problem\nsize than existing interior point methods. Using a log determinant relaxation\nof the log partition function (Wainwright & Jordan (2006)), we show that these\nsame algorithms can be used to solve an approximate sparse maximum likelihood\nproblem for the binary case. We test our algorithms on synthetic data, as well\nas on gene expression and senate voting records data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2007 22:13:42 GMT"}], "update_date": "2007-07-06", "authors_parsed": [["Banerjee", "Onureena", ""], ["Ghaoui", "Laurent El", ""], ["d'Aspremont", "Alexandre", ""]]}
{"id": "0707.0705", "submitter": "Alexandre d'Aspremont", "authors": "Alexandre d'Aspremont, Francis Bach, Laurent El Ghaoui", "title": "Optimal Solutions for Sparse Principal Component Analysis", "comments": "Revised journal version. More efficient optimality conditions and new\n  examples in subset selection and sparse recovery. Original version is in ICML\n  proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": null, "abstract": "  Given a sample covariance matrix, we examine the problem of maximizing the\nvariance explained by a linear combination of the input variables while\nconstraining the number of nonzero coefficients in this combination. This is\nknown as sparse principal component analysis and has a wide array of\napplications in machine learning and engineering. We formulate a new\nsemidefinite relaxation to this problem and derive a greedy algorithm that\ncomputes a full set of good solutions for all target numbers of non zero\ncoefficients, with total complexity O(n^3), where n is the number of variables.\nWe then use the same relaxation to derive sufficient conditions for global\noptimality of a solution, which can be tested in O(n^3) per pattern. We discuss\napplications in subset selection and sparse recovery and show on artificial\nexamples and biological data that our algorithm does provide globally optimal\nsolutions in many cases.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2007 22:28:28 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2007 22:30:22 GMT"}, {"version": "v3", "created": "Fri, 24 Aug 2007 00:49:31 GMT"}, {"version": "v4", "created": "Fri, 9 Nov 2007 17:27:11 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["d'Aspremont", "Alexandre", ""], ["Bach", "Francis", ""], ["Ghaoui", "Laurent El", ""]]}
{"id": "0707.0808", "submitter": "Patrick C. McGuire", "authors": "Alexandra Bartolo, Patrick C. McGuire, Kenneth P. Camilleri,\n  Christopher Spiteri, Jonathan C. Borg, Philip J. Farrugia, Jens Ormo, Javier\n  Gomez-Elvira, Jose Antonio Rodriguez-Manfredi, Enrique Diaz-Martinez, Helge\n  Ritter, Robert Haschke, Markus Oesker, Joerg Ontrup", "title": "The Cyborg Astrobiologist: Porting from a wearable computer to the\n  Astrobiology Phone-cam", "comments": "15 pages, 4 figures, accepted for publication in the International\n  Journal of Astrobiology", "journal-ref": "International Journal of Astrobiology, vol. 6, issue 4, pp.\n  255-261 (2007)", "doi": "10.1017/S1473550407003862", "report-no": null, "categories": "cs.CV astro-ph cs.AI cs.CE cs.HC cs.NI cs.RO cs.SE", "license": null, "abstract": "  We have used a simple camera phone to significantly improve an `exploration\nsystem' for astrobiology and geology. This camera phone will make it much\neasier to develop and test computer-vision algorithms for future planetary\nexploration. We envision that the `Astrobiology Phone-cam' exploration system\ncan be fruitfully used in other problem domains as well.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2007 15:19:37 GMT"}], "update_date": "2010-01-08", "authors_parsed": [["Bartolo", "Alexandra", ""], ["McGuire", "Patrick C.", ""], ["Camilleri", "Kenneth P.", ""], ["Spiteri", "Christopher", ""], ["Borg", "Jonathan C.", ""], ["Farrugia", "Philip J.", ""], ["Ormo", "Jens", ""], ["Gomez-Elvira", "Javier", ""], ["Rodriguez-Manfredi", "Jose Antonio", ""], ["Diaz-Martinez", "Enrique", ""], ["Ritter", "Helge", ""], ["Haschke", "Robert", ""], ["Oesker", "Markus", ""], ["Ontrup", "Joerg", ""]]}
{"id": "0707.0808", "submitter": "Patrick C. McGuire", "authors": "Alexandra Bartolo, Patrick C. McGuire, Kenneth P. Camilleri,\n  Christopher Spiteri, Jonathan C. Borg, Philip J. Farrugia, Jens Ormo, Javier\n  Gomez-Elvira, Jose Antonio Rodriguez-Manfredi, Enrique Diaz-Martinez, Helge\n  Ritter, Robert Haschke, Markus Oesker, Joerg Ontrup", "title": "The Cyborg Astrobiologist: Porting from a wearable computer to the\n  Astrobiology Phone-cam", "comments": "15 pages, 4 figures, accepted for publication in the International\n  Journal of Astrobiology", "journal-ref": "International Journal of Astrobiology, vol. 6, issue 4, pp.\n  255-261 (2007)", "doi": "10.1017/S1473550407003862", "report-no": null, "categories": "cs.CV astro-ph cs.AI cs.CE cs.HC cs.NI cs.RO cs.SE", "license": null, "abstract": "  We have used a simple camera phone to significantly improve an `exploration\nsystem' for astrobiology and geology. This camera phone will make it much\neasier to develop and test computer-vision algorithms for future planetary\nexploration. We envision that the `Astrobiology Phone-cam' exploration system\ncan be fruitfully used in other problem domains as well.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2007 15:19:37 GMT"}], "update_date": "2010-01-08", "authors_parsed": [["Bartolo", "Alexandra", ""], ["McGuire", "Patrick C.", ""], ["Camilleri", "Kenneth P.", ""], ["Spiteri", "Christopher", ""], ["Borg", "Jonathan C.", ""], ["Farrugia", "Philip J.", ""], ["Ormo", "Jens", ""], ["Gomez-Elvira", "Javier", ""], ["Rodriguez-Manfredi", "Jose Antonio", ""], ["Diaz-Martinez", "Enrique", ""], ["Ritter", "Helge", ""], ["Haschke", "Robert", ""], ["Oesker", "Markus", ""], ["Ontrup", "Joerg", ""]]}
{"id": "0707.0891", "submitter": "Philip Fellman", "authors": "Philip V. Fellman", "title": "The Nash Equilibrium Revisited: Chaos and Complexity Hidden in\n  Simplicity", "comments": "13 Pages, 5th International Conference on Complex Systems", "journal-ref": "InterJournal Complex Systems, 1013, 2004.\n  http://www.interjournal.org/", "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": null, "abstract": "  The Nash Equilibrium is a much discussed, deceptively complex, method for the\nanalysis of non-cooperative games. If one reads many of the commonly available\ndefinitions the description of the Nash Equilibrium is deceptively simple in\nappearance. Modern research has discovered a number of new and important\ncomplex properties of the Nash Equilibrium, some of which remain as\ncontemporary conundrums of extraordinary difficulty and complexity. Among the\nrecently discovered features which the Nash Equilibrium exhibits under various\nconditions are heteroclinic Hamiltonian dynamics, a very complex asymptotic\nstructure in the context of two-player bi-matrix games and a number of\ncomputationally complex or computationally intractable features in other\nsettings. This paper reviews those findings and then suggests how they may\ninform various market prediction strategies.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2007 00:55:01 GMT"}], "update_date": "2007-07-09", "authors_parsed": [["Fellman", "Philip V.", ""]]}
{"id": "0707.1151", "submitter": "Philip Baback Alipour", "authors": "P. B. Alipour", "title": "Logic, Design & Organization of PTVD-SHAM; A Parallel Time Varying &\n  Data Super-helical Access Memory", "comments": "34 pages, 5 figures (2 multi-figures), 1 table. v.1 & v.2: corrupt\n  file layout due to *.doc file's bad conversion; v.3: fig.2.1 corruption; v.4:\n  correction to v.1-3; v.5: major content revision, spacing levelled; v.6+:\n  theorems, hypotheses content, restructured and conformed with its new topic\n  [arXiv:0710.0244v1] published in cs.CE category. (Avoid corrupted versions.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper encompasses a super helical memory system's design, 'Boolean logic\n& image-logic' as a theoretical concept of an invention-model to 'store\ntime-data' in terms of anticipating the best memory location ever for\ndata/time. A waterfall effect is deemed to assist the process of\npotential-difference output-switch into diverse logic states in quantum dot\ncomputational methods via utilizing coiled carbon nanotubes (CCNTs) and carbon\nnanotube field effect transistors (CNFETs). A 'quantum confinement' is thus\nderived for a flow of particles in a categorized quantum well substrate with a\nnormalized capacitance rectifying high B-field flux into electromagnetic\ninduction. Multi-access of coherent sequences of 'qubit addressing' is gained\nin any magnitude as pre-defined for the orientation of array displacement.\nBriefly, Gaussian curvature of k<0 is debated in aim of specifying the 2D\nelectron gas characteristics in scenarios where data is stored in short\nintervals versus long ones e.g. when k'>(k<0) for greater CCNT diameters,\nspace-time continuum is folded by chance for the particle. This benefits from\nMaxwell-Lorentz theory in Minkowski's space-time viewpoint alike to crystal\noscillators for precise data timing purposes and radar systems e.g., time\nvarying self-clocking devices in diverse geographic locations. This application\ncould also be optional for data depository versus extraction, in the best\nsupercomputer system's locations, autonomously. For best performance in\nminimizing current limiting mechanisms including electromigration, a multilevel\nmetallization and implant process forming elevated sources/drains for the\ncircuit's staircase pyramidal construction, is discussed accordingly.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2007 19:26:06 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2007 20:48:51 GMT"}, {"version": "v3", "created": "Thu, 12 Jul 2007 18:36:06 GMT"}, {"version": "v4", "created": "Thu, 12 Jul 2007 20:06:57 GMT"}, {"version": "v5", "created": "Wed, 18 Jul 2007 11:22:22 GMT"}, {"version": "v6", "created": "Tue, 2 Oct 2007 16:31:53 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Alipour", "P. B.", ""]]}
{"id": "0707.1176", "submitter": "Deepak Chermakani Mr", "authors": "Deepak Chermakani", "title": "Expressing an NP-Complete Problem as the Solvability of a Polynomial\n  Equation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": null, "abstract": "  We demonstrate a polynomial approach to express the decision version of the\ndirected Hamiltonian Cycle Problem (HCP), which is NP-Complete, as the\nSolvability of a Polynomial Equation with a constant number of variables,\nwithin a bounded real space. We first introduce four new Theorems for a set of\nperiodic Functions with irrational periods, based on which we then use a\ntrigonometric substitution, to show how the HCP can be expressed as the\nSolvability of a single polynomial Equation with a constant number of\nvariables. The feasible solution of each of these variables is bounded within\ntwo real numbers. We point out what future work is necessary to prove that\nP=NP.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2007 04:49:47 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2007 14:08:41 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Chermakani", "Deepak", ""]]}
{"id": "0707.1364", "submitter": "Robert Gilman", "authors": "Robert Gilman, Alexei G. Miasnikov, Alexey D. Myasnikov, Alexander\n  Ushakov", "title": "Report on Generic Case Complexity", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  This article is a short introduction to generic case complexity, which is a\nrecently developed way of measuring the difficulty of a computational problem\nwhile ignoring atypical behavior on a small set of inputs. Generic case\ncomplexity applies to both recursively solvable and recursively unsolvable\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2007 18:57:08 GMT"}], "update_date": "2007-07-11", "authors_parsed": [["Gilman", "Robert", ""], ["Miasnikov", "Alexei G.", ""], ["Myasnikov", "Alexey D.", ""], ["Ushakov", "Alexander", ""]]}
{"id": "0707.1452", "submitter": "Xavier Polanco", "authors": "Xavier Polanco (INIST)", "title": "Clusters, Graphs, and Networks for Analysing Internet-Web-Supported\n  Communication within a Virtual Community", "comments": null, "journal-ref": "Advances in Knowledge Organization (2002) 364-371", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": null, "abstract": "  The proposal is to use clusters, graphs and networks as models in order to\nanalyse the Web structure. Clusters, graphs and networks provide knowledge\nrepresentation and organization. Clusters were generated by co-site analysis.\nThe sample is a set of academic Web sites from the countries belonging to the\nEuropean Union. These clusters are here revisited from the point of view of\ngraph theory and social network analysis. This is a quantitative and structural\nanalysis. In fact, the Internet is a computer network that connects people and\norganizations. Thus we may consider it to be a social network. The set of Web\nacademic sites represents an empirical social network, and is viewed as a\nvirtual community. The network structural properties are here analysed applying\ntogether cluster analysis, graph theory and social network analysis.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2007 13:47:32 GMT"}], "update_date": "2007-07-11", "authors_parsed": [["Polanco", "Xavier", "", "INIST"]]}
{"id": "0707.1515", "submitter": "Gun Srijuntongsiri", "authors": "Gun Srijuntongsiri, Stephen A. Vavasis", "title": "Properties of polynomial bases used in a line-surface intersection\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [5], Srijuntongsiri and Vavasis propose the \"Kantorovich-Test Subdivision\nalgorithm\", or KTS, which is an algorithm for finding all zeros of a polynomial\nsystem in a bounded region of the plane. This algorithm can be used to find the\nintersections between a line and a surface. The main features of KTS are that\nit can operate on polynomials represented in any basis that satisfies certain\nconditions and that its efficiency has an upper bound that depends only on the\nconditioning of the problem and the choice of the basis representing the\npolynomial system.\n  This article explores in detail the dependence of the efficiency of the KTS\nalgorithm on the choice of basis. Three bases are considered: the power, the\nBernstein, and the Chebyshev bases. These three bases satisfy the basis\nproperties required by KTS. Theoretically, Chebyshev case has the smallest\nupper bound on its running time. The computational results, however, do not\nshow that Chebyshev case performs better than the other two.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2007 18:56:05 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2007 00:37:41 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2007 03:20:49 GMT"}, {"version": "v4", "created": "Mon, 8 Sep 2008 09:18:56 GMT"}, {"version": "v5", "created": "Fri, 27 Feb 2009 10:43:30 GMT"}], "update_date": "2009-02-27", "authors_parsed": [["Srijuntongsiri", "Gun", ""], ["Vavasis", "Stephen A.", ""]]}
{"id": "0707.2376", "submitter": "Francesc Rossell\\'o", "authors": "Gabriel Cardona, Francesc Rossello, Gabriel Valiente", "title": "Tripartitions do not always discriminate phylogenetic networks", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE cs.DM", "license": null, "abstract": "  Phylogenetic networks are a generalization of phylogenetic trees that allow\nfor the representation of non-treelike evolutionary events, like recombination,\nhybridization, or lateral gene transfer. In a recent series of papers devoted\nto the study of reconstructibility of phylogenetic networks, Moret, Nakhleh,\nWarnow and collaborators introduced the so-called {tripartition metric for\nphylogenetic networks. In this paper we show that, in fact, this tripartition\nmetric does not satisfy the separation axiom of distances (zero distance means\nisomorphism, or, in a more relaxed version, zero distance means\nindistinguishability in some specific sense) in any of the subclasses of\nphylogenetic networks where it is claimed to do so. We also present a subclass\nof phylogenetic networks whose members can be singled out by means of their\nsets of tripartitions (or even clusters), and hence where the latter can be\nused to define a meaningful metric.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2007 19:59:42 GMT"}], "update_date": "2007-07-17", "authors_parsed": [["Cardona", "Gabriel", ""], ["Rossello", "Francesc", ""], ["Valiente", "Gabriel", ""]]}
{"id": "0707.2432", "submitter": "Erhan Bayraktar", "authors": "Erhan Bayraktar, Hao Xing", "title": "Pricing Asian Options for Jump Diffusions", "comments": "Key Words: Pricing Asian Options, Jump diffusions, an Iterative\n  Numerical Scheme, Classical Solutions of Integro-PDEs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a sequence of functions that uniformly converge (on compact\nsets) to the price of Asian option, which is written on a stock whose dynamics\nfollows a jump diffusion, exponentially fast. Each of the element in this\nsequence solves a parabolic partial differen- tial equation (not an\nintegro-differential equation). As a result we obtain a fast numerical\napproximation scheme whose accuracy versus speed characteristics can be\ncontrolled. We analyze the performance of our numerical algorithm on several\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2007 04:55:18 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2007 17:35:45 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2007 03:04:13 GMT"}, {"version": "v4", "created": "Sat, 12 Jan 2008 18:28:58 GMT"}, {"version": "v5", "created": "Thu, 22 May 2008 02:58:57 GMT"}, {"version": "v6", "created": "Sun, 15 Jun 2008 21:36:58 GMT"}, {"version": "v7", "created": "Wed, 29 Oct 2008 13:49:51 GMT"}], "update_date": "2008-10-29", "authors_parsed": [["Bayraktar", "Erhan", ""], ["Xing", "Hao", ""]]}
{"id": "0707.2506", "submitter": "Alain Dutech", "authors": "Raghav Aras (INRIA Lorraine - LORIA), Alain Dutech (INRIA Lorraine -\n  LORIA), Fran\\c{c}ois Charpillet (INRIA Lorraine - LORIA)", "title": "Mixed Integer Linear Programming For Exact Finite-Horizon Planning In\n  Decentralized Pomdps", "comments": null, "journal-ref": "Dans The International Conference on Automated Planning and\n  Scheduling (2007)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  We consider the problem of finding an n-agent joint-policy for the optimal\nfinite-horizon control of a decentralized Pomdp (Dec-Pomdp). This is a problem\nof very high complexity (NEXP-hard in n >= 2). In this paper, we propose a new\nmathematical programming approach for the problem. Our approach is based on two\nideas: First, we represent each agent's policy in the sequence-form and not in\nthe tree-form, thereby obtaining a very compact representation of the set of\njoint-policies. Second, using this compact representation, we solve this\nproblem as an instance of combinatorial optimization for which we formulate a\nmixed integer linear program (MILP). The optimal solution of the MILP directly\nyields an optimal joint-policy for the Dec-Pomdp. Computational experience\nshows that formulating and solving the MILP requires significantly less time to\nsolve benchmark Dec-Pomdp problems than existing algorithms. For example, the\nmulti-agent tiger problem for horizon 4 is solved in 72 secs with the MILP\nwhereas existing algorithms require several hours to solve it.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2007 12:49:30 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Aras", "Raghav", "", "INRIA Lorraine - LORIA"], ["Dutech", "Alain", "", "INRIA Lorraine -\n  LORIA"], ["Charpillet", "François", "", "INRIA Lorraine - LORIA"]]}
{"id": "0707.2562", "submitter": "Claude Tardif", "authors": "Benoit Larose, Cynthia Loten, Claude Tardif", "title": "A Characterisation of First-Order Constraint Satisfaction Problems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 3, Issue 4 (November\n  6, 2007) lmcs:1097", "doi": "10.2168/LMCS-3(4:6)2007", "report-no": null, "categories": "cs.LO cs.CC", "license": null, "abstract": "  We describe simple algebraic and combinatorial characterisations of finite\nrelational core structures admitting finitely many obstructions. As a\nconsequence, we show that it is decidable to determine whether a constraint\nsatisfaction problem is first-order definable: we show the general problem to\nbe NP-complete, and give a polynomial-time algorithm in the case of cores. A\nslight modification of this algorithm provides, for first-order definable\nCSP's, a simple poly-time algorithm to produce a solution when one exists. As\nan application of our algebraic characterisation of first order CSP's, we\ndescribe a large family of L-complete CSP's.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2007 16:23:45 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2007 10:18:41 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Larose", "Benoit", ""], ["Loten", "Cynthia", ""], ["Tardif", "Claude", ""]]}
{"id": "0707.3030", "submitter": "Matthias Brust R.", "authors": "Gregoire Danoy, Pascal Bouvry, Matthias R. Brust, Enrique Alba", "title": "Optimal Design of Ad Hoc Injection Networks by Using Genetic Algorithms", "comments": "1 page, 1 figure", "journal-ref": "Genetic and Evolutionary Computation Conference (GECCO 2007), ISBN\n  978-1-59593-697-4", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.NI", "license": null, "abstract": "  This work aims at optimizing injection networks, which consist in adding a\nset of long-range links (called bypass links) in mobile multi-hop ad hoc\nnetworks so as to improve connectivity and overcome network partitioning. To\nthis end, we rely on small-world network properties, that comprise a high\nclustering coefficient and a low characteristic path length. We investigate the\nuse of two genetic algorithms (generational and steady-state) to optimize three\ninstances of this topology control problem and present results that show\ninitial evidence of their capacity to solve it.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2007 10:07:27 GMT"}], "update_date": "2007-07-23", "authors_parsed": [["Danoy", "Gregoire", ""], ["Bouvry", "Pascal", ""], ["Brust", "Matthias R.", ""], ["Alba", "Enrique", ""]]}
{"id": "0707.3205", "submitter": "Andrew Schumann", "authors": "Andrew Schumann, Florentin Smarandache", "title": "Neutrality and Many-Valued Logics", "comments": "119 pages", "journal-ref": "A. Schumann, F. Smarandache, Neutrality and Many-Valued Logics.\n  American Research Press, 2007", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": null, "abstract": "  In this book, we consider various many-valued logics: standard, linear,\nhyperbolic, parabolic, non-Archimedean, p-adic, interval, neutrosophic, etc. We\nsurvey also results which show the tree different proof-theoretic frameworks\nfor many-valued logics, e.g. frameworks of the following deductive calculi:\nHilbert's style, sequent, and hypersequent. We present a general way that\nallows to construct systematically analytic calculi for a large family of\nnon-Archimedean many-valued logics: hyperrational-valued, hyperreal-valued, and\np-adic valued logics characterized by a special format of semantics with an\nappropriate rejection of Archimedes' axiom. These logics are built as different\nextensions of standard many-valued logics (namely, Lukasiewicz's, Goedel's,\nProduct, and Post's logics). The informal sense of Archimedes' axiom is that\nanything can be measured by a ruler. Also logical multiple-validity without\nArchimedes' axiom consists in that the set of truth values is infinite and it\nis not well-founded and well-ordered. On the base of non-Archimedean valued\nlogics, we construct non-Archimedean valued interval neutrosophic logic INL by\nwhich we can describe neutrality phenomena.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2007 10:35:37 GMT"}], "update_date": "2007-07-24", "authors_parsed": [["Schumann", "Andrew", ""], ["Smarandache", "Florentin", ""]]}
{"id": "0707.3263", "submitter": "Wojciech Wislicki", "authors": "Wojciech Wislicki", "title": "Autonomous tools for Grid management, monitoring and optimization", "comments": "The original version of this proposal was created on 22nd March 2006,\n  published as the ICM UW preprint and registered in the bibliographic database\n  of the University of Warsaw on the following Internet address:\n  http://bibliografia.icm.edu.pl/g2/main.pl?mod=p&id=51470&t=1&tytul=Autonomous&lim=100&ord=1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE hep-ex", "license": null, "abstract": "  We outline design and lines of development of autonomous tools for the\ncomputing Grid management, monitoring and optimization. The management is\nproposed to be based on the notion of utility. Grid optimization is considered\nto be application-oriented. A generic Grid simulator is proposed as an\noptimization tool for Grid structure and functionality.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2007 14:02:21 GMT"}], "update_date": "2009-07-09", "authors_parsed": [["Wislicki", "Wojciech", ""]]}
{"id": "0707.3407", "submitter": "Alexander Tiskin", "authors": "Alexander Tiskin", "title": "Faster subsequence recognition in compressed strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": null, "abstract": "  Computation on compressed strings is one of the key approaches to processing\nmassive data sets. We consider local subsequence recognition problems on\nstrings compressed by straight-line programs (SLP), which is closely related to\nLempel--Ziv compression. For an SLP-compressed text of length $\\bar m$, and an\nuncompressed pattern of length $n$, C{\\'e}gielski et al. gave an algorithm for\nlocal subsequence recognition running in time $O(\\bar mn^2 \\log n)$. We improve\nthe running time to $O(\\bar mn^{1.5})$. Our algorithm can also be used to\ncompute the longest common subsequence between a compressed text and an\nuncompressed pattern in time $O(\\bar mn^{1.5})$; the same problem with a\ncompressed pattern is known to be NP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2007 16:26:24 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2007 14:16:07 GMT"}, {"version": "v3", "created": "Fri, 11 Jan 2008 21:54:54 GMT"}, {"version": "v4", "created": "Fri, 18 Jan 2008 10:20:48 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Tiskin", "Alexander", ""]]}
{"id": "0707.3409", "submitter": "Alexander Tiskin", "authors": "Alexander Tiskin", "title": "Faster exon assembly by sparse spliced alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CE q-bio.QM", "license": null, "abstract": "  Assembling a gene from candidate exons is an important problem in\ncomputational biology. Among the most successful approaches to this problem is\n\\emph{spliced alignment}, proposed by Gelfand et al., which scores different\ncandidate exon chains within a DNA sequence of length $m$ by comparing them to\na known related gene sequence of length n, $m = \\Theta(n)$. Gelfand et al.\\\ngave an algorithm for spliced alignment running in time O(n^3). Kent et al.\\\nconsidered sparse spliced alignment, where the number of candidate exons is\nO(n), and proposed an algorithm for this problem running in time O(n^{2.5}). We\nimprove on this result, by proposing an algorithm for sparse spliced alignment\nrunning in time O(n^{2.25}). Our approach is based on a new framework of\n\\emph{quasi-local string comparison}.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2007 16:35:54 GMT"}], "update_date": "2007-07-24", "authors_parsed": [["Tiskin", "Alexander", ""]]}
{"id": "0707.3409", "submitter": "Alexander Tiskin", "authors": "Alexander Tiskin", "title": "Faster exon assembly by sparse spliced alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CE q-bio.QM", "license": null, "abstract": "  Assembling a gene from candidate exons is an important problem in\ncomputational biology. Among the most successful approaches to this problem is\n\\emph{spliced alignment}, proposed by Gelfand et al., which scores different\ncandidate exon chains within a DNA sequence of length $m$ by comparing them to\na known related gene sequence of length n, $m = \\Theta(n)$. Gelfand et al.\\\ngave an algorithm for spliced alignment running in time O(n^3). Kent et al.\\\nconsidered sparse spliced alignment, where the number of candidate exons is\nO(n), and proposed an algorithm for this problem running in time O(n^{2.5}). We\nimprove on this result, by proposing an algorithm for sparse spliced alignment\nrunning in time O(n^{2.25}). Our approach is based on a new framework of\n\\emph{quasi-local string comparison}.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2007 16:35:54 GMT"}], "update_date": "2007-07-24", "authors_parsed": [["Tiskin", "Alexander", ""]]}
{"id": "0707.3457", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "A Generalized Information Formula as the Bridge between Shannon and\n  Popper", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": null, "abstract": "  A generalized information formula related to logical probability and fuzzy\nset is deduced from the classical information formula. The new information\nmeasure accords with to Popper's criterion for knowledge evolution very much.\nIn comparison with square error criterion, the information criterion does not\nonly reflect error of a proposition, but also reflects the particularity of the\nevent described by the proposition. It gives a proposition with less logical\nprobability higher evaluation. The paper introduces how to select a prediction\nor sentence from many for forecasts and language translations according to the\ngeneralized information criterion. It also introduces the rate fidelity theory,\nwhich comes from the improvement of the rate distortion theory in the classical\ninformation theory by replacing distortion (i.e. average error) criterion with\nthe generalized mutual information criterion, for data compression and\ncommunication efficiency. Some interesting conclusions are obtained from the\nrate-fidelity function in relation to image communication. It also discusses\nhow to improve Popper's theory.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2007 00:04:32 GMT"}], "update_date": "2007-07-25", "authors_parsed": [["Lu", "Chenguang", ""]]}
{"id": "0707.3482", "submitter": "Kenton K. Yee", "authors": "Kenton K. Yee", "title": "A Bayesian Framework for Combining Valuation Estimates", "comments": "Citations at\n  http://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=240309 Review of\n  Quantitative Finance and Accounting, 30.3 (2008) forthcoming", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE nlin.AO nlin.CD nlin.SI physics.pop-ph physics.soc-ph stat.AP", "license": null, "abstract": "  Obtaining more accurate equity value estimates is the starting point for\nstock selection, value-based indexing in a noisy market, and beating benchmark\nindices through tactical style rotation. Unfortunately, discounted cash flow,\nmethod of comparables, and fundamental analysis typically yield discrepant\nvaluation estimates. Moreover, the valuation estimates typically disagree with\nmarket price. Can one form a superior valuation estimate by averaging over the\nindividual estimates, including market price? This article suggests a Bayesian\nframework for combining two or more estimates into a superior valuation\nestimate. The framework justifies the common practice of averaging over several\nestimates to arrive at a final point estimate.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2007 05:04:53 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Yee", "Kenton K.", ""]]}
{"id": "0707.3531", "submitter": "Luis Nunez A", "authors": "J. L. Chaves, G. Diaz, V. Hamar, R. Isea, F. Rojas, N. Ruiz, R.\n  Torrens, M. Uzcategui, J. Florez-Lopez, H. Hoeger, C. Mendoza, L. A. Nunez", "title": "e-Science initiatives in Venezuela", "comments": "9 pages, 4 figures", "journal-ref": "Procceedings Spanish Conference on e-Science Grid Computing, J.\n  Casado, R. Mayo y R. Munoz (Editors) CIEMAT, Madrid Spain (2007), pp 45 - 52", "doi": null, "report-no": null, "categories": "cs.CE cs.DC", "license": null, "abstract": "  Within the context of the nascent e-Science infrastructure in Venezuela, we\ndescribe several web-based scientific applications developed at the Centro\nNacional de Calculo Cientifico Universidad de Los Andes (CeCalCULA), Merida,\nand at the Instituto Venezolano de Investigaciones Cientificas (IVIC), Caracas.\nThe different strategies that have been followed for implementing quantum\nchemistry and atomic physics applications are presented. We also briefly\ndiscuss a damage portal based on dynamic, nonlinear, finite elements of lumped\ndamage mechanics and a biomedical portal developed within the framework of the\n\\textit{E-Infrastructure shared between Europe and Latin America} (EELA)\ninitiative for searching common sequences and inferring their functions in\nparasitic diseases such as leishmaniasis, chagas and malaria.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2007 12:00:43 GMT"}], "update_date": "2007-07-25", "authors_parsed": [["Chaves", "J. L.", ""], ["Diaz", "G.", ""], ["Hamar", "V.", ""], ["Isea", "R.", ""], ["Rojas", "F.", ""], ["Ruiz", "N.", ""], ["Torrens", "R.", ""], ["Uzcategui", "M.", ""], ["Florez-Lopez", "J.", ""], ["Hoeger", "H.", ""], ["Mendoza", "C.", ""], ["Nunez", "L. A.", ""]]}
{"id": "0707.3559", "submitter": "Wilson Wong", "authors": "Wilson Wong", "title": "Practical Approach to Knowledge-based Question Answering with Natural\n  Language Understanding and Advanced Reasoning", "comments": "Master of Science thesis, National Technical University College of\n  Malaysia, 2005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.IR", "license": null, "abstract": "  This research hypothesized that a practical approach in the form of a\nsolution framework known as Natural Language Understanding and Reasoning for\nIntelligence (NaLURI), which combines full-discourse natural language\nunderstanding, powerful representation formalism capable of exploiting\nontological information and reasoning approach with advanced features, will\nsolve the following problems without compromising practicality factors: 1)\nrestriction on the nature of question and response, and 2) limitation to scale\nacross domains and to real-life natural language text.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2007 14:30:27 GMT"}], "update_date": "2007-07-25", "authors_parsed": [["Wong", "Wilson", ""]]}
{"id": "0707.3781", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Bijective Faithful Translations among Default Logics", "comments": "Removed one useless section", "journal-ref": null, "doi": "10.1093/logcom/ext073", "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  In this article, we study translations between variants of defaults logics\nsuch that the extensions of the theories that are the input and the output of\nthe translation are in a bijective correspondence. We assume that a translation\ncan introduce new variables and that the result of translating a theory can\neither be produced in time polynomial in the size of the theory or its output\nis polynomial in that size; we however restrict to the case in which the\noriginal theory has extensions. This study fills a gap between two previous\npieces of work, one studying bijective translations among restrictions of\ndefault logics, and the other one studying non-bijective translations between\ndefault logics variants.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2007 17:03:57 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2007 13:46:43 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Liberatore", "Paolo", ""]]}
{"id": "0707.3972", "submitter": "Ted Pedersen", "authors": "Ted Pedersen", "title": "Learning Probabilistic Models of Word Sense Disambiguation", "comments": "195 pages", "journal-ref": "PhD dissertation, May 1998, Department of Computer Science and\n  Engineering, Southern Methodist University", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": null, "abstract": "  This dissertation presents several new methods of supervised and unsupervised\nlearning of word sense disambiguation models. The supervised methods focus on\nperforming model searches through a space of probabilistic models, and the\nunsupervised methods rely on the use of Gibbs Sampling and the Expectation\nMaximization (EM) algorithm. In both the supervised and unsupervised case, the\nNaive Bayesian model is found to perform well. An explanation for this success\nis presented in terms of learning rates and bias-variance decompositions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2007 17:02:40 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Pedersen", "Ted", ""]]}
{"id": "0707.3979", "submitter": "Refugio Vallejo", "authors": "Isidro B. Nieto and J. Refugio Vallejo", "title": "Clifford Algebra of the Vector Space of Conics for decision boundary\n  Hyperplanes in m-Euclidean Space", "comments": "12 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CG", "license": null, "abstract": "  In this paper we embed $m$-dimensional Euclidean space in the geometric\nalgebra $Cl_m $ to extend the operators of incidence in ${R^m}$ to operators of\nincidence in the geometric algebra to generalize the notion of separator to a\ndecision boundary hyperconic in the Clifford algebra of hyperconic sections\ndenoted as ${Cl}({Co}_{2})$. This allows us to extend the concept of a linear\nperceptron or the spherical perceptron in conformal geometry and introduce the\nmore general conic perceptron, namely the {elliptical perceptron}. Using\nClifford duality a vector orthogonal to the decision boundary hyperplane is\ndetermined. Experimental results are shown in 2-dimensional Euclidean space\nwhere we separate data that are naturally separated by some typical plane conic\nseparators by this procedure. This procedure is more general in the sense that\nit is independent of the dimension of the input data and hence we can speak of\nthe hyperconic elliptic perceptron.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2007 18:03:23 GMT"}], "update_date": "2007-07-27", "authors_parsed": [["Nieto", "Isidro B.", ""], ["Vallejo", "J. Refugio", ""]]}
{"id": "0707.4255", "submitter": "Iddo Tzameret", "authors": "Nachum Dershowitz and Iddo Tzameret", "title": "Complexity of Propositional Proofs under a Promise", "comments": "32 pages; a preliminary version appeared in the Proceedings of\n  ICALP'07", "journal-ref": "ACM Transactions on Computational Logic, 11(3):1-29, 2010;", "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": null, "abstract": "  We study -- within the framework of propositional proof complexity -- the\nproblem of certifying unsatisfiability of CNF formulas under the promise that\nany satisfiable formula has many satisfying assignments, where ``many'' stands\nfor an explicitly specified function $\\Lam$ in the number of variables $n$. To\nthis end, we develop propositional proof systems under different measures of\npromises (that is, different $\\Lam$) as extensions of resolution. This is done\nby augmenting resolution with axioms that, roughly, can eliminate sets of truth\nassignments defined by Boolean circuits. We then investigate the complexity of\nsuch systems, obtaining an exponential separation in the average-case between\nresolution under different size promises:\n  1. Resolution has polynomial-size refutations for all unsatisfiable 3CNF\nformulas when the promise is $\\eps\\cd2^n$, for any constant $0<\\eps<1$.\n  2. There are no sub-exponential size resolution refutations for random 3CNF\nformulas, when the promise is $2^{\\delta n}$ (and the number of clauses is\n$o(n^{3/2})$), for any constant $0<\\delta<1$.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2007 18:36:01 GMT"}], "update_date": "2010-04-19", "authors_parsed": [["Dershowitz", "Nachum", ""], ["Tzameret", "Iddo", ""]]}
{"id": "0707.4258", "submitter": "Joseph O'Rourke", "authors": "Jin-ichi Itoh, Joseph O'Rourke, Costin V\\^ilcu", "title": "Star Unfolding Convex Polyhedra via Quasigeodesic Loops", "comments": "10 pages, 7 figures. v2 improves the description of cut locus, and\n  adds references. v3 improves two figures and their captions. New version v4\n  offers a completely different proof of non-overlap in the quasigeodesic loop\n  case, and contains several other substantive improvements. This version is 23\n  pages long, with 15 figures", "journal-ref": null, "doi": null, "report-no": "Smith College Computer Science Technical Report 084", "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the notion of star unfolding to be based on a quasigeodesic loop Q\nrather than on a point. This gives a new general method to unfold the surface\nof any convex polyhedron P to a simple (non-overlapping), planar polygon: cut\nalong one shortest path from each vertex of P to Q, and cut all but one segment\nof Q.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2007 20:02:05 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2007 20:09:50 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2007 17:40:06 GMT"}, {"version": "v4", "created": "Wed, 24 Jun 2009 17:18:46 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Itoh", "Jin-ichi", ""], ["O'Rourke", "Joseph", ""], ["Vîlcu", "Costin", ""]]}
{"id": "0707.4289", "submitter": "Sheng Bao", "authors": "Stephen Gang Wu, Forrest Sheng Bao, Eric You Xu, Yu-Xuan Wang, Yi-Fan\n  Chang and Qiao-Liang Xiang", "title": "A Leaf Recognition Algorithm for Plant Classification Using\n  Probabilistic Neural Network", "comments": "6 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  In this paper, we employ Probabilistic Neural Network (PNN) with image and\ndata processing techniques to implement a general purpose automated leaf\nrecognition algorithm. 12 leaf features are extracted and orthogonalized into 5\nprincipal variables which consist the input vector of the PNN. The PNN is\ntrained by 1800 leaves to classify 32 kinds of plants with an accuracy greater\nthan 90%. Compared with other approaches, our algorithm is an accurate\nartificial intelligence approach which is fast in execution and easy in\nimplementation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2007 12:31:40 GMT"}], "update_date": "2007-07-31", "authors_parsed": [["Wu", "Stephen Gang", ""], ["Bao", "Forrest Sheng", ""], ["Xu", "Eric You", ""], ["Wang", "Yu-Xuan", ""], ["Chang", "Yi-Fan", ""], ["Xiang", "Qiao-Liang", ""]]}
{"id": "0707.4298", "submitter": "Shlomo Reisner", "authors": "M. A. Lopez, S. Reisner", "title": "A note on equipartition", "comments": "Some misprints in earlier versions are corrected, one reference is\n  added with remarks concerning it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of the existence of an equi-partition of a curve in $\\R^n$ has\nrecently been raised in the context of computational geometry. The problem is\nto show that for a (continuous) curve $\\Gamma : [0,1] \\to \\R^n$ and for any\npositive integer N, there exist points $t_0=0<t_1<...<t_{N-1}<1=t_N$, such that\n$d(\\Gamma(t_{i-1}),\\Gamma(t_i))=d(\\Gamma(t_{i}),\\Gamma(t_{i+1}))$ for all\n$i=1,...,N$, where d is a metric or even a semi-metric (a weaker notion) on\n$\\R^n$. We show here that the existence of such points, in a broader context,\nis a consequence of Brower's fixed point theorem.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2007 15:46:53 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2008 13:28:41 GMT"}, {"version": "v3", "created": "Tue, 15 Jul 2008 16:21:55 GMT"}], "update_date": "2008-07-15", "authors_parsed": [["Lopez", "M. A.", ""], ["Reisner", "S.", ""]]}
{"id": "0707.4448", "submitter": "Mohamed-Ali Belabbas", "authors": "Mohamed-Ali Belabbas and Patrick J. Wolfe", "title": "On sparse representations of linear operators and the approximation of\n  matrix products", "comments": "6 pages, 3 figures; presented at the 42nd Annual Conference on\n  Information Sciences and Systems (CISS 2008)", "journal-ref": null, "doi": "10.1109/CISS.2008.4558532", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thus far, sparse representations have been exploited largely in the context\nof robustly estimating functions in a noisy environment from a few\nmeasurements. In this context, the existence of a basis in which the signal\nclass under consideration is sparse is used to decrease the number of necessary\nmeasurements while controlling the approximation error. In this paper, we\ninstead focus on applications in numerical analysis, by way of sparse\nrepresentations of linear operators with the objective of minimizing the number\nof operations needed to perform basic operations (here, multiplication) on\nthese operators. We represent a linear operator by a sum of rank-one operators,\nand show how a sparse representation that guarantees a low approximation error\nfor the product can be obtained from analyzing an induced quadratic form. This\nconstruction in turn yields new algorithms for computing approximate matrix\nproducts.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2007 17:20:23 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2009 12:04:44 GMT"}], "update_date": "2009-06-26", "authors_parsed": [["Belabbas", "Mohamed-Ali", ""], ["Wolfe", "Patrick J.", ""]]}
{"id": "0707.4489", "submitter": "Turlough Neary", "authors": "Turlough Neary and Damien Woods", "title": "Small weakly universal Turing machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  We give small universal Turing machines with state-symbol pairs of (6, 2),\n(3, 3) and (2, 4). These machines are weakly universal, which means that they\nhave an infinitely repeated word to the left of their input and another to the\nright. They simulate Rule 110 and are currently the smallest known weakly\nuniversal Turing machines.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2007 21:40:55 GMT"}], "update_date": "2007-08-01", "authors_parsed": [["Neary", "Turlough", ""], ["Woods", "Damien", ""]]}
{"id": "0707.4565", "submitter": "Christian Hoffmann", "authors": "Markus Bl\\\"aser, Christian Hoffmann", "title": "On the Complexity of the Interlace Polynomial", "comments": "18 pages, 1 figure; new graph transformation (adding cycles) solves\n  some unknown points, error in the statement of the inapproximability result\n  fixed; a previous version has appeared in the proceedings of STACS 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": null, "abstract": "  We consider the two-variable interlace polynomial introduced by Arratia,\nBollobas and Sorkin (2004). We develop graph transformations which allow us to\nderive point-to-point reductions for the interlace polynomial. Exploiting these\nreductions we obtain new results concerning the computational complexity of\nevaluating the interlace polynomial at a fixed point. Regarding exact\nevaluation, we prove that the interlace polynomial is #P-hard to evaluate at\nevery point of the plane, except on one line, where it is trivially polynomial\ntime computable, and four lines, where the complexity is still open. This\nsolves a problem posed by Arratia, Bollobas and Sorkin (2004). In particular,\nthree specializations of the two-variable interlace polynomial, the\nvertex-nullity interlace polynomial, the vertex-rank interlace polynomial and\nthe independent set polynomial, are almost everywhere #P-hard to evaluate, too.\nFor the independent set polynomial, our reductions allow us to prove that it is\neven hard to approximate at any point except at 0.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2007 12:23:13 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2007 09:34:17 GMT"}, {"version": "v3", "created": "Wed, 16 Apr 2008 13:51:09 GMT"}], "update_date": "2008-04-16", "authors_parsed": [["Bläser", "Markus", ""], ["Hoffmann", "Christian", ""]]}
{"id": "0707.4618", "submitter": "Shmuel Onn", "authors": "Yael Berstein, Jon Lee, Hugo Maruri-Aguilar, Shmuel Onn, Eva\n  Riccomagno, Robert Weismantel, Henry Wynn", "title": "Nonlinear Matroid Optimization and Experimental Design", "comments": null, "journal-ref": "SIAM Journal on Discrete Mathematics, 22:901--919, 2008", "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM math.OC", "license": null, "abstract": "  We study the problem of optimizing nonlinear objective functions over\nmatroids presented by oracles or explicitly. Such functions can be interpreted\nas the balancing of multi-criteria optimization. We provide a combinatorial\npolynomial time algorithm for arbitrary oracle-presented matroids, that makes\nrepeated use of matroid intersection, and an algebraic algorithm for vectorial\nmatroids.\n  Our work is partly motivated by applications to minimum-aberration\nmodel-fitting in experimental design in statistics, which we discuss and\ndemonstrate in detail.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2007 13:54:07 GMT"}], "update_date": "2008-07-24", "authors_parsed": [["Berstein", "Yael", ""], ["Lee", "Jon", ""], ["Maruri-Aguilar", "Hugo", ""], ["Onn", "Shmuel", ""], ["Riccomagno", "Eva", ""], ["Weismantel", "Robert", ""], ["Wynn", "Henry", ""]]}
{"id": "0708.0353", "submitter": "Dariusz Grech", "authors": "D. Grech, G. Pamu{\\l}a (University of Wroclaw, ITP)", "title": "The Local Fractal Properties of the Financial Time Series on the Polish\n  Stock Exchange Market", "comments": "LaTeX, 14 pages, 12 figures included", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE physics.data-an", "license": null, "abstract": "  We investigate the local fractal properties of the financial time series\nbased on the evolution of the Warsaw Stock Exchange Index (WIG) connected with\nthe largest developing financial market in Europe. Calculating the local Hurst\nexponent for the WIG time series we find an interesting dependence between the\nbehavior of the local fractal properties of the WIG time series and the crashes\nappearance on the financial market.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 14:22:30 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Grech", "D.", "", "University of Wroclaw, ITP"], ["Pamuła", "G.", "", "University of Wroclaw, ITP"]]}
{"id": "0708.0505", "submitter": "Luca Di Gaspero PhD", "authors": "Luca Di Gaspero, Andrea Roli", "title": "A preliminary analysis on metaheuristics methods applied to the\n  Haplotype Inference Problem", "comments": "22 pages, 4 figures Technical Report: DEIS - Alma Mater Studiorum,\n  University of Bologna no. DEIS-LIA-006-07", "journal-ref": null, "doi": null, "report-no": "DEIS-LIA-006-07", "categories": "cs.AI cs.CE cs.DM q-bio.QM", "license": null, "abstract": "  Haplotype Inference is a challenging problem in bioinformatics that consists\nin inferring the basic genetic constitution of diploid organisms on the basis\nof their genotype. This information allows researchers to perform association\nstudies for the genetic variants involved in diseases and the individual\nresponses to therapeutic agents.\n  A notable approach to the problem is to encode it as a combinatorial problem\n(under certain hypotheses, such as the pure parsimony criterion) and to solve\nit using off-the-shelf combinatorial optimization techniques. The main methods\napplied to Haplotype Inference are either simple greedy heuristic or exact\nmethods (Integer Linear Programming, Semidefinite Programming, SAT encoding)\nthat, at present, are adequate only for moderate size instances.\n  We believe that metaheuristic and hybrid approaches could provide a better\nscalability. Moreover, metaheuristics can be very easily combined with problem\nspecific heuristics and they can also be integrated with tree-based search\ntechniques, thus providing a promising framework for hybrid systems in which a\ngood trade-off between effectiveness and efficiency can be reached.\n  In this paper we illustrate a feasibility study of the approach and discuss\nsome relevant design issues, such as modeling and design of approximate solvers\nthat combine constructive heuristics, local search-based improvement strategies\nand learning mechanisms. Besides the relevance of the Haplotype Inference\nproblem itself, this preliminary analysis is also an interesting case study\nbecause the formulation of the problem poses some challenges in modeling and\nhybrid metaheuristic solver design that can be generalized to other problems.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2007 12:49:21 GMT"}], "update_date": "2007-08-06", "authors_parsed": [["Di Gaspero", "Luca", ""], ["Roli", "Andrea", ""]]}
{"id": "0708.0505", "submitter": "Luca Di Gaspero PhD", "authors": "Luca Di Gaspero, Andrea Roli", "title": "A preliminary analysis on metaheuristics methods applied to the\n  Haplotype Inference Problem", "comments": "22 pages, 4 figures Technical Report: DEIS - Alma Mater Studiorum,\n  University of Bologna no. DEIS-LIA-006-07", "journal-ref": null, "doi": null, "report-no": "DEIS-LIA-006-07", "categories": "cs.AI cs.CE cs.DM q-bio.QM", "license": null, "abstract": "  Haplotype Inference is a challenging problem in bioinformatics that consists\nin inferring the basic genetic constitution of diploid organisms on the basis\nof their genotype. This information allows researchers to perform association\nstudies for the genetic variants involved in diseases and the individual\nresponses to therapeutic agents.\n  A notable approach to the problem is to encode it as a combinatorial problem\n(under certain hypotheses, such as the pure parsimony criterion) and to solve\nit using off-the-shelf combinatorial optimization techniques. The main methods\napplied to Haplotype Inference are either simple greedy heuristic or exact\nmethods (Integer Linear Programming, Semidefinite Programming, SAT encoding)\nthat, at present, are adequate only for moderate size instances.\n  We believe that metaheuristic and hybrid approaches could provide a better\nscalability. Moreover, metaheuristics can be very easily combined with problem\nspecific heuristics and they can also be integrated with tree-based search\ntechniques, thus providing a promising framework for hybrid systems in which a\ngood trade-off between effectiveness and efficiency can be reached.\n  In this paper we illustrate a feasibility study of the approach and discuss\nsome relevant design issues, such as modeling and design of approximate solvers\nthat combine constructive heuristics, local search-based improvement strategies\nand learning mechanisms. Besides the relevance of the Haplotype Inference\nproblem itself, this preliminary analysis is also an interesting case study\nbecause the formulation of the problem poses some challenges in modeling and\nhybrid metaheuristic solver design that can be generalized to other problems.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2007 12:49:21 GMT"}], "update_date": "2007-08-06", "authors_parsed": [["Di Gaspero", "Luca", ""], ["Roli", "Andrea", ""]]}
{"id": "0708.0927", "submitter": "Emanuel Diamant", "authors": "Emanuel Diamant", "title": "Modeling Visual Information Processing in Brain: A Computer Vision Point\n  of View and Approach", "comments": "That is a journal version of a paper that in 2007 has been submitted\n  to 15 computer vision conferences and was discarded by 11 of them", "journal-ref": "Signal Processing: Image Communication, vol. 22, issue 6, pp.\n  583-590, July 2007", "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": null, "abstract": "  We live in the Information Age, and information has become a critically\nimportant component of our life. The success of the Internet made huge amounts\nof it easily available and accessible to everyone. To keep the flow of this\ninformation manageable, means for its faultless circulation and effective\nhandling have become urgently required. Considerable research efforts are\ndedicated today to address this necessity, but they are seriously hampered by\nthe lack of a common agreement about \"What is information?\" In particular, what\nis \"visual information\" - human's primary input from the surrounding world. The\nproblem is further aggravated by a long-lasting stance borrowed from the\nbiological vision research that assumes human-like information processing as an\nenigmatic mix of perceptual and cognitive vision faculties. I am trying to find\na remedy for this bizarre situation. Relying on a new definition of\n\"information\", which can be derived from Kolmogorov's compexity theory and\nChaitin's notion of algorithmic information, I propose a unifying framework for\nvisual information processing, which explicitly accounts for the perceptual and\ncognitive image processing peculiarities. I believe that this framework will be\nuseful to overcome the difficulties that are impeding our attempts to develop\nthe right model of human-like intelligent image processing.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2007 11:16:15 GMT"}], "update_date": "2007-08-08", "authors_parsed": [["Diamant", "Emanuel", ""]]}
{"id": "0708.0964", "submitter": "Colm \\'O D\\'unlaing", "authors": "Colm O Dunlaing", "title": "Nodally 3-connected planar graphs and convex combination mappings", "comments": "27 pages Latex, 11 postscript figures", "journal-ref": null, "doi": null, "report-no": "TCDMATH 06-16", "categories": "cs.CG", "license": null, "abstract": "  A convex combination mapping of a planar graph is a plane mapping in which\nthe external vertices are mapped to the corners of a convex polygon and every\ninternal vertex is a proper weighted average of its neighbours. If a planar\ngraph is nodally 3-connected or triangulated then every such mapping is an\nembedding (Tutte, Floater).\n  We give a simple characterisation of nodally 3-connected planar graphs, and\ngeneralise the above result to any planar graph which admits any convex\nembedding.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2007 14:32:38 GMT"}], "update_date": "2007-08-08", "authors_parsed": [["Dunlaing", "Colm O", ""]]}
{"id": "0708.0977", "submitter": "Valerio Lucarini", "authors": "Valerio Lucarini", "title": "From symmetry break to Poisson point process in 2D Voronoi\n  tessellations: the generic nature of hexagons", "comments": "14 pages, 4 figures", "journal-ref": "J. Stat. Phys., 130, 1047-1062 (2008)", "doi": "10.1007/s10955-007-9475-x", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.CG math-ph math.MP physics.data-an", "license": null, "abstract": "  We bridge the properties of the regular square and honeycomb Voronoi\ntessellations of the plane to those of the Poisson-Voronoi case, thus analyzing\nin a common framework symmetry-break processes and the approach to uniformly\nrandom distributions of tessellation-generating points. We consider ensemble\nsimulations of tessellations generated by points whose regular positions are\nperturbed through a Gaussian noise controlled by the parameter alpha. We study\nthe number of sides, the area, and the perimeter of the Voronoi cells. For\nalpha>0, hexagons are the most common class of cells, and 2-parameter gamma\ndistributions describe well the statistics of the geometrical characteristics.\nThe symmetry break due to noise destroys the square tessellation, whereas the\nhoneycomb hexagonal tessellation is very stable and all Voronoi cells are\nhexagon for small but finite noise with alpha<0.1. For a moderate amount of\nGaussian noise, memory of the specific unperturbed tessellation is lost,\nbecause the statistics of the two perturbed tessellations is indistinguishable.\nWhen alpha>2, results converge to those of Poisson-Voronoi tessellations. The\nproperties of n-sided cells change with alpha until the Poisson-Voronoi limit\nis reached for alpha>2. The Desch law for perimeters is confirmed to be not\nvalid and a square root dependence on n is established. The ensemble mean of\nthe cells area and perimeter restricted to the hexagonal cells coincides with\nthe full ensemble mean; this might imply that the number of sides acts as a\nthermodynamic state variable fluctuating about n=6; this reinforces the idea\nthat hexagons, beyond their ubiquitous numerical prominence, can be taken as\ngeneric polygons in 2D Voronoi tessellations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2007 15:23:31 GMT"}], "update_date": "2011-10-11", "authors_parsed": [["Lucarini", "Valerio", ""]]}
{"id": "0708.1116", "submitter": "Florian Simatos", "authors": "Florian Simatos", "title": "A variant of the Recoil Growth algorithm to generate multi-polymer\n  systems", "comments": "Title changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Recoil Growth algorithm, proposed in 1999 by Consta et al., is one of the\nmost efficient algorithm available in the literature to sample from a\nmulti-polymer system. Such problems are closely related to the generation of\nself-avoiding paths. In this paper, we study a variant of the original Recoil\nGrowth algorithm, where we constrain the generation of a new polymer to take\nplace on a specific class of graphs. This makes it possible to make a fine\ntrade-off between computational cost and success rate. We moreover give a\nsimple proof for a lower bound on the irreducibility of this new algorithm,\nwhich applies to the original algorithm as well.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2007 15:07:53 GMT"}, {"version": "v2", "created": "Fri, 12 Sep 2008 10:02:19 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2009 12:31:15 GMT"}], "update_date": "2009-07-02", "authors_parsed": [["Simatos", "Florian", ""]]}
{"id": "0708.1150", "submitter": "Marko Antonio Rodriguez", "authors": "Marko A. Rodriguez, Johah Bollen, Herbert Van de Sompel", "title": "A Practical Ontology for the Large-Scale Modeling of Scholarly Artifacts\n  and their Usage", "comments": null, "journal-ref": "Proceedings of the IEEE/ACM Joint Conference on Digital Libraries\n  (JCDL'07), pp. 278-287, 2007", "doi": "10.1145/1255175.1255229", "report-no": null, "categories": "cs.DL cs.AI", "license": null, "abstract": "  The large-scale analysis of scholarly artifact usage is constrained primarily\nby current practices in usage data archiving, privacy issues concerned with the\ndissemination of usage data, and the lack of a practical ontology for modeling\nthe usage domain. As a remedy to the third constraint, this article presents a\nscholarly ontology that was engineered to represent those classes for which\nlarge-scale bibliographic and usage data exists, supports usage research, and\nwhose instantiation is scalable to the order of 50 million articles along with\ntheir associated artifacts (e.g. authors and journals) and an accompanying 1\nbillion usage events. The real world instantiation of the presented abstract\nontology is a semantic network model of the scholarly community which lends the\nscholarly process to statistical analysis and computational support. We present\nthe ontology, discuss its instantiation, and provide some example inference\nrules for calculating various scholarly artifact metrics.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2007 17:06:55 GMT"}], "update_date": "2007-08-09", "authors_parsed": [["Rodriguez", "Marko A.", ""], ["Bollen", "Johah", ""], ["Van de Sompel", "Herbert", ""]]}
{"id": "0708.1362", "submitter": "David Wolpert", "authors": "David H. Wolpert", "title": "Physical limits of inference", "comments": "43 pages, updated version of Physica D version, which originally\n  appeared in 2007 CNLS conference on unconventional computation", "journal-ref": "PhysicaD237:1257-1281,2008", "doi": "10.1016/j.physd.2008.03.040", "report-no": null, "categories": "cond-mat.stat-mech cs.CC cs.IT gr-qc math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I show that physical devices that perform observation, prediction, or\nrecollection share an underlying mathematical structure. I call devices with\nthat structure \"inference devices\". I present a set of existence and\nimpossibility results concerning inference devices. These results hold\nindependent of the precise physical laws governing our universe. In a limited\nsense, the impossibility results establish that Laplace was wrong to claim that\neven in a classical, non-chaotic universe the future can be unerringly\npredicted, given sufficient knowledge of the present. Alternatively, these\nimpossibility results can be viewed as a non-quantum mechanical \"uncertainty\nprinciple\". Next I explore the close connections between the mathematics of\ninference devices and of Turing Machines. In particular, the impossibility\nresults for inference devices are similar to the Halting theorem for TM's.\nFurthermore, one can define an analog of Universal TM's (UTM's) for inference\ndevices. I call those analogs \"strong inference devices\". I use strong\ninference devices to define the \"inference complexity\" of an inference task,\nwhich is the analog of the Kolmogorov complexity of computing a string. However\nno universe can contain more than one strong inference device. So whereas the\nKolmogorov complexity of a string is arbitrary up to specification of the UTM,\nthere is no such arbitrariness in the inference complexity of an inference\ntask. I end by discussing the philosophical implications of these results,\ne.g., for whether the universe \"is\" a computer.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2007 03:19:38 GMT"}, {"version": "v2", "created": "Thu, 23 Oct 2008 22:11:34 GMT"}], "update_date": "2008-11-26", "authors_parsed": [["Wolpert", "David H.", ""]]}
{"id": "0708.1496", "submitter": "Mihai Oltean", "authors": "Mihai Oltean", "title": "A Light-Based Device for Solving the Hamiltonian Path Problem", "comments": "11 pages, Unconventional Computation conference, 2006", "journal-ref": "LNCS 4135, Unconventional Computation conference, pp. 217-227,\n  2006", "doi": "10.1007/11839132", "report-no": null, "categories": "cs.AR cs.DC", "license": null, "abstract": "  In this paper we suggest the use of light for performing useful computations.\nNamely, we propose a special device which uses light rays for solving the\nHamiltonian path problem on a directed graph. The device has a graph-like\nrepresentation and the light is traversing it following the routes given by the\nconnections between nodes. In each node the rays are uniquely marked so that\nthey can be easily identified. At the destination node we will search only for\nparticular rays that have passed only once through each node. We show that the\nproposed device can solve small and medium instances of the problem in\nreasonable time.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2007 18:12:52 GMT"}], "update_date": "2007-08-13", "authors_parsed": [["Oltean", "Mihai", ""]]}
{"id": "0708.1512", "submitter": "Mihai Oltean", "authors": "Mihai Oltean", "title": "Solving the Hamiltonian path problem with a light-based computer", "comments": "17 pages, Natural Computing journal", "journal-ref": "Natural Computing, Springer, Vol 6, 2007", "doi": "10.1007/s11047-007-9042-z", "report-no": null, "categories": "cs.AR cs.DC", "license": null, "abstract": "  In this paper we propose a special computational device which uses light rays\nfor solving the Hamiltonian path problem on a directed graph. The device has a\ngraph-like representation and the light is traversing it by following the\nroutes given by the connections between nodes. In each node the rays are\nuniquely marked so that they can be easily identified. At the destination node\nwe will search only for particular rays that have passed only once through each\nnode. We show that the proposed device can solve small and medium instances of\nthe problem in reasonable time.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2007 20:01:24 GMT"}], "update_date": "2007-08-14", "authors_parsed": [["Oltean", "Mihai", ""]]}
{"id": "0708.1527", "submitter": "Stasinos Konstantopoulos", "authors": "Stasinos Konstantopoulos", "title": "A Data-Parallel Version of Aleph", "comments": "Proceedings of Parallel and Distributed Computing for Machine\n  Learning workshop, held in conjunction with the 14th European Conference on\n  Machine Learning. Cavtat, Croatia, 2003", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": null, "abstract": "  This is to present work on modifying the Aleph ILP system so that it\nevaluates the hypothesised clauses in parallel by distributing the data-set\namong the nodes of a parallel or distributed machine. The paper briefly\ndiscusses MPI, the interface used to access message- passing libraries for\nparallel computers and clusters. It then proceeds to describe an extension of\nYAP Prolog with an MPI interface and an implementation of data-parallel clause\nevaluation for Aleph through this interface. The paper concludes by testing the\ndata-parallel Aleph on artificially constructed data-sets.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2007 23:32:16 GMT"}], "update_date": "2007-08-14", "authors_parsed": [["Konstantopoulos", "Stasinos", ""]]}
{"id": "0708.1529", "submitter": "Iddo Tzameret", "authors": "Ran Raz, Iddo Tzameret", "title": "Resolution over Linear Equations and Multilinear Proofs", "comments": "44 pages", "journal-ref": "Annals of Pure and Applied Logic , 155(3):194-224, 2008;", "doi": "10.1016/j.apal.2008.04.001", "report-no": null, "categories": "cs.CC cs.LO", "license": null, "abstract": "  We develop and study the complexity of propositional proof systems of varying\nstrength extending resolution by allowing it to operate with disjunctions of\nlinear equations instead of clauses. We demonstrate polynomial-size refutations\nfor hard tautologies like the pigeonhole principle, Tseitin graph tautologies\nand the clique-coloring tautologies in these proof systems. Using the\n(monotone) interpolation by a communication game technique we establish an\nexponential-size lower bound on refutations in a certain, considerably strong,\nfragment of resolution over linear equations, as well as a general polynomial\nupper bound on (non-monotone) interpolants in this fragment.\n  We then apply these results to extend and improve previous results on\nmultilinear proofs (over fields of characteristic 0), as studied in\n[RazTzameret06]. Specifically, we show the following:\n  1. Proofs operating with depth-3 multilinear formulas polynomially simulate a\ncertain, considerably strong, fragment of resolution over linear equations.\n  2. Proofs operating with depth-3 multilinear formulas admit polynomial-size\nrefutations of the pigeonhole principle and Tseitin graph tautologies. The\nformer improve over a previous result that established small multilinear proofs\nonly for the \\emph{functional} pigeonhole principle. The latter are different\nthan previous proofs, and apply to multilinear proofs of Tseitin mod p graph\ntautologies over any field of characteristic 0.\n  We conclude by connecting resolution over linear equations with extensions of\nthe cutting planes proof system.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2007 23:23:10 GMT"}], "update_date": "2010-04-19", "authors_parsed": [["Raz", "Ran", ""], ["Tzameret", "Iddo", ""]]}
{"id": "0708.1723", "submitter": "Volker Weber", "authors": "Volker Weber", "title": "Hybrid Branching-Time Logics", "comments": "An extended abstract of this paper was presented at the International\n  Workshop on Hybrid Logics (HyLo 2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": null, "abstract": "  Hybrid branching-time logics are introduced as extensions of CTL-like logics\nwith state variables and the downarrow-binder. Following recent work in the\nlinear framework, only logics with a single variable are considered. The\nexpressive power and the complexity of satisfiability of the resulting logics\nis investigated.\n  As main result, the satisfiability problem for the hybrid versions of several\nbranching-time logics is proved to be 2EXPTIME-complete. These branching-time\nlogics range from strict fragments of CTL to extensions of CTL that can talk\nabout the past and express fairness-properties. The complexity gap relative to\nCTL is explained by a corresponding succinctness result.\n  To prove the upper bound, the automata-theoretic approach to branching-time\nlogics is extended to hybrid logics, showing that non-emptiness of alternating\none-pebble Buchi tree automata is 2EXPTIME-complete.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2007 15:04:12 GMT"}], "update_date": "2007-08-14", "authors_parsed": [["Weber", "Volker", ""]]}
{"id": "0708.1818", "submitter": "Francoise Heres-Renzetti", "authors": "L.-V. Bochkareva, M.-V. Kireitseu, G. R. Tomlinson, H. Altenbach, V.\n  Kompis, D. Hui", "title": "Computational Simulation and 3D Virtual Reality Engineering Tools for\n  Dynamical Modeling and Imaging of Composite Nanomaterials", "comments": "Submitted on behalf of TIMA Editions\n  (http://irevues.inist.fr/tima-editions)", "journal-ref": "Dans European Nano Systems Worshop - ENS 2005, Paris : France\n  (2005)", "doi": null, "report-no": null, "categories": "cs.CE cond-mat.other", "license": null, "abstract": "  An adventure at engineering design and modeling is possible with a Virtual\nReality Environment (VRE) that uses multiple computer-generated media to let a\nuser experience situations that are temporally and spatially prohibiting. In\nthis paper, an approach to developing some advanced architecture and modeling\ntools is presented to allow multiple frameworks work together while being\nshielded from the application program. This architecture is being developed in\na framework of workbench interactive tools for next generation\nnanoparticle-reinforced damping/dynamic systems. Through the use of system, an\nengineer/programmer can respectively concentrate on tailoring an engineering\ndesign concept of novel system and the application software design while using\nexisting databases/software outputs.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2007 08:17:45 GMT"}], "update_date": "2007-08-15", "authors_parsed": [["Bochkareva", "L. -V.", ""], ["Kireitseu", "M. -V.", ""], ["Tomlinson", "G. R.", ""], ["Altenbach", "H.", ""], ["Kompis", "V.", ""], ["Hui", "D.", ""]]}
{"id": "0708.1909", "submitter": "Maike Buchin", "authors": "Kevin Buchin and Maike Buchin", "title": "Lower Bounds for the Complexity of the Voronoi Diagram of Polygonal\n  Curves under the Discrete Frechet Distance", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": null, "abstract": "  We give lower bounds for the combinatorial complexity of the Voronoi diagram\nof polygonal curves under the discrete Frechet distance. We show that the\nVoronoi diagram of n curves in R^d with k vertices each, has complexity\nOmega(n^{dk}) for dimension d=1,2 and Omega(n^{d(k-1)+2}) for d>2.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2007 14:53:44 GMT"}], "update_date": "2007-08-15", "authors_parsed": [["Buchin", "Kevin", ""], ["Buchin", "Maike", ""]]}
{"id": "0708.1909", "submitter": "Maike Buchin", "authors": "Kevin Buchin and Maike Buchin", "title": "Lower Bounds for the Complexity of the Voronoi Diagram of Polygonal\n  Curves under the Discrete Frechet Distance", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": null, "abstract": "  We give lower bounds for the combinatorial complexity of the Voronoi diagram\nof polygonal curves under the discrete Frechet distance. We show that the\nVoronoi diagram of n curves in R^d with k vertices each, has complexity\nOmega(n^{dk}) for dimension d=1,2 and Omega(n^{d(k-1)+2}) for d>2.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2007 14:53:44 GMT"}], "update_date": "2007-08-15", "authors_parsed": [["Buchin", "Kevin", ""], ["Buchin", "Maike", ""]]}
{"id": "0708.1962", "submitter": "Mihai Oltean", "authors": "Mihai Oltean, Oana Muntean", "title": "Exact Cover with light", "comments": "20 pages, 4 figures, New Generation Computing, accepted, 2007", "journal-ref": "New Generation Computing, Springer-Verlag, Vol. 26, Issue 4, pp.\n  327-344, 2008", "doi": "10.1007/s00354-008-0049-5", "report-no": null, "categories": "cs.AR cs.DC", "license": null, "abstract": "  We suggest a new optical solution for solving the YES/NO version of the Exact\nCover problem by using the massive parallelism of light. The idea is to build\nan optical device which can generate all possible solutions of the problem and\nthen to pick the correct one. In our case the device has a graph-like\nrepresentation and the light is traversing it by following the routes given by\nthe connections between nodes. The nodes are connected by arcs in a special way\nwhich lets us to generate all possible covers (exact or not) of the given set.\nFor selecting the correct solution we assign to each item, from the set to be\ncovered, a special integer number. These numbers will actually represent delays\ninduced to light when it passes through arcs. The solution is represented as a\nsubray arriving at a certain moment in the destination node. This will tell us\nif an exact cover does exist or not.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2007 21:41:55 GMT"}], "update_date": "2009-02-07", "authors_parsed": [["Oltean", "Mihai", ""], ["Muntean", "Oana", ""]]}
{"id": "0708.1964", "submitter": "Mihai Oltean", "authors": "Mihai Oltean, Oana Muntean", "title": "Solving the subset-sum problem with a light-based device", "comments": "14 pages, 6 figures, Natural Computing, 2007", "journal-ref": "Natural Computing, Springer-Verlag, Vol 8, Issue 2, pp. 321-331,\n  2009", "doi": "10.1007/s11047-007-9059-3", "report-no": null, "categories": "cs.AR cs.AI cs.DC", "license": null, "abstract": "  We propose a special computational device which uses light rays for solving\nthe subset-sum problem. The device has a graph-like representation and the\nlight is traversing it by following the routes given by the connections between\nnodes. The nodes are connected by arcs in a special way which lets us to\ngenerate all possible subsets of the given set. To each arc we assign either a\nnumber from the given set or a predefined constant. When the light is passing\nthrough an arc it is delayed by the amount of time indicated by the number\nplaced in that arc. At the destination node we will check if there is a ray\nwhose total delay is equal to the target value of the subset sum problem (plus\nsome constants).\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2007 21:46:32 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Oltean", "Mihai", ""], ["Muntean", "Oana", ""]]}
{"id": "0708.1964", "submitter": "Mihai Oltean", "authors": "Mihai Oltean, Oana Muntean", "title": "Solving the subset-sum problem with a light-based device", "comments": "14 pages, 6 figures, Natural Computing, 2007", "journal-ref": "Natural Computing, Springer-Verlag, Vol 8, Issue 2, pp. 321-331,\n  2009", "doi": "10.1007/s11047-007-9059-3", "report-no": null, "categories": "cs.AR cs.AI cs.DC", "license": null, "abstract": "  We propose a special computational device which uses light rays for solving\nthe subset-sum problem. The device has a graph-like representation and the\nlight is traversing it by following the routes given by the connections between\nnodes. The nodes are connected by arcs in a special way which lets us to\ngenerate all possible subsets of the given set. To each arc we assign either a\nnumber from the given set or a predefined constant. When the light is passing\nthrough an arc it is delayed by the amount of time indicated by the number\nplaced in that arc. At the destination node we will check if there is a ray\nwhose total delay is equal to the target value of the subset sum problem (plus\nsome constants).\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2007 21:46:32 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Oltean", "Mihai", ""], ["Muntean", "Oana", ""]]}
{"id": "0708.2105", "submitter": "Nicholas Pippenger", "authors": "Krzysztof Majewski and Nicholas Pippenger", "title": "Attribute Estimation and Testing Quasi-Symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  A Boolean function is symmetric if it is invariant under all permutations of\nits arguments; it is quasi-symmetric if it is symmetric with respect to the\narguments on which it actually depends. We present a test that accepts every\nquasi-symmetric function and, except with an error probability at most delta>0,\nrejects every function that differs from every quasi-symmetric function on at\nleast a fraction epsilon>0 of the inputs. For a function of n arguments, the\ntest probes the function at O((n/epsilon)\\log(n/delta)) inputs. Our\nquasi-symmetry test acquires information concerning the arguments on which the\nfunction actually depends. To do this, it employs a generalization of the\nproperty testing paradigm that we call attribute estimation. Like property\ntesting, attribute estimation uses random sampling to obtain results that have\nonly \"one-sided'' errors and that are close to accurate with high probability.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2007 20:56:22 GMT"}], "update_date": "2007-08-17", "authors_parsed": [["Majewski", "Krzysztof", ""], ["Pippenger", "Nicholas", ""]]}
{"id": "0708.2303", "submitter": "W Saba", "authors": "Walid S. Saba", "title": "Compositional Semantics Grounded in Commonsense Metaphysics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": null, "abstract": "  We argue for a compositional semantics grounded in a strongly typed ontology\nthat reflects our commonsense view of the world and the way we talk about it in\nordinary language. Assuming the existence of such a structure, we show that the\nsemantics of various natural language phenomena may become nearly trivial.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2007 01:15:11 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2007 17:48:14 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Saba", "Walid S.", ""]]}
{"id": "0708.2336", "submitter": "Dominik Scheder", "authors": "Dominik Scheder", "title": "Unsatisfiable Linear k-CNFs Exist, for every k", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.LO", "license": null, "abstract": "  We call a CNF formula linear if any two clauses have at most one variable in\ncommon. Let Linear k-SAT be the problem of deciding whether a given linear\nk-CNF formula is satisfiable. Here, a k-CNF formula is a CNF formula in which\nevery clause has size exactly k. It was known that for k >= 3, Linear k-SAT is\nNP-complete if and only if an unsatisfiable linear k-CNF formula exists, and\nthat they do exist for k >= 4. We prove that unsatisfiable linear k-CNF\nformulas exist for every k. Let f(k) be the minimum number of clauses in an\nunsatisfiable linear k-CNF formula. We show that f(k) is Omega(k2^k) and\nO(4^k*k^4), i.e., minimum size unsatisfiable linear k-CNF formulas are\nsignificantly larger than minimum size unsatisfiable k-CNF formulas. Finally,\nwe prove that, surprisingly, linear k-CNF formulas do not allow for a larger\nfraction of clauses to be satisfied than general k-CNF formulas.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2007 09:44:21 GMT"}], "update_date": "2007-08-20", "authors_parsed": [["Scheder", "Dominik", ""]]}
{"id": "0708.2432", "submitter": "Oliver Knill", "authors": "Oliver Knill and Jose Ramirez-Herran", "title": "A structure from motion inequality", "comments": "15 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": null, "abstract": "  We state an elementary inequality for the structure from motion problem for m\ncameras and n points. This structure from motion inequality relates space\ndimension, camera parameter dimension, the number of cameras and number points\nand global symmetry properties and provides a rigorous criterion for which\nreconstruction is not possible with probability 1. Mathematically the\ninequality is based on Frobenius theorem which is a geometric incarnation of\nthe fundamental theorem of linear algebra. The paper also provides a general\nmathematical formalism for the structure from motion problem. It includes the\nsituation the points can move while the camera takes the pictures.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2007 14:36:28 GMT"}], "update_date": "2007-08-21", "authors_parsed": [["Knill", "Oliver", ""], ["Ramirez-Herran", "Jose", ""]]}
{"id": "0708.2438", "submitter": "Oliver Knill", "authors": "Oliver Knill and Jose Ramirez-Herran", "title": "On Ullman's theorem in computer vision", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": null, "abstract": "  Both in the plane and in space, we invert the nonlinear Ullman transformation\nfor 3 points and 3 orthographic cameras. While Ullman's theorem assures a\nunique reconstruction modulo a reflection for 3 cameras and 4 points, we find a\nlocally unique reconstruction for 3 cameras and 3 points. Explicit\nreconstruction formulas allow to decide whether picture data of three cameras\nseeing three points can be realized as a point-camera configuration.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2007 21:36:08 GMT"}], "update_date": "2007-08-21", "authors_parsed": [["Knill", "Oliver", ""], ["Ramirez-Herran", "Jose", ""]]}
{"id": "0708.2442", "submitter": "Oliver Knill", "authors": "Oliver Knill and Jose Ramirez-Herran", "title": "Space and camera path reconstruction for omni-directional vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": null, "abstract": "  In this paper, we address the inverse problem of reconstructing a scene as\nwell as the camera motion from the image sequence taken by an omni-directional\ncamera. Our structure from motion results give sharp conditions under which the\nreconstruction is unique. For example, if there are three points in general\nposition and three omni-directional cameras in general position, a unique\nreconstruction is possible up to a similarity. We then look at the\nreconstruction problem with m cameras and n points, where n and m can be large\nand the over-determined system is solved by least square methods. The\nreconstruction is robust and generalizes to the case of a dynamic environment\nwhere landmarks can move during the movie capture. Possible applications of the\nresult are computer assisted scene reconstruction, 3D scanning, autonomous\nrobot navigation, medical tomography and city reconstructions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2007 21:53:41 GMT"}], "update_date": "2007-08-21", "authors_parsed": [["Knill", "Oliver", ""], ["Ramirez-Herran", "Jose", ""]]}
{"id": "0708.2514", "submitter": "Arash Rafiey", "authors": "Arvind Gupta, Pavol Hell, Mehdi Karimi, Arash Rafiey", "title": "Minimum Cost Homomorphisms to Reflexive Digraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": null, "abstract": "  For digraphs $G$ and $H$, a homomorphism of $G$ to $H$ is a mapping $f:\\\nV(G)\\dom V(H)$ such that $uv\\in A(G)$ implies $f(u)f(v)\\in A(H)$. If moreover\neach vertex $u \\in V(G)$ is associated with costs $c_i(u), i \\in V(H)$, then\nthe cost of a homomorphism $f$ is $\\sum_{u\\in V(G)}c_{f(u)}(u)$. For each fixed\ndigraph $H$, the {\\em minimum cost homomorphism problem} for $H$, denoted\nMinHOM($H$), is the following problem. Given an input digraph $G$, together\nwith costs $c_i(u)$, $u\\in V(G)$, $i\\in V(H)$, and an integer $k$, decide if\n$G$ admits a homomorphism to $H$ of cost not exceeding $k$. We focus on the\nminimum cost homomorphism problem for {\\em reflexive} digraphs $H$ (every\nvertex of $H$ has a loop). It is known that the problem MinHOM($H$) is\npolynomial time solvable if the digraph $H$ has a {\\em Min-Max ordering}, i.e.,\nif its vertices can be linearly ordered by $<$ so that $i<j, s<r$ and $ir, js\n\\in A(H)$ imply that $is \\in A(H)$ and $jr \\in A(H)$. We give a forbidden\ninduced subgraph characterization of reflexive digraphs with a Min-Max\nordering; our characterization implies a polynomial time test for the existence\nof a Min-Max ordering. Using this characterization, we show that for a\nreflexive digraph $H$ which does not admit a Min-Max ordering, the minimum cost\nhomomorphism problem is NP-complete. Thus we obtain a full dichotomy\nclassification of the complexity of minimum cost homomorphism problems for\nreflexive digraphs.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2007 23:34:45 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2007 13:31:36 GMT"}], "update_date": "2007-10-16", "authors_parsed": [["Gupta", "Arvind", ""], ["Hell", "Pavol", ""], ["Karimi", "Mehdi", ""], ["Rafiey", "Arash", ""]]}
{"id": "0708.2584", "submitter": "Seiichiro Tani", "authors": "Seiichiro Tani", "title": "Claw Finding Algorithms Using Quantum Walk", "comments": "12 pages. Introduction revised. A reference added. Weak lower bound\n  deleted", "journal-ref": "Theoretical Computer Science, 410(50): 5285-5297 (2009)", "doi": "10.1016/j.tcs.2009.08.030", "report-no": null, "categories": "quant-ph cs.CC", "license": null, "abstract": "  The claw finding problem has been studied in terms of query complexity as one\nof the problems closely connected to cryptography. For given two functions, f\nand g, as an oracle which have domains of size N and M (N<=M), respectively,\nand the same range, the goal of the problem is to find x and y such that\nf(x)=g(y). This paper describes an optimal algorithm using quantum walk that\nsolves this problem. Our algorithm can be generalized to find a claw of k\nfunctions for any constant integer k>1, where the domains of the functions may\nhave different size.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2007 07:56:12 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 13:23:09 GMT"}], "update_date": "2011-06-17", "authors_parsed": [["Tani", "Seiichiro", ""]]}
{"id": "0708.2668", "submitter": "Daniel Reem", "authors": "Daniel Reem, Simeon Reich", "title": "Zone and double zone diagrams in abstract spaces", "comments": "17 pages, 5 figures; slight modifications and additions (including\n  thanks); Theorem 5.5 was slightly improved. This version is essentially from\n  the beginning of 2009 and it does not take into account several developments\n  which have occurred since then", "journal-ref": "Colloquium Mathematicum 115 (2009), 129-145", "doi": "10.4064/cm115-1-11", "report-no": null, "categories": "math.MG cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A zone diagram is a relatively new concept which was first defined and\nstudied by T. Asano, J. Matousek and T. Tokuyama. It can be interpreted as a\nstate of equilibrium between several mutually hostile kingdoms. Formally, it is\na fixed point of a certain mapping. These authors considered the Euclidean\nplane and proved the existence and uniqueness of zone diagrams there. In the\npresent paper we generalize this concept in various ways. We consider general\nsites in m-spaces (a simple generalization of metric spaces) and prove several\nexistence and (non)uniqueness results in this setting. In contrast to previous\nworks, our (rather simple) proofs are based on purely order theoretic\narguments. Many explicit examples are given, and some of them illustrate new\nphenomena which occur in the general case. We also re-interpret zone diagrams\nas a stable configuration in a certain combinatorial game, and provide an\nalgorithm for finding this configuration in a particular case.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2007 15:35:25 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2011 13:30:41 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Reem", "Daniel", ""], ["Reich", "Simeon", ""]]}
{"id": "0708.2854", "submitter": "Saugata Basu", "authors": "Saugata Basu", "title": "Algorithmic Semi-algebraic Geometry and Topology -- Recent Progress and\n  Open Problems", "comments": "Survey article, 74 pages, 15 figures. Final revision. This version\n  will appear in the AMS Contemporary Math. Series: Proceedings of the Summer\n  Research Conference on Discrete and Computational Geometry, Snowbird, Utah\n  (June, 2006). J.E. Goodman, J. Pach, R. Pollack Eds", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CC cs.CG math.AG math.AT", "license": null, "abstract": "  We give a survey of algorithms for computing topological invariants of\nsemi-algebraic sets with special emphasis on the more recent developments in\ndesigning algorithms for computing the Betti numbers of semi-algebraic sets.\nAside from describing these results, we discuss briefly the background as well\nas the importance of these problems, and also describe the main tools from\nalgorithmic semi-algebraic geometry, as well as algebraic topology, which make\nthese advances possible. We end with a list of open problems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2007 14:55:56 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2007 23:12:20 GMT"}], "update_date": "2007-09-17", "authors_parsed": [["Basu", "Saugata", ""]]}
{"id": "0708.2854", "submitter": "Saugata Basu", "authors": "Saugata Basu", "title": "Algorithmic Semi-algebraic Geometry and Topology -- Recent Progress and\n  Open Problems", "comments": "Survey article, 74 pages, 15 figures. Final revision. This version\n  will appear in the AMS Contemporary Math. Series: Proceedings of the Summer\n  Research Conference on Discrete and Computational Geometry, Snowbird, Utah\n  (June, 2006). J.E. Goodman, J. Pach, R. Pollack Eds", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CC cs.CG math.AG math.AT", "license": null, "abstract": "  We give a survey of algorithms for computing topological invariants of\nsemi-algebraic sets with special emphasis on the more recent developments in\ndesigning algorithms for computing the Betti numbers of semi-algebraic sets.\nAside from describing these results, we discuss briefly the background as well\nas the importance of these problems, and also describe the main tools from\nalgorithmic semi-algebraic geometry, as well as algebraic topology, which make\nthese advances possible. We end with a list of open problems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2007 14:55:56 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2007 23:12:20 GMT"}], "update_date": "2007-09-17", "authors_parsed": [["Basu", "Saugata", ""]]}
{"id": "0708.3014", "submitter": "Elisa Gorla", "authors": "Elisa Gorla, Christoph Puttmann, and Jamshid Shokrollahi", "title": "Explicit formulas for efficient multiplication in F_{3^{6m}}", "comments": "11 pages, to appear in the proceedings of SAC2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": null, "abstract": "  Efficient computation of the Tate pairing is an important part of\npairing-based cryptography. Recently with the introduction of the Duursma-Lee\nmethod special attention has been given to the fields of characteristic 3.\nEspecially multiplication in F_{3^{6m}}, where m is prime, is an important\noperation in the above method. In this paper we propose a new method to reduce\nthe number of F_{3^m} multiplications for multiplication in F_{3^{6m}} from 18\nin recent implementations to 15. The method is based on the fast Fourier\ntranmsform and explicit formulas are given. The execution times of our software\nimplementations for F_{3^{6m}} show the efficiency of our results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2007 13:52:09 GMT"}], "update_date": "2007-08-23", "authors_parsed": [["Gorla", "Elisa", ""], ["Puttmann", "Christoph", ""], ["Shokrollahi", "Jamshid", ""]]}
{"id": "0708.3048", "submitter": "Alexandre d'Aspremont", "authors": "Alexandre d'Aspremont", "title": "Identifying Small Mean Reverting Portfolios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  Given multivariate time series, we study the problem of forming portfolios\nwith maximum mean reversion while constraining the number of assets in these\nportfolios. We show that it can be formulated as a sparse canonical correlation\nanalysis and study various algorithms to solve the corresponding sparse\ngeneralized eigenvalue problems. After discussing penalized parameter\nestimation procedures, we study the sparsity versus predictability tradeoff and\nthe impact of predictability in various markets.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2007 16:25:17 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2008 16:29:01 GMT"}], "update_date": "2008-02-26", "authors_parsed": [["d'Aspremont", "Alexandre", ""]]}
{"id": "0708.3226", "submitter": "Rustem Takhanov", "authors": "Rustem Takhanov", "title": "A Dichotomy Theorem for General Minimum Cost Homomorphism Problem", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the constraint satisfaction problem ($CSP$), the aim is to find an\nassignment of values to a set of variables subject to specified constraints. In\nthe minimum cost homomorphism problem ($MinHom$), one is additionally given\nweights $c_{va}$ for every variable $v$ and value $a$, and the aim is to find\nan assignment $f$ to the variables that minimizes $\\sum_{v} c_{vf(v)}$. Let\n$MinHom(\\Gamma)$ denote the $MinHom$ problem parameterized by the set of\npredicates allowed for constraints. $MinHom(\\Gamma)$ is related to many\nwell-studied combinatorial optimization problems, and concrete applications can\nbe found in, for instance, defence logistics and machine learning. We show that\n$MinHom(\\Gamma)$ can be studied by using algebraic methods similar to those\nused for CSPs. With the aid of algebraic techniques, we classify the\ncomputational complexity of $MinHom(\\Gamma)$ for all choices of $\\Gamma$. Our\nresult settles a general dichotomy conjecture previously resolved only for\ncertain classes of directed graphs, [Gutin, Hell, Rafiey, Yeo, European J. of\nCombinatorics, 2008].\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2007 18:26:21 GMT"}, {"version": "v2", "created": "Sun, 31 Aug 2008 21:54:49 GMT"}, {"version": "v3", "created": "Thu, 22 Jan 2009 13:53:56 GMT"}, {"version": "v4", "created": "Fri, 23 Jan 2009 16:13:44 GMT"}, {"version": "v5", "created": "Mon, 20 Apr 2009 15:18:35 GMT"}, {"version": "v6", "created": "Thu, 16 Jul 2009 16:43:08 GMT"}, {"version": "v7", "created": "Sun, 4 Apr 2010 20:39:03 GMT"}], "update_date": "2010-04-06", "authors_parsed": [["Takhanov", "Rustem", ""]]}
{"id": "0708.3463", "submitter": "Sabatino Costanzo", "authors": "Sabatino Costanzo, Loren Trigo, Luis Jimenez, Juan Gonzalez", "title": "A Neural Networks Model of the Venezuelan Economy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  Besides an indicator of the GDP, the Central Bank of Venezuela generates the\nso called Monthly Economic Activity General Indicator. The a priori knowledge\nof this indicator, which represents and sometimes even anticipates the\neconomy's fluctuations, could be helpful in developing public policies and in\ninvestment decision making. The purpose of this study is forecasting the IGAEM\nthrough non parametric methods, an approach that has proven effective in a wide\nvariety of problems in economics and finance.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2007 05:10:29 GMT"}], "update_date": "2007-08-28", "authors_parsed": [["Costanzo", "Sabatino", ""], ["Trigo", "Loren", ""], ["Jimenez", "Luis", ""], ["Gonzalez", "Juan", ""]]}
{"id": "0708.3464", "submitter": "Sabatino Costanzo", "authors": "Sabatino Costanzo, Loren Trigo, Ramses Dominguez, William Moreno", "title": "A Non Parametric Study of the Volatility of the Economy as a Country\n  Risk Predictor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  This paper intends to explain Venezuela's country spread behavior through the\nNeural Networks analysis of a monthly economic activity general index of\neconomic indicators constructed by the Central Bank of Venezuela, a measure of\nthe shocks affecting country risk of emerging markets and the U.S. short term\ninterest rate. The use of non parametric methods allowed the finding of non\nlinear relationship between these inputs and the country risk. The networks\nperformance was evaluated using the method of excess predictability.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2007 05:30:18 GMT"}], "update_date": "2007-08-28", "authors_parsed": [["Costanzo", "Sabatino", ""], ["Trigo", "Loren", ""], ["Dominguez", "Ramses", ""], ["Moreno", "William", ""]]}
{"id": "0708.3465", "submitter": "Sabatino Costanzo", "authors": "Loren Trigo, Sabatino Costanzo, Felix Gonzalez, Jose Llamozas", "title": "An Early Warning System for Bankruptcy Prediction: lessons from the\n  Venezuelan Bank Crisis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  During 1993-94 Venezuela experienced a severe banking crisis which ended up\nwith 18 commercial banks intervened by the government. Here we develop an early\nwarning system for detecting credit related bankruptcy through discriminant\nfunctions developed on financial and macroeconomic data predating the crisis. A\nrobustness test performed on these functions shows high precision in error\nestimation. The model calibrated on pre-crisis data could detect abnormal\nfinancial tension in the late Banco Capital many months before it was\nintervened and liquidated.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2007 05:33:41 GMT"}], "update_date": "2007-08-28", "authors_parsed": [["Trigo", "Loren", ""], ["Costanzo", "Sabatino", ""], ["Gonzalez", "Felix", ""], ["Llamozas", "Jose", ""]]}
{"id": "0708.3499", "submitter": "Francesc Rossell\\'o", "authors": "Gabriel Cardona, Francesc Rossello, Gabriel Valiente", "title": "Comparison of Tree-Child Phylogenetic Networks", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE cs.DM", "license": null, "abstract": "  Phylogenetic networks are a generalization of phylogenetic trees that allow\nfor the representation of non-treelike evolutionary events, like recombination,\nhybridization, or lateral gene transfer. In this paper, we present and study a\nnew class of phylogenetic networks, called tree-child phylogenetic networks,\nwhere every non-extant species has some descendant through mutation. We provide\nan injective representation of these networks as multisets of vectors of\nnatural numbers, their path multiplicity vectors, and we use this\nrepresentation to define a distance on this class and to give an alignment\nmethod for pairs of these networks. To the best of our knowledge, they are\nrespectively the first true distance and the first alignment method defined on\na meaningful class of phylogenetic networks strictly extending the class of\nphylogenetic trees. Simple, polynomial algorithms for reconstructing a\ntree-child phylogenetic network from its path multiplicity vectors, for\ncomputing the distance between two tree-child phylogenetic networks, and for\naligning a pair of tree-child phylogenetic networks, are provided, and they\nhave been implemented as a Perl package and a Java applet, and they are\navailable at http://bioinfo.uib.es/~recerca/phylonetworks/mudistance\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2007 09:37:55 GMT"}], "update_date": "2007-08-28", "authors_parsed": [["Cardona", "Gabriel", ""], ["Rossello", "Francesc", ""], ["Valiente", "Gabriel", ""]]}
{"id": "0708.3568", "submitter": "Vadim Tarin", "authors": "Vadim Tarin", "title": "A Polynomial-time Algorithm for Computing the Permanent in GF(3^q)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  A polynomial-time algorithm for computing the permanent in any field of\ncharacteristic 3 is presented in this article. The principal objects utilized\nfor that purpose are the Cauchy and Vandermonde matrices, the discriminant\nfunction and their generalizations of various types. Classical theorems on the\npermanent such as the Binet-Minc identity and Borchadt's formula are widely\napplied, while a special new technique involving the notion of limit re-defined\nfor fields of finite characteristics and corresponding computational methods\nwas developed in order to deal with a number of polynomial-time reductions. All\nthe constructions preserve a strictly algebraic nature ignoring the structure\nof the basic field, while applying its infinite extensions for calculating\nlimits.\n  A natural corollary of the polynomial-time computability of the permanent in\na field of a characteristic different from 2 is the non-uniform equality\nbetween the complexity classes P and NP what is equivalent to RP=NP (Ref. [1]).\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2007 15:47:49 GMT"}], "update_date": "2007-08-28", "authors_parsed": [["Tarin", "Vadim", ""]]}
{"id": "0708.3829", "submitter": "Sabatino Costanzo", "authors": "Sabatino Costanzo, Loren Trigo, Wafaa Dehne, Hender Prato", "title": "A Non Parametric Model for the Forecasting of the Venezuelan Oil Prices", "comments": "17 pages, in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  A neural net model for forecasting the prices of Venezuelan crude oil is\nproposed. The inputs of the neural net are selected by reference to a dynamic\nsystem model of oil prices by Mashayekhi (1995, 2001) and its performance is\nevaluated using two criteria: the Excess Profitability test by Anatoliev and\nGerko (2005) and the characteristics of the equity curve generated by a trading\nstrategy based on the neural net predictions.\n  -----\n  Se introduce aqui un modelo no parametrico para pronosticar los precios del\npetroleo Venezolano cuyos insumos son seleccionados en base a un sistema\ndinamico que explica los precios en terminos de dichos insumos. Se describe el\nproceso de recoleccion y pre-procesamiento de datos y la corrida de la red y se\nevaluan sus pronosticos a traves de un test estadistico de predictibilidad y de\nlas caracteristicas del Equity Curve inducido por la estrategia de compraventa\nbursatil generada por dichos pronosticos.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2007 18:29:55 GMT"}], "update_date": "2007-08-29", "authors_parsed": [["Costanzo", "Sabatino", ""], ["Trigo", "Loren", ""], ["Dehne", "Wafaa", ""], ["Prato", "Hender", ""]]}
{"id": "0708.4075", "submitter": "Matthew Delacorte", "authors": "Matthew Delacorte", "title": "Graph Isomorphism is PSPACE-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  Combining the the results of A.R. Meyer and L.J. Stockmeyer \"The Equivalence\nProblem for Regular Expressions with Squaring Requires Exponential Space\", and\nK.S. Booth \"Isomorphism testing for graphs, semigroups, and finite automata are\npolynomiamlly equivalent problems\" shows that graph isomorphism is\nPSPACE-complete.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2007 05:06:39 GMT"}], "update_date": "2007-08-31", "authors_parsed": [["Delacorte", "Matthew", ""]]}
{"id": "0708.4170", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Raising a Hardness Result", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": null, "abstract": "  This article presents a technique for proving problems hard for classes of\nthe polynomial hierarchy or for PSPACE. The rationale of this technique is that\nsome problem restrictions are able to simulate existential or universal\nquantifiers. If this is the case, reductions from Quantified Boolean Formulae\n(QBF) to these restrictions can be transformed into reductions from QBFs having\none more quantifier in the front. This means that a proof of hardness of a\nproblem at level n in the polynomial hierarchy can be split into n separate\nproofs, which may be simpler than a proof directly showing a reduction from a\nclass of QBFs to the considered problem.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2007 14:42:50 GMT"}], "update_date": "2007-08-31", "authors_parsed": [["Liberatore", "Paolo", ""]]}
{"id": "0708.4170", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Raising a Hardness Result", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": null, "abstract": "  This article presents a technique for proving problems hard for classes of\nthe polynomial hierarchy or for PSPACE. The rationale of this technique is that\nsome problem restrictions are able to simulate existential or universal\nquantifiers. If this is the case, reductions from Quantified Boolean Formulae\n(QBF) to these restrictions can be transformed into reductions from QBFs having\none more quantifier in the front. This means that a proof of hardness of a\nproblem at level n in the polynomial hierarchy can be split into n separate\nproofs, which may be simpler than a proof directly showing a reduction from a\nclass of QBFs to the considered problem.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2007 14:42:50 GMT"}], "update_date": "2007-08-31", "authors_parsed": [["Liberatore", "Paolo", ""]]}
{"id": "0708.4176", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (LIP, ELM), Dominique Lecomte (UMR 7586)", "title": "Classical and Effective Descriptive Complexities of omega-Powers", "comments": "Final Version, published in A.P.A.L. This paper is an extended\n  version of a conference paper which appeared in the Proceedings of the 16th\n  EACSL Annual Conference on Computer Science and Logic, CSL 07. Part of the\n  results in this paper have been also presented at the International\n  Conference Computability in Europe, CiE 07, Siena, Italy, June 2007", "journal-ref": "Annals of Pure and Applied Logic 2, 160 (2009) 163-191", "doi": null, "report-no": "LIP Research Report RR 2007-38", "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that, for each non null countable ordinal alpha, there exist some\nSigma^0_alpha-complete omega-powers, and some Pi^0_alpha-complete omega-powers,\nextending previous works on the topological complexity of omega-powers. We\nprove effective versions of these results. In particular, for each non null\nrecursive ordinal alpha, there exists a recursive finitary language A such that\nA^omega is Sigma^0_alpha-complete (respectively, Pi^0_alpha-complete). To do\nthis, we prove effective versions of a result by Kuratowski, describing a Borel\nset as the range of a closed subset of the Baire space by a continuous\nbijection. This leads us to prove closure properties for the classes\nEffective-Pi^0_alpha and Effective-Sigma^0_alpha of the hyperarithmetical\nhierarchy in arbitrary recursively presented Polish spaces. We apply our\nexistence results to get better computations of the topological complexity of\nsome sets of dictionaries considered by the second author in [Omega-Powers and\nDescriptive Set Theory, Journal of Symbolic Logic, Volume 70 (4), 2005, p.\n1210-1232].\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2007 14:56:24 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2009 17:02:41 GMT"}], "update_date": "2009-08-04", "authors_parsed": [["Finkel", "Olivier", "", "LIP, ELM"], ["Lecomte", "Dominique", "", "UMR 7586"]]}
{"id": "0708.4311", "submitter": "Juergen Schmidhuber", "authors": "Juergen Schmidhuber", "title": "2006: Celebrating 75 years of AI - History and Outlook: the Next 25\n  Years", "comments": "14 pages; preprint of invited contribution to the Proceedings of the\n  ``50th Anniversary Summit of Artificial Intelligence'' at Monte Verita,\n  Ascona, Switzerland, 9-14 July 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  When Kurt Goedel layed the foundations of theoretical computer science in\n1931, he also introduced essential concepts of the theory of Artificial\nIntelligence (AI). Although much of subsequent AI research has focused on\nheuristics, which still play a major role in many practical AI applications, in\nthe new millennium AI theory has finally become a full-fledged formal science,\nwith important optimality results for embodied agents living in unknown\nenvironments, obtained through a combination of theory a la Goedel and\nprobability theory. Here we look back at important milestones of AI history,\nmention essential recent results, and speculate about what we may expect from\nthe next 25 years, emphasizing the significance of the ongoing dramatic\nhardware speedups, and discussing Goedel-inspired, self-referential,\nself-improving universal problem solvers.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2007 11:12:26 GMT"}], "update_date": "2007-09-03", "authors_parsed": [["Schmidhuber", "Juergen", ""]]}
{"id": "0709.0116", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh", "title": "On Ultrametric Algorithmic Information", "comments": "Forthcoming, Computer Journal. Minor corrections 29 Oct. 2007", "journal-ref": "Computer Journal, 53, 405-416, 2010", "doi": "10.1093/comjnl/bxm084", "report-no": null, "categories": "cs.AI cs.CL", "license": null, "abstract": "  How best to quantify the information of an object, whether natural or\nartifact, is a problem of wide interest. A related problem is the computability\nof an object. We present practical examples of a new way to address this\nproblem. By giving an appropriate representation to our objects, based on a\nhierarchical coding of information, we exemplify how it is remarkably easy to\ncompute complex objects. Our algorithmic complexity is related to the length of\nthe class of objects, rather than to the length of the object.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2007 17:00:40 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2007 11:21:51 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Murtagh", "Fionn", ""]]}
{"id": "0709.0170", "submitter": "Alexander Wolff", "authors": "Xavier Goaoc and Jan Kratochvil and Yoshio Okamoto and Chan-Su Shin\n  and Andreas Spillner and Alexander Wolff", "title": "Untangling a Planar Graph", "comments": "(v5) Minor, mostly linguistic changes", "journal-ref": null, "doi": "10.1007/s00454-008-9130-6", "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A straight-line drawing $\\delta$ of a planar graph $G$ need not be plane, but\ncan be made so by \\emph{untangling} it, that is, by moving some of the vertices\nof $G$. Let shift$(G,\\delta)$ denote the minimum number of vertices that need\nto be moved to untangle $\\delta$. We show that shift$(G,\\delta)$ is NP-hard to\ncompute and to approximate. Our hardness results extend to a version of\n\\textsc{1BendPointSetEmbeddability}, a well-known graph-drawing problem.\n  Further we define fix$(G,\\delta)=n-shift(G,\\delta)$ to be the maximum number\nof vertices of a planar $n$-vertex graph $G$ that can be fixed when untangling\n$\\delta$. We give an algorithm that fixes at least $\\sqrt{((\\log n)-1)/\\log\n\\log n}$ vertices when untangling a drawing of an $n$-vertex graph $G$. If $G$\nis outerplanar, the same algorithm fixes at least $\\sqrt{n/2}$ vertices. On the\nother hand we construct, for arbitrarily large $n$, an $n$-vertex planar graph\n$G$ and a drawing $\\delta_G$ of $G$ with fix$(G,\\delta_G) \\le \\sqrt{n-2}+1$ and\nan $n$-vertex outerplanar graph $H$ and a drawing $\\delta_H$ of $H$ with\nfix$(H,\\delta_H) \\le 2 \\sqrt{n-1}+1$. Thus our algorithm is asymptotically\nworst-case optimal for outerplanar graphs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2007 08:59:34 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2008 08:46:19 GMT"}, {"version": "v3", "created": "Thu, 6 Nov 2008 21:53:18 GMT"}, {"version": "v4", "created": "Wed, 12 Nov 2008 13:15:12 GMT"}, {"version": "v5", "created": "Tue, 27 Jan 2009 21:38:25 GMT"}], "update_date": "2009-01-27", "authors_parsed": [["Goaoc", "Xavier", ""], ["Kratochvil", "Jan", ""], ["Okamoto", "Yoshio", ""], ["Shin", "Chan-Su", ""], ["Spillner", "Andreas", ""], ["Wolff", "Alexander", ""]]}
{"id": "0709.0178", "submitter": "Yasmine B. Sanderson", "authors": "Yasmine B. Sanderson", "title": "Effective Generation of Subjectively Random Binary Sequences", "comments": "Introduction and Section 6 revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for effectively generating binary sequences which\nwould be rated by people as highly likely to have been generated by a random\nprocess, such as flipping a fair coin.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2007 09:32:28 GMT"}, {"version": "v2", "created": "Sun, 5 Oct 2008 10:19:14 GMT"}], "update_date": "2008-10-05", "authors_parsed": [["Sanderson", "Yasmine B.", ""]]}
{"id": "0709.0355", "submitter": "Roland Bouffanais", "authors": "Nicolas Bodard, Roland Bouffanais, Michel O. Deville", "title": "Solution of moving-boundary problems by the spectral element method", "comments": "Applied Numerical Mathematics, In Press, 2008", "journal-ref": "Applied Numerial Mathematics 58 (2008) 968-984", "doi": "10.1016/j.apnum.2007.04.009", "report-no": null, "categories": "cs.CE cs.NA", "license": null, "abstract": "  This paper describes a novel numerical model aiming at solving\nmoving-boundary problems such as free-surface flows or fluid-structure\ninteraction. This model uses a moving-grid technique to solve the\nNavier--Stokes equations expressed in the arbitrary Lagrangian--Eulerian\nkinematics. The discretization in space is based on the spectral element\nmethod. The coupling of the fluid equations and the moving-grid equations is\nessentially done through the conditions on the moving boundaries. Two- and\nthree-dimensional simulations are presented: translation and rotation of a\ncylinder in a fluid, and large-amplitude sloshing in a rectangular tank. The\naccuracy and robustness of the present numerical model is studied and\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2007 14:51:56 GMT"}], "update_date": "2022-09-29", "authors_parsed": [["Bodard", "Nicolas", ""], ["Bouffanais", "Roland", ""], ["Deville", "Michel O.", ""]]}
{"id": "0709.0367", "submitter": "Francesco Zamponi", "authors": "Fabrizio Altarelli, Remi Monasson and Francesco Zamponi", "title": "Relationship between clustering and algorithmic phase transitions in the\n  random k-XORSAT model and its NP-complete extensions", "comments": "15 pages, 4 figures, Proceedings of the International Workshop on\n  Statistical-Mechanical Informatics, September 16-19, 2007, Kyoto, Japan; some\n  imprecisions in the previous version have been corrected", "journal-ref": "Journal of Physics: Conference Series 95 (2008) 012013", "doi": "10.1088/1742-6596/95/1/012013", "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  We study the performances of stochastic heuristic search algorithms on\nUniquely Extendible Constraint Satisfaction Problems with random inputs. We\nshow that, for any heuristic preserving the Poissonian nature of the underlying\ninstance, the (heuristic-dependent) largest ratio $\\alpha_a$ of constraints per\nvariables for which a search algorithm is likely to find solutions is smaller\nthan the critical ratio $\\alpha_d$ above which solutions are clustered and\nhighly correlated. In addition we show that the clustering ratio can be reached\nwhen the number k of variables per constraints goes to infinity by the\nso-called Generalized Unit Clause heuristic.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2007 08:56:27 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2007 11:35:29 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Altarelli", "Fabrizio", ""], ["Monasson", "Remi", ""], ["Zamponi", "Francesco", ""]]}
{"id": "0709.0522", "submitter": "Florentin Smarandache", "authors": "Florentin Smarandache, Jean Dezert", "title": "Qualitative Belief Conditioning Rules (QBCR)", "comments": "13 pages. Presented at Fusion 2007 International Conference, Quebec\n  City, Canada, July 2007", "journal-ref": "Proceedings of Fusion 2007 International Conference, Quebec City,\n  Canada, July 2007", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  In this paper we extend the new family of (quantitative) Belief Conditioning\nRules (BCR) recently developed in the Dezert-Smarandache Theory (DSmT) to their\nqualitative counterpart for belief revision. Since the revision of quantitative\nas well as qualitative belief assignment given the occurrence of a new event\n(the conditioning constraint) can be done in many possible ways, we present\nhere only what we consider as the most appealing Qualitative Belief\nConditioning Rules (QBCR) which allow to revise the belief directly with words\nand linguistic labels and thus avoids the introduction of ad-hoc translations\nof quantitative beliefs into quantitative ones for solving the problem.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2007 20:03:04 GMT"}], "update_date": "2007-09-06", "authors_parsed": [["Smarandache", "Florentin", ""], ["Dezert", "Jean", ""]]}
{"id": "0709.0674", "submitter": "Juergen Schmidhuber", "authors": "Juergen Schmidhuber", "title": "Simple Algorithmic Principles of Discovery, Subjective Beauty, Selective\n  Attention, Curiosity & Creativity", "comments": "15 pages, 3 highly compressible low-complexity drawings. Joint\n  Invited Lecture for Algorithmic Learning Theory (ALT 2007) and Discovery\n  Science (DS 2007), Sendai, Japan, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GR", "license": null, "abstract": "  I postulate that human or other intelligent agents function or should\nfunction as follows. They store all sensory observations as they come - the\ndata is holy. At any time, given some agent's current coding capabilities, part\nof the data is compressible by a short and hopefully fast program / description\n/ explanation / world model. In the agent's subjective eyes, such data is more\nregular and more \"beautiful\" than other data. It is well-known that knowledge\nof regularity and repeatability may improve the agent's ability to plan actions\nleading to external rewards. In absence of such rewards, however, known beauty\nis boring. Then \"interestingness\" becomes the first derivative of subjective\nbeauty: as the learning agent improves its compression algorithm, formerly\napparently random data parts become subjectively more regular and beautiful.\nSuch progress in compressibility is measured and maximized by the curiosity\ndrive: create action sequences that extend the observation history and yield\npreviously unknown / unpredictable but quickly learnable algorithmic\nregularity. We discuss how all of the above can be naturally implemented on\ncomputers, through an extension of passive unsupervised learning to the case of\nactive data selection: we reward a general reinforcement learner (with access\nto the adaptive compressor) for actions that improve the subjective\ncompressibility of the growing data. An unusually large breakthrough in\ncompressibility deserves the name \"discovery\". The \"creativity\" of artists,\ndancers, musicians, pure mathematicians can be viewed as a by-product of this\nprinciple. Several qualitative examples support this hypothesis.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2007 15:20:59 GMT"}], "update_date": "2007-09-06", "authors_parsed": [["Schmidhuber", "Juergen", ""]]}
{"id": "0709.0677", "submitter": "Binhai Zhu", "authors": "Binhai Zhu", "title": "On the Complexity of Protein Local Structure Alignment Under the\n  Discrete Fr\\'echet Distance", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": null, "abstract": "  We show that given $m$ proteins (or protein backbones, which are modeled as\n3D polygonal chains each of length O(n)) the problem of protein local structure\nalignment under the discrete Fr\\'{e}chet distance is as hard as Independent\nSet. So the problem does not admit any approximation of factor\n$n^{1-\\epsilon}$. This is the strongest negative result regarding the protein\nlocal structure alignment problem. On the other hand, if $m$ is a constant,\nthen the problem can be solved in polygnomial time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2007 15:30:54 GMT"}], "update_date": "2007-09-06", "authors_parsed": [["Zhu", "Binhai", ""]]}
{"id": "0709.0746", "submitter": "Ketan Mulmuley D", "authors": "Ketan D. Mulmuley, Milind Sohoni", "title": "Geometric Complexity Theory: Introduction", "comments": "161 pages", "journal-ref": null, "doi": null, "report-no": "TR-2007-16, comp. sci. dept., The University Of Chicago", "categories": "cs.CC", "license": null, "abstract": "  These are lectures notes for the introductory graduate courses on geometric\ncomplexity theory (GCT) in the computer science department, the university of\nChicago. Part I consists of the lecture notes for the course given by the first\nauthor in the spring quarter, 2007. It gives introduction to the basic\nstructure of GCT. Part II consists of the lecture notes for the course given by\nthe second author in the spring quarter, 2003. It gives introduction to\ninvariant theory with a view towards GCT. No background in algebraic geometry\nor representation theory is assumed. These lecture notes in conjunction with\nthe article \\cite{GCTflip1}, which describes in detail the basic plan of GCT\nbased on the principle called the flip, should provide a high level picture of\nGCT assuming familiarity with only basic notions of algebra, such as groups,\nrings, fields etc.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2007 21:54:52 GMT"}], "update_date": "2014-08-02", "authors_parsed": [["Mulmuley", "Ketan D.", ""], ["Sohoni", "Milind", ""]]}
{"id": "0709.0748", "submitter": "Ketan Mulmuley D", "authors": "Ketan D. Mulmuley", "title": "On P vs. NP, Geometric Complexity Theory, and the Flip I: a high level\n  view", "comments": "103 pages", "journal-ref": null, "doi": null, "report-no": "TR-2007-13, comp. sci. dept., The University of Chicago", "categories": "cs.CC", "license": null, "abstract": "  Geometric complexity theory (GCT) is an approach to the $P$ vs. $NP$ and\nrelated problems through algebraic geometry and representation theory. This\narticle gives a high-level exposition of the basic plan of GCT based on the\nprinciple, called the flip, without assuming any background in algebraic\ngeometry or representation theory.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2007 22:10:31 GMT"}], "update_date": "2007-09-07", "authors_parsed": [["Mulmuley", "Ketan D.", ""]]}
{"id": "0709.0749", "submitter": "Ketan Mulmuley D", "authors": "Ketan D. Mulmuley", "title": "Geometric Complexity Theory VII: Nonstandard quantum group for the\n  plethysm problem", "comments": "59 pages, changed content", "journal-ref": null, "doi": null, "report-no": "TR-2007-14, comp. sci. dept., The University Of Chicago", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a {\\em nonstandard} quantum group that may be used to\nderive a positive formula for the plethysm problem, just as the standard\n(Drinfeld-Jimbo) quantum group can be used to derive the positive\nLittlewood-Richardson rule for arbitrary complex semisimple Lie groups. The\nsequel \\cite{GCT8} gives conjecturally correct algorithms to construct\ncanonical bases of the coordinate rings of these nonstandard quantum groups and\ncanonical bases of the dually paired nonstandard deformations of the symmetric\ngroup algebra. A positive $#P$-formula for the plethysm constant follows from\nthe conjectural properties of these canonical bases and the duality and\nreciprocity conjectures herein.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2007 22:23:15 GMT"}, {"version": "v2", "created": "Mon, 1 Sep 2008 17:06:03 GMT"}], "update_date": "2008-09-01", "authors_parsed": [["Mulmuley", "Ketan D.", ""]]}
{"id": "0709.0751", "submitter": "Ketan Mulmuley D", "authors": "Ketan D. Mulmuley", "title": "Geometric Complexity Theory VIII: On canonical bases for the nonstandard\n  quantum groups", "comments": "71 pages, changed content", "journal-ref": null, "doi": null, "report-no": "TR-2007-15, comp. sci. dept., The University Of Chicago", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article gives conjecturally correct algorithms to construct canonical\nbases of the irreducible polynomial representations and the matrix coordinate\nrings of the nonstandard quantum groups in GCT4 and GCT7, and canonical bases\nof the dually paired nonstandard deformations of the symmetric group algebra\ntherein. These are generalizations of the canonical bases of the irreducible\npolynomial representations and the matrix coordinate ring of the standard\nquantum group, as constructed by Kashiwara and Lusztig, and the Kazhdan-Lusztig\nbasis of the Hecke algebra. A positive ($#P$-) formula for the well-known\nplethysm constants follows from their conjectural properties and the duality\nand reciprocity conjectures in \\cite{GCT7}.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2007 22:30:50 GMT"}, {"version": "v2", "created": "Mon, 1 Sep 2008 17:11:21 GMT"}], "update_date": "2008-09-01", "authors_parsed": [["Mulmuley", "Ketan D.", ""]]}
{"id": "0709.0787", "submitter": "Toshiya Takami", "authors": "Taizo Kobayashi, Toshiya Takami, Kin'ya Takahashi, Ryota Mibu, Mutsumi\n  Aoyagi", "title": "Sound Generation by a Turbulent Flow in Musical Instruments -\n  Multiphysics Simulation Approach -", "comments": "6 pages, 10 figure files, to appear in the proceedings of HPCAsia07", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE physics.flu-dyn", "license": null, "abstract": "  Total computational costs of scientific simulations are analyzed between\ndirect numerical simulations (DNS) and multiphysics simulations (MPS) for sound\ngeneration in musical instruments. In order to produce acoustic sound by a\nturbulent flow in a simple recorder-like instrument, compressible fluid dynamic\ncalculations with a low Mach number are required around the edges and the\nresonator of the instrument in DNS, while incompressible fluid dynamic\ncalculations coupled with dynamics of sound propagation based on the\nLighthill's acoustic analogy are used in MPS. These strategies are evaluated\nnot only from the viewpoint of computational performances but also from the\ntheoretical points of view as tools for scientific simulations of complicated\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2007 13:47:31 GMT"}], "update_date": "2007-09-07", "authors_parsed": [["Kobayashi", "Taizo", ""], ["Takami", "Toshiya", ""], ["Takahashi", "Kin'ya", ""], ["Mibu", "Ryota", ""], ["Aoyagi", "Mutsumi", ""]]}
{"id": "0709.0883", "submitter": "Joshua Herman J", "authors": "Joshua Jay Herman", "title": "Liquid State Machines in Adbiatic Quantum Computers for General\n  Computation", "comments": "Totally wrong", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.NE", "license": null, "abstract": "  Major mistakes do not read\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2007 16:04:42 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2007 19:34:51 GMT"}, {"version": "v3", "created": "Sun, 9 Sep 2007 14:29:14 GMT"}, {"version": "v4", "created": "Fri, 21 Sep 2007 13:09:13 GMT"}, {"version": "v5", "created": "Fri, 8 Jul 2011 01:54:35 GMT"}], "update_date": "2011-07-11", "authors_parsed": [["Herman", "Joshua Jay", ""]]}
{"id": "0709.0974", "submitter": "Sergey Gubin", "authors": "Sergey Gubin", "title": "Finding Paths and Cycles in Graphs", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": null, "abstract": "  A polynomial time algorithm which detects all paths and cycles of all lengths\nin form of vertex pairs (start, finish).\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2007 00:04:20 GMT"}], "update_date": "2007-09-10", "authors_parsed": [["Gubin", "Sergey", ""]]}
{"id": "0709.1023", "submitter": "Jorge Kurchan", "authors": "Florent Krzakala and Jorge Kurchan", "title": "Constraint optimization and landscapes", "comments": "Contribution to STATPHYS23", "journal-ref": "Eur. Phys. J. B 64, 563-565 (2008)", "doi": "10.1140/epjb/e2008-00052-x", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.CC nlin.AO", "license": null, "abstract": "  We describe an effective landscape introduced in [1] for the analysis of\nConstraint Satisfaction problems, such as Sphere Packing, K-SAT and Graph\nColoring. This geometric construction reexpresses these problems in the more\nfamiliar terms of optimization in rugged energy landscapes. In particular, it\nallows one to understand the puzzling fact that unsophisticated programs are\nsuccessful well beyond what was considered to be the `hard' transition, and\nsuggests an algorithm defining a new, higher, easy-hard frontier.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2007 08:49:38 GMT"}], "update_date": "2008-09-25", "authors_parsed": [["Krzakala", "Florent", ""], ["Kurchan", "Jorge", ""]]}
{"id": "0709.1099", "submitter": "Cherif Smaili", "authors": "Cherif Smaili (INRIA Lorraine - LORIA), Maan El Badaoui El Najjar\n  (INRIA Lorraine - LORIA), Fran\\c{c}ois Charpillet (INRIA Lorraine - LORIA)", "title": "Multi-Sensor Fusion Method using Dynamic Bayesian Network for Precise\n  Vehicle Localization and Road Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": null, "abstract": "  This paper presents a multi-sensor fusion strategy for a novel road-matching\nmethod designed to support real-time navigational features within advanced\ndriving-assistance systems. Managing multihypotheses is a useful strategy for\nthe road-matching problem. The multi-sensor fusion and multi-modal estimation\nare realized using Dynamical Bayesian Network. Experimental results, using data\nfrom Antilock Braking System (ABS) sensors, a differential Global Positioning\nSystem (GPS) receiver and an accurate digital roadmap, illustrate the\nperformances of this approach, especially in ambiguous situations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2007 15:03:37 GMT"}], "update_date": "2007-09-10", "authors_parsed": [["Smaili", "Cherif", "", "INRIA Lorraine - LORIA"], ["Najjar", "Maan El Badaoui El", "", "INRIA Lorraine - LORIA"], ["Charpillet", "François", "", "INRIA Lorraine - LORIA"]]}
{"id": "0709.1167", "submitter": "Marko Antonio Rodriguez", "authors": "Marko A. Rodriguez, Jennifer H. Watkins, Johan Bollen, Carlos\n  Gershenson", "title": "Using RDF to Model the Structure and Process of Systems", "comments": "International Conference on Complex Systems, Boston MA, October 2007", "journal-ref": "InterJournal of Complex Systems, 2131, ISSN: 1081-0625, February\n  2008", "doi": null, "report-no": "LAUR-07-5720", "categories": "cs.AI", "license": null, "abstract": "  Many systems can be described in terms of networks of discrete elements and\ntheir various relationships to one another. A semantic network, or\nmulti-relational network, is a directed labeled graph consisting of a\nheterogeneous set of entities connected by a heterogeneous set of\nrelationships. Semantic networks serve as a promising general-purpose modeling\nsubstrate for complex systems. Various standardized formats and tools are now\navailable to support practical, large-scale semantic network models. First, the\nResource Description Framework (RDF) offers a standardized semantic network\ndata model that can be further formalized by ontology modeling languages such\nas RDF Schema (RDFS) and the Web Ontology Language (OWL). Second, the recent\nintroduction of highly performant triple-stores (i.e. semantic network\ndatabases) allows semantic network models on the order of $10^9$ edges to be\nefficiently stored and manipulated. RDF and its related technologies are\ncurrently used extensively in the domains of computer science, digital library\nscience, and the biological sciences. This article will provide an introduction\nto RDF/RDFS/OWL and an examination of its suitability to model discrete element\ncomplex systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2007 01:18:18 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2007 16:00:19 GMT"}], "update_date": "2008-11-03", "authors_parsed": [["Rodriguez", "Marko A.", ""], ["Watkins", "Jennifer H.", ""], ["Bollen", "Johan", ""], ["Gershenson", "Carlos", ""]]}
{"id": "0709.1190", "submitter": "Mohsen Bayati", "authors": "Mohsen Bayati, Christian Borgs, Jennifer Chayes, Riccardo Zecchina", "title": "Belief-Propagation for Weighted b-Matchings on Arbitrary Graphs and its\n  Relation to Linear Programs with Integer Solutions", "comments": "28 pages, 2 figures. Submitted to SIAM journal on Discrete\n  Mathematics on March 19, 2009; accepted for publication (in revised form)\n  August 30, 2010; published electronically July 1, 2011", "journal-ref": "SIAM J. Discrete Math. 2011, Vol 25, Issue 2, pp. 989-1011", "doi": "10.1137/090753115", "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the general problem of finding the minimum weight $\\bm$-matching\non arbitrary graphs. We prove that, whenever the linear programming (LP)\nrelaxation of the problem has no fractional solutions, then the belief\npropagation (BP) algorithm converges to the correct solution. We also show that\nwhen the LP relaxation has a fractional solution then the BP algorithm can be\nused to solve the LP relaxation. Our proof is based on the notion of graph\ncovers and extends the analysis of (Bayati-Shah-Sharma 2005 and Huang-Jebara\n2007}.\n  These results are notable in the following regards: (1) It is one of a very\nsmall number of proofs showing correctness of BP without any constraint on the\ngraph structure. (2) Variants of the proof work for both synchronous and\nasynchronous BP; it is the first proof of convergence and correctness of an\nasynchronous BP algorithm for a combinatorial optimization problem.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2007 08:21:34 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2008 02:56:38 GMT"}, {"version": "v3", "created": "Thu, 4 Aug 2011 21:43:21 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Bayati", "Mohsen", ""], ["Borgs", "Christian", ""], ["Chayes", "Jennifer", ""], ["Zecchina", "Riccardo", ""]]}
{"id": "0709.1201", "submitter": "Alessio Guglielmi", "authors": "Paola Bruscoli and Alessio Guglielmi", "title": "On the Proof Complexity of Deep Inference", "comments": "Minor improvements over the published version. Always updated version\n  at <http://cs.bath.ac.uk/ag/p/PrComplDI.pdf>", "journal-ref": "ACM Transactions on Computational Logic 10 (2:14) 2009, pp. 1-34", "doi": "10.1145/1462179.1462186", "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain two results about the proof complexity of deep inference: 1)\ndeep-inference proof systems are as powerful as Frege ones, even when both are\nextended with the Tseitin extension rule or with the substitution rule; 2)\nthere are analytic deep-inference proof systems that exhibit an exponential\nspeed-up over analytic Gentzen proof systems that they polynomially simulate.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2007 11:35:28 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2008 15:34:38 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2009 18:55:21 GMT"}], "update_date": "2009-04-19", "authors_parsed": [["Bruscoli", "Paola", ""], ["Guglielmi", "Alessio", ""]]}
{"id": "0709.1207", "submitter": "Mikael Franzen", "authors": "Mikael Franzen", "title": "The P versus NP Brief", "comments": "4 pages, 1 figure; added notational definition for functions for\n  section 2, formatting and wording changes; corrected typo, recompiled\n  pdf-file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper discusses why P and NP are likely to be different. It analyses the\nessence of the concepts and points out that P and NP might be diverse by sheer\ndefinition. It also speculates that P and NP may be unequal due to natural\nlaws.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2007 12:45:51 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2009 23:42:52 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2009 23:58:14 GMT"}], "update_date": "2009-05-01", "authors_parsed": [["Franzen", "Mikael", ""]]}
{"id": "0709.1500", "submitter": "Shmuel Onn", "authors": "Yael Berstein and Shmuel Onn", "title": "The Graver Complexity of Integer Programming", "comments": "Improved Bound $\\Omega(2^m)$", "journal-ref": "Annals of Combinatorics, 13:289--296, 2009", "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM math.AC", "license": null, "abstract": "  In this article we establish an exponential lower bound on the Graver\ncomplexity of integer programs. This provides new type of evidence supporting\nthe presumable intractability of integer programming. Specifically, we show\nthat the Graver complexity of the incidence matrix of the complete bipartite\ngraph $K_{3,m}$ satisfies $g(m)=\\Omega(2^m)$, with $g(m)\\geq 17\\cdot 2^{m-3}-7$\nfor every $m>3$ .\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2007 22:19:06 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2007 08:00:10 GMT"}], "update_date": "2010-06-07", "authors_parsed": [["Berstein", "Yael", ""], ["Onn", "Shmuel", ""]]}
{"id": "0709.1647", "submitter": "Joseph O'Rourke", "authors": "Joseph O'Rourke", "title": "Unfolding Restricted Convex Caps", "comments": null, "journal-ref": null, "doi": null, "report-no": "Smith Computer Science 086", "categories": "cs.CG", "license": null, "abstract": "  This paper details an algorithm for unfolding a class of convex polyhedra,\nwhere each polyhedron in the class consists of a convex cap over a rectangular\nbase, with several restrictions: the cap's faces are quadrilaterals, with\nvertices over an underlying integer lattice, and such that the cap convexity is\n``radially monotone,'' a type of smoothness constraint. Extensions of Cauchy's\narm lemma are used in the proof of non-overlap.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2007 15:01:31 GMT"}], "update_date": "2007-09-12", "authors_parsed": [["O'Rourke", "Joseph", ""]]}
{"id": "0709.1667", "submitter": "Federico Ricci-Tersenghi", "authors": "Andrea Montanari, Federico Ricci-Tersenghi and Guilhem Semerjian", "title": "Solving Constraint Satisfaction Problems through Belief\n  Propagation-guided decimation", "comments": "10 pages, 4 figures. A longer version can be found as arXiv:0904.3395\n  [cond-mat.dis-nn]", "journal-ref": "Proceedings of the 45th Annual Allerton Conference on\n  Communication, Control, and Computing (Monticello, IL, USA), 352-359 (2007)", "doi": null, "report-no": null, "categories": "cs.AI cond-mat.dis-nn cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing algorithms have proved surprisingly successful in solving\nhard constraint satisfaction problems on sparse random graphs. In such\napplications, variables are fixed sequentially to satisfy the constraints.\nMessage passing is run after each step. Its outcome provides an heuristic to\nmake choices at next step. This approach has been referred to as `decimation,'\nwith reference to analogous procedures in statistical physics.\n  The behavior of decimation procedures is poorly understood. Here we consider\na simple randomized decimation algorithm based on belief propagation (BP), and\nanalyze its behavior on random k-satisfiability formulae. In particular, we\npropose a tree model for its analysis and we conjecture that it provides\nasymptotically exact predictions in the limit of large instances. This\nconjecture is confirmed by numerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2007 15:48:56 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2007 15:01:01 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 11:43:45 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Montanari", "Andrea", ""], ["Ricci-Tersenghi", "Federico", ""], ["Semerjian", "Guilhem", ""]]}
{"id": "0709.1667", "submitter": "Federico Ricci-Tersenghi", "authors": "Andrea Montanari, Federico Ricci-Tersenghi and Guilhem Semerjian", "title": "Solving Constraint Satisfaction Problems through Belief\n  Propagation-guided decimation", "comments": "10 pages, 4 figures. A longer version can be found as arXiv:0904.3395\n  [cond-mat.dis-nn]", "journal-ref": "Proceedings of the 45th Annual Allerton Conference on\n  Communication, Control, and Computing (Monticello, IL, USA), 352-359 (2007)", "doi": null, "report-no": null, "categories": "cs.AI cond-mat.dis-nn cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing algorithms have proved surprisingly successful in solving\nhard constraint satisfaction problems on sparse random graphs. In such\napplications, variables are fixed sequentially to satisfy the constraints.\nMessage passing is run after each step. Its outcome provides an heuristic to\nmake choices at next step. This approach has been referred to as `decimation,'\nwith reference to analogous procedures in statistical physics.\n  The behavior of decimation procedures is poorly understood. Here we consider\na simple randomized decimation algorithm based on belief propagation (BP), and\nanalyze its behavior on random k-satisfiability formulae. In particular, we\npropose a tree model for its analysis and we conjecture that it provides\nasymptotically exact predictions in the limit of large instances. This\nconjecture is confirmed by numerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2007 15:48:56 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2007 15:01:01 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 11:43:45 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Montanari", "Andrea", ""], ["Ricci-Tersenghi", "Federico", ""], ["Semerjian", "Guilhem", ""]]}
{"id": "0709.1699", "submitter": "Paul Fodor", "authors": "Paul Fodor", "title": "Efficient Tabling Mechanisms for Transaction Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": null, "abstract": "  In this paper we present efficient evaluation algorithms for the Horn\nTransaction Logic (a generalization of the regular Horn logic programs with\nstate updates). We present two complementary methods for optimizing the\nimplementation of Transaction Logic. The first method is based on tabling and\nwe modified the proof theory to table calls and answers on states (practically,\nequivalent to dynamic programming). The call-answer table is indexed on the\ncall and a signature of the state in which the call was made. The answer\ncolumns contain the answer unification and a signature of the state after the\ncall was executed. The states are signed efficiently using a technique based on\ntries and counting. The second method is based on incremental evaluation and it\napplies when the data oracle contains derived relations. The deletions and\ninsertions (executed in the transaction oracle) change the state of the\ndatabase. Using the heuristic of inertia (only a part of the state changes in\nresponse to elementary updates), most of the time it is cheaper to compute only\nthe changes in the state than to recompute the entire state from scratch. The\ntwo methods are complementary by the fact that the first method optimizes the\nevaluation when a call is repeated in the same state, and the second method\noptimizes the evaluation of a new state when a call-state pair is not found by\nthe tabling mechanism (i.e. the first method). The proof theory of Transaction\nLogic with the application of tabling and incremental evaluation is sound and\ncomplete with respect to its model theory.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2007 19:00:02 GMT"}], "update_date": "2007-09-12", "authors_parsed": [["Fodor", "Paul", ""]]}
{"id": "0709.1701", "submitter": "Jean Dezert", "authors": "Xinde Li (ICRL), Xinhan Huang (ICRL), Florentin Smarandache (UNM),\n  Jean Dezert (ONERA)", "title": "Enrichment of Qualitative Beliefs for Reasoning under Uncertainty", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper deals with enriched qualitative belief functions for reasoning\nunder uncertainty and for combining information expressed in natural language\nthrough linguistic labels. In this work, two possible enrichments (quantitative\nand/or qualitative) of linguistic labels are considered and operators\n(addition, multiplication, division, etc) for dealing with them are proposed\nand explained. We denote them $qe$-operators, $qe$ standing for\n\"qualitative-enriched\" operators. These operators can be seen as a direct\nextension of the classical qualitative operators ($q$-operators) proposed\nrecently in the Dezert-Smarandache Theory of plausible and paradoxist reasoning\n(DSmT). $q$-operators are also justified in details in this paper. The\nquantitative enrichment of linguistic label is a numerical supporting degree in\n$[0,\\infty)$, while the qualitative enrichment takes its values in a finite\nordered set of linguistic values. Quantitative enrichment is less precise than\nqualitative enrichment, but it is expected more close with what human experts\ncan easily provide when expressing linguistic labels with supporting degrees.\nTwo simple examples are given to show how the fusion of qualitative-enriched\nbelief assignments can be done.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2007 19:12:25 GMT"}], "update_date": "2007-09-12", "authors_parsed": [["Li", "Xinde", "", "ICRL"], ["Huang", "Xinhan", "", "ICRL"], ["Smarandache", "Florentin", "", "UNM"], ["Dezert", "Jean", "", "ONERA"]]}
{"id": "0709.1934", "submitter": "Petar Markovi\\'c", "authors": "Catarina Carvalho, V\\'ictor Dalmau, Petar Markovi\\'c and Mikl\\'os\n  Mar\\'oti", "title": "CD(4) has bounded width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": null, "abstract": "  We prove that the constraint languages invariant under a short sequence of\nJ\\'onsson terms (containing at most three non-trivial ternary terms) are\ntractable by showing that they have bounded width. This improves the previous\nresult by Kiss and Valeriote and presents some evidence that the Larose-Zadori\nconjecture holds in the congruence-distributive case.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2007 17:26:10 GMT"}], "update_date": "2007-09-14", "authors_parsed": [["Carvalho", "Catarina", ""], ["Dalmau", "Víctor", ""], ["Marković", "Petar", ""], ["Maróti", "Miklós", ""]]}
{"id": "0709.1941", "submitter": "Pierre-Francois Marteau", "authors": "Pierre-Fran\\c{c}ois Marteau (VALORIA), Gildas G. M\\'enier (VALORIA)", "title": "Speeding up Simplification of Polygonal Curves using Nested\n  Approximations", "comments": "12 pages + figures", "journal-ref": "Pattern Analysis & Applications (2008) 1-8", "doi": "10.1007/s10044-008-0133-y", "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  We develop a multiresolution approach to the problem of polygonal curve\napproximation. We show theoretically and experimentally that, if the\nsimplification algorithm A used between any two successive levels of resolution\nsatisfies some conditions, the multiresolution algorithm MR will have a\ncomplexity lower than the complexity of A. In particular, we show that if A has\na O(N2/K) complexity (the complexity of a reduced search dynamic solution\napproach), where N and K are respectively the initial and the final number of\nsegments, the complexity of MR is in O(N).We experimentally compare the\noutcomes of MR with those of the optimal \"full search\" dynamic programming\nsolution and of classical merge and split approaches. The experimental\nevaluations confirm the theoretical derivations and show that the proposed\napproach evaluated on 2D coastal maps either shows a lower complexity or\nprovides polygonal approximations closer to the initial curves.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2007 18:27:53 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2007 15:32:03 GMT"}, {"version": "v3", "created": "Sun, 2 Mar 2008 17:14:36 GMT"}], "update_date": "2008-07-22", "authors_parsed": [["Marteau", "Pierre-François", "", "VALORIA"], ["Ménier", "Gildas G.", "", "VALORIA"]]}
{"id": "0709.1942", "submitter": "Joseph O'Rourke", "authors": "Mirela Damian, Robin Flatland, Joseph O'Rourke, Suneeta Ramaswami", "title": "Connecting Polygonizations via Stretches and Twangs", "comments": "15 pages, 14 figures, 3 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": null, "abstract": "  We show that the space of polygonizations of a fixed planar point set S of n\npoints is connected by O(n^2) ``moves'' between simple polygons. Each move is\ncomposed of a sequence of atomic moves called ``stretches'' and ``twangs''.\nThese atomic moves walk between weakly simple ``polygonal wraps'' of S. These\nmoves show promise to serve as a basis for generating random polygons.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2007 18:38:54 GMT"}], "update_date": "2007-09-13", "authors_parsed": [["Damian", "Mirela", ""], ["Flatland", "Robin", ""], ["O'Rourke", "Joseph", ""], ["Ramaswami", "Suneeta", ""]]}
{"id": "0709.2065", "submitter": "Andrei Khrennikov", "authors": "Andrei Khrennikov", "title": "Toward Psycho-robots", "comments": null, "journal-ref": "Paladyn Volume 1, Number 2, 99-108, 2010", "doi": "10.2478/s13230-010-0014-0", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  We try to perform geometrization of psychology by representing mental states,\n<<ideas>>, by points of a metric space, <<mental space>>. Evolution of ideas is\ndescribed by dynamical systems in metric mental space. We apply the mental\nspace approach for modeling of flows of unconscious and conscious information\nin the human brain. In a series of models, Models 1-4, we consider cognitive\nsystems with increasing complexity of psychological behavior determined by\nstructure of flows of ideas. Since our models are in fact models of the\nAI-type, one immediately recognizes that they can be used for creation of\nAI-systems, which we call psycho-robots, exhibiting important elements of human\npsyche. Creation of such psycho-robots may be useful improvement of domestic\nrobots. At the moment domestic robots are merely simple working devices (e.g.\nvacuum cleaners or lawn mowers) . However, in future one can expect demand in\nsystems which be able not only perform simple work tasks, but would have\nelements of human self-developing psyche. Such AI-psyche could play an\nimportant role both in relations between psycho-robots and their owners as well\nas between psycho-robots. Since the presence of a huge numbers of\npsycho-complexes is an essential characteristic of human psychology, it would\nbe interesting to model them in the AI-framework.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2007 13:06:34 GMT"}], "update_date": "2010-11-30", "authors_parsed": [["Khrennikov", "Andrei", ""]]}
{"id": "0709.2196", "submitter": "Frank Nielsen", "authors": "Frank Nielsen, Jean-Daniel Boissonnat, Richard Nock", "title": "Bregman Voronoi Diagrams: Properties, Algorithms and Applications", "comments": "Extend the proceedings abstract of SODA 2007 (46 pages, 15 figures)", "journal-ref": "Discrete & Computational Geometry volume 44, pages281-307(2010)", "doi": "10.1007/s00454-010-9256-1", "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  The Voronoi diagram of a finite set of objects is a fundamental geometric\nstructure that subdivides the embedding space into regions, each region\nconsisting of the points that are closer to a given object than to the others.\nWe may define many variants of Voronoi diagrams depending on the class of\nobjects, the distance functions and the embedding space. In this paper, we\ninvestigate a framework for defining and building Voronoi diagrams for a broad\nclass of distance functions called Bregman divergences. Bregman divergences\ninclude not only the traditional (squared) Euclidean distance but also various\ndivergence measures based on entropic functions. Accordingly, Bregman Voronoi\ndiagrams allow to define information-theoretic Voronoi diagrams in statistical\nparametric spaces based on the relative entropy of distributions. We define\nseveral types of Bregman diagrams, establish correspondences between those\ndiagrams (using the Legendre transformation), and show how to compute them\nefficiently. We also introduce extensions of these diagrams, e.g. k-order and\nk-bag Bregman Voronoi diagrams, and introduce Bregman triangulations of a set\nof points and their connexion with Bregman Voronoi diagrams. We show that these\ntriangulations capture many of the properties of the celebrated Delaunay\ntriangulation. Finally, we give some applications of Bregman Voronoi diagrams\nwhich are of interest in the context of computational geometry and machine\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2007 01:31:17 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Nielsen", "Frank", ""], ["Boissonnat", "Jean-Daniel", ""], ["Nock", "Richard", ""]]}
{"id": "0709.2346", "submitter": "Pilar Albert", "authors": "Pilar Albert, Elvira Mayordomo, Philippe Moser, Sylvain Perifel", "title": "Pushdown Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": null, "abstract": "  The pressing need for eficient compression schemes for XML documents has\nrecently been focused on stack computation [6, 9], and in particular calls for\na formulation of information-lossless stack or pushdown compressors that allows\na formal analysis of their performance and a more ambitious use of the stack in\nXML compression, where so far it is mainly connected to parsing mechanisms. In\nthis paper we introduce the model of pushdown compressor, based on pushdown\ntransducers that compute a single injective function while keeping the widest\ngenerality regarding stack computation. The celebrated Lempel-Ziv algorithm\nLZ78 [10] was introduced as a general purpose compression algorithm that\noutperforms finite-state compressors on all sequences. We compare the\nperformance of the Lempel-Ziv algorithm with that of the pushdown compressors,\nor compression algorithms that can be implemented with a pushdown transducer.\nThis comparison is made without any a priori assumption on the data's source\nand considering the asymptotic compression ratio for infinite sequences. We\nprove that Lempel-Ziv is incomparable with pushdown compressors.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2007 17:00:09 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2007 11:15:58 GMT"}], "update_date": "2007-09-17", "authors_parsed": [["Albert", "Pilar", ""], ["Mayordomo", "Elvira", ""], ["Moser", "Philippe", ""], ["Perifel", "Sylvain", ""]]}
{"id": "0709.2405", "submitter": "J. Maurice Rojas", "authors": "Joel Gomez, Andrew Niles, and J. Maurice Rojas", "title": "New Complexity Bounds for Certain Real Fewnomial Zero Sets", "comments": "8 pages, no figures. Extended abstract accepted and presented at MEGA\n  (Effective Methods in Algebraic Geometry) 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CG", "license": null, "abstract": "  Consider real bivariate polynomials f and g, respectively having 3 and m\nmonomial terms. We prove that for all m>=3, there are systems of the form (f,g)\nhaving exactly 2m-1 roots in the positive quadrant. Even examples with m=4\nhaving 7 positive roots were unknown before this paper, so we detail an\nexplicit example of this form. We also present an O(n^{11}) upper bound for the\nnumber of diffeotopy types of the real zero set of an n-variate polynomial with\nn+4 monomial terms.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2007 06:28:46 GMT"}], "update_date": "2007-09-18", "authors_parsed": [["Gomez", "Joel", ""], ["Niles", "Andrew", ""], ["Rojas", "J. Maurice", ""]]}
{"id": "0709.2506", "submitter": "Tshilidzi Marwala", "authors": "Vukosi N. Marivate, Fulufhelo V. Nelwamodo, Tshilidzi Marwala", "title": "Autoencoder, Principal Component Analysis and Support Vector Regression\n  for Data Imputation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": null, "abstract": "  Data collection often results in records that have missing values or\nvariables. This investigation compares 3 different data imputation models and\nidentifies their merits by using accuracy measures. Autoencoder Neural\nNetworks, Principal components and Support Vector regression are used for\nprediction and combined with a genetic algorithm to then impute missing\nvariables. The use of PCA improves the overall performance of the autoencoder\nnetwork while the use of support vector regression shows promising potential\nfor future investigation. Accuracies of up to 97.4 % on imputation of some of\nthe variables were achieved.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2007 18:15:01 GMT"}], "update_date": "2007-09-18", "authors_parsed": [["Marivate", "Vukosi N.", ""], ["Nelwamodo", "Fulufhelo V.", ""], ["Marwala", "Tshilidzi", ""]]}
{"id": "0709.2512", "submitter": "Chao Chen", "authors": "Chao Chen, Daniel Freedman", "title": "Quantifying Homology Classes II: Localization and Stability", "comments": "The \"companion paper\" referred in this paper is another version of\n  the paper \"Measuring and localizing homology classes\" by the same authors.\n  Sept. 21st: authors name fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.AT", "license": null, "abstract": "  In the companion paper, we measured homology classes and computed the optimal\nhomology basis. This paper addresses two related problems, namely, localization\nand stability. We localize a class with the cycle minimizing a certain\nobjective function. We explore three different objective functions, namely,\nvolume, diameter and radius. We show that it is NP-hard to compute the smallest\ncycle using the former two. We also prove that the measurement defined in the\ncompanion paper is stable with regard to small changes of the geometry of the\nconcerned space.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2007 20:48:49 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2007 16:41:02 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Chen", "Chao", ""], ["Freedman", "Daniel", ""]]}
{"id": "0709.2512", "submitter": "Chao Chen", "authors": "Chao Chen, Daniel Freedman", "title": "Quantifying Homology Classes II: Localization and Stability", "comments": "The \"companion paper\" referred in this paper is another version of\n  the paper \"Measuring and localizing homology classes\" by the same authors.\n  Sept. 21st: authors name fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.AT", "license": null, "abstract": "  In the companion paper, we measured homology classes and computed the optimal\nhomology basis. This paper addresses two related problems, namely, localization\nand stability. We localize a class with the cycle minimizing a certain\nobjective function. We explore three different objective functions, namely,\nvolume, diameter and radius. We show that it is NP-hard to compute the smallest\ncycle using the former two. We also prove that the measurement defined in the\ncompanion paper is stable with regard to small changes of the geometry of the\nconcerned space.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2007 20:48:49 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2007 16:41:02 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Chen", "Chao", ""], ["Freedman", "Daniel", ""]]}
{"id": "0709.2831", "submitter": "Monique Teillaud", "authors": "Mridul Aanjaneya, Monique Teillaud (INRIA Sophia Antipolis)", "title": "Triangulating the Real Projective Plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  We consider the problem of computing a triangulation of the real projective\nplane P2, given a finite point set S={p1, p2,..., pn} as input. We prove that a\ntriangulation of P2 always exists if at least six points in S are in general\nposition, i.e., no three of them are collinear. We also design an algorithm for\ntriangulating P2 if this necessary condition holds. As far as we know, this is\nthe first computational result on the real projective plane.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2007 15:36:38 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2007 15:23:14 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Aanjaneya", "Mridul", "", "INRIA Sophia Antipolis"], ["Teillaud", "Monique", "", "INRIA Sophia Antipolis"]]}
{"id": "0709.2961", "submitter": "Andreas Schutt", "authors": "Andreas Schutt and Peter J. Stuckey", "title": "Incremental Satisfiability and Implication for UTVPI Constraints", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LO", "license": null, "abstract": "  Unit two-variable-per-inequality (UTVPI) constraints form one of the largest\nclass of integer constraints which are polynomial time solvable (unless P=NP).\nThere is considerable interest in their use for constraint solving, abstract\ninterpretation, spatial databases, and theorem proving. In this paper we\ndevelop a new incremental algorithm for UTVPI constraint satisfaction and\nimplication checking that requires O(m + n log n + p) time and O(n+m+p) space\nto incrementally check satisfiability of m UTVPI constraints on n variables and\ncheck implication of p UTVPI constraints.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2007 06:58:05 GMT"}], "update_date": "2007-09-20", "authors_parsed": [["Schutt", "Andreas", ""], ["Stuckey", "Peter J.", ""]]}
{"id": "0709.3283", "submitter": "Michael Kettner", "authors": "Michael Kettner", "title": "Algorithmic and topological aspects of semi-algebraic sets defined by\n  quadratic polynomial", "comments": "PhD thesis, final version, 109 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CG math.AT math.GT", "license": null, "abstract": "  In this thesis, we consider semi-algebraic sets over a real closed field $R$\ndefined by quadratic polynomials. Semi-algebraic sets of $R^k$ are defined as\nthe smallest family of sets in $R^k$ that contains the algebraic sets as well\nas the sets defined by polynomial inequalities, and which is also closed under\nthe boolean operations (complementation, finite unions and finite\nintersections). We prove new bounds on the Betti numbers as well as on the\nnumber of different stable homotopy types of certain fibers of semi-algebraic\nsets over a real closed field $R$ defined by quadratic polynomials, in terms of\nthe parameters of the system of polynomials defining them, which improve the\nknown results. We conclude the thesis with presenting two new algorithms along\nwith their implementations. The first algorithm computes the number of\nconnected components and the first Betti number of a semi-algebraic set defined\nby compact objects in $\\mathbb{R}^k$ which are simply connected. This algorithm\nimproves the well-know method using a triangulation of the semi-algebraic set.\nMoreover, the algorithm has been efficiently implemented which was not possible\nbefore. The second algorithm computes efficiently the real intersection of\nthree quadratic surfaces in $\\mathbb{R}^3$ using a semi-numerical approach.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2007 19:28:10 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Kettner", "Michael", ""]]}
{"id": "0709.3554", "submitter": "Mirela Damian", "authors": "Mirela Damian, Robin Flatland, Joseph O'Rourke and Suneeta Ramaswami", "title": "A New Lower Bound on Guard Placement for Wireless Localization", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": null, "abstract": "  The problem of wireless localization asks to place and orient stations in the\nplane, each of which broadcasts a unique key within a fixed angular range, so\nthat each point in the plane can determine whether it is inside or outside a\ngiven polygonal region. The primary goal is to minimize the number of stations.\nIn this paper we establish a lower bound of 2n/3 - 1 stations for polygons in\ngeneral position, for the case in which the placement of stations is restricted\nto polygon vertices, improving upon the existing n/2 lower bound.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2007 00:35:28 GMT"}], "update_date": "2007-09-25", "authors_parsed": [["Damian", "Mirela", ""], ["Flatland", "Robin", ""], ["O'Rourke", "Joseph", ""], ["Ramaswami", "Suneeta", ""]]}
{"id": "0709.3554", "submitter": "Mirela Damian", "authors": "Mirela Damian, Robin Flatland, Joseph O'Rourke and Suneeta Ramaswami", "title": "A New Lower Bound on Guard Placement for Wireless Localization", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": null, "abstract": "  The problem of wireless localization asks to place and orient stations in the\nplane, each of which broadcasts a unique key within a fixed angular range, so\nthat each point in the plane can determine whether it is inside or outside a\ngiven polygonal region. The primary goal is to minimize the number of stations.\nIn this paper we establish a lower bound of 2n/3 - 1 stations for polygons in\ngeneral position, for the case in which the placement of stations is restricted\nto polygon vertices, improving upon the existing n/2 lower bound.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2007 00:35:28 GMT"}], "update_date": "2007-09-25", "authors_parsed": [["Damian", "Mirela", ""], ["Flatland", "Robin", ""], ["O'Rourke", "Joseph", ""], ["Ramaswami", "Suneeta", ""]]}
{"id": "0709.3965", "submitter": "Tshilidzi Marwala", "authors": "Greg Hulley and Tshilidzi Marwala", "title": "Evolving Classifiers: Methods for Incremental Learning", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": null, "abstract": "  The ability of a classifier to take on new information and classes by\nevolving the classifier without it having to be fully retrained is known as\nincremental learning. Incremental learning has been successfully applied to\nmany classification problems, where the data is changing and is not all\navailable at once. In this paper there is a comparison between Learn++, which\nis one of the most recent incremental learning algorithms, and the new proposed\nmethod of Incremental Learning Using Genetic Algorithm (ILUGA). Learn++ has\nshown good incremental learning capabilities on benchmark datasets on which the\nnew ILUGA method has been tested. ILUGA has also shown good incremental\nlearning ability using only a few classifiers and does not suffer from\ncatastrophic forgetting. The results obtained for ILUGA on the Optical\nCharacter Recognition (OCR) and Wine datasets are good, with an overall\naccuracy of 93% and 94% respectively showing a 4% improvement over Learn++.MT\nfor the difficult multi-class OCR dataset.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 14:28:32 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2007 10:37:00 GMT"}], "update_date": "2007-09-26", "authors_parsed": [["Hulley", "Greg", ""], ["Marwala", "Tshilidzi", ""]]}
{"id": "0709.3967", "submitter": "Tshilidzi Marwala", "authors": "Gidudu Anthony, Hulley Greg and Marwala Tshilidzi", "title": "Classification of Images Using Support Vector Machines", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": null, "abstract": "  Support Vector Machines (SVMs) are a relatively new supervised classification\ntechnique to the land cover mapping community. They have their roots in\nStatistical Learning Theory and have gained prominence because they are robust,\naccurate and are effective even when using a small training sample. By their\nnature SVMs are essentially binary classifiers, however, they can be adopted to\nhandle the multiple classification tasks common in remote sensing studies. The\ntwo approaches commonly used are the One-Against-One (1A1) and One-Against-All\n(1AA) techniques. In this paper, these approaches are evaluated in as far as\ntheir impact and implication for land cover mapping. The main finding from this\nresearch is that whereas the 1AA technique is more predisposed to yielding\nunclassified and mixed pixels, the resulting classification accuracy is not\nsignificantly different from 1A1 approach. It is the authors conclusions that\nultimately the choice of technique adopted boils down to personal preference\nand the uniqueness of the dataset at hand.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 14:37:40 GMT"}], "update_date": "2007-09-26", "authors_parsed": [["Anthony", "Gidudu", ""], ["Greg", "Hulley", ""], ["Tshilidzi", "Marwala", ""]]}
{"id": "0709.3974", "submitter": "Sebastien Verel", "authors": "S\\'ebastien Verel (I3S), Philippe Collard (I3S), Marco Tomassini\n  (ISI), Leonardo Vanneschi (DISCO)", "title": "Fitness landscape of the cellular automata majority problem: View from\n  the Olympus", "comments": null, "journal-ref": "Theoretical Computer Science 378, 1 (2007) 54-77", "doi": "10.1016/j.tcs.2007.01.001", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  In this paper we study cellular automata (CAs) that perform the computational\nMajority task. This task is a good example of what the phenomenon of emergence\nin complex systems is. We take an interest in the reasons that make this\nparticular fitness landscape a difficult one. The first goal is to study the\nlandscape as such, and thus it is ideally independent from the actual\nheuristics used to search the space. However, a second goal is to understand\nthe features a good search technique for this particular problem space should\npossess. We statistically quantify in various ways the degree of difficulty of\nsearching this landscape. Due to neutrality, investigations based on sampling\ntechniques on the whole landscape are difficult to conduct. So, we go exploring\nthe landscape from the top. Although it has been proved that no CA can perform\nthe task perfectly, several efficient CAs for this task have been found.\nExploiting similarities between these CAs and symmetries in the landscape, we\ndefine the Olympus landscape which is regarded as the ''heavenly home'' of the\nbest local optima known (blok). Then we measure several properties of this\nsubspace. Although it is easier to find relevant CAs in this subspace than in\nthe overall landscape, there are structural reasons that prevent a searcher\nfrom finding overfitted CAs in the Olympus. Finally, we study dynamics and\nperformance of genetic algorithms on the Olympus in order to confirm our\nanalysis and to find efficient CAs for the Majority problem with low\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 15:40:38 GMT"}], "update_date": "2007-09-26", "authors_parsed": [["Verel", "Sébastien", "", "I3S"], ["Collard", "Philippe", "", "I3S"], ["Tomassini", "Marco", "", "ISI"], ["Vanneschi", "Leonardo", "", "DISCO"]]}
{"id": "0709.4010", "submitter": "Sebastien Verel", "authors": "Philippe Collard (I3S), S\\'ebastien Verel (I3S), Manuel Clergue (I3S)", "title": "Local search heuristics: Fitness Cloud versus Fitness Landscape", "comments": null, "journal-ref": "Dans Poster at the 2004 European Conference on Artificial\n  Intelligence (ECAI04) - the 2004 European Conference on Artificial\n  Intelligence (ECAI04), Valencia : Espagne (2004)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper introduces the concept of fitness cloud as an alternative way to\nvisualize and analyze search spaces than given by the geographic notion of\nfitness landscape. It is argued that the fitness cloud concept overcomes\nseveral deficiencies of the landscape representation. Our analysis is based on\nthe correlation between fitness of solutions and fitnesses of nearest solutions\naccording to some neighboring. We focus on the behavior of local search\nheuristics, such as hill climber, on the well-known NK fitness landscape. In\nboth cases the fitness vs. fitness correlation is shown to be related to the\nepistatic parameter K.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 19:15:50 GMT"}], "update_date": "2007-09-26", "authors_parsed": [["Collard", "Philippe", "", "I3S"], ["Verel", "Sébastien", "", "I3S"], ["Clergue", "Manuel", "", "I3S"]]}
{"id": "0709.4011", "submitter": "Sebastien Verel", "authors": "S\\'ebastien Verel (I3S), Philippe Collard (I3S), Manuel Clergue (I3S)", "title": "Measuring the Evolvability Landscape to study Neutrality", "comments": null, "journal-ref": "Dans Poster at Genetic and Evolutionary Computation -- GECCO-2006\n  - Genetic and Evolutionary Computation -- GECCO-2006, Seattle, WA :\n  \\'Etats-Unis d'Am\\'erique (2006)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This theoretical work defines the measure of autocorrelation of evolvability\nin the context of neutral fitness landscape. This measure has been studied on\nthe classical MAX-SAT problem. This work highlight a new characteristic of\nneutral fitness landscapes which allows to design new adapted metaheuristic.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 19:17:08 GMT"}], "update_date": "2007-09-26", "authors_parsed": [["Verel", "Sébastien", "", "I3S"], ["Collard", "Philippe", "", "I3S"], ["Clergue", "Manuel", "", "I3S"]]}
{"id": "0709.4015", "submitter": "Amanda Bouffier", "authors": "Amanda Bouffier (LIPN)", "title": "From Texts to Structured Documents: The Case of Health Practice\n  Guidelines", "comments": null, "journal-ref": "Dans International Semantic Web Conference Proceedings -\n  International Semantic Web Conference-Doctoral Consortium, Busan : Cor\\'ee,\n  R\\'epublique de (2007)", "doi": "10.1007/978-3-540-76298-0_69", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper describes a system capable of semi-automatically filling an XML\ntemplate from free texts in the clinical domain (practice guidelines). The XML\ntemplate includes semantic information not explicitly encoded in the text\n(pairs of conditions and actions/recommendations). Therefore, there is a need\nto compute the exact scope of conditions over text sequences expressing the\nrequired actions. We present in this paper the rules developed for this task.\nWe show that the system yields good performance when applied to the analysis of\nFrench practice guidelines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 19:26:08 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Bouffier", "Amanda", "", "LIPN"]]}
{"id": "0709.4087", "submitter": "David Eppstein", "authors": "David Eppstein", "title": "The Topology of Bendless Three-Dimensional Orthogonal Graph Drawing", "comments": "23 pages, 16 figures. A much shorter version of this paper will\n  appear at Graph Drawing 2008. This version incorporates feedback from the GD\n  reviewers and new material on covering maps", "journal-ref": "J. Graph Algorithms & Applications 17(1): 35-55, 2013", "doi": "10.7155/jgaa.00283", "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider embeddings of 3-regular graphs into 3-dimensional Cartesian\ncoordinates, in such a way that two vertices are adjacent if and only if two of\ntheir three coordinates are equal (that is, if they lie on an axis-parallel\nline) and such that no three points lie on the same axis-parallel line; we call\na graph with such an embedding an xyz graph}. We describe a correspondence\nbetween xyz graphs and face-colored embeddings of the graph onto\ntwo-dimensional manifolds, and we relate bipartiteness of the xyz graph to\norientability of the underlying topological surface. Using this correspondence,\nwe show that planar graphs are xyz graphs if and only if they are bipartite,\ncubic, and three-connected, and that it is NP-complete to determine whether an\narbitrary graph is an xyz graph. We also describe an algorithm with running\ntime O(n 2^{n/2}) for testing whether a given graph is an xyz graph.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2007 06:49:33 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2007 20:39:27 GMT"}, {"version": "v3", "created": "Fri, 22 Aug 2008 23:31:11 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Eppstein", "David", ""]]}
{"id": "0709.4117", "submitter": "Sylvain Lombardy", "authors": "Ines Klimann (LIAFA), Sylvain Lombardy (LIAFA), Jean Mairesse (LIAFA),\n  Christophe Prieur (LIAFA)", "title": "Deciding Unambiguity and Sequentiality starting from a Finitely\n  Ambiguous Max-Plus Automaton", "comments": null, "journal-ref": "Theoretical Computer Science 327, 3 (2004) 349-373", "doi": "10.1016/j.tcs.2004.02.049", "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  Finite automata with weights in the max-plus semiring are considered. The\nmain result is: it is decidable in an effective way whether a series that is\nrecognized by a finitely ambiguous max-plus automaton is unambiguous, or is\nsequential. A collection of examples is given to illustrate the hierarchy of\nmax-plus series with respect to ambiguity.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2007 09:51:28 GMT"}], "update_date": "2007-09-27", "authors_parsed": [["Klimann", "Ines", "", "LIAFA"], ["Lombardy", "Sylvain", "", "LIAFA"], ["Mairesse", "Jean", "", "LIAFA"], ["Prieur", "Christophe", "", "LIAFA"]]}
{"id": "0709.4273", "submitter": "Sergey Gubin", "authors": "Sergey Gubin", "title": "Set Matrices and The Path/Cycle Problem", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": null, "abstract": "  Presentation of set matrices and demonstration of their efficiency as a tool\nusing the path/cycle problem.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2007 21:44:10 GMT"}], "update_date": "2007-09-28", "authors_parsed": [["Gubin", "Sergey", ""]]}
{"id": "0709.4464", "submitter": "Jesus-Emeterio Navarro-Barrientos", "authors": "J.-Emeterio Navarro", "title": "Adaptive Investment Strategies For Periodic Environments", "comments": "Paper submitted to Advances in Complex Systems (November, 2007) 22\n  pages, 9 figures", "journal-ref": "Advances in Complex Systems Vol. 11, No. 5 (2008) 761-787", "doi": "10.1142/S0219525908001933", "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  In this paper, we present an adaptive investment strategy for environments\nwith periodic returns on investment. In our approach, we consider an investment\nmodel where the agent decides at every time step the proportion of wealth to\ninvest in a risky asset, keeping the rest of the budget in a risk-free asset.\nEvery investment is evaluated in the market via a stylized return on investment\nfunction (RoI), which is modeled by a stochastic process with unknown\nperiodicities and levels of noise. For comparison reasons, we present two\nreference strategies which represent the case of agents with zero-knowledge and\ncomplete-knowledge of the dynamics of the returns. We consider also an\ninvestment strategy based on technical analysis to forecast the next return by\nfitting a trend line to previous received returns. To account for the\nperformance of the different strategies, we perform some computer experiments\nto calculate the average budget that can be obtained with them over a certain\nnumber of time steps. To assure for fair comparisons, we first tune the\nparameters of each strategy. Afterwards, we compare the performance of these\nstrategies for RoIs with different periodicities and levels of noise.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2007 19:04:00 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2007 16:13:07 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Navarro", "J. -Emeterio", ""]]}
{"id": "0709.4497", "submitter": "Fedor Manin", "authors": "Fedor Manin", "title": "The complexity of nonrepetitive edge coloring of graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": null, "abstract": "  A squarefree word is a sequence $w$ of symbols such that there are no strings\n$x, y$, and $z$ for which $w=xyyz$. A nonrepetitive coloring of a graph is an\nedge coloring in which the sequence of colors along any open path is\nsquarefree. We show that determining whether a graph $G$ has a nonrepetitive\n$k$-coloring is $\\Sigma_2^p$-complete. When we restrict to paths of lengths at\nmost $n$, the problem becomes NP-complete for fixed $n$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2007 20:56:42 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2007 22:05:37 GMT"}], "update_date": "2007-12-07", "authors_parsed": [["Manin", "Fedor", ""]]}
{"id": "0709.4655", "submitter": "Jan Van den Bussche", "authors": "Jan Van den Bussche", "title": "Mining for trees in a graph is NP-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": null, "abstract": "  Mining for trees in a graph is shown to be NP-complete.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2007 17:08:39 GMT"}], "update_date": "2007-10-01", "authors_parsed": [["Bussche", "Jan Van den", ""]]}
{"id": "0710.0009", "submitter": "Adam Lipowski", "authors": "Adam Lipowski and Dorota Lipowska", "title": "Bio-linguistic transition and Baldwin effect in an evolutionary\n  naming-game model", "comments": "7 pages, minor changes, accepted in Int.J.Mod.Phys.C, proceedings of\n  Max Born Symp. Wroclaw (Poland), Sept. 2007. Java applet is available at\n  http://spin.amu.edu.pl/~lipowski/biolin.html or\n  http://www.amu.edu.pl/~lipowski/biolin.html", "journal-ref": "Int.J.Mod.Phys. C vol.19, pp. 399-407 (2008)", "doi": "10.1142/S0129183108012248", "report-no": null, "categories": "cs.CL cond-mat.stat-mech cs.AI physics.soc-ph q-bio.PE", "license": null, "abstract": "  We examine an evolutionary naming-game model where communicating agents are\nequipped with an evolutionarily selected learning ability. Such a coupling of\nbiological and linguistic ingredients results in an abrupt transition: upon a\nsmall change of a model control parameter a poorly communicating group of\nlinguistically unskilled agents transforms into almost perfectly communicating\ngroup with large learning abilities. When learning ability is kept fixed, the\ntransition appears to be continuous. Genetic imprinting of the learning\nabilities proceeds via Baldwin effect: initially unskilled communicating agents\nlearn a language and that creates a niche in which there is an evolutionary\npressure for the increase of learning ability.Our model suggests that when\nlinguistic (or cultural) processes became intensive enough, a transition took\nplace where both linguistic performance and biological endowment of our species\nexperienced an abrupt change that perhaps triggered the rapid expansion of\nhuman civilization.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 09:39:49 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2007 13:20:17 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Lipowski", "Adam", ""], ["Lipowska", "Dorota", ""]]}
{"id": "0710.0013", "submitter": "Jason Johnson", "authors": "Jason K. Johnson, Dmitry M. Malioutov, Alan S. Willsky", "title": "Lagrangian Relaxation for MAP Estimation in Graphical Models", "comments": "10 pages, presented at 45th Allerton conference on communication,\n  control and computing, to appear in proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  We develop a general framework for MAP estimation in discrete and Gaussian\ngraphical models using Lagrangian relaxation techniques. The key idea is to\nreformulate an intractable estimation problem as one defined on a more\ntractable graph, but subject to additional constraints. Relaxing these\nconstraints gives a tractable dual problem, one defined by a thin graph, which\nis then optimized by an iterative procedure. When this iterative optimization\nleads to a consistent estimate, one which also satisfies the constraints, then\nit corresponds to an optimal MAP estimate of the original model. Otherwise\nthere is a ``duality gap'', and we obtain a bound on the optimal solution.\nThus, our approach combines convex optimization with dynamic programming\ntechniques applicable for thin graphs. The popular tree-reweighted max-product\n(TRMP) method may be seen as solving a particular class of such relaxations,\nwhere the intractable graph is relaxed to a set of spanning trees. We also\nconsider relaxations to a set of small induced subgraphs, thin subgraphs (e.g.\nloops), and a connected tree obtained by ``unwinding'' cycles. In addition, we\npropose a new class of multiscale relaxations that introduce ``summary''\nvariables. The potential benefits of such generalizations include: reducing or\neliminating the ``duality gap'' in hard problems, reducing the number or\nLagrange multipliers in the dual problem, and accelerating convergence of the\niterative optimization procedure.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2007 21:29:43 GMT"}], "update_date": "2007-10-02", "authors_parsed": [["Johnson", "Jason K.", ""], ["Malioutov", "Dmitry M.", ""], ["Willsky", "Alan S.", ""]]}
{"id": "0710.0213", "submitter": "Marc Schoenauer", "authors": "Fei Jiang (INRIA Futurs, INRIA Futurs), Hugues Berry (INRIA Futurs),\n  Marc Schoenauer (INRIA Futurs)", "title": "Optimising the topology of complex neural networks", "comments": null, "journal-ref": "Dans ECCS'07 (2007)", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  In this paper, we study instances of complex neural networks, i.e. neural\nnetwo rks with complex topologies. We use Self-Organizing Map neural networks\nwhose n eighbourhood relationships are defined by a complex network, to\nclassify handwr itten digits. We show that topology has a small impact on\nperformance and robus tness to neuron failures, at least at long learning\ntimes. Performance may howe ver be increased (by almost 10%) by artificial\nevolution of the network topo logy. In our experimental conditions, the evolved\nnetworks are more random than their parents, but display a more heterogeneous\ndegree distribution.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 06:51:42 GMT"}], "update_date": "2007-10-02", "authors_parsed": [["Jiang", "Fei", "", "INRIA Futurs, INRIA Futurs"], ["Berry", "Hugues", "", "INRIA Futurs"], ["Schoenauer", "Marc", "", "INRIA Futurs"]]}
{"id": "0710.0232", "submitter": "Maurice Margenstern", "authors": "Maurice Margenstern", "title": "Constructing a uniform plane-filling path in the ternary heptagrid of\n  the hyperbolic plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": null, "abstract": "  In this paper, we distinguish two levels for the plane-filling property. We\nconsider a simple and a strong one. In this paper, we give the construction\nwhich proves that the simple plane-filling property also holds for the\nhyperbolic plane. The plane-filling property was established for the Euclidean\nplane by J. Kari, in 1994, in the strong version.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 08:42:03 GMT"}], "update_date": "2007-10-02", "authors_parsed": [["Margenstern", "Maurice", ""]]}
{"id": "0710.0244", "submitter": "Philip Baback Alipour", "authors": "Philip B. Alipour", "title": "Theoretical Engineering and Satellite Comlink of a PTVD-SHAM System", "comments": "50 pages, 10 figures (3 multi-figures), 2 tables. v.1: 1 postulate\n  entailing hypothetical ideas, design and model on future technological\n  advances of PTVD-SHAM. The results of the previous paper [arXiv:0707.1151v6],\n  are extended in order to prove some introductory conjectures in theoretical\n  engineering advanced to architectural analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AR", "license": null, "abstract": "  This paper focuses on super helical memory system's design, 'Engineering,\nArchitectural and Satellite Communications' as a theoretical approach of an\ninvention-model to 'store time-data'. The current release entails three\nconcepts: 1- an in-depth theoretical physics engineering of the chip including\nits, 2- architectural concept based on VLSI methods, and 3- the time-data\nversus data-time algorithm. The 'Parallel Time Varying & Data Super-helical\nAccess Memory' (PTVD-SHAM), possesses a waterfall effect in its architecture\ndealing with the process of voltage output-switch into diverse logic and\nquantum states described as 'Boolean logic & image-logic', respectively.\nQuantum dot computational methods are explained by utilizing coiled carbon\nnanotubes (CCNTs) and CNT field effect transistors (CNFETs) in the chip's\narchitecture. Quantum confinement, categorized quantum well substrate, and\nB-field flux involvements are discussed in theory. Multi-access of coherent\nsequences of 'qubit addressing' in any magnitude, gained as pre-defined, here\ne.g., the 'big O notation' asymptotically confined into singularity while\npossessing a magnitude of 'infinity' for the orientation of array displacement.\nGaussian curvature of k<0 versus k'>(k<0) is debated in aim of specifying the\n2D electron gas characteristics, data storage system for defining short and\nlong time cycles for different CCNT diameters where space-time continuum is\nfolded by chance for the particle. Precise pre/post data timing for, e.g.,\nseismic waves before earthquake mantle-reach event occurrence, including time\nvarying self-clocking devices in diverse geographic locations for radar systems\nis illustrated in the Subsections of the paper. The theoretical fabrication\nprocess, electromigration between chip's components is discussed as well.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 09:35:30 GMT"}], "update_date": "2009-12-05", "authors_parsed": [["Alipour", "Philip B.", ""]]}
{"id": "0710.0244", "submitter": "Philip Baback Alipour", "authors": "Philip B. Alipour", "title": "Theoretical Engineering and Satellite Comlink of a PTVD-SHAM System", "comments": "50 pages, 10 figures (3 multi-figures), 2 tables. v.1: 1 postulate\n  entailing hypothetical ideas, design and model on future technological\n  advances of PTVD-SHAM. The results of the previous paper [arXiv:0707.1151v6],\n  are extended in order to prove some introductory conjectures in theoretical\n  engineering advanced to architectural analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AR", "license": null, "abstract": "  This paper focuses on super helical memory system's design, 'Engineering,\nArchitectural and Satellite Communications' as a theoretical approach of an\ninvention-model to 'store time-data'. The current release entails three\nconcepts: 1- an in-depth theoretical physics engineering of the chip including\nits, 2- architectural concept based on VLSI methods, and 3- the time-data\nversus data-time algorithm. The 'Parallel Time Varying & Data Super-helical\nAccess Memory' (PTVD-SHAM), possesses a waterfall effect in its architecture\ndealing with the process of voltage output-switch into diverse logic and\nquantum states described as 'Boolean logic & image-logic', respectively.\nQuantum dot computational methods are explained by utilizing coiled carbon\nnanotubes (CCNTs) and CNT field effect transistors (CNFETs) in the chip's\narchitecture. Quantum confinement, categorized quantum well substrate, and\nB-field flux involvements are discussed in theory. Multi-access of coherent\nsequences of 'qubit addressing' in any magnitude, gained as pre-defined, here\ne.g., the 'big O notation' asymptotically confined into singularity while\npossessing a magnitude of 'infinity' for the orientation of array displacement.\nGaussian curvature of k<0 versus k'>(k<0) is debated in aim of specifying the\n2D electron gas characteristics, data storage system for defining short and\nlong time cycles for different CCNT diameters where space-time continuum is\nfolded by chance for the particle. Precise pre/post data timing for, e.g.,\nseismic waves before earthquake mantle-reach event occurrence, including time\nvarying self-clocking devices in diverse geographic locations for radar systems\nis illustrated in the Subsections of the paper. The theoretical fabrication\nprocess, electromigration between chip's components is discussed as well.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 09:35:30 GMT"}], "update_date": "2009-12-05", "authors_parsed": [["Alipour", "Philip B.", ""]]}
{"id": "0710.0262", "submitter": "Sebastian Roch", "authors": "Elchanan Mossel and Sebastien Roch", "title": "Incomplete Lineage Sorting: Consistent Phylogeny Estimation From\n  Multiple Loci", "comments": "Added a section on more general distance-based methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE cs.DS math.PR math.ST stat.TH", "license": null, "abstract": "  We introduce a simple algorithm for reconstructing phylogenies from multiple\ngene trees in the presence of incomplete lineage sorting, that is, when the\ntopology of the gene trees may differ from that of the species tree. We show\nthat our technique is statistically consistent under standard stochastic\nassumptions, that is, it returns the correct tree given sufficiently many\nunlinked loci. We also show that it can tolerate moderate estimation errors.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 11:11:43 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2007 03:41:04 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Mossel", "Elchanan", ""], ["Roch", "Sebastien", ""]]}
{"id": "0710.0318", "submitter": "Alexander Tiskin", "authors": "Vladimir Deineko and Alexander Tiskin", "title": "Fast minimum-weight double-tree shortcutting for Metric TSP: Is the best\n  one good enough?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Metric Traveling Salesman Problem (TSP) is a classical NP-hard\noptimization problem. The double-tree shortcutting method for Metric TSP yields\nan exponentially-sized space of TSP tours, each of which approximates the\noptimal solution within at most a factor of 2. We consider the problem of\nfinding among these tours the one that gives the closest approximation, i.e.\\\nthe \\emph{minimum-weight double-tree shortcutting}. Burkard et al. gave an\nalgorithm for this problem, running in time $O(n^3+2^d n^2)$ and memory $O(2^d\nn^2)$, where $d$ is the maximum node degree in the rooted minimum spanning\ntree. We give an improved algorithm for the case of small $d$ (including planar\nEuclidean TSP, where $d \\leq 4$), running in time $O(4^d n^2)$ and memory\n$O(4^d n)$. This improvement allows one to solve the problem on much larger\ninstances than previously attempted. Our computational experiments suggest that\nin terms of the time-quality tradeoff, the minimum-weight double-tree\nshortcutting method provides one of the best known tour-constructing\nheuristics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 15:25:18 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2009 16:17:30 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2009 16:17:25 GMT"}], "update_date": "2009-07-16", "authors_parsed": [["Deineko", "Vladimir", ""], ["Tiskin", "Alexander", ""]]}
{"id": "0710.0360", "submitter": "Sylvain Perifel", "authors": "Pascal Koiran (LIP), Sylvain Perifel (LIP)", "title": "Interpolation in Valiant's theory", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  We investigate the following question: if a polynomial can be evaluated at\nrational points by a polynomial-time boolean algorithm, does it have a\npolynomial-size arithmetic circuit? We argue that this question is certainly\ndifficult. Answering it negatively would indeed imply that the constant-free\nversions of the algebraic complexity classes VP and VNP defined by Valiant are\ndifferent. Answering this question positively would imply a transfer theorem\nfrom boolean to algebraic complexity. Our proof method relies on Lagrange\ninterpolation and on recent results connecting the (boolean) counting hierarchy\nto algebraic complexity classes. As a byproduct we obtain two additional\nresults: (i) The constant-free, degree-unbounded version of Valiant's\nhypothesis that VP and VNP differ implies the degree-bounded version. This\nresult was previously known to hold for fields of positive characteristic only.\n(ii) If exponential sums of easy to compute polynomials can be computed\nefficiently, then the same is true of exponential products. We point out an\napplication of this result to the P=NP problem in the Blum-Shub-Smale model of\ncomputation over the field of complex numbers.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 18:58:19 GMT"}], "update_date": "2007-10-02", "authors_parsed": [["Koiran", "Pascal", "", "LIP"], ["Perifel", "Sylvain", "", "LIP"]]}
{"id": "0710.0410", "submitter": "Philip Baback Alipour", "authors": "Philip B. Alipour", "title": "The Theory of Unified Relativity for a Biovielectroluminescence\n  Phenomenon via Fly's Visual and Imaging System", "comments": "51 pages, 4 figures (2 multi-figures), 4 tables, 3 Appendices, 1\n  Animation clip. This is a personalized report, extension to project license\n  No. TXU001347562. A very concise report is to be published in other journals\n  encompassing the relevant categories on computing and physical sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CV", "license": null, "abstract": "  The elucidation upon fly's neuronal patterns as a link to computer graphics\nand memory cards I/O's, is investigated for the phenomenon by propounding a\nunified theory of Einstein's two known relativities. It is conclusive that\nflies could contribute a certain amount of neuromatrices indicating an imagery\nfunction of a visual-computational system into computer graphics and storage\nsystems. The visual system involves the time aspect, whereas flies possess\nfaster pulses compared to humans' visual ability due to the E-field state on an\nactive fly's eye surface. This behaviour can be tested on a dissected fly\nspecimen at its ommatidia. Electro-optical contacts and electrodes are wired\nthrough the flesh forming organic emitter layer to stimulate light emission,\nthereby to a computer circuit. The next step is applying a threshold voltage\nwith secondary voltages to the circuit denoting an array of essential\nelectrodes for bit switch. As a result, circuit's dormant pulses versus active\npulses at the specimen's area are recorded. The outcome matrix possesses a\nconstruction of RGB and time radicals expressing the time problem in\nconsumption, allocating time into computational algorithms, enhancing the\ntechnology far beyond. The obtained formulation generates consumed distance\ncons(x), denoting circuital travel between data source/sink for pixel data and\nbendable wavelengths. Once 'image logic' is in place, incorporating this point\nof graphical acceleration permits one to enhance graphics and optimize\nimmensely central processing, data transmissions between memory and computer\nvisual system. The phenomenon can be mainly used in 360-deg. display/viewing,\n3D scanning techniques, military and medicine, a robust and cheap substitution\nfor e.g. pre-motion pattern analysis, real-time rendering and LCDs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 23:55:50 GMT"}], "update_date": "2009-12-05", "authors_parsed": [["Alipour", "Philip B.", ""]]}
{"id": "0710.0539", "submitter": "Anthony A. Ruffa", "authors": "Anthony A. Ruffa", "title": "A Novel Solution to the ATT48 Benchmark Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  A solution to the benchmark ATT48 Traveling Salesman Problem (from the\nTSPLIB95 library) results from isolating the set of vertices into ten\nopen-ended zones with nine lengthwise boundaries. In each zone, a\nminimum-length Hamiltonian Path (HP) is found for each combination of boundary\nvertices, leading to an approximation for the minimum-length Hamiltonian Cycle\n(HC). Determination of the optimal HPs for subsequent zones has the effect of\nautomatically filtering out non-optimal HPs from earlier zones. Although the\noptimal HC for ATT48 involves only two crossing edges between all zones (with\none exception), adding inter-zone edges can accommodate more complex problems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2007 14:26:33 GMT"}], "update_date": "2007-10-03", "authors_parsed": [["Ruffa", "Anthony A.", ""]]}
{"id": "0710.0748", "submitter": "M Sabu THAMPI", "authors": "Murali Krishna P, Sabu .M Thampi", "title": "A Fast Heuristic Algorithm Based on Verification and Elimination Methods\n  for Maximum Clique Problem", "comments": "06 pages,01 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": null, "abstract": "  A clique in an undirected graph G= (V, E) is a subset V' V of vertices, each\npair of which is connected by an edge in E. The clique problem is an\noptimization problem of finding a clique of maximum size in graph. The clique\nproblem is NP-Complete. We have succeeded in developing a fast algorithm for\nmaximum clique problem by employing the method of verification and elimination.\nFor a graph of size N there are 2N sub graphs, which may be cliques and hence\nverifying all of them, will take a long time. Idea is to eliminate a major\nnumber of sub graphs, which cannot be cliques and verifying only the remaining\nsub graphs. This heuristic algorithm runs in polynomial time and executes\nsuccessfully for several examples when applied to random graphs and DIMACS\nbenchmark graphs.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2007 09:33:20 GMT"}], "update_date": "2007-10-04", "authors_parsed": [["P", "Murali Krishna", ""], ["Thampi", "Sabu . M", ""]]}
{"id": "0710.0805", "submitter": "Elitza Maneva", "authors": "Elitza Maneva and Alistair Sinclair", "title": "On the Satisfiability Threshold and Clustering of Solutions of Random\n  3-SAT Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the structure of satisfying assignments of a random 3-SAT formula.\nIn particular, we show that a random formula of density 4.453 or higher almost\nsurely has no non-trivial \"core\" assignments. Core assignments are certain\npartial assignments that can be extended to satisfying assignments, and have\nbeen studied recently in connection with the Survey Propagation heuristic for\nrandom SAT. Their existence implies the presence of clusters of solutions, and\nthey have been shown to exist with high probability below the satisfiability\nthreshold for k-SAT with k>8, by Achlioptas and Ricci-Tersenghi, STOC 2006. Our\nresult implies that either this does not hold for 3-SAT or the threshold\ndensity for satisfiability in 3-SAT lies below 4.453.\n  The main technical tool that we use is a novel simple application of the\nfirst moment method.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2007 19:04:44 GMT"}, {"version": "v2", "created": "Mon, 30 Jun 2008 23:01:27 GMT"}, {"version": "v3", "created": "Sun, 31 Aug 2008 18:27:03 GMT"}], "update_date": "2008-09-01", "authors_parsed": [["Maneva", "Elitza", ""], ["Sinclair", "Alistair", ""]]}
{"id": "0710.0811", "submitter": "Joseph O'Rourke", "authors": "Joseph O'Rourke", "title": "Band Unfoldings and Prismatoids: A Counterexample", "comments": "5 pages, 3 figures. v2 replaced Fig.1(b) and Fig.3 to illustrate the\n  angles delta=(1/2)epsilon (rather than delta=epsilon)", "journal-ref": null, "doi": null, "report-no": "Smith Computer Science 086", "categories": "cs.CG", "license": null, "abstract": "  This note shows that the hope expressed in [ADL+07]--that the new algorithm\nfor edge-unfolding any polyhedral band without overlap might lead to an\nalgorithm for unfolding any prismatoid without overlap--cannot be realized. A\nprismatoid is constructed whose sides constitute a nested polyhedral band, with\nthe property that every placement of the prismatoid top face overlaps with the\nband unfolding.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2007 15:18:35 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2007 13:10:37 GMT"}], "update_date": "2007-10-04", "authors_parsed": [["O'Rourke", "Joseph", ""]]}
{"id": "0710.0925", "submitter": "Kimikazu Kato", "authors": "Hidetoshi Muta and Kimikazu Kato", "title": "Degeneracy of Angular Voronoi Diagram", "comments": "8 pages, 11 figures, 1 table, presented at 4th International\n  Symposium on Voronoi Diagrams in Science and Engineering (ISVD07)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  Angular Voronoi diagram was introduced by Asano et al. as fundamental\nresearch for a mesh generation. In an angular Voronoi diagram, the edges are\ncurves of degree three. From view of computational robustness we need to treat\nthe curves carefully, because they might have a singularity.\n  We enumerate all the possible types of curves that appear as an edge of an\nangular Voronoi diagram, which tells us what kind of degeneracy is possible and\ntells us necessity of considering a singularity for computational robustness.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2007 05:05:06 GMT"}], "update_date": "2007-10-05", "authors_parsed": [["Muta", "Hidetoshi", ""], ["Kato", "Kimikazu", ""]]}
{"id": "0710.1153", "submitter": "Patrick Baillot", "authors": "Vincent Atassi, Patrick Baillot, Kazushige Terui", "title": "Verification of Ptime Reducibility for system F Terms: Type Inference\n  in<br> Dual Light Affine Logic", "comments": "32 pages, 8 figures", "journal-ref": "Logical Methods in Computer Science, Volume 3, Issue 4 (November\n  15, 2007) lmcs:1234", "doi": "10.2168/LMCS-3(4:10)2007", "report-no": null, "categories": "cs.LO cs.CC", "license": null, "abstract": "  In a previous work Baillot and Terui introduced Dual light affine logic\n(DLAL) as a variant of Light linear logic suitable for guaranteeing complexity\nproperties on lambda calculus terms: all typable terms can be evaluated in\npolynomial time by beta reduction and all Ptime functions can be represented.\nIn the present work we address the problem of typing lambda-terms in\nsecond-order DLAL. For that we give a procedure which, starting with a term\ntyped in system F, determines whether it is typable in DLAL and outputs a\nconcrete typing if there exists any. We show that our procedure can be run in\ntime polynomial in the size of the original Church typed system F term.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2007 09:24:31 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2007 11:02:50 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Atassi", "Vincent", ""], ["Baillot", "Patrick", ""], ["Terui", "Kazushige", ""]]}
{"id": "0710.1481", "submitter": "Stasinos Konstantopoulos", "authors": "Stasinos Konstantopoulos", "title": "What's in a Name?", "comments": "Presented at the Computational Phonology Workshop, 6th Intl. Conf.\n  Recent Advances in NLP, Borovets, Bulgaria, September 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": null, "abstract": "  This paper describes experiments on identifying the language of a single name\nin isolation or in a document written in a different language. A new corpus has\nbeen compiled and made available, matching names against languages. This corpus\nis used in a series of experiments measuring the performance of general\nlanguage models and names-only language models on the language identification\ntask. Conclusions are drawn from the comparison between using general language\nmodels and names-only language models and between identifying the language of\nisolated names and the language of very short document fragments. Future\nresearch directions are outlined.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2007 08:36:32 GMT"}], "update_date": "2007-10-09", "authors_parsed": [["Konstantopoulos", "Stasinos", ""]]}
{"id": "0710.1641", "submitter": "Vida Dujmovi\\'c", "authors": "Prosenjit Bose, Vida Dujmovic, Ferran Hurtado, Stefan Langerman, Pat\n  Morin, David R. Wood", "title": "A polynomial bound for untangling geometric planar graphs", "comments": "14 pages, 7 figures", "journal-ref": "Discrete & Computational Geometry 42(4):570-585, 2009", "doi": "10.1007/s00454-008-9125-3", "report-no": null, "categories": "cs.CG cs.DM math.CO", "license": null, "abstract": "  To untangle a geometric graph means to move some of the vertices so that the\nresulting geometric graph has no crossings. Pach and Tardos [Discrete Comput.\nGeom., 2002] asked if every n-vertex geometric planar graph can be untangled\nwhile keeping at least n^\\epsilon vertices fixed. We answer this question in\nthe affirmative with \\epsilon=1/4. The previous best known bound was\n\\Omega((\\log n / \\log\\log n)^{1/2}). We also consider untangling geometric\ntrees. It is known that every n-vertex geometric tree can be untangled while\nkeeping at least (n/3)^{1/2} vertices fixed, while the best upper bound was\nO(n\\log n)^{2/3}. We answer a question of Spillner and Wolff [arXiv:0709.0170\n2007] by closing this gap for untangling trees. In particular, we show that for\ninfinitely many values of n, there is an n-vertex geometric tree that cannot be\nuntangled while keeping more than 3(n^{1/2}-1) vertices fixed. Moreover, we\nimprove the lower bound to (n/2)^{1/2}.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2007 13:13:24 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2007 15:04:13 GMT"}], "update_date": "2010-05-31", "authors_parsed": [["Bose", "Prosenjit", ""], ["Dujmovic", "Vida", ""], ["Hurtado", "Ferran", ""], ["Langerman", "Stefan", ""], ["Morin", "Pat", ""], ["Wood", "David R.", ""]]}
{"id": "0710.1879", "submitter": "Ning Chen", "authors": "Ning Chen and Zhiyuan Yan", "title": "Cyclotomic FFTs with Reduced Additive Complexities Based on a Novel\n  Common Subexpression Elimination Algorithm", "comments": "11 pages, submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first propose a novel common subexpression elimination\n(CSE) algorithm for matrix-vector multiplications over characteristic-2 fields.\nAs opposed to previously proposed CSE algorithms, which usually focus on\ncomplexity savings due to recurrences of subexpressions, our CSE algorithm\nachieves two types of complexity reductions, differential savings and\nrecurrence savings, by taking advantage of the cancelation property of\ncharacteristic-2 fields. Using our CSE algorithm, we reduce the additive\ncomplexities of cyclotomic fast Fourier transforms (CFFTs). Using a weighted\nsum of the numbers of multiplications and additions as a metric, our CFFTs\nachieve smaller total complexities than previously proposed CFFTs and other\nFFTs, requiring both fewer multiplications and fewer additions in many cases.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2007 08:13:44 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2007 18:09:03 GMT"}, {"version": "v3", "created": "Thu, 8 May 2008 03:23:10 GMT"}, {"version": "v4", "created": "Thu, 23 Oct 2008 06:18:31 GMT"}], "update_date": "2008-10-23", "authors_parsed": [["Chen", "Ning", ""], ["Yan", "Zhiyuan", ""]]}
{"id": "0710.1924", "submitter": "Mohsen Ravanbakhsh", "authors": "Mohsen Ravanbakhsh, Yasin Abbasi-Yadkori, Maghsoud Abbaspour, Hamid\n  Sarbazi-Azad", "title": "A Heuristic Routing Mechanism Using a New Addressing Scheme", "comments": "8 pages, because of lack of space journal reference just contains the\n  reference to the proceeding", "journal-ref": "Proceedings of First International Conference on Bio Inspired\n  models of Networks, Information and Computing Systems (BIONETICS), Cavalese,\n  Italy, December 2006", "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": null, "abstract": "  Current methods of routing are based on network information in the form of\nrouting tables, in which routing protocols determine how to update the tables\naccording to the network changes. Despite the variability of data in routing\ntables, node addresses are constant. In this paper, we first introduce the new\nconcept of variable addresses, which results in a novel framework to cope with\nrouting problems using heuristic solutions. Then we propose a heuristic routing\nmechanism based on the application of genes for determination of network\naddresses in a variable address network and describe how this method flexibly\nsolves different problems and induces new ideas in providing integral solutions\nfor variety of problems. The case of ad-hoc networks is where simulation\nresults are more supportive and original solutions have been proposed for\nissues like mobility.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2007 04:29:24 GMT"}], "update_date": "2007-10-11", "authors_parsed": [["Ravanbakhsh", "Mohsen", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Abbaspour", "Maghsoud", ""], ["Sarbazi-Azad", "Hamid", ""]]}
{"id": "0710.2139", "submitter": "Ashkan Aazami", "authors": "Ashkan Aazami, Michael D. Stilp", "title": "Approximation algorithms and hardness for domination with propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": null, "abstract": "  The power dominating set (PDS) problem is the following extension of the\nwell-known dominating set problem: find a smallest-size set of nodes $S$ that\npower dominates all the nodes, where a node $v$ is power dominated if (1) $v$\nis in $S$ or $v$ has a neighbor in $S$, or (2) $v$ has a neighbor $w$ such that\n$w$ and all of its neighbors except $v$ are power dominated. We show a hardness\nof approximation threshold of $2^{\\log^{1-\\epsilon}{n}}$ in contrast to the\nlogarithmic hardness for the dominating set problem. We give an $O(\\sqrt{n})$\napproximation algorithm for planar graphs, and show that our methods cannot\nimprove on this approximation guarantee. Finally, we initiate the study of PDS\non directed graphs, and show the same hardness threshold of\n$2^{\\log^{1-\\epsilon}{n}}$ for directed \\emph{acyclic} graphs. Also we show\nthat the directed PDS problem can be solved optimally in linear time if the\nunderlying undirected graph has bounded tree-width.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2007 23:30:49 GMT"}], "update_date": "2007-10-12", "authors_parsed": [["Aazami", "Ashkan", ""], ["Stilp", "Michael D.", ""]]}
{"id": "0710.2227", "submitter": "M Sabu THAMPI", "authors": "Sabu M. Thampi, K. Chandra Sekaran", "title": "A System for Predicting Subcellular Localization of Yeast Genome Using\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  The subcellular location of a protein can provide valuable information about\nits function. With the rapid increase of sequenced genomic data, the need for\nan automated and accurate tool to predict subcellular localization becomes\nincreasingly important. Many efforts have been made to predict protein\nsubcellular localization. This paper aims to merge the artificial neural\nnetworks and bioinformatics to predict the location of protein in yeast genome.\nWe introduce a new subcellular prediction method based on a backpropagation\nneural network. The results show that the prediction within an error limit of 5\nto 10 percentage can be achieved with the system.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2007 12:09:33 GMT"}], "update_date": "2007-10-12", "authors_parsed": [["Thampi", "Sabu M.", ""], ["Sekaran", "K. Chandra", ""]]}
{"id": "0710.2446", "submitter": "Catherine Recanati", "authors": "Catherine Recanati (LIPN), Nicoleta Rogovschi (LIPN), Youn\\`es Bennani\n  (LIPN)", "title": "The structure of verbal sequences analyzed with unsupervised learning\n  techniques", "comments": null, "journal-ref": "Dans Proceedings - The 3rd Language & Technology Conference: Human\n  Language Technologies as a Challenge for Computer Science and Linguistics,\n  Poznan : Pologne (2007)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": null, "abstract": "  Data mining allows the exploration of sequences of phenomena, whereas one\nusually tends to focus on isolated phenomena or on the relation between two\nphenomena. It offers invaluable tools for theoretical analyses and exploration\nof the structure of sentences, texts, dialogues, and speech. We report here the\nresults of an attempt at using it for inspecting sequences of verbs from French\naccounts of road accidents. This analysis comes from an original approach of\nunsupervised training allowing the discovery of the structure of sequential\ndata. The entries of the analyzer were only made of the verbs appearing in the\nsentences. It provided a classification of the links between two successive\nverbs into four distinct clusters, allowing thus text segmentation. We give\nhere an interpretation of these clusters by applying a statistical analysis to\nindependent semantic annotations.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2007 12:44:11 GMT"}], "update_date": "2007-10-15", "authors_parsed": [["Recanati", "Catherine", "", "LIPN"], ["Rogovschi", "Nicoleta", "", "LIPN"], ["Bennani", "Younès", "", "LIPN"]]}
{"id": "0710.2611", "submitter": "Marek Czachor", "authors": "Diederik Aerts, Marek Czachor, Bart De Moor", "title": "Geometric Analogue of Holographic Reduced Representation", "comments": "typos in eqs. (57-58) are corrected", "journal-ref": "Journal of Mathematical Psychology 53, 389-398 (2009)", "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": null, "abstract": "  Holographic reduced representations (HRR) are based on superpositions of\nconvolution-bound $n$-tuples, but the $n$-tuples cannot be regarded as vectors\nsince the formalism is basis dependent. This is why HRR cannot be associated\nwith geometric structures. Replacing convolutions by geometric products one\narrives at reduced representations analogous to HRR but interpretable in terms\nof geometry. Variable bindings occurring in both HRR and its geometric analogue\nmathematically correspond to two different representations of\n$Z_2\\times...\\times Z_2$ (the additive group of binary $n$-tuples with addition\nmodulo 2). As opposed to standard HRR, variable binding performed by means of\ngeometric product allows for computing exact inverses of all nonzero vectors, a\nprocedure even simpler than approximate inverses employed in HRR. The formal\nstructure of the new reduced representation is analogous to cartoon\ncomputation, a geometric analogue of quantum computation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2007 13:56:39 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2007 16:51:40 GMT"}], "update_date": "2009-12-01", "authors_parsed": [["Aerts", "Diederik", ""], ["Czachor", "Marek", ""], ["De Moor", "Bart", ""]]}
{"id": "0710.2732", "submitter": "Marie-Annick Guillemer", "authors": "Dima Grigoriev (IRMAR)", "title": "Probabilistic communication complexity over the reals", "comments": null, "journal-ref": null, "doi": null, "report-no": "07-60", "categories": "cs.CC", "license": null, "abstract": "  Deterministic and probabilistic communication protocols are introduced in\nwhich parties can exchange the values of polynomials (rather than bits in the\nusual setting). It is established a sharp lower bound $2n$ on the communication\ncomplexity of recognizing the $2n$-dimensional orthant, on the other hand the\nprobabilistic communication complexity of its recognizing does not exceed 4. A\npolyhedron and a union of hyperplanes are constructed in $\\RR^{2n}$ for which a\nlower bound $n/2$ on the probabilistic communication complexity of recognizing\neach is proved. As a consequence this bound holds also for the EMPTINESS and\nthe KNAPSACK problems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2007 08:03:38 GMT"}], "update_date": "2007-10-16", "authors_parsed": [["Grigoriev", "Dima", "", "IRMAR"]]}
{"id": "0710.2782", "submitter": "Leonardo Emmendorfer", "authors": "Leonardo Emmendorfer and Aurora Pozo", "title": "Effective linkage learning using low-order statistics and clustering", "comments": "Submitted to IEEE Transactions on Evolutionary Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  The adoption of probabilistic models for the best individuals found so far is\na powerful approach for evolutionary computation. Increasingly more complex\nmodels have been used by estimation of distribution algorithms (EDAs), which\noften result better effectiveness on finding the global optima for hard\noptimization problems. Supervised and unsupervised learning of Bayesian\nnetworks are very effective options, since those models are able to capture\ninteractions of high order among the variables of a problem. Diversity\npreservation, through niching techniques, has also shown to be very important\nto allow the identification of the problem structure as much as for keeping\nseveral global optima. Recently, clustering was evaluated as an effective\nniching technique for EDAs, but the performance of simpler low-order EDAs was\nnot shown to be much improved by clustering, except for some simple multimodal\nproblems. This work proposes and evaluates a combination operator guided by a\nmeasure from information theory which allows a clustered low-order EDA to\neffectively solve a comprehensive range of benchmark optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2007 15:28:47 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2007 13:27:03 GMT"}], "update_date": "2007-10-16", "authors_parsed": [["Emmendorfer", "Leonardo", ""], ["Pozo", "Aurora", ""]]}
{"id": "0710.3185", "submitter": "Harki Tanaka", "authors": "Harki Tanaka, Neli Regina Siqueira Ortega, Mauricio Stanzione Galizia,\n  Joao Batista Borges Sobrinho, and Marcelo Britto Passos Amato", "title": "Fuzzy Modeling of Electrical Impedance Tomography Image of the Lungs", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": null, "abstract": "  Electrical Impedance Tomography (EIT) is a functional imaging method that is\nbeing developed for bedside use in critical care medicine. Aiming at improving\nthe chest anatomical resolution of EIT images we developed a fuzzy model based\non EIT high temporal resolution and the functional information contained in the\npulmonary perfusion and ventilation signals. EIT data from an experimental\nanimal model were collected during normal ventilation and apnea while an\ninjection of hypertonic saline was used as a reference . The fuzzy model was\nelaborated in three parts: a modeling of the heart, a pulmonary map from\nventilation images and, a pulmonary map from perfusion images. Image\nsegmentation was performed using a threshold method and a ventilation/perfusion\nmap was generated. EIT images treated by the fuzzy model were compared with the\nhypertonic saline injection method and CT-scan images, presenting good results\nin both qualitative (the image obtained by the model was very similar to that\nof the CT-scan) and quantitative (the ROC curve provided an area equal to 0.93)\npoint of view. Undoubtedly, these results represent an important step in the\nEIT images area, since they open the possibility of developing EIT-based\nbedside clinical methods, which are not available nowadays. These achievements\ncould serve as the base to develop EIT diagnosis system for some\nlife-threatening diseases commonly found in critical care medicine.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2007 22:13:11 GMT"}], "update_date": "2007-10-18", "authors_parsed": [["Tanaka", "Harki", ""], ["Ortega", "Neli Regina Siqueira", ""], ["Galizia", "Mauricio Stanzione", ""], ["Sobrinho", "Joao Batista Borges", ""], ["Amato", "Marcelo Britto Passos", ""]]}
{"id": "0710.3443", "submitter": "EDA Publishing Association", "authors": "G.F. Bouesse (TIMA), M. Renaudin (TIMA), S. Dumont (TIMA), F. Germain", "title": "DPA on quasi delay insensitive asynchronous circuits: formalization and\n  improvement", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": "10.1109/DATE.2005.124", "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The purpose of this paper is to formally specify a flow devoted to the design\nof Differential Power Analysis (DPA) resistant QDI asynchronous circuits. The\npaper first proposes a formal modeling of the electrical signature of QDI\nasynchronous circuits. The DPA is then applied to the formal model in order to\nidentify the source of leakage of this type of circuits. Finally, a complete\ndesign flow is specified to minimize the information leakage. The relevancy and\nefficiency of the approach is demonstrated using the design of an AES\ncrypto-processor.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2007 06:57:52 GMT"}], "update_date": "2007-10-19", "authors_parsed": [["Bouesse", "G. F.", "", "TIMA"], ["Renaudin", "M.", "", "TIMA"], ["Dumont", "S.", "", "TIMA"], ["Germain", "F.", ""]]}
{"id": "0710.3519", "submitter": "Jan Foniok", "authors": "Jan Foniok", "title": "P-matrix recognition is co-NP-complete", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  This is a summary of the proof by G.E. Coxson that P-matrix recognition is\nco-NP-complete. The result follows by a reduction from the MAX CUT problem\nusing results of S. Poljak and J. Rohn.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2007 14:14:26 GMT"}], "update_date": "2007-10-19", "authors_parsed": [["Foniok", "Jan", ""]]}
{"id": "0710.3535", "submitter": "Andrea Maiorano", "authors": "F. Belletti, M. Cotallo, A. Cruz, L. A. Fern\\'andez, A. Gordillo, M.\n  Guidetti, A. Maiorano, F. Mantovani, E. Marinari, V. Mart\\'in-Mayor, A.\n  Mu\\~noz-Sudupe, D. Navarro, G. Parisi, S. P\\'erez-Gaviro, M. Rossi, J. J.\n  Ruiz-Lorenzo, S. F. Schifano, D. Sciretti, A. Taranc\\'on, R. Tripiccione, J.\n  L. Velasco", "title": "JANUS: an FPGA-based System for High Performance Scientific Computing", "comments": "11 pages, 6 figures. Improved version, largely rewritten, submitted\n  to Computing in Science & Engineering", "journal-ref": "Computing in Science & Engineering 11 (2009 ) 48-58", "doi": "10.1109/MCSE.2009.11", "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper describes JANUS, a modular massively parallel and reconfigurable\nFPGA-based computing system. Each JANUS module has a computational core and a\nhost. The computational core is a 4x4 array of FPGA-based processing elements\nwith nearest-neighbor data links. Processors are also directly connected to an\nI/O node attached to the JANUS host, a conventional PC. JANUS is tailored for,\nbut not limited to, the requirements of a class of hard scientific applications\ncharacterized by regular code structure, unconventional data manipulation\ninstructions and not too large data-base size. We discuss the architecture of\nthis configurable machine, and focus on its use on Monte Carlo simulations of\nstatistical mechanics. On this class of application JANUS achieves impressive\nperformances: in some cases one JANUS processing element outperfoms high-end\nPCs by a factor ~ 1000. We also discuss the role of JANUS on other classes of\nscientific applications.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2007 15:26:32 GMT"}, {"version": "v2", "created": "Tue, 8 Apr 2008 11:10:12 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Belletti", "F.", ""], ["Cotallo", "M.", ""], ["Cruz", "A.", ""], ["Fernández", "L. A.", ""], ["Gordillo", "A.", ""], ["Guidetti", "M.", ""], ["Maiorano", "A.", ""], ["Mantovani", "F.", ""], ["Marinari", "E.", ""], ["Martín-Mayor", "V.", ""], ["Muñoz-Sudupe", "A.", ""], ["Navarro", "D.", ""], ["Parisi", "G.", ""], ["Pérez-Gaviro", "S.", ""], ["Rossi", "M.", ""], ["Ruiz-Lorenzo", "J. J.", ""], ["Schifano", "S. F.", ""], ["Sciretti", "D.", ""], ["Tarancón", "A.", ""], ["Tripiccione", "R.", ""], ["Velasco", "J. L.", ""]]}
{"id": "0710.3561", "submitter": "Arturo Berrones", "authors": "Arturo Berrones", "title": "Stationary probability density of stochastic search processes in global\n  optimization", "comments": null, "journal-ref": "J. Stat. Mech. (2008) P01013", "doi": "10.1088/1742-5468/2008/01/P01013", "report-no": null, "categories": "cs.AI cond-mat.stat-mech cs.NE", "license": null, "abstract": "  A method for the construction of approximate analytical expressions for the\nstationary marginal densities of general stochastic search processes is\nproposed. By the marginal densities, regions of the search space that with high\nprobability contain the global optima can be readily defined. The density\nestimation procedure involves a controlled number of linear operations, with a\ncomputational cost per iteration that grows linearly with problem size.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2007 18:04:42 GMT"}], "update_date": "2008-01-30", "authors_parsed": [["Berrones", "Arturo", ""]]}
{"id": "0710.3621", "submitter": "Withawat Withayachumnankul", "authors": "Withawat Withayachumnankul, Bernd M. Fischer, Samuel P. Mickan, Derek\n  Abbott", "title": "Numerical removal of water-vapor effects from THz-TDS measurements", "comments": null, "journal-ref": "Proceedings of the Royal Society A: Mathematical, Physical &\n  Engineering Sciences, vol. 464, no. 2097, pp 2435-2456, 2008", "doi": "10.1098/rspa.2007.0294", "report-no": null, "categories": "cs.CE physics.comp-ph", "license": null, "abstract": "  One source of disturbance in a pulsed T-ray signal is attributed to ambient\nwater vapor. Water molecules in the gas phase selectively absorb T-rays at\ndiscrete frequencies corresponding to their molecular rotational transitions.\nThis results in prominent resonances spread over the T-ray spectrum, and in the\ntime domain the T-ray signal is observed as fluctuations after the main pulse.\nThese effects are generally undesired, since they may mask critical\nspectroscopic data. So, ambient water vapor is commonly removed from the T-ray\npath by using a closed chamber during the measurement. Yet, in some\napplications a closed chamber is not applicable. This situation, therefore,\nmotivates the need for another method to reduce these unwanted artifacts. This\npaper presents a study on a computational means to address the problem.\nInitially, a complex frequency response of water vapor is modeled from a\nspectroscopic catalog. Using a deconvolution technique, together with fine\ntuning of the strength of each resonance, parts of the water-vapor response are\nremoved from a measured T-ray signal, with minimal signal distortion.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2007 02:17:35 GMT"}], "update_date": "2008-07-16", "authors_parsed": [["Withayachumnankul", "Withawat", ""], ["Fischer", "Bernd M.", ""], ["Mickan", "Samuel P.", ""], ["Abbott", "Derek", ""]]}
{"id": "0710.3642", "submitter": "Florent Bouchez", "authors": "Florent Bouchez (LIP), Alain Darte (LIP), Fabrice Rastello (LIP)", "title": "On the Complexity of Spill Everywhere under SSA Form", "comments": "10 pages", "journal-ref": "ACM SIGPLAN Notices Issue 7, Volume 42 (2007) 103 - 112", "doi": "10.1145/1254766.1254782", "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  Compilation for embedded processors can be either aggressive (time consuming\ncross-compilation) or just in time (embedded and usually dynamic). The\nheuristics used in dynamic compilation are highly constrained by limited\nresources, time and memory in particular. Recent results on the SSA form open\npromising directions for the design of new register allocation heuristics for\nembedded systems and especially for embedded compilation. In particular,\nheuristics based on tree scan with two separated phases -- one for spilling,\nthen one for coloring/coalescing -- seem good candidates for designing\nmemory-friendly, fast, and competitive register allocators. Still, also because\nof the side effect on power consumption, the minimization of loads and stores\noverhead (spilling problem) is an important issue. This paper provides an\nexhaustive study of the complexity of the ``spill everywhere'' problem in the\ncontext of the SSA form. Unfortunately, conversely to our initial hopes, many\nof the questions we raised lead to NP-completeness results. We identify some\npolynomial cases but that are impractical in JIT context. Nevertheless, they\ncan give hints to simplify formulations for the design of aggressive\nallocators.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2007 07:24:58 GMT"}], "update_date": "2009-09-18", "authors_parsed": [["Bouchez", "Florent", "", "LIP"], ["Darte", "Alain", "", "LIP"], ["Rastello", "Fabrice", "", "LIP"]]}
{"id": "0710.3789", "submitter": "Mohd Abubakr", "authors": "Mohd Abubakr", "title": "Frequency Analysis of Decoupling Capacitors for Three Voltage Supplies\n  in SoC", "comments": "5 pages, 9 figures, Submitted to ICCSC 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Reduction in power consumption has become a major criterion of design in\nmodern ICs. One such scheme to reduce power consumption by an IC is the use of\nmultiple power supplies for critical and non-critical paths. To maintain the\nimpedance of a power distribution system below a specified level, multiple\ndecoupling capacitors are placed at different levels of power grid hierarchy.\nThis paper describes about three-voltage supply power distribution systems. The\nnoise at one power supply can propagate to the other power supply, causing\npower and signal integrity problems in the overall system. Effects such as\nanti-resonance and remedies for these effects are studied. Impedance of the\nthree-voltage supply power distribution system is calculated in terms of\nRLC-model of decoupling capacitors. Further the obtained impedance depends on\nthe frequency; hence brief frequency analysis of impedance is done.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2007 20:59:53 GMT"}], "update_date": "2007-10-23", "authors_parsed": [["Abubakr", "Mohd", ""]]}
{"id": "0710.3804", "submitter": "Thierry Mora", "authors": "Thierry Mora and Lenka Zdeborova", "title": "Random subcubes as a toy model for constraint satisfaction problems", "comments": "21 pages, 4 figures", "journal-ref": "J. Stat. Phys. 131, n. 6 (2008), 1121-1138", "doi": "10.1007/s10955-008-9543-x", "report-no": null, "categories": "cs.CC cond-mat.dis-nn", "license": null, "abstract": "  We present an exactly solvable random-subcube model inspired by the structure\nof hard constraint satisfaction and optimization problems. Our model reproduces\nthe structure of the solution space of the random k-satisfiability and\nk-coloring problems, and undergoes the same phase transitions as these\nproblems. The comparison becomes quantitative in the large-k limit. Distance\nproperties, as well the x-satisfiability threshold, are studied. The model is\nalso generalized to define a continuous energy landscape useful for studying\nseveral aspects of glassy dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2007 23:33:18 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2008 16:32:21 GMT"}], "update_date": "2008-05-23", "authors_parsed": [["Mora", "Thierry", ""], ["Zdeborova", "Lenka", ""]]}
{"id": "0710.3961", "submitter": "Victor Korotkikh", "authors": "Victor Korotkikh and Galina Korotkikh", "title": "On a New Type of Information Processing for Efficient Management of\n  Complex Systems", "comments": "5 pages, 2 figures, to be presented at the International Conference\n  on Complex Systems, Boston, October 28 - November 2, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  It is a challenge to manage complex systems efficiently without confronting\nNP-hard problems. To address the situation we suggest to use self-organization\nprocesses of prime integer relations for information processing.\nSelf-organization processes of prime integer relations define correlation\nstructures of a complex system and can be equivalently represented by\ntransformations of two-dimensional geometrical patterns determining the\ndynamics of the system and revealing its structural complexity. Computational\nexperiments raise the possibility of an optimality condition of complex systems\npresenting the structural complexity of a system as a key to its optimization.\n  From this perspective the optimization of a system could be all about the\ncontrol of the structural complexity of the system to make it consistent with\nthe structural complexity of the problem. The experiments also indicate that\nthe performance of a complex system may behave as a concave function of the\nstructural complexity. Therefore, once the structural complexity could be\ncontrolled as a single entity, the optimization of a complex system would be\npotentially reduced to a one-dimensional concave optimization irrespective of\nthe number of variables involved its description. This might open a way to a\nnew type of information processing for efficient management of complex systems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2007 01:10:02 GMT"}], "update_date": "2007-10-23", "authors_parsed": [["Korotkikh", "Victor", ""], ["Korotkikh", "Galina", ""]]}
{"id": "0710.4231", "submitter": "Yoshiharu Maeno", "authors": "Yoshiharu Maeno, and Yukio Ohsawa", "title": "Analyzing covert social network foundation behind terrorism disaster", "comments": "17pages, 10 figures, submitted to Int. J. Services Sciences", "journal-ref": "International Journal of Services Sciences Vol.2, pp.125-141\n  (2009)", "doi": "10.1504/IJSSCI.2009.024936", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper addresses a method to analyze the covert social network foundation\nhidden behind the terrorism disaster. It is to solve a node discovery problem,\nwhich means to discover a node, which functions relevantly in a social network,\nbut escaped from monitoring on the presence and mutual relationship of nodes.\nThe method aims at integrating the expert investigator's prior understanding,\ninsight on the terrorists' social network nature derived from the complex graph\ntheory, and computational data processing. The social network responsible for\nthe 9/11 attack in 2001 is used to execute simulation experiment to evaluate\nthe performance of the method.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2007 10:40:55 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Maeno", "Yoshiharu", ""], ["Ohsawa", "Yukio", ""]]}
{"id": "0710.4272", "submitter": "Leslie Ann Goldberg", "authors": "Martin Dyer, Leslie Ann Goldberg and Mark Jerrum", "title": "An approximation trichotomy for Boolean #CSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a trichotomy theorem for the complexity of approximately counting the\nnumber of satisfying assignments of a Boolean CSP instance. Such problems are\nparameterised by a constraint language specifying the relations that may be\nused in constraints. If every relation in the constraint language is affine\nthen the number of satisfying assignments can be exactly counted in polynomial\ntime. Otherwise, if every relation in the constraint language is in the\nco-clone IM_2 from Post's lattice, then the problem of counting satisfying\nassignments is complete with respect to approximation-preserving reductions in\nthe complexity class #RH\\Pi_1. This means that the problem of approximately\ncounting satisfying assignments of such a CSP instance is equivalent in\ncomplexity to several other known counting problems, including the problem of\napproximately counting the number of independent sets in a bipartite graph. For\nevery other fixed constraint language, the problem is complete for #P with\nrespect to approximation-preserving reductions, meaning that there is no fully\npolynomial randomised approximation scheme for counting satisfying assignments\nunless NP=RP.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2007 14:35:05 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2009 21:14:30 GMT"}], "update_date": "2009-07-23", "authors_parsed": [["Dyer", "Martin", ""], ["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}
{"id": "0710.4486", "submitter": "Michel Fliess", "authors": "Michel Fliess (INRIA Futurs), C\\'edric Join (INRIA Futurs, CRAN),\n  Hebertt Sira-Ramirez", "title": "Non-linear estimation is easy", "comments": null, "journal-ref": "Int. J. Modelling Identification and Control 4, 1 (2008) 12-27", "doi": "10.1504/IJMIC.2008.020996", "report-no": null, "categories": "cs.CE cs.NA cs.PF math.AC math.NA math.OC", "license": null, "abstract": "  Non-linear state estimation and some related topics, like parametric\nestimation, fault diagnosis, and perturbation attenuation, are tackled here via\na new methodology in numerical differentiation. The corresponding basic system\ntheoretic definitions and properties are presented within the framework of\ndifferential algebra, which permits to handle system variables and their\nderivatives of any order. Several academic examples and their computer\nsimulations, with on-line estimations, are illustrating our viewpoint.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2007 14:48:39 GMT"}], "update_date": "2008-11-06", "authors_parsed": [["Fliess", "Michel", "", "INRIA Futurs"], ["Join", "Cédric", "", "INRIA Futurs, CRAN"], ["Sira-Ramirez", "Hebertt", ""]]}
{"id": "0710.4508", "submitter": "Gregorio Malajovich", "authors": "Felipe Cucker, Teresa Krick, Gregorio Malajovich and Mario Wschebor", "title": "A Numerical Algorithm for Zero Counting. I: Complexity and Accuracy", "comments": "We made minor but necessary improvements in the presentation", "journal-ref": "Journal of Complexity 24 Issues 5-6, pp 582-605 (Oct-Dec 2008)", "doi": "10.1016/j.jco.2008.03.001", "report-no": null, "categories": "cs.CC cs.NA cs.SC math.NA", "license": null, "abstract": "  We describe an algorithm to count the number of distinct real zeros of a\npolynomial (square) system f. The algorithm performs O(n D kappa(f)) iterations\nwhere n is the number of polynomials (as well as the dimension of the ambient\nspace), D is a bound on the polynomials' degree, and kappa(f) is a condition\nnumber for the system. Each iteration uses an exponential number of operations.\nThe algorithm uses finite-precision arithmetic and a polynomial bound for the\nprecision required to ensure the returned output is correct is exhibited. This\nbound is a major feature of our algorithm since it is in contrast with the\nexponential precision required by the existing (symbolic) algorithms for\ncounting real zeros. The algorithm parallelizes well in the sense that each\niteration can be computed in parallel polynomial time with an exponential\nnumber of processors.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2007 16:33:07 GMT"}, {"version": "v2", "created": "Wed, 19 Mar 2008 20:28:15 GMT"}], "update_date": "2010-07-12", "authors_parsed": [["Cucker", "Felipe", ""], ["Krick", "Teresa", ""], ["Malajovich", "Gregorio", ""], ["Wschebor", "Mario", ""]]}
{"id": "0710.4596", "submitter": "Naoto Morikawa", "authors": "Naoto Morikawa", "title": "Discrete differential geometry of tetrahedrons and encoding of local\n  protein structure", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.MG q-bio.BM", "license": null, "abstract": "  Local protein structure analysis is informative to protein structure analysis\nand has been used successfully in protein structure prediction and others.\nProteins have recurring structural features, such as helix caps and beta turns,\nwhich often have strong amino acid sequence preferences. And the challenges for\nlocal structure analysis have been identification and assignment of such common\nshort structural motifs.\n  This paper proposes a new mathematical framework that can be applied to\nanalysis of the local structure of proteins, where local conformations of\nprotein backbones are described using differential geometry of folded\ntetrahedron sequences. Using the framework, we could capture the recurring\nstructural features without any structural templates, which makes local\nstructure analysis not only simpler, but also more objective.\n  Programs and examples are available from http://www.genocript.com .\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 01:16:39 GMT"}], "update_date": "2007-10-26", "authors_parsed": [["Morikawa", "Naoto", ""]]}
{"id": "0710.4630", "submitter": "EDA Publishing Association", "authors": "Trent Mcconaghy, Tom Eeckelaert, Georges Gielen", "title": "CAFFEINE: Template-Free Symbolic Model Generation of Analog Circuits via\n  Canonical Form Functions and Genetic Programming", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents a method to automatically generate compact symbolic\nperformance models of analog circuits with no prior specification of an\nequation template. The approach takes SPICE simulation data as input, which\nenables modeling of any nonlinear circuits and circuit characteristics. Genetic\nprogramming is applied as a means of traversing the space of possible symbolic\nexpressions. A grammar is specially designed to constrain the search to a\ncanonical form for functions. Novel evolutionary search operators are designed\nto exploit the structure of the grammar. The approach generates a set of\nsymbolic models which collectively provide a tradeoff between error and model\ncomplexity. Experimental results show that the symbolic models generated are\ncompact and easy to understand, making this an effective method for aiding\nunderstanding in analog design. The models also demonstrate better prediction\nquality than posynomials.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:07:11 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Mcconaghy", "Trent", ""], ["Eeckelaert", "Tom", ""], ["Gielen", "Georges", ""]]}
{"id": "0710.4632", "submitter": "EDA Publishing Association", "authors": "Nikolaos Kavvadias, Spiridon Nikolaidis", "title": "Hardware Support for Arbitrarily Complex Loop Structures in Embedded\n  Applications", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper, the program control unit of an embedded RISC processor is\nenhanced with a novel zero-overhead loop controller (ZOLC) supporting arbitrary\nloop structures with multiple-entry/exit nodes. The ZOLC has been incorporated\nto an open RISC processor core to evaluate the performance of the proposed unit\nfor alternative configurations of the selected processor. It is proven that\nspeed improvements of 8.4% to 48.2% are feasible for the used benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:07:52 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kavvadias", "Nikolaos", ""], ["Nikolaidis", "Spiridon", ""]]}
{"id": "0710.4634", "submitter": "EDA Publishing Association", "authors": "Y. Satish Kumar, Jun Li, Claudio Talarico, Janet Wang", "title": "A Probabilistic Collocation Method Based Statistical Gate Delay Model\n  Considering Process Variations and Multiple Input Switching", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": "10.1109/DATE.2005.31", "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Since the advent of new nanotechnologies, the variability of gate delay due\nto process variations has become a major concern. This paper proposes a new\ngate delay model that includes impact from both process variations and multiple\ninput switching. The proposed model uses orthogonal polynomial based\nprobabilistic collocation method to construct a delay analytical equation from\ncircuit timing performance. From the experimental results, our approach has\nless that 0.2% error on the mean delay of gates and less than 3% error on the\nstandard deviation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:08:50 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kumar", "Y. Satish", ""], ["Li", "Jun", ""], ["Talarico", "Claudio", ""], ["Wang", "Janet", ""]]}
{"id": "0710.4636", "submitter": "EDA Publishing Association", "authors": "Stephen J. Mellor, John R. Wolfe, Campbell Mccausland", "title": "Why Systems-on-Chip Needs More UML like a Hole in the Head", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Let's be clear from the outset: SoC can most certainly make use of UML; SoC\njust doesn't need more UML, or even all of it. The advent of model mappings,\ncoupled with marks that indicate which mapping rule to apply, enable a major\nsimplification of the use of UML in SoC.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:09:23 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Mellor", "Stephen J.", ""], ["Wolfe", "John R.", ""], ["Mccausland", "Campbell", ""]]}
{"id": "0710.4638", "submitter": "EDA Publishing Association", "authors": "Sankalp S. Kallakuri, Alex Doboli, Eugene A. Feinberg", "title": "Buffer Insertion for Bridges and Optimal Buffer Sizing for Communication\n  Sub-System of Systems-on-Chip", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  We have presented an optimal buffer sizing and buffer insertion methodology\nwhich uses stochastic models of the architecture and Continuous Time Markov\nDecision Processes CTMDPs. Such a methodology is useful in managing the scarce\nbuffer resources available on chip as compared to network based data\ncommunication which can have large buffer space. The modeling of this problem\nin terms of a CT-MDP framework lead to a nonlinear formulation due to usage of\nbridges in the bus architecture. We present a methodology to split the problem\ninto several smaller though linear systems and we then solve these subsystems.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:10:40 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kallakuri", "Sankalp S.", ""], ["Doboli", "Alex", ""], ["Feinberg", "Eugene A.", ""]]}
{"id": "0710.4639", "submitter": "EDA Publishing Association", "authors": "Cristiano Forzan, Davide Pandini", "title": "Modeling the Non-Linear Behavior of Library Cells for an Accurate Static\n  Noise Analysis", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In signal integrity analysis, the joint effect of propagated noise through\nlibrary cells, and of the noise injected on a quiet net by neighboring\nswitching nets through coupling capacitances, must be considered in order to\naccurately estimate the overall noise impact on design functionality and\nperformances. In this work the impact of the cell non-linearity on the noise\nglitch waveform is analyzed in detail, and a new macromodel that allows to\naccurately and efficiently modeling the non-linear effects of the victim driver\nin noise analysis is presented. Experimental results demonstrate the\neffectiveness of our method, and confirm that existing noise analysis\napproaches based on linear superposition of the propagated and\ncrosstalk-injected noise can be highly inaccurate, thus impairing the sign-off\nfunctional verification phase.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:11:06 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Forzan", "Cristiano", ""], ["Pandini", "Davide", ""]]}
{"id": "0710.4643", "submitter": "EDA Publishing Association", "authors": "Mehrdad Reshadi, Nikil Dutt", "title": "Generic Pipelined Processor Modeling and High Performance Cycle-Accurate\n  Simulator Generation", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": "10.1109/DATE.2005.166", "report-no": null, "categories": "cs.AR cs.PF", "license": null, "abstract": "  Detailed modeling of processors and high performance cycle-accurate\nsimulators are essential for today's hardware and software design. These\nproblems are challenging enough by themselves and have seen many previous\nresearch efforts. Addressing both simultaneously is even more challenging, with\nmany existing approaches focusing on one over another. In this paper, we\npropose the Reduced Colored Petri Net (RCPN) model that has two advantages:\nfirst, it offers a very simple and intuitive way of modeling pipelined\nprocessors; second, it can generate high performance cycle-accurate simulators.\nRCPN benefits from all the useful features of Colored Petri Nets without\nsuffering from their exponential growth in complexity. RCPN processor models\nare very intuitive since they are a mirror image of the processor pipeline\nblock diagram. Furthermore, in our experiments on the generated cycle-accurate\nsimulators for XScale and StrongArm processor models, we achieved an order of\nmagnitude (~15 times) speedup over the popular SimpleScalar ARM simulator.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:14:40 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Reshadi", "Mehrdad", ""], ["Dutt", "Nikil", ""]]}
{"id": "0710.4644", "submitter": "EDA Publishing Association", "authors": "Jurgen Schnerr, Oliver Bringmann, Wolfgang Rosenstiel", "title": "Cycle Accurate Binary Translation for Simulation Acceleration in Rapid\n  Prototyping of SoCs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper, the application of a cycle accurate binary translator for\nrapid prototyping of SoCs will be presented. This translator generates code to\nrun on a rapid prototyping system consisting of a VLIW processor and FPGAs. The\ngenerated code is annotated with information that triggers cycle generation for\nthe hardware in parallel to the execution of the translated program. The VLIW\nprocessor executes the translated program whereas the FPGAs contain the\nhardware for the parallel cycle generation and the bus interface that adapts\nthe bus of the VLIW processor to the SoC bus of the emulated processor core.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:18:14 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Schnerr", "Jurgen", ""], ["Bringmann", "Oliver", ""], ["Rosenstiel", "Wolfgang", ""]]}
{"id": "0710.4645", "submitter": "EDA Publishing Association", "authors": "B. Cheon, E. Lee, L.-T. Wang, X. Wen, P. Hsu, J. Cho, J. Park, H.\n  Chao, S. Wu", "title": "At-Speed Logic BIST for IP Cores", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper describes a flexible logic BIST scheme that features high fault\ncoverage achieved by fault-simulation guided test point insertion, real\nat-speed test capability for multi-clock designs without clock frequency\nmanipulation, and easy physical implementation due to the use of a low-speed SE\nsignal. Application results of this scheme to two widely used IP cores are also\nreported.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:19:34 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Cheon", "B.", ""], ["Lee", "E.", ""], ["Wang", "L. -T.", ""], ["Wen", "X.", ""], ["Hsu", "P.", ""], ["Cho", "J.", ""], ["Park", "J.", ""], ["Chao", "H.", ""], ["Wu", "S.", ""]]}
{"id": "0710.4646", "submitter": "EDA Publishing Association", "authors": "O. Villa, P. Schaumont, I. Verbauwhede, M. Monchiero, G. Palermo", "title": "Fast Dynamic Memory Integration in Co-Simulation Frameworks for\n  Multiprocessor System on-Chip", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper is proposed a technique to integrate and simulate a dynamic\nmemory in a multiprocessor framework based on C/C++/SystemC. Using host\nmachine's memory management capabilities, dynamic data processing is supported\nwithout compromising speed and accuracy of the simulation. A first prototype in\na shared memory context is presented.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:20:27 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Villa", "O.", ""], ["Schaumont", "P.", ""], ["Verbauwhede", "I.", ""], ["Monchiero", "M.", ""], ["Palermo", "G.", ""]]}
{"id": "0710.4649", "submitter": "EDA Publishing Association", "authors": "Praveen Ghanta, Sarma Vrudhula, Rajendran Panda, Janet Wang", "title": "Stochastic Power Grid Analysis Considering Process Variations", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper, we investigate the impact of interconnect and device process\nvariations on voltage fluctuations in power grids. We consider random\nvariations in the power grid's electrical parameters as spatial stochastic\nprocesses and propose a new and efficient method to compute the stochastic\nvoltage response of the power grid. Our approach provides an explicit\nanalytical representation of the stochastic voltage response using orthogonal\npolynomials in a Hilbert space. The approach has been implemented in a\nprototype software called OPERA (Orthogonal Polynomial Expansions for Response\nAnalysis). Use of OPERA on industrial power grids demonstrated speed-ups of up\nto two orders of magnitude. The results also show a significant variation of\nabout $\\pm$ 35% in the nominal voltage drops at various nodes of the power\ngrids and demonstrate the need for variation-aware power grid analysis.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:24:02 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Ghanta", "Praveen", ""], ["Vrudhula", "Sarma", ""], ["Panda", "Rajendran", ""], ["Wang", "Janet", ""]]}
{"id": "0710.4652", "submitter": "EDA Publishing Association", "authors": "Mahmut Kandemir, Guilin Chen", "title": "Locality-Aware Process Scheduling for Embedded MPSoCs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Utilizing on-chip caches in embedded multiprocessor-system-on-a-chip (MPSoC)\nbased systems is critical from both performance and power perspectives. While\nmost of the prior work that targets at optimizing cache behavior are performed\nat hardware and compilation levels, operating system (OS) can also play major\nrole as it sees the global access pattern information across applications. This\npaper proposes a cache-conscious OS process scheduling strategy based on data\nreuse. The proposed scheduler implements two complementary approaches. First,\nthe processes that do not share any data between them are scheduled at\ndifferent cores if it is possible to do so. Second, the processes that could\nnot be executed at the same time (due to dependences) but share data among each\nother are mapped to the same processor core so that they share the cache\ncontents. Our experimental results using this new data locality aware OS\nscheduling strategy are promising, and show significant improvements in task\ncompletion times.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:31:15 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kandemir", "Mahmut", ""], ["Chen", "Guilin", ""]]}
{"id": "0710.4653", "submitter": "EDA Publishing Association", "authors": "Shervin Sharifi, Javid Jaffari, Mohammad Hosseinabady, Ali\n  Afzali-Kusha, Zainalabedin Navabi", "title": "Simultaneous Reduction of Dynamic and Static Power in Scan Structures", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Power dissipation during test is a major challenge in testing integrated\ncircuits. Dynamic power has been the dominant part of power dissipation in CMOS\ncircuits, however, in future technologies the static portion of power\ndissipation will outreach the dynamic portion. This paper proposes an efficient\ntechnique to reduce both dynamic and static power dissipation in scan\nstructures. Scan cell outputs which are not on the critical path(s) are\nmultiplexed to fixed values during scan mode. These constant values and primary\ninputs are selected such that the transitions occurred on non-multiplexed scan\ncells are suppressed and the leakage current during scan mode is decreased. A\nmethod for finding these vectors is also proposed. Effectiveness of this\ntechnique is proved by experiments performed on ISCAS89 benchmark circuits.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:32:08 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Sharifi", "Shervin", ""], ["Jaffari", "Javid", ""], ["Hosseinabady", "Mohammad", ""], ["Afzali-Kusha", "Ali", ""], ["Navabi", "Zainalabedin", ""]]}
{"id": "0710.4654", "submitter": "EDA Publishing Association", "authors": "Peng Li, Frank Liu, Xin Li, Lawrence T. Pileggi, Sani R. Nassif", "title": "Modeling Interconnect Variability Using Efficient Parametric Model Order\n  Reduction", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Assessing IC manufacturing process fluctuations and their impacts on IC\ninterconnect performance has become unavoidable for modern DSM designs.\nHowever, the construction of parametric interconnect models is often hampered\nby the rapid increase in computational cost and model complexity. In this paper\nwe present an efficient yet accurate parametric model order reduction algorithm\nfor addressing the variability of IC interconnect performance. The efficiency\nof the approach lies in a novel combination of low-rank matrix approximation\nand multi-parameter moment matching. The complexity of the proposed parametric\nmodel order reduction is as low as that of a standard Krylov subspace method\nwhen applied to a nominal system. Under the projection-based framework, our\nalgorithm also preserves the passivity of the resulting parametric models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:33:14 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Li", "Peng", ""], ["Liu", "Frank", ""], ["Li", "Xin", ""], ["Pileggi", "Lawrence T.", ""], ["Nassif", "Sani R.", ""]]}
{"id": "0710.4655", "submitter": "EDA Publishing Association", "authors": "Baosheng Wang, Yuejian Wu, Andre Ivanov", "title": "A Fast Diagnosis Scheme for Distributed Small Embedded SRAMs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper proposes a diagnosis scheme aimed at reducing diagnosis time of\ndistributed small embedded SRAMs (e-SRAMs). This scheme improves the one\nproposed in [A parallel built-in self-diagnostic method for embedded memory\nbuffers, A parallel built-in self-diagnostic method for embedded memory\narrays]. The improvements are mainly two-fold. On one hand, the diagnosis of\ntime-consuming Data Retention Faults (DRFs), which is neglected by the\ndiagnosis architecture in [A parallel built-in self-diagnostic method for\nembedded memory buffers, A parallel built-in self-diagnostic method for\nembedded memory arrays], is now considered and performed via a DFT technique\nreferred to as the \"No Write Recovery Test Mode (NWRTM)\". On the other hand, a\npair comprising a Serial to Parallel Converter (SPC) and a Parallel to Serial\nConverter (PSC) is utilized to replace the bi-directional serial interface, to\navoid the problems of serial fault masking and defect rate dependent diagnosis.\nResults from our evaluations show that the proposed diagnosis scheme achieves\nan increased diagnosis coverage and reduces diagnosis time compared to those\nobtained in [A parallel built-in self-diagnostic method for embedded memory\nbuffers, A parallel built-in self-diagnostic method for embedded memory\narrays], with neglectable extra area cost.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:34:09 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Wang", "Baosheng", ""], ["Wu", "Yuejian", ""], ["Ivanov", "Andre", ""]]}
{"id": "0710.4656", "submitter": "EDA Publishing Association", "authors": "Minas Dasygenis, Erik Brockmeyer, Bart Durinck, Francky Catthoor,\n  Dimitrios Soudris, Antonios Thanailakis", "title": "A Memory Hierarchical Layer Assigning and Prefetching Technique to\n  Overcome the Memory Performance/Energy Bottleneck", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The memory subsystem has always been a bottleneck in performance as well as\nsignificant power contributor in memory intensive applications. Many\nresearchers have presented multi-layered memory hierarchies as a means to\ndesign energy and performance efficient systems. However, most of the previous\nwork do not explore trade-offs systematically. We fill this gap by proposing a\nformalized technique that takes into consideration data reuse, limited lifetime\nof the arrays of an application and application specific prefetching\nopportunities, and performs a thorough trade-off exploration for different\nmemory layer sizes. This technique has been implemented on a prototype tool,\nwhich was tested successfully using nine real-life applications of industrial\nrelevance. Following this approach we have able to reduce execution time up to\n60%, and energy consumption up to 70%.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:34:32 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Dasygenis", "Minas", ""], ["Brockmeyer", "Erik", ""], ["Durinck", "Bart", ""], ["Catthoor", "Francky", ""], ["Soudris", "Dimitrios", ""], ["Thanailakis", "Antonios", ""]]}
{"id": "0710.4657", "submitter": "EDA Publishing Association", "authors": "Gh. Bodean, D. Bodean, A. Labunetz", "title": "New Schemes for Self-Testing RAM", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper gives an overview of a new technique, named pseudo-ring testing\n(PRT). PRT can be applied for testing wide type of random access memories\n(RAM): bit- or word-oriented and single- or dual-port RAM's. An essential\nparticularity of the proposed methodology is the emulation of a linear\nautomaton over Galois field by memory own components.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:34:59 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Bodean", "Gh.", ""], ["Bodean", "D.", ""], ["Labunetz", "A.", ""]]}
{"id": "0710.4658", "submitter": "EDA Publishing Association", "authors": "A. M. Molnos, M. J. M. Heijligers, S. D. Cotofana, J. T. J. Van\n  Eijndhoven", "title": "Compositional Memory Systems for Multimedia Communicating Tasks", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR cs.MM", "license": null, "abstract": "  Conventional cache models are not suited for real-time parallel processing\nbecause tasks may flush each other's data out of the cache in an unpredictable\nmanner. In this way the system is not compositional so the overall performance\nis difficult to predict and the integration of new tasks expensive. This paper\nproposes a new method that imposes compositionality to the system?s performance\nand makes different memory hierarchy optimizations possible for multimedia\ncommunicating tasks when running on embedded multiprocessor architectures. The\nmethod is based on a cache allocation strategy that assigns sets of the unified\ncache exclusively to tasks and to the communication buffers. We also\nanalytically formulate the problem and describe a method to compute the cache\npartitioning ratio for optimizing the throughput and the consumed power. When\napplied to a multiprocessor with memory hierarchy our technique delivers also\nperformance gain. Compared to the shared cache case, for an application\nconsisting of two jpeg decoders and one edge detection algorithm 5 times less\nmisses are experienced and for an mpeg2 decoder 6.5 times less misses are\nexperienced.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:35:10 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Molnos", "A. M.", ""], ["Heijligers", "M. J. M.", ""], ["Cotofana", "S. D.", ""], ["Van Eijndhoven", "J. T. J.", ""]]}
{"id": "0710.4659", "submitter": "EDA Publishing Association", "authors": "Pierre Bomel (LESTER), Eric Martin (LESTER), Emmanuel Boutillon\n  (LESTER)", "title": "Synchronization Processor Synthesis for Latency Insensitive Systems", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper we present our contribution in terms of synchronization\nprocessor for a SoC design methodology based on the theory of the latency\ninsensitive systems (LIS) of Carloni et al. Our contribution consists in IP\nencapsulation into a new wrapper model which speed and area are optimized and\nsynthetizability guarantied. The main benefit of our approach is to preserve\nthe local IP performances when encapsulating them and reduce SoC silicon area.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:35:37 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Bomel", "Pierre", "", "LESTER"], ["Martin", "Eric", "", "LESTER"], ["Boutillon", "Emmanuel", "", "LESTER"]]}
{"id": "0710.4660", "submitter": "EDA Publishing Association", "authors": "W.-L. Hung, Y. Xie, N. Vijaykrishnan, M. Kandemir, M. J. Irwin", "title": "Thermal-Aware Task Allocation and Scheduling for Embedded Systems", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Temperature affects not only the reliability but also the performance, power,\nand cost of the embedded system. This paper proposes a thermal-aware task\nallocation and scheduling algorithm for embedded systems. The algorithm is used\nas a sub-routine for hardware/software co-synthesis to reduce the peak\ntemperature and achieve a thermally even distribution while meeting real time\nconstraints. The paper investigates both power-aware and thermal-aware\napproaches to task allocation and scheduling. The experimental results show\nthat the thermal-aware approach outperforms the power-aware schemes in terms of\nmaximal and average temperature reductions. To the best of our knowledge, this\nis the first task allocation and scheduling algorithm that takes temperature\ninto consideration.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:36:55 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Hung", "W. -L.", ""], ["Xie", "Y.", ""], ["Vijaykrishnan", "N.", ""], ["Kandemir", "M.", ""], ["Irwin", "M. J.", ""]]}
{"id": "0710.4661", "submitter": "EDA Publishing Association", "authors": "C. Chiang, A. Kahng, S. Sinha, X. Xu, A. Zelikovsky", "title": "Bright-Field AAPSM Conflict Detection and Correction", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  As feature sizes shrink, it will be necessary to use AAPSM\n(Alternating-Aperture Phase Shift Masking) to image critical features,\nespecially on the polysilicon layer. This imposes additional constraints on the\nlayouts beyond traditional design rules. Of particular note is the requirement\nthat all critical features be flanked by opposite-phase shifters, while the\nshifters obey minimum width and spacing requirements. A layout is called\nphase-assignable if it satisfies this requirement. If a layout is not\nphase-assignable, the phase conflicts have to removed to enable the use of\nAAPSM for the layout. Previous work has sought to detect a suitable set of\nphase Conflicts to be removed, as well as correct them. The contribution of\nthis paper are the following: (1) a new approach to detect a minimal set of\nphase conflicts (also referred to as AAPSM conflicts), which when corrected\nwill produce a phase-assignable layout; (2) a novel layout modification scheme\nfor correcting these AAPSM conflicts. The proposed approach for conflict\ndetection shows significant improvements in the quality of results and runtime\nfor real industrial circuits, when compared to previous methods. To the best of\nour knowledge, this is the first time layout modification results are presented\nfor bright-field AAPSM. Our experiments show that the percentage area increase\nfor making a layout phase-assignable ranges from 0.7-11.8%.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:37:31 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Chiang", "C.", ""], ["Kahng", "A.", ""], ["Sinha", "S.", ""], ["Xu", "X.", ""], ["Zelikovsky", "A.", ""]]}
{"id": "0710.4663", "submitter": "EDA Publishing Association", "authors": "Animesh Datta, Swarup Bhunia, Saibal Mukhopadhyay, Nilanjan Banerjee,\n  Kaushik Roy", "title": "Statistical Modeling of Pipeline Delay and Design of Pipeline under\n  Process Variation to Enhance Yield in sub-100nm Technologies", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Operating frequency of a pipelined circuit is determined by the delay of the\nslowest pipeline stage. However, under statistical delay variation in sub-100nm\ntechnology regime, the slowest stage is not readily identifiable and the\nestimation of the pipeline yield with respect to a target delay is a\nchallenging problem. We have proposed analytical models to estimate yield for a\npipelined design based on delay distributions of individual pipe stages. Using\nthe proposed models, we have shown that change in logic depth and imbalance\nbetween the stage delays can improve the yield of a pipeline. A statistical\nmethodology has been developed to optimally design a pipeline circuit for\nenhancing yield. Optimization results show that, proper imbalance among the\nstage delays in a pipeline improves design yield by 9% for the same area and\nperformance (and area reduction by about 8.4% under a yield constraint) over a\nbalanced design.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:41:06 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Datta", "Animesh", ""], ["Bhunia", "Swarup", ""], ["Mukhopadhyay", "Saibal", ""], ["Banerjee", "Nilanjan", ""], ["Roy", "Kaushik", ""]]}
{"id": "0710.4665", "submitter": "EDA Publishing Association", "authors": "Nicolo Manaresi, Gianni Medoro, Melanie Abonnenc, Vincent Auger, Paul\n  Vulto, Aldo Romani, Luigi Altomare, Marco Tartagni, Roberto Guerrieri", "title": "New Perspectives and Opportunities From the Wild West of Microelectronic\n  Biochips", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Application of Microelectronic to bioanalysis is an emerging field which\nholds great promise. From the standpoint of electronic and system design,\nbiochips imply a radical change of perspective, since new, completely different\nconstraints emerge while other usual constraints can be relaxed. While\nelectronic parts of the system can rely on the usual established design-flow,\nfluidic and packaging design, calls for a new approach which relies\nsignificantly on experiments. We hereby make some general considerations based\non our experience in the development of biochips for cell analysis.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:43:31 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Manaresi", "Nicolo", ""], ["Medoro", "Gianni", ""], ["Abonnenc", "Melanie", ""], ["Auger", "Vincent", ""], ["Vulto", "Paul", ""], ["Romani", "Aldo", ""], ["Altomare", "Luigi", ""], ["Tartagni", "Marco", ""], ["Guerrieri", "Roberto", ""]]}
{"id": "0710.4667", "submitter": "EDA Publishing Association", "authors": "Chien-Liang Chen, Jiing-Yuan Lin, Youn-Long Lin", "title": "Integration, Verification and Layout of a Complex Multimedia SOC", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR cs.MM", "license": null, "abstract": "  We present our experience of designing a single-chip controller for advanced\ndigital still camera from specification all the way to mass production. The\nprocess involves collaboration with camera system designer, IP vendors, EDA\nvendors, silicon wafer foundry, package and testing houses, and camera maker.\nWe also co-work with academic research groups to develop a JPEG codec IP and\nmemory BIST and SOC testing methodology. In this presentation, we cover the\nproblems encountered, our solutions, and lessons learned.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:44:47 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Chen", "Chien-Liang", ""], ["Lin", "Jiing-Yuan", ""], ["Lin", "Youn-Long", ""]]}
{"id": "0710.4669", "submitter": "EDA Publishing Association", "authors": "Cheng-Wen Wu", "title": "SOC Testing Methodology and Practice", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  On a commercial digital still camera (DSC) controller chip we practice a\nnovel SOC test integration platform, solving real problems in test scheduling,\ntest IO reduction, timing of functional test, scan IO sharing, embedded memory\nbuilt-in self-test (BIST), etc. The chip has been fabricated and tested\nsuccessfully by our approach. Test results justify that short test integration\ncost, short test time, and small area overhead can be achieved. To support SOC\ntesting, a memory BIST compiler and an SOC testing integration system have been\ndeveloped.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:45:18 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Wu", "Cheng-Wen", ""]]}
{"id": "0710.4670", "submitter": "EDA Publishing Association", "authors": "Ilia Polian, Alejandro Czutro, Bernd Becker", "title": "Evolutionary Optimization in Code-Based Test Compression", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  We provide a general formulation for the code-based test compression problem\nwith fixed-length input blocks and propose a solution approach based on\nEvolutionary Algorithms. In contrast to existing code-based methods, we allow\nunspecified values in matching vectors, which allows encoding of arbitrary test\nsets using a relatively small number of code-words. Experimental results for\nboth stuck-at and path delay fault test sets for ISCAS circuits demonstrate an\nimprovement compared to existing techniques.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:45:52 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Polian", "Ilia", ""], ["Czutro", "Alejandro", ""], ["Becker", "Bernd", ""]]}
{"id": "0710.4671", "submitter": "EDA Publishing Association", "authors": "Srinivasan Murali, Giovanni De Micheli", "title": "An Application-Specific Design Methodology for STbus Crossbar Generation", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  As the communication requirements of current and future Multiprocessor\nSystems on Chips (MPSoCs) continue to increase, scalable communication\narchitectures are needed to support the heavy communication demands of the\nsystem. This is reflected in the recent trend that many of the standard bus\nproducts such as STbus, have now introduced the capability of designing a\ncrossbar with multiple buses operating in parallel. The crossbar configuration\nshould be designed to closely match the application traffic characteristics and\nperformance requirements. In this work we address this issue of\napplication-specific design of optimal crossbar (using STbus crossbar\narchitecture), satisfying the performance requirements of the application and\noptimal binding of cores onto the crossbar resources. We present a simulation\nbased design approach that is based on analysis of actual traffic trace of the\napplication, considering local variations in traffic rates, temporal overlap\namong traffic streams and criticality of traffic streams. Our methodology is\napplied to several MPSoC designs and the resulting crossbar platforms are\nvalidated for performance by cycle-accurate SystemC simulation of the designs.\nThe experimental case studies show large reduction in packet latencies (up to\n7x) and large crossbar component savings (up to 3.5x) compared to traditional\ndesign approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:46:59 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Murali", "Srinivasan", ""], ["De Micheli", "Giovanni", ""]]}
{"id": "0710.4672", "submitter": "EDA Publishing Association", "authors": "Fei Su, Krishnendu Chakrabarty, Vamsee K. Pamula", "title": "Yield Enhancement of Digital Microfluidics-Based Biochips Using Space\n  Redundancy and Local Reconfiguration", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  As microfluidics-based biochips become more complex, manufacturing yield will\nhave significant influence on production volume and product cost. We propose an\ninterstitial redundancy approach to enhance the yield of biochips that are\nbased on droplet-based microfluidics. In this design method, spare cells are\nplaced in the interstitial sites within the microfluidic array, and they\nreplace neighboring faulty cells via local reconfiguration. The proposed design\nmethod is evaluated using a set of concurrent real-life bioassays.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:47:40 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Su", "Fei", ""], ["Chakrabarty", "Krishnendu", ""], ["Pamula", "Vamsee K.", ""]]}
{"id": "0710.4673", "submitter": "EDA Publishing Association", "authors": "Fei Su, Krishnendu Chakrabarty", "title": "Design of Fault-Tolerant and Dynamically-Reconfigurable Microfluidic\n  Biochips", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Microfluidics-based biochips are soon expected to revolutionize clinical\ndiagnosis, DNA sequencing, and other laboratory procedures involving molecular\nbiology. Most microfluidic biochips are based on the principle of continuous\nfluid flow and they rely on permanently-etched microchannels, micropumps, and\nmicrovalves. We focus here on the automated design of \"digital\" droplet-based\nmicrofluidic biochips. In contrast to continuous-flow systems, digital\nmicrofluidics offers dynamic reconfigurability; groups of cells in a\nmicrofluidics array can be reconfigured to change their functionality during\nthe concurrent execution of a set of bioassays. We present a simulated\nannealing-based technique for module placement in such biochips. The placement\nprocedure not only addresses chip area, but it also considers fault tolerance,\nwhich allows a microfluidic module to be relocated elsewhere in the system when\na single cell is detected to be faulty. Simulation results are presented for a\ncase study involving the polymerase chain reaction.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:48:12 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Su", "Fei", ""], ["Chakrabarty", "Krishnendu", ""]]}
{"id": "0710.4678", "submitter": "EDA Publishing Association", "authors": "R. Thewes, C. Paulus, M. Schienle, F. Hofmann, A. Frey, R. Brederlow,\n  M. Augustyniak, M. Jenkner, B. Eversmann, P. Schindler-Bauer, M. Atzesberger,\n  B. Holzapfl, G. Beer, T. Haneder, H.-C. Hanke", "title": "CMOS-Based Biosensor Arrays", "comments": null, "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  CMOS-based sensor array chips provide new and attractive features as compared\nto today's standard tools for medical, diagnostic, and biotechnical\napplications. Examples for molecule- and cell-based approaches and related\ncircuit design issues are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:02:53 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Thewes", "R.", ""], ["Paulus", "C.", ""], ["Schienle", "M.", ""], ["Hofmann", "F.", ""], ["Frey", "A.", ""], ["Brederlow", "R.", ""], ["Augustyniak", "M.", ""], ["Jenkner", "M.", ""], ["Eversmann", "B.", ""], ["Schindler-Bauer", "P.", ""], ["Atzesberger", "M.", ""], ["Holzapfl", "B.", ""], ["Beer", "G.", ""], ["Haneder", "T.", ""], ["Hanke", "H. -C.", ""]]}
{"id": "0710.4679", "submitter": "EDA Publishing Association", "authors": "Himanshu Kaul, Dennis Sylvester, David Blaauw, Trevor Mudge, Todd\n  Austin", "title": "DVS for On-Chip Bus Designs Based on Timing Error Correction", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  On-chip buses are typically designed to meet performance constraints at\nworst-case conditions, including process corner, temperature, IR-drop, and\nneighboring net switching pattern. This can result in significant performance\nslack at more typical operating conditions. In this paper, we propose a dynamic\nvoltage scaling (DVS) technique for buses, based on a double sampling latch\nwhich can detect and correct for delay errors without the need for\nretransmission. The proposed approach recovers the available slack at\nnon-worst-case operating points through more aggressive voltage scaling and\ntracks changing conditions by monitoring the error recovery rate. Voltage\nmargins needed in traditional designs to accommodate worst-case performance\nconditions are therefore eliminated, resulting in a significant improvement in\nenergy efficiency. The approach was implemented for a 6mm memory read bus\noperating at 1.5GHz (0.13 $\\mu$m technology node) and was simulated for a\nnumber of benchmark programs. Even at the worst-case process and environment\nconditions, energy gains of up to 17% are achieved, with error recovery rates\nunder 2.3%. At more typical process and environment conditions, energy gains\nrange from 35% to 45%, with a performance degradation under 2%. An analysis of\noptimum interconnect architectures for maximizing energy gains with this\napproach shows that the proposed approach performs well with technology\nscaling.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:03:13 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kaul", "Himanshu", ""], ["Sylvester", "Dennis", ""], ["Blaauw", "David", ""], ["Mudge", "Trevor", ""], ["Austin", "Todd", ""]]}
{"id": "0710.4680", "submitter": "EDA Publishing Association", "authors": "Diana Marculescu", "title": "Energy Bounds for Fault-Tolerant Nanoscale Designs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": null, "abstract": "  The problem of determining lower bounds for the energy cost of a given\nnanoscale design is addressed via a complexity theory-based approach. This\npaper provides a theoretical framework that is able to assess the trade-offs\nexisting in nanoscale designs between the amount of redundancy needed for a\ngiven level of resilience to errors and the associated energy cost. Circuit\nsize, logic depth and error resilience are analyzed and brought together in a\ntheoretical framework that can be seamlessly integrated with automated\nsynthesis tools and can guide the design process of nanoscale systems comprised\nof failure prone devices. The impact of redundancy addition on the switching\nenergy and its relationship with leakage energy is modeled in detail. Results\nshow that 99% error resilience is possible for fault-tolerant designs, but at\nthe expense of at least 40% more energy if individual gates fail independently\nwith probability of 1%.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:04:27 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Marculescu", "Diana", ""]]}
{"id": "0710.4681", "submitter": "EDA Publishing Association", "authors": "Wolf-Dietrich Weber, Joe Chou, Ian Swarbrick, Drew Wingard", "title": "A Quality-of-Service Mechanism for Interconnection Networks in\n  System-on-Chips", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  As Moore's Law continues to fuel the ability to build ever increasingly\ncomplex system-on-chips (SoCs), achieving performance goals is rising as a\ncritical challenge to completing designs. In particular, the system\ninterconnect must efficiently service a diverse set of data flows with widely\nranging quality-of-service (QoS) requirements. However, the known solutions for\noff-chip interconnects such as large-scale networks are not necessarily\napplicable to the on-chip environment. Latency and memory constraints for\non-chip interconnects are quite different from larger-scale interconnects. This\npaper introduces a novel on-chip interconnect arbitration scheme. We show how\nthis scheme can be distributed across a chip for high-speed implementation. We\ncompare the performance of the arbitration scheme with other known interconnect\narbitration schemes. Existing schemes typically focus heavily on either low\nlatency of service for some initiators, or alternatively on guaranteed\nbandwidth delivery for other initiators. Our scheme allows service latency on\nsome initiators to be traded off smoothly against jitter bounds on other\ninitiators, while still delivering bandwidth guarantees. This scheme is a\nsubset of the QoS controls that are available in the SonicsMX? (SMX) product.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:05:03 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Weber", "Wolf-Dietrich", ""], ["Chou", "Joe", ""], ["Swarbrick", "Ian", ""], ["Wingard", "Drew", ""]]}
{"id": "0710.4684", "submitter": "EDA Publishing Association", "authors": "S. Tosun, N. Mansouri, E. Arvas, M. Kandemir, Yuan Xie", "title": "Reliability-Centric High-Level Synthesis", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Importance of addressing soft errors in both safety critical applications and\ncommercial consumer products is increasing, mainly due to ever shrinking\ngeometries, higher-density circuits, and employment of power-saving techniques\nsuch as voltage scaling and component shut-down. As a result, it is becoming\nnecessary to treat reliability as a first-class citizen in system design. In\nparticular, reliability decisions taken early in system design can have\nsignificant benefits in terms of design quality. Motivated by this observation,\nthis paper presents a reliability-centric high-level synthesis approach that\naddresses the soft error problem. The proposed approach tries to maximize\nreliability of the design while observing the bounds on area and performance,\nand makes use of our reliability characterization of hardware components such\nas adders and multipliers. We implemented the proposed approach, performed\nexperiments with several designs, and compared the results with those obtained\nby a prior proposal.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:07:44 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Tosun", "S.", ""], ["Mansouri", "N.", ""], ["Arvas", "E.", ""], ["Kandemir", "M.", ""], ["Xie", "Yuan", ""]]}
{"id": "0710.4685", "submitter": "EDA Publishing Association", "authors": "C. Bolchini, F. Salice, D. Sciuto, L. Pomante", "title": "Reliable System Specification for Self-Checking Data-Paths", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The design of reliable circuits has received a lot of attention in the past,\nleading to the definition of several design techniques introducing fault\ndetection and fault tolerance properties in systems for critical\napplications/environments. Such design methodologies tackled the problem at\ndifferent abstraction levels, from switch-level to logic, RT level, and more\nrecently to system level. Aim of this paper is to introduce a novel\nsystem-level technique based on the redefinition of the operators functionality\nin the system specification. This technique provides reliability properties to\nthe system data path, transparently with respect to the designer. Feasibility,\nfault coverage, performance degradation and overheads are investigated on a FIR\ncircuit.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:08:39 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Bolchini", "C.", ""], ["Salice", "F.", ""], ["Sciuto", "D.", ""], ["Pomante", "L.", ""]]}
{"id": "0710.4686", "submitter": "EDA Publishing Association", "authors": "Anuja Sehgal, Fang Liu, Sule Ozev, Krishnendu Chakrabarty", "title": "Test Planning for Mixed-Signal SOCs with Wrapped Analog Cores", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Many SOCs today contain both digital and analog embedded cores. Even though\nthe test cost for such mixed-signal SOCs is significantly higher than that for\ndigital SOCs, most prior research in this area has focused exclusively on\ndigital cores. We propose a low-cost test development methodology for\nmixed-signal SOCs that allows the analog and digital cores to be tested in a\nunified manner, thereby minimizing the overall test cost. The analog cores in\nthe SOC are wrapped such that they can be accessed using a digital test access\nmechanism (TAM). We evaluate the impact of the use of analog test wrappers on\narea overhead and test time. To reduce area overhead, we present an analog test\nwrapper optimization technique, which is then combined with TAM optimization in\na cost-oriented heuristic approach for test scheduling. We also demonstrate the\nfeasibility of using analog wrappers by presenting transistor-level simulations\nfor an analog wrapper and a representative core. We present experimental\nresults on test scheduling for an ITC'02 benchmark SOC that has been augmented\nwith five analog cores.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:08:40 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Sehgal", "Anuja", ""], ["Liu", "Fang", ""], ["Ozev", "Sule", ""], ["Chakrabarty", "Krishnendu", ""]]}
{"id": "0710.4687", "submitter": "EDA Publishing Association", "authors": "Sandeep Kumar Goel, Erik Jan Marinissen", "title": "On-Chip Test Infrastructure Design for Optimal Multi-Site Testing of\n  System Chips", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Multi-site testing is a popular and effective way to increase test throughput\nand reduce test costs. We present a test throughput model, in which we focus on\nwafer testing, and consider parameters like test time, index time,\nabort-on-fail, and contact yield. Conventional multi-site testing requires\nsufficient ATE resources, such as ATE channels, to allow to test multiple SOCs\nin parallel. In this paper, we design and optimize on-chip DfT, in order to\nmaximize the test throughput for a given SOC and ATE. The on-chip DfT consists\nof an E-RPCT wrapper, and, for modular SOCs, module wrappers and TAMs. We\npresent experimental results for a Philips SOC and several ITC'02 SOC Test\nBenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:09:14 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Goel", "Sandeep Kumar", ""], ["Marinissen", "Erik Jan", ""]]}
{"id": "0710.4688", "submitter": "EDA Publishing Association", "authors": "F. Lima Kastensmidt, L. Sterpone, L. Carro, M. Sonza Reorda", "title": "On the Optimal Design of Triple Modular Redundancy Logic for SRAM-based\n  FPGAs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Triple Modular Redundancy (TMR) is a suitable fault tolerant technique for\nSRAM-based FPGA. However, one of the main challenges in achieving 100%\nrobustness in designs protected by TMR running on programmable platforms is to\nprevent upsets in the routing from provoking undesirable connections between\nsignals from distinct redundant logic parts, which can generate an error in the\noutput. This paper investigates the optimal design of the TMR logic (e.g., by\ncleverly inserting voters) to ensure robustness. Four different versions of a\nTMR digital filter were analyzed by fault injection. Faults were randomly\ninserted straight into the bitstream of the FPGA. The experimental results\npresented in this paper demonstrate that the number and placement of voters in\nthe TMR design can directly affect the fault tolerance, ranging from 4.03% to\n0.98% the number of upsets in the routing able to cause an error in the TMR\ncircuit.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:09:34 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kastensmidt", "F. Lima", ""], ["Sterpone", "L.", ""], ["Carro", "L.", ""], ["Reorda", "M. Sonza", ""]]}
{"id": "0710.4691", "submitter": "EDA Publishing Association", "authors": "Zhuo Li, Weiping Shi", "title": "An O(bn^2) Time Algorithm for Optimal Buffer Insertion with b Buffer\n  Types", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Buffer insertion is a popular technique to reduce the interconnect delay. The\nclassic buffer insertion algorithm of van Ginneken has time complexity O(n^2),\nwhere n is the number of buffer positions. Lillis, Cheng and Lin extended van\nGinneken's algorithm to allow b buffer types in time O (b^2 n^2). For modern\ndesign libraries that contain hundreds of buffers, it is a serious challenge to\nbalance the speed and performance of the buffer insertion algorithm. In this\npaper, we present a new algorithm that computes the optimal buffer insertion in\nO (bn^2) time. The reduction is achieved by the observation that the (Q, C)\npairs of the candidates that generate the new candidates must form a convex\nhull. On industrial test cases, the new algorithm is faster than the previous\nbest buffer insertion algorithms by orders of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:11:11 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Li", "Zhuo", ""], ["Shi", "Weiping", ""]]}
{"id": "0710.4692", "submitter": "EDA Publishing Association", "authors": "K.-U. Kirstein, Y. Li, M. Zimmermann, C. Vancura, T. Volden, W. H.\n  Song, J. Lichtenberg, A. Hierlemannn", "title": "Cantilever-Based Biosensors in CMOS Technology", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Single-chip CMOS-based biosensors that feature microcantilevers as transducer\nelements are presented. The cantilevers are functionalized for the capturing of\nspecific analytes, e.g., proteins or DNA. The binding of the analyte changes\nthe mechanical properties of the cantilevers such as surface stress and\nresonant frequency, which can be detected by an integrated Wheatstone bridge.\nThe monolithic integrated readout allows for a high signal-to-noise ratio,\nlowers the sensitivity to external interference and enables autonomous device\noperation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:11:49 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kirstein", "K. -U.", ""], ["Li", "Y.", ""], ["Zimmermann", "M.", ""], ["Vancura", "C.", ""], ["Volden", "T.", ""], ["Song", "W. H.", ""], ["Lichtenberg", "J.", ""], ["Hierlemannn", "A.", ""]]}
{"id": "0710.4693", "submitter": "EDA Publishing Association", "authors": "Ananta K. Majhi, Mohamed Azimane, Guido Gronthoud, Maurice Lousberg,\n  Stefan Eichenberger, Fred Bowen", "title": "Memory Testing Under Different Stress Conditions: An Industrial\n  Evaluation", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents the effectiveness of various stress conditions (mainly\nvoltage and frequency) on detecting the resistive shorts and open defects in\ndeep sub-micron embedded memories in an industrial environment. Simulation\nstudies on very-low voltage, high voltage and at-speed testing show the need of\nthe stress conditions for high quality products; i.e., low defect-per-million\n(DPM) level, which is driving the semiconductor market today. The above test\nconditions have been validated to screen out bad devices on real silicon (a\ntest-chip) built on CMOS 0.18 um technology. IFA (inductive fault analysis)\nbased simulation technique leads to an efficient fault coverage and DPM\nestimator, which helps the customers upfront to make decisions on test\nalgorithm implementations under different stress conditions in order to reduce\nthe number of test escapes.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:14:05 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Majhi", "Ananta K.", ""], ["Azimane", "Mohamed", ""], ["Gronthoud", "Guido", ""], ["Lousberg", "Maurice", ""], ["Eichenberger", "Stefan", ""], ["Bowen", "Fred", ""]]}
{"id": "0710.4697", "submitter": "EDA Publishing Association", "authors": "Aseem Agarwal, Kaviraj Chopra, David Blaauw", "title": "Statistical Timing Based Optimization using Gate Sizing", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The increased dominance of intra-die process variations has motivated the\nfield of Statistical Static Timing Analysis (SSTA) and has raised the need for\nSSTA-based circuit optimization. In this paper, we propose a new sensitivity\nbased, statistical gate sizing method. Since brute-force computation of the\nchange in circuit delay distribution to gate size change is computationally\nexpensive, we propose an efficient and exact pruning algorithm. The pruning\nalgorithm is based on a novel theory of perturbation bounds which are shown to\ndecrease as they propagate through the circuit. This allows pruning of gate\nsensitivities without complete propagation of their perturbations. We apply our\nproposed optimization algorithm to ISCAS benchmark circuits and demonstrate the\naccuracy and efficiency of the proposed method. Our results show an improvement\nof up to 10.5% in the 99-percentile circuit delay for the same circuit area,\nusing the proposed statistical optimizer and a run time improvement of up to\n56x compared to the brute-force approach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:16:49 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Agarwal", "Aseem", ""], ["Chopra", "Kaviraj", ""], ["Blaauw", "David", ""]]}
{"id": "0710.4703", "submitter": "EDA Publishing Association", "authors": "Tohru Ishihara, Farzan Fallah", "title": "A Way Memoization Technique for Reducing Power Consumption of Caches in\n  Application Specific Integrated Processors", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents a technique for eliminating redundant cache-tag and\ncache-way accesses to reduce power consumption. The basic idea is to keep a\nsmall number of Most Recently Used (MRU) addresses in a Memory Address Buffer\n(MAB) and to omit redundant tag and way accesses when there is a MAB-hit. Since\nthe approach keeps only tag and set-index values in the MAB, the energy and\narea overheads are relatively small even for a MAB with a large number of\nentries. Furthermore, the approach does not sacrifice the performance. In other\nwords, neither the cycle time nor the number of executed cycles increases. The\nproposed technique has been applied to Fujitsu VLIW processor (FR-V) and its\npower saving has been estimated using NanoSim. Experiments for 32kB 2-way set\nassociative caches show the power consumption of I-cache and D-cache can be\nreduced by 40% and 50%, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:27:22 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Ishihara", "Tohru", ""], ["Fallah", "Farzan", ""]]}
{"id": "0710.4704", "submitter": "EDA Publishing Association", "authors": "Yoonjin Kim, Mary Kiemb, Chulsoo Park, Jinyong Jung, Kiyoung Choi", "title": "Resource Sharing and Pipelining in Coarse-Grained Reconfigurable\n  Architecture for Domain-Specific Optimization", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Coarse-grained reconfigurable architectures aim to achieve both goals of high\nperformance and flexibility. However, existing reconfigurable array\narchitectures require many resources without considering the specific\napplication domain. Functional resources that take long latency and/or large\narea can be pipelined and/or shared among the processing elements. Therefore\nthe hardware cost and the delay can be effectively reduced without any\nperformance degradation for some application domains. We suggest such\nreconfigurable array architecture template and design space exploration flow\nfor domain-specific optimization. Experimental results show that our approach\nis much more efficient both in performance and area compared to existing\nreconfigurable architectures.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:28:05 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kim", "Yoonjin", ""], ["Kiemb", "Mary", ""], ["Park", "Chulsoo", ""], ["Jung", "Jinyong", ""], ["Choi", "Kiyoung", ""]]}
{"id": "0710.4705", "submitter": "EDA Publishing Association", "authors": "Roman Lysecky, Frank Vahid", "title": "A Study of the Speedups and Competitiveness of FPGA Soft Processor Cores\n  using Dynamic Hardware/Software Partitioning", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Field programmable gate arrays (FPGAs) provide designers with the ability to\nquickly create hardware circuits. Increases in FPGA configurable logic capacity\nand decreasing FPGA costs have enabled designers to more readily incorporate\nFPGAs in their designs. FPGA vendors have begun providing configurable soft\nprocessor cores that can be synthesized onto their FPGA products. While FPGAs\nwith soft processor cores provide designers with increased flexibility, such\nprocessors typically have degraded performance and energy consumption compared\nto hard-core processors. Previously, we proposed warp processing, a technique\ncapable of optimizing a software application by dynamically and transparently\nre-implementing critical software kernels as custom circuits in on-chip\nconfigurable logic. In this paper, we study the potential of a MicroBlaze\nsoft-core based warp processing system to eliminate the performance and energy\noverhead of a soft-core processor compared to a hard-core processor. We\ndemonstrate that the soft-core based warp processor achieves average speedups\nof 5.8 and energy reductions of 57% compared to the soft core alone. Our data\nshows that a soft-core based warp processor yields performance and energy\nconsumption competitive with existing hard-core processors, thus expanding the\nusefulness of soft processor cores on FPGAs to a broader range of applications.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:29:03 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Lysecky", "Roman", ""], ["Vahid", "Frank", ""]]}
{"id": "0710.4706", "submitter": "EDA Publishing Association", "authors": "Rui Rodrigues, Joao M. P. Cardoso", "title": "An Infrastructure to Functionally Test Designs Generated by Compilers\n  Targeting FPGAs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents an infrastructure to test the functionality of the\nspecific architectures output by a high-level compiler targeting dynamically\nreconfigurable hardware. It results in a suitable scheme to verify the\narchitectures generated by the compiler, each time new optimization techniques\nare included or changes in the compiler are performed. We believe this kind of\ninfrastructure is important to verify, by functional simulation, further\nresearch techniques, as far as compilation to Field-Programmable Gate Array\n(FPGA) platforms is concerned.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:29:33 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Rodrigues", "Rui", ""], ["Cardoso", "Joao M. P.", ""]]}
{"id": "0710.4707", "submitter": "EDA Publishing Association", "authors": "Umit Y. Ogras, Radu Marculescu", "title": "Energy- and Performance-Driven NoC Communication Architecture Synthesis\n  Using a Decomposition Approach", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper, we present a methodology for customized communication\narchitecture synthesis that matches the communication requirements of the\ntarget application. This is an important problem, particularly for\nnetwork-based implementations of complex applications. Our approach is based on\nusing frequently encountered generic communication primitives as an alphabet\ncapable of characterizing any given communication pattern. The proposed\nalgorithm searches through the entire design space for a solution that\nminimizes the system total energy consumption, while satisfying the other\ndesign constraints. Compared to the standard mesh architecture, the customized\narchitecture generated by the newly proposed approach shows about 36%\nthroughput increase and 51% reduction in the energy required to encrypt 128\nbits of data with a standard encryption algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:29:58 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Ogras", "Umit Y.", ""], ["Marculescu", "Radu", ""]]}
{"id": "0710.4709", "submitter": "EDA Publishing Association", "authors": "Georges Gielen, Wim Dehaene, Phillip Christie, Dieter Draxelmayr,\n  Edmond Janssens, Karen Maex, Ted Vucurevich", "title": "Analog and Digital Circuit Design in 65 nm CMOS: End of the Road?", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This special session adresses the problems that designers face when\nimplementing analog and digital circuits in nanometer technologies. An\nintroductory embedded tutorial will give an overview of the design problems at\nhand : the leakage power and process variability and their implications for\ndigital circuits and memories, and the reducing supply voltages, the design\nproductivity and signal integrity problems for embedded analog blocks. Next, a\npanel of experts from both industrial semiconductor houses and design\ncompanies, EDA vendors and research institutes will present and discuss with\nthe audience their opinions on whether the design road ends at marker \"65nm\" or\nnot.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:30:46 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Gielen", "Georges", ""], ["Dehaene", "Wim", ""], ["Christie", "Phillip", ""], ["Draxelmayr", "Dieter", ""], ["Janssens", "Edmond", ""], ["Maex", "Karen", ""], ["Vucurevich", "Ted", ""]]}
{"id": "0710.4711", "submitter": "EDA Publishing Association", "authors": "N. Huot (TIMA), H. Dubreuil (TIMA), L. Fesquet (TIMA), M. Renaudin\n  (TIMA)", "title": "FPGA Architecture for Multi-Style Asynchronous Logic", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents a novel FPGA architecture for implementing various styles\nof asynchronous logic. The main objective is to break the dependency between\nthe FPGA architecture dedicated to asynchronous logic and the logic style. The\ninnovative aspects of the architecture are described. Moreover the structure is\nwell suited to be rebuilt and adapted to fit with further asynchronous logic\nevolutions thanks to the architecture genericity. A full-adder was implemented\nin different styles of logic to show the architecture flexibility.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:32:43 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Huot", "N.", "", "TIMA"], ["Dubreuil", "H.", "", "TIMA"], ["Fesquet", "L.", "", "TIMA"], ["Renaudin", "M.", "", "TIMA"]]}
{"id": "0710.4712", "submitter": "EDA Publishing Association", "authors": "Ghazanfar Asadi, Mehdi B. Tahoori", "title": "An Accurate SER Estimation Method Based on Propagation Probability", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper, we present an accurate but very fast soft error rate (SER)\nestimation technique for digital circuits based on error propagation\nprobability (EPP) computation. Experiments results and comparison of the\nresults with the random simulation technique show that our proposed method is\non average within 6% of the random simulation method and four to five orders of\nmagnitude faster.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:33:14 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Asadi", "Ghazanfar", ""], ["Tahoori", "Mehdi B.", ""]]}
{"id": "0710.4713", "submitter": "EDA Publishing Association", "authors": "Osama Neiroukh, Xiaoyu Song", "title": "Improving the Process-Variation Tolerance of Digital Circuits Using Gate\n  Sizing and Statistical Techniques", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  A new approach for enhancing the process-variation tolerance of digital\ncircuits is described. We extend recent advances in statistical timing analysis\ninto an optimization framework. Our objective is to reduce the performance\nvariance of a technology-mapped circuit where delays across elements are\nrepresented by random variables which capture the manufacturing variations. We\nintroduce the notion of statistical critical paths, which account for both\nmeans and variances of performance variation. An optimization engine is used to\nsize gates with a goal of reducing the timing variance along the statistical\ncritical paths. We apply a pair of nested statistical analysis methods\ndeploying a slower more accurate approach for tracking statistical critical\npaths and a fast engine for evaluation of gate size assignments. We derive a\nnew approximation for the max operation on random variables which is deployed\nfor the faster inner engine. Circuit optimization is carried out using a\ngain-based algorithm that terminates when constraints are satisfied or no\nfurther improvements can be made. We show optimization results that demonstrate\nan average of 72% reduction in performance variation at the expense of average\n20% increase in design area.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:33:36 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Neiroukh", "Osama", ""], ["Song", "Xiaoyu", ""]]}
{"id": "0710.4714", "submitter": "EDA Publishing Association", "authors": "Jia Yu, Wei Wu, Xi Chen, Harry Hsieh, Jun Yang, Felice Balarin", "title": "Assertion-Based Design Exploration of DVS in Network Processor\n  Architectures", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  With the scaling of technology and higher requirements on performance and\nfunctionality, power dissipation is becoming one of the major design\nconsiderations in the development of network processors. In this paper, we use\nan assertion-based methodology for system-level power/performance analysis to\nstudy two dynamic voltage scaling (DVS) techniques, traffic-based DVS and\nexecution-based DVS, in a network processor model. Using the automatically\ngenerated distribution analyzers, we analyze the power and performance\ndistributions and study their trade-offs for the two DVS policies with\ndifferent parameter settings such as threshold values and window sizes. We\ndiscuss the optimal configurations of the two DVS policies under different\ndesign requirements. By a set of experiments, we show that the assertion-based\ntrace analysis methodology is an efficient tool that can help a designer easily\ncompare and study optimal architectural configurations in a large design space.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:33:38 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Yu", "Jia", ""], ["Wu", "Wei", ""], ["Chen", "Xi", ""], ["Hsieh", "Harry", ""], ["Yang", "Jun", ""], ["Balarin", "Felice", ""]]}
{"id": "0710.4715", "submitter": "EDA Publishing Association", "authors": "Jonathan R. Carter, Sule Ozev, Daniel J. Sorin", "title": "Circuit-Level Modeling for Concurrent Testing of Operational Defects due\n  to Gate Oxide Breakdown", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  As device sizes shrink and current densities increase, the probability of\ndevice failures due to gate oxide breakdown (OBD) also increases. To provide\ndesigns that are tolerant to such failures, we must investigate and understand\nthe manifestations of this physical phenomenon at the circuit and system level.\nIn this paper, we develop a model for operational OBD defects, and we explore\nhow to test for faults due to OBD. For a NAND gate, we derive the necessary\ninput conditions that excite and detect errors due to OBD defects at the gate\nlevel. We show that traditional pattern generators fail to exercise all of\nthese defects. Finally, we show that these test patterns can be propagated and\njustified for a combinational circuit in a manner similar to traditional ATPG.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:34:11 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Carter", "Jonathan R.", ""], ["Ozev", "Sule", ""], ["Sorin", "Daniel J.", ""]]}
{"id": "0710.4716", "submitter": "EDA Publishing Association", "authors": "Zhi Guo, Betul Buyukkurt, Walid Najjar, Kees Vissers", "title": "Optimized Generation of Data-Path from C Codes for FPGAs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  FPGAs, as computing devices, offer significant speedup over microprocessors.\nFurthermore, their configurability offers an advantage over traditional ASICs.\nHowever, they do not yet enjoy high-level language programmability, as\nmicroprocessors do. This has become the main obstacle for their wider\nacceptance by application designers. ROCCC is a compiler designed to generate\ncircuits from C source code to execute on FPGAs, more specifically on CSoCs. It\ngenerates RTL level HDLs from frequently executing kernels in an application.\nIn this paper, we describe ROCCC's system overview and focus on its data path\ngeneration. We compare the performance of ROCCC-generated VHDL code with that\nof Xilinx IPs. The synthesis result shows that ROCCC-generated circuit takes\naround 2x ~ 3x area and runs at comparable clock rate.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:34:19 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Guo", "Zhi", ""], ["Buyukkurt", "Betul", ""], ["Najjar", "Walid", ""], ["Vissers", "Kees", ""]]}
{"id": "0710.4717", "submitter": "EDA Publishing Association", "authors": "Raoul F. Badaoui, Ranga Vemuri", "title": "Multi-Placement Structures for Fast and Optimized Placement in Analog\n  Circuit Synthesis", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents the novel idea of multi-placement structures, for a fast\nand optimized placement instantiation in analog circuit synthesis. These\nstructures need to be generated only once for a specific circuit topology. When\nused in synthesis, these pre-generated structures instantiate various layout\nfloorplans for various sizes and parameters of a circuit. Unlike procedural\nlayout generators, they enable fast placement of circuits while keeping the\nquality of the placements at a high level during a synthesis process. The fast\nplacement is a result of high speed instantiation resulting from the efficiency\nof the multi-placement structure. The good quality of placements derive from\nthe extensive and intelligent search process that is used to build the\nmulti-placement structure. The target benchmarks of these structures are analog\ncircuits in the vicinity of 25 modules. An algorithm for the generation of such\nmulti-placement structures is presented. Experimental results show placement\nexecution times with an average of a few milliseconds making them usable during\nlayout-aware synthesis for optimized placements.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:35:03 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Badaoui", "Raoul F.", ""], ["Vemuri", "Ranga", ""]]}
{"id": "0710.4719", "submitter": "EDA Publishing Association", "authors": "Sounil Biswas, Peng Li, R. D. (shawn) Blanton, Larry T. Pileggi", "title": "Specification Test Compaction for Analog Circuits and MEMS", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Testing a non-digital integrated system against all of its specifications can\nbe quite expensive due to the elaborate test application and measurement setup\nrequired. We propose to eliminate redundant tests by employing e-SVM based\nstatistical learning. Application of the proposed methodology to an operational\namplifier and a MEMS accelerometer reveal that redundant tests can be\nstatistically identified from a complete set of specification-based tests with\nnegligible error. Specifically, after eliminating five of eleven\nspecification-based tests for an operational amplifier, the defect escape and\nyield loss is small at 0.6% and 0.9%, respectively. For the accelerometer,\ndefect escape of 0.2% and yield loss of 0.1% occurs when the hot and colt tests\nare eliminated. For the accelerometer, this level of Compaction would reduce\ntest cost by more than half.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:36:21 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Biswas", "Sounil", "", "shawn"], ["Li", "Peng", "", "shawn"], ["D.", "R.", "", "shawn"], ["Blanton", "", ""], ["Pileggi", "Larry T.", ""]]}
{"id": "0710.4720", "submitter": "EDA Publishing Association", "authors": "Yuvraj Singh Dhillon, Abdulkadir Utku Diril, Abhijit Chatterjee", "title": "Soft-Error Tolerance Analysis and Optimization of Nanometer Circuits", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Nanometer circuits are becoming increasingly susceptible to soft-errors due\nto alpha-particle and atmospheric neutron strikes as device scaling reduces\nnode capacitances and supply/threshold voltage scaling reduces noise margins.\nIt is becoming crucial to add soft-error tolerance estimation and optimization\nto the design flow to handle the increasing susceptibility. The first part of\nthis paper presents a tool for accurate soft-error tolerance analysis of\nnanometer circuits (ASERTA) that can be used to estimate the soft-error\ntolerance of nanometer circuits consisting of millions of gates. The tolerance\nestimates generated by the tool match SPICE generated estimates closely while\ntaking orders of magnitude less computation time. The second part of the paper\npresents a tool for soft-error tolerance optimization of nanometer circuits\n(SERTOPT) using the tolerance estimates generated by ASERTA. The tool finds\noptimal sizes, channel lengths, supply voltages and threshold voltages to be\nassigned to gates in a combinational circuit such that the soft-error tolerance\nis increased while meeting the timing constraint. Experiments on ISCAS'85\nbenchmark circuits showed that soft-error rate of the optimized circuit\ndecreased by as much as 47% with marginal increase in circuit delay.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:36:27 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Dhillon", "Yuvraj Singh", ""], ["Diril", "Abdulkadir Utku", ""], ["Chatterjee", "Abhijit", ""]]}
{"id": "0710.4721", "submitter": "EDA Publishing Association", "authors": "Pekka Syri, Juha Hakkinen, Markku Moilanen", "title": "IEEE 1149.4 Compatible ABMs for Basic RF Measurements", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  An analogue testing standard IEEE 1149.4 is mainly targeted for low-frequency\ntesting. The problem studied in this paper is extending the standard also for\nradio frequency testing. IEEE 1149.4 compatible measurement structures (ABMs)\ndeveloped in this study extract the information one is measuring from the radio\nfrequency signal and represent the result as a DC voltage level. The ABMs\npresented in this paper are targeted for power and frequency measurements\noperating in frequencies from 1 GHz to 2 GHz. The power measurement error\ncaused by temperature, supply voltage and process variations is roughly 2 dB\nand the frequency measurement error is 0.1 GHz, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:36:53 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Syri", "Pekka", ""], ["Hakkinen", "Juha", ""], ["Moilanen", "Markku", ""]]}
{"id": "0710.4722", "submitter": "EDA Publishing Association", "authors": "Yu-Tsun Chien, Dong Chen, Jea-Hong Lou, Gin-Kou Ma, Rob A. Rutenbar,\n  Tamal Mukherjee", "title": "Designer-Driven Topology Optimization for Pipelined Analog to Digital\n  Converters", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper suggests a practical \"hybrid\" synthesis methodology which\nintegrates designer-derived analytical models for system-level description with\nsimulation-based models at the circuit level. We show how to optimize\nstage-resolution to minimize the power in a pipelined ADC. Exploration (via\ndetailed synthesis) of several ADC configurations is used to show that a\n4-3-2... resolution distribution uses the least power for a 13-bit 40 MSPS\nconverter in a 0.25 $\\mu$m CMOS process.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:36:56 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Chien", "Yu-Tsun", ""], ["Chen", "Dong", ""], ["Lou", "Jea-Hong", ""], ["Ma", "Gin-Kou", ""], ["Rutenbar", "Rob A.", ""], ["Mukherjee", "Tamal", ""]]}
{"id": "0710.4724", "submitter": "EDA Publishing Association", "authors": "L. Barrandon (IETR), S. Crand (IETR), D. Houzet (IETR)", "title": "Systematic Figure of Merit Computation for the Design of Pipeline ADC", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The emerging concept of SoC-AMS leads to research new top-down methodologies\nto aid systems designers in sizing analog and mixed devices. This work applies\nthis idea to the high-level optimization of pipeline ADC. Considering a given\ntechnology, it consists in comparing different configurations according to\ntheir imperfections and their architectures without FFT computation or\ntime-consuming simulations. The final selection is based on a figure of merit.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:37:45 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Barrandon", "L.", "", "IETR"], ["Crand", "S.", "", "IETR"], ["Houzet", "D.", "", "IETR"]]}
{"id": "0710.4727", "submitter": "EDA Publishing Association", "authors": "Paul Muller, Armin Tajalli, Mojtaba Atarodi, Yusuf Leblebici", "title": "Top-Down Design of a Low-Power Multi-Channel 2.5-Gbit/s/Channel Gated\n  Oscillator Clock-Recovery Circuit", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  We present a complete top-down design of a low-power multi-channel clock\nrecovery circuit based on gated current-controlled oscillators. The flow\nincludes several tools and methods used to specify block constraints, to design\nand verify the topology down to the transistor level, as well as to achieve a\npower consumption as low as 5mW/Gbit/s. Statistical simulation is used to\nestimate the achievable bit error rate in presence of phase and frequency\nerrors and to prove the feasibility of the concept. VHDL modeling provides\nextensive verification of the topology. Thermal noise modeling based on\nwell-known concepts delivers design parameters for the device sizing and\nbiasing. We present two practical examples of possible design improvements\nanalyzed and implemented with this methodology.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:38:14 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Muller", "Paul", ""], ["Tajalli", "Armin", ""], ["Atarodi", "Mojtaba", ""], ["Leblebici", "Yusuf", ""]]}
{"id": "0710.4728", "submitter": "EDA Publishing Association", "authors": "Jung-Chun Kao, Radu Marculescu", "title": "Energy-Aware Routing for E-Textile Applications", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  As the scale of electronic devices shrinks, \"electronic textiles\"\n(e-textiles) will make possible a wide variety of novel applications which are\ncurrently unfeasible. Due to the wearability concerns, low-power techniques are\ncritical for e-textile applications. In this paper, we address the issue of the\nenergy-aware routing for e-textile platforms and propose an efficient algorithm\nto solve it. The platform we consider consists of dedicated components for\ne-textiles, including computational modules, dedicated transmission lines and\nthin-film batteries on fiber substrates. Furthermore, we derive an analytical\nupper bound for the achievable number of jobs completed over all possible\nrouting strategies. From a practical standpoint, for the Advanced Encryption\nStandard (AES) cipher, the routing technique we propose achieves about fifty\npercent of this analytical upper bound. Moreover, compared to the\nnon-energy-aware counterpart, our routing technique increases the number of\nencryption jobs completed by one order of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:38:43 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kao", "Jung-Chun", ""], ["Marculescu", "Radu", ""]]}
{"id": "0710.4729", "submitter": "EDA Publishing Association", "authors": "Saibal Mukhopadhyay, Swarup Bhunia, Kaushik Roy", "title": "Modeling and Analysis of Loading Effect in Leakage of Nano-Scaled\n  Bulk-CMOS Logic Circuits", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In nanometer scaled CMOS devices significant increase in the subthreshold,\nthe gate and the reverse biased junction band-to-band-tunneling (BTBT) leakage,\nresults in the large increase of total leakage power in a logic circuit.\nLeakage components interact with each other in device level (through device\ngeometry, doping profile) and also in the circuit level (through node\nvoltages). Due to the circuit level interaction of the different leakage\ncomponents, the leakage of a logic gate strongly depends on the circuit\ntopology i.e. number and nature of the other logic gates connected to its input\nand output. In this paper, for the first time, we have analyzed loading effect\non leakage and proposed a method to accurately estimate the total leakage in a\nlogic circuit, from its logic level description considering the impact of\nloading and transistor stacking.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:39:25 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Mukhopadhyay", "Saibal", ""], ["Bhunia", "Swarup", ""], ["Roy", "Kaushik", ""]]}
{"id": "0710.4731", "submitter": "EDA Publishing Association", "authors": "Yuh-Fang Tsai, Vijaykrishnan Narayaynan, Yuan Xie, Mary Jane Irwin", "title": "Leakage-Aware Interconnect for On-Chip Network", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  On-chip networks have been proposed as the interconnect fabric for future\nsystems-on-chip and multi-processors on chip. Power is one of the main\nconstraints of these systems and interconnect consumes a significant portion of\nthe power budget. In this paper, we propose four leakage-aware interconnect\nschemes. Our schemes achieve 10.13%~63.57% active leakage savings and\n12.35%~95.96% standby leakage savings across schemes while the delay penalty\nranges from 0% to 4.69%.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:40:02 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Tsai", "Yuh-Fang", ""], ["Narayaynan", "Vijaykrishnan", ""], ["Xie", "Yuan", ""], ["Irwin", "Mary Jane", ""]]}
{"id": "0710.4733", "submitter": "EDA Publishing Association", "authors": "S. A. Bota, M. Rosales, J. L. Rossello, J. Segura", "title": "Smart Temperature Sensor for Thermal Testing of Cell-Based ICs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper we present a simple and efficient built-in temperature sensor\nfor thermal monitoring of standard-cell based VLSI circuits. The proposed smart\ntemperature sensor uses a ring-oscillator composed of complex gates instead of\ninverters to optimize their linearity. Simulation results from a 0.18$\\mu$m\nCMOS technology show that the non-linearity error of the sensor can be reduced\nwhen an adequate set of standard logic gates is selected.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:41:13 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Bota", "S. A.", ""], ["Rosales", "M.", ""], ["Rossello", "J. L.", ""], ["Segura", "J.", ""]]}
{"id": "0710.4734", "submitter": "EDA Publishing Association", "authors": "Eric Liau, Doris Schmitt-Landsiedel", "title": "Computational Intelligence Characterization Method of Semiconductor\n  Device", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": null, "abstract": "  Characterization of semiconductor devices is used to gather as much data\nabout the device as possible to determine weaknesses in design or trends in the\nmanufacturing process. In this paper, we propose a novel multiple trip point\ncharacterization concept to overcome the constraint of single trip point\nconcept in device characterization phase. In addition, we use computational\nintelligence techniques (e.g. neural network, fuzzy and genetic algorithm) to\nfurther manipulate these sets of multiple trip point values and tests based on\nsemiconductor test equipments, Our experimental results demonstrate an\nexcellent design parameter variation analysis in device characterization phase,\nas well as detection of a set of worst case tests that can provoke the worst\ncase variation, while traditional approach was not capable of detecting them.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:41:43 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Liau", "Eric", ""], ["Schmitt-Landsiedel", "Doris", ""]]}
{"id": "0710.4735", "submitter": "EDA Publishing Association", "authors": "Irith Pomeranz, Sudhakar M. Reddy", "title": "Worst-Case and Average-Case Analysis of n-Detection Test Sets", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Test sets that detect each target fault n times (n-detection test sets) are\ntypically generated for restricted values of n due to the increase in test set\nsize with n. We perform both a worst-case analysis and an average-case analysis\nto check the effect of restricting n on the unmodeled fault coverage of an\n(arbitrary) n-detection test set. Our analysis is independent of any particular\ntest set or test generation approach. It is based on a specific set of target\nfaults and a specific set of untargeted faults. It shows that, depending on the\ncircuit, very large values of n may be needed to guarantee the detection of all\nthe untargeted faults. We discuss the implications of these results.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:42:30 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Pomeranz", "Irith", ""], ["Reddy", "Sudhakar M.", ""]]}
{"id": "0710.4736", "submitter": "EDA Publishing Association", "authors": "L. Lopez (L2MP), J. M. Portal (L2MP), D. Nee (ST-Rousset)", "title": "A New Embedded Measurement Structure for eDRAM Capacitor", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The embedded DRAM (eDRAM) is more and more used in System On Chip (SOC). The\nintegration of the DRAM capacitor process into a logic process is challenging\nto get satisfactory yields. The specific process of DRAM capacitor and the low\ncapacitance value (~30F) of this device induce problems of process monitoring\nand failure analysis. We propose a new test structure to measure the\ncapacitance value of each DRAM cell capacitor in a DRAM array. This concept has\nbeen validated by simulation on a 0.18$\\mu$m eDRAM technology.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:42:35 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Lopez", "L.", "", "L2MP"], ["Portal", "J. M.", "", "L2MP"], ["Nee", "D.", "", "ST-Rousset"]]}
{"id": "0710.4738", "submitter": "EDA Publishing Association", "authors": "Cesar Marcon, Ney Calazans, Fernando Moraes, Altamiro Susin, Igor\n  Reis, Fabiano Hessel", "title": "Exploring NoC Mapping Strategies: An Energy and Timing Aware Technique", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Complex applications implemented as Systems on Chip (SoCs) demand extensive\nuse of system level modeling and validation. Their implementation gathers a\nlarge number of complex IP cores and advanced interconnection schemes, such as\nhierarchical bus architectures or networks on chip (NoCs). Modeling\napplications involves capturing its computation and communication\ncharacteristics. Previously proposed communication weighted models (CWM)\nconsider only the application communication aspects. This work proposes a\ncommunication dependence and computation model (CDCM) that can simultaneously\nconsider both aspects of an application. It presents a solution to the problem\nof mapping applications on regular NoCs while considering execution time and\nenergy consumption. The use of CDCM is shown to provide estimated average\nreductions of 40% in execution time, and 20% in energy consumption, for current\ntechnologies.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:43:59 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Marcon", "Cesar", ""], ["Calazans", "Ney", ""], ["Moraes", "Fernando", ""], ["Susin", "Altamiro", ""], ["Reis", "Igor", ""], ["Hessel", "Fabiano", ""]]}
{"id": "0710.4742", "submitter": "EDA Publishing Association", "authors": "Joel Coburn, Srivaths Ravi, Anand Raghunathan", "title": "Hardware Accelerated Power Estimation", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper, we present power emulation, a novel design paradigm that\nutilizes hardware acceleration for the purpose of fast power estimation. Power\nemulation is based on the observation that the functions necessary for power\nestimation (power model evaluation, aggregation, etc.) can be implemented as\nhardware circuits. Therefore, we can enhance any given design with \"power\nestimation hardware\", map it to a prototyping platform, and exercise it with\nany given test stimuli to obtain power consumption estimates. Our empirical\nstudies with industrial designs reveal that power emulation can achieve\nsignificant speedups (10X to 500X) over state-of-the-art commercial\nregister-transfer level (RTL) power estimation tools.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:45:28 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Coburn", "Joel", ""], ["Ravi", "Srivaths", ""], ["Raghunathan", "Anand", ""]]}
{"id": "0710.4747", "submitter": "EDA Publishing Association", "authors": "Jin-Fu Li, Tsu-Wei Tseng, Chin-Long Wey", "title": "An Efficient Transparent Test Scheme for Embedded Word-Oriented Memories", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Memory cores are usually the densest portion with the smallest feature size\nin system-on-chip (SOC) designs. The reliability of memory cores thus has heavy\nimpact on the reliability of SOCs. Transparent test is one of useful technique\nfor improving the reliability of memories during life time. This paper presents\na systematic algorithm used for transforming a bit-oriented march test into a\ntransparent word-oriented march test. The transformed transparent march test\nhas shorter test complexity compared with that proposed in the previous works\n[Theory of transparent BIST for RAMs, A transparent online memory test for\nsimultaneous detection of functional faults and soft errors in memories]. For\nexample, if a memory with 32-bit words is tested with March C-, time complexity\nof the transparent word-oriented test transformed by the proposed scheme is\nonly about 56% or 19% time complexity of the transparent word-oriented test\nconverted by the scheme reported in [Theory of transparent BIST for RAMs] or [A\ntransparent online memory test for simultaneous detection of functional faults\nand soft errors in memories], respectively.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:48:22 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Li", "Jin-Fu", ""], ["Tseng", "Tsu-Wei", ""], ["Wey", "Chin-Long", ""]]}
{"id": "0710.4748", "submitter": "EDA Publishing Association", "authors": "Wolfgang Klingauf", "title": "Systematic Transaction Level Modeling of Embedded Systems with SystemC", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper gives an overview of a transaction level modeling (TLM) design\nflow for straightforward embedded system design with SystemC. The goal is to\nsystematically develop both application-specific HW and SW components of an\nembedded system using the TLM approach, thus allowing for fast communication\narchitecture exploration, rapid prototyping and early embedded SW development.\nTo this end, we specify the lightweight transaction-based communication\nprotocol SHIP and present a methodology for automatic mapping of the\ncommunication part of a system to a given architecture, including HW/SW\ninterfaces.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:49:10 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Klingauf", "Wolfgang", ""]]}
{"id": "0710.4751", "submitter": "EDA Publishing Association", "authors": "Lars Wehmeyer, Peter Marwedel", "title": "Influence of Memory Hierarchies on Predictability for Time Constrained\n  Embedded Software", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Safety-critical embedded systems having to meet real-time constraints are\nexpected to be highly predictable in order to guarantee at design time that\ncertain timing deadlines will always be met. This requirement usually prevents\ndesigners from utilizing caches due to their highly dynamic, thus hardly\npredictable behavior. The integration of scratchpad memories represents an\nalternative approach which allows the system to benefit from a performance gain\ncomparable to that of caches while at the same time maintaining predictability.\nIn this work, we compare the impact of scratchpad memories and caches on worst\ncase execution time (WCET) analysis results. We show that caches, despite\nrequiring complex techniques, can have a negative impact on the predicted WCET,\nwhile the estimated WCET for scratchpad memories scales with the achieved\nPerformance gain at no extra analysis cost.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:51:11 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Wehmeyer", "Lars", ""], ["Marwedel", "Peter", ""]]}
{"id": "0710.4754", "submitter": "EDA Publishing Association", "authors": "Philippe Martin", "title": "Design of a Virtual Component Neutral Network-on-Chip Transaction Layer", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Research studies have demonstrated the feasibility and advantages of\nNetwork-on-Chip (NoC) over traditional bus-based architectures but have not\nfocused on compatibility communication standards. This paper describes a number\nof issues faced when designing a VC-neutral NoC, i.e. compatible with standards\nsuch as AHB 2.0, AXI, VCI, OCP, and various other proprietary protocols, and\nhow a layered approach to communication helps solve these issues.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:52:56 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Martin", "Philippe", ""]]}
{"id": "0710.4757", "submitter": "EDA Publishing Association", "authors": "Celia Lopez-Ongil, Mario Garcia-Valderas, Marta Portela-Garcia, Luis\n  Entrena-Arrontes", "title": "Techniques for Fast Transient Fault Grading Based on Autonomous\n  Emulation", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Very deep submicron and nanometer technologies have increased notably\nintegrated circuit (IC) sensitiveness to radiation. Soft errors are currently\nappearing into ICs working at earth surface. Hardened circuits are currently\nrequired in many applications where Fault Tolerance (FT) was not a requirement\nin the very near past. The use of platform FPGAs for the emulation of\nsingle-event upset effects (SEU) is gaining attention in order to speed up the\nFT evaluation. In this work, a new emulation system for FT evaluation with\nrespect to SEU effects is proposed, providing shorter evaluation times by\nperforming all the evaluation process in the FPGA and avoiding emulator-host\ncommunication bottlenecks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:53:37 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Lopez-Ongil", "Celia", ""], ["Garcia-Valderas", "Mario", ""], ["Portela-Garcia", "Marta", ""], ["Entrena-Arrontes", "Luis", ""]]}
{"id": "0710.4759", "submitter": "EDA Publishing Association", "authors": "J. L. Rossello, V. Canals, S. A. Bota, A. Keshavarzi, J. Segura", "title": "A Fast Concurrent Power-Thermal Model for Sub-100nm Digital ICs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  As technology scales down, the static power is expected to become a\nsignificant fraction of the total power. The exponential dependence of static\npower with the operating temperature makes the thermal profile estimation of\nhigh-performance ICs a key issue to compute the total power dissipated in\nnext-generations. In this paper we present accurate and compact analytical\nmodels to estimate the static power dissipation and the temperature of\noperation of CMOS gates. The models are the fundamentals of a performance\nestimation tool in which numerical procedures are avoided for any computation\nto set a faster estimation and optimization. The models developed are compared\nto measurements and SPICE simulations for a 0.12mm technology showing excellent\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:54:18 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Rossello", "J. L.", ""], ["Canals", "V.", ""], ["Bota", "S. A.", ""], ["Keshavarzi", "A.", ""], ["Segura", "J.", ""]]}
{"id": "0710.4760", "submitter": "EDA Publishing Association", "authors": "A. Verle (LIRMM), X. Michel (LIRMM), N. Azemard (LIRMM), P. Maurine\n  (LIRMM), D. Auvergne (LIRMM)", "title": "Low Power Oriented CMOS Circuit Optimization Protocol", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Low power oriented circuit optimization consists in selecting the best\nalternative between gate sizing, buffer insertion and logic structure\ntransformation, for satisfying a delay constraint at minimum area cost. In this\npaper we used a closed form model of delay in CMOS structures to define metrics\nfor a deterministic selection of the optimization alternative. The target is\ndelay constraint satisfaction with minimum area cost. We validate the design\nspace exploration method, defining maximum and minimum delay bounds on logical\npaths. Then we adapt this method to a \"constant sensitivity method\" allowing to\nsize a circuit at minimum area under a delay constraint. An optimisation\nprotocol is finally defined to manage the trade-off performance constraint -\ncircuit structure. These methods are implemented in an optimization tool (POPS)\nand validated by comparing on a 0.25$\\mu$m process, the optimization efficiency\nobtained on various benchmarks (ISCAS?85) to that resulting from an industrial\ntool.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:54:46 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Verle", "A.", "", "LIRMM"], ["Michel", "X.", "", "LIRMM"], ["Azemard", "N.", "", "LIRMM"], ["Maurine", "P.", "", "LIRMM"], ["Auvergne", "D.", "", "LIRMM"]]}
{"id": "0710.4761", "submitter": "EDA Publishing Association", "authors": "D. C. Keezer, C. Gray, A. Majid, N. Taher", "title": "Low-Cost Multi-Gigahertz Test Systems Using CMOS FPGAs and PECL", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper describes two research projects that develop new low-cost\ntechniques for testing devices with multiple high-speed (2 to 5 Gbps) signals.\nEach project uses commercially available components to keep costs low, yet\nachieves performance characteristics comparable to (and in some ways exceeding)\nmore expensive ATE. A common CMOS FPGA-based logic core provides flexibility,\nadaptability, and communication with controlling computers while customized\npositive emitter-coupled logic (PECL) achieves multi-gigahertz data rates with\nabout $\\pm$25ps timing accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:55:04 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Keezer", "D. C.", ""], ["Gray", "C.", ""], ["Majid", "A.", ""], ["Taher", "N.", ""]]}
{"id": "0710.4762", "submitter": "EDA Publishing Association", "authors": "Takeshi Kitahara, Naoyuki Kawabe, Fimihiro Minami, Katsuhiro Seta,\n  Toshiyuki Furusawa", "title": "Area-Efficient Selective Multi-Threshold CMOS Design Methodology for\n  Standby Leakage Power Reduction", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents a design flow for an improved selective\nmulti-threshold(Selective-MT) circuit. The Selective-MT circuit is improved so\nthat plural MT-cells can share one switch transistor. We propose the design\nmethodology from RTL(Register Transfer Level) to final layout with optimizing\nswitch transistor structure.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:55:21 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kitahara", "Takeshi", ""], ["Kawabe", "Naoyuki", ""], ["Minami", "Fimihiro", ""], ["Seta", "Katsuhiro", ""], ["Furusawa", "Toshiyuki", ""]]}
{"id": "0710.4763", "submitter": "EDA Publishing Association", "authors": "Matthias Beck, Olivier Barondeau, Martin Kaibel, Frank Poehl, Xijiang\n  Lin, Ron Press", "title": "Logic Design for On-Chip Test Clock Generation - Implementation Details\n  and Impact on Delay Test Quality", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper addresses delay test for SOC devices with high frequency clock\ndomains. A logic design for on-chip high-speed clock generation, implemented to\navoid expensive test equipment, is described in detail. Techniques for on-chip\nclock generation, meant to reduce test vector count and to increase test\nquality, are discussed. ATPG results for the proposed techniques are given.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:55:27 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Beck", "Matthias", ""], ["Barondeau", "Olivier", ""], ["Kaibel", "Martin", ""], ["Poehl", "Frank", ""], ["Lin", "Xijiang", ""], ["Press", "Ron", ""]]}
{"id": "0710.4764", "submitter": "EDA Publishing Association", "authors": "G. M. Link, N. Vijaykrishnan", "title": "Hotspot Prevention Through Runtime Reconfiguration in Network-On-Chip", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Many existing thermal management techniques focus on reducing the overall\npower consumption of the chip, and do not address location-specific temperature\nproblems referred to as hotspots. We propose the use of dynamic runtime\nreconfiguration to shift the hotspot-inducing computation periodically and make\nthe thermal profile more uniform. Our analysis shows that dynamic\nreconfiguration is an effective technique in reducing hotspots for NoCs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:55:48 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Link", "G. M.", ""], ["Vijaykrishnan", "N.", ""]]}
{"id": "0710.4794", "submitter": "EDA Publishing Association", "authors": "Robert Bai, Nam-Sung Kim, Tae Ho Kgil, Dennis Sylvester, Trevor Mudge", "title": "Power-Performance Trade-Offs in Nanometer-Scale Multi-Level Caches\n  Considering Total Leakage", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper, we investigate the impact of T_{ox} and Vth on power\nperformance trade-offs for on-chip caches. We start by examining the\noptimization of the various components of a single level cache and then extend\nthis to two level cache systems. In addition to leakage, our studies also\naccount for the dynamic power expanded as a result of cache misses. Our results\nshow that one can often reduce overall power by increasing the size of the L2\ncache if we only allow one pair of Vth/T_{ox} in L2. However, if we allow the\nmemory cells and the peripherals to have their own Vth's and T_{ox}'s, we show\nthat a two-level cache system with smaller L2's will yield less total leakage.\nWe further show that two Vth's and two T_{ox}'s are sufficient to get close to\nan optimal solution, and that Vth is generally a better design knob than T_{ox}\nfor leakage optimization, thus it is better to restrict the number of T_{ox}'s\nrather than Vth's if cost is a concern.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 11:51:44 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Bai", "Robert", ""], ["Kim", "Nam-Sung", ""], ["Kgil", "Tae Ho", ""], ["Sylvester", "Dennis", ""], ["Mudge", "Trevor", ""]]}
{"id": "0710.4795", "submitter": "EDA Publishing Association", "authors": "Alexandre M. Amory, Marcelo Lubaszewski, Fernando G. Moraes, Edson I.\n  Moreno", "title": "Test Time Reduction Reusing Multiple Processors in a Network-on-Chip\n  Based Architecture", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The increasing complexity and the short life cycles of embedded systems are\npushing the current system-on-chip designs towards a rapid increasing on the\nnumber of programmable processing units, while decreasing the gate count for\ncustom logic. Considering this trend, this work proposes a test planning method\ncapable of reusing available processors as test sources and sinks, and the\non-chip network as the test access mechanism. Experimental results are based on\nITC'02 benchmarks and on two open core processors compliant with MIPS and SPARC\ninstruction set. The results show that the cooperative use of both the on-chip\nnetwork and the embedded processors can increase the test parallelism and\nreduce the test time without additional cost in area and pins.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 11:52:22 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Amory", "Alexandre M.", ""], ["Lubaszewski", "Marcelo", ""], ["Moraes", "Fernando G.", ""], ["Moreno", "Edson I.", ""]]}
{"id": "0710.4796", "submitter": "EDA Publishing Association", "authors": "Javier Resano, Daniel Mozos, Francky Catthoor", "title": "A Hybrid Prefetch Scheduling Heuristic to Minimize at Run-Time the\n  Reconfiguration Overhead of Dynamically Reconfigurable Hardware", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Due to the emergence of highly dynamic multimedia applications there is a\nneed for flexible platforms and run-time scheduling support for embedded\nsystems. Dynamic Reconfigurable Hardware (DRHW) is a promising candidate to\nprovide this flexibility but, currently, not sufficient run-time scheduling\nsupport to deal with the run-time reconfigurations exists. Moreover, executing\nat run-time a complex scheduling heuristic to provide this support may generate\nan excessive run-time penalty. Hence, we have developed a hybrid\ndesign/run-time prefetch heuristic that schedules the reconfigurations at\nrun-time, but carries out the scheduling computations at design-time by\ncarefully identifying a set of near-optimal schedules that can be selected at\nrun-time. This approach provides run-time flexibility with a negligible\npenalty.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 11:53:03 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Resano", "Javier", ""], ["Mozos", "Daniel", ""], ["Catthoor", "Francky", ""]]}
{"id": "0710.4801", "submitter": "EDA Publishing Association", "authors": "R. Ruiz-Sautua, M. C. Molina, J. M. Mendias, R. Hermida", "title": "Behavioural Transformation to Improve Circuit Performance in High-Level\n  Synthesis", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Early scheduling algorithms usually adjusted the clock cycle duration to the\nexecution time of the slowest operation. This resulted in large slack times\nwasted in those cycles executing faster operations. To reduce the wasted times\nmulti-cycle and chaining techniques have been employed. While these techniques\nhave produced successful designs, its effectiveness is often limited due to the\narea increment that may derive from chaining, and the extra latencies that may\nderive from multicycling. In this paper we present an optimization method that\nsolves the time-constrained scheduling problem by transforming behavioural\nspecifications into new ones whose subsequent synthesis substantially improves\ncircuit performance. Our proposal breaks up some of the specification\noperations, allowing their execution during several possibly unconsecutive\ncycles, and also the calculation of several data-dependent operation fragments\nin the same cycle. To do so, it takes into account the circuit latency and the\nexecution time of every specification operation. The experimental results\ncarried out show that circuits obtained from the optimized specification are on\naverage 60% faster than those synthesized from the original specification, with\nonly slight increments in the circuit area.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 11:55:59 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Ruiz-Sautua", "R.", ""], ["Molina", "M. C.", ""], ["Mendias", "J. M.", ""], ["Hermida", "R.", ""]]}
{"id": "0710.4805", "submitter": "EDA Publishing Association", "authors": "Hannu Heusala, Jussi Liedes", "title": "Modeling of a Reconfigurable OFDM IP Block Family For an RF System\n  Simulator", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The idea of design domain specific Mother Model of IP block family as a base\nof modeling of system integration is presented here. A common reconfigurable\nMother Model for ten different standardized digital OFDM transmitters has been\ndeveloped. By means of a set of parameters, the mother model can be\nreconfigured to any of the ten selected standards. So far the applicability of\nthe proposed reconfiguration and analog-digital co-modeling methods have been\nproved by modeling the function of the digital parts of three, 802.11a, ADSL\nand DRM, transmitters in an RF system simulator. The model is intended to be\nused as signal source template in RF system simulations. The concept is not\nrestricted to signal sources, it can be applied to any IP block development.\nThe idea of the Mother Model will be applied in other design domains to prove\nthat in certain application areas, OFDM transceivers in this case, the design\nprocess can progress simultaneously in different design domains - mixed signal,\nsystem and RTL-architectural - without the need of high-level synthesis. Only\nthe Mother Models of three design domains are needed to be formally proved to\nfunction as specified.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 11:57:50 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Heusala", "Hannu", ""], ["Liedes", "Jussi", ""]]}
{"id": "0710.4806", "submitter": "EDA Publishing Association", "authors": "Kris Tiri, Ingrid Verbauwhede", "title": "A VLSI Design Flow for Secure Side-Channel Attack Resistant ICs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents a digital VLSI design flow to create secure, side-channel\nattack (SCA) resistant integrated circuits. The design flow starts from a\nnormal design in a hardware description language such as VHDL or Verilog and\nprovides a direct path to a SCA resistant layout. Instead of a full custom\nlayout or an iterative design process with extensive simulations, a few key\nmodifications are incorporated in a regular synchronous CMOS standard cell\ndesign flow. We discuss the basis for side-channel attack resistance and adjust\nthe library databases and constraints files of the synthesis and place & route\nprocedures accordingly. Experimental results show that a DPA attack on a\nregular single ended CMOS standard cell implementation of a module of the DES\nalgorithm discloses the secret key after 200 measurements. The same attack on a\nsecure version still does not disclose the secret key after more than 2000\nmeasurements.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 11:57:56 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Tiri", "Kris", ""], ["Verbauwhede", "Ingrid", ""]]}
{"id": "0710.4808", "submitter": "EDA Publishing Association", "authors": "Young-Taek Kim, Taehun Kim, Youngduk Kim, Chulho Shin, Eui-Young\n  Chung, Kyu-Myung Choi, Jeong-Taek Kong, Soo-Kwan Eo", "title": "Fast and Accurate Transaction Level Modeling of an Extended AMBA2.0 Bus\n  Architecture", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Transaction Level Modeling (TLM) approach is used to meet the simulation\nspeed as well as cycle accuracy for large scale SoC performance analysis. We\nimplemented a transaction-level model of a proprietary bus called AHB+ which\nsupports an extended AMBA2.0 protocol. The AHB+ transaction-level model shows\n353 times faster than pin-accurate RTL model while maintaining 97% of accuracy\non average. We also present the development procedure of TLM of a bus\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 11:59:15 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Kim", "Young-Taek", ""], ["Kim", "Taehun", ""], ["Kim", "Youngduk", ""], ["Shin", "Chulho", ""], ["Chung", "Eui-Young", ""], ["Choi", "Kyu-Myung", ""], ["Kong", "Jeong-Taek", ""], ["Eo", "Soo-Kwan", ""]]}
{"id": "0710.4809", "submitter": "EDA Publishing Association", "authors": "Andres Takach, Bryan Bowyer, Thomas Bollaert", "title": "C Based Hardware Design for Wireless Applications", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The algorithms used in wireless applications are increasingly more\nsophisticated and consequently more challenging to implement in hardware.\nTraditional design flows require developing the micro architecture, coding the\nRTL, and verifying the generated RTL against the original functional C or\nMATLAB specification. This paper describes a C-based design flow that is well\nsuited for the hardware implementation of DSP algorithms commonly found in\nwireless applications. The C design flow relies on guided synthesis to generate\nthe RTL directly from the untimed C algorithm. The specifics of the C-based\ndesign flow are described using a simple DSP filtering algorithm consisting of\na forward adaptive equalizer, a 64-QAM slicer and an adaptive decision feedback\nequalizer. The example illustrates some of the capabilities and advantages\noffered by this flow.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 11:59:48 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Takach", "Andres", ""], ["Bowyer", "Bryan", ""], ["Bollaert", "Thomas", ""]]}
{"id": "0710.4812", "submitter": "EDA Publishing Association", "authors": "Sandro V. Silva, Sergio Bampi", "title": "Area and Throughput Trade-Offs in the Design of Pipelined Discrete\n  Wavelet Transform Architectures", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The JPEG2000 standard defines the discrete wavelet transform (DWT) as a\nlinear space-to-frequency transform of the image domain in an irreversible\ncompression. This irreversible discrete wavelet transform is implemented by FIR\nfilter using 9/7 Daubechies coefficients or a lifting scheme of factorizated\ncoefficients from 9/7 Daubechies coefficients. This work investigates the\ntradeoffs between area, power and data throughput (or operating frequency) of\nseveral implementations of the Discrete Wavelet Transform using the lifting\nscheme in various pipeline designs. This paper shows the results of five\ndifferent architectures synthesized and simulated in FPGAs. It concludes that\nthe descriptions with pipelined operators provide the best area-power-operating\nfrequency trade-off over non-pipelined operators descriptions. Those\ndescriptions require around 40% more hardware to increase the maximum operating\nfrequency up to 100% and reduce power consumption to less than 50%. Starting\nfrom behavioral HDL descriptions provide the best area-power-operating\nfrequency trade-off, improving hardware cost and maximum operating frequency\naround 30% in comparison to structural descriptions for the same power\nrequirement.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:00:41 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Silva", "Sandro V.", ""], ["Bampi", "Sergio", ""]]}
{"id": "0710.4813", "submitter": "EDA Publishing Association", "authors": "I. Papaefstathiou, T. Orphanoudakis, G. Kornaros, C. Kachris, I.\n  Mavroidis, A. Nikologiannis", "title": "Queue Management in Network Processors", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  One of the main bottlenecks when designing a network processing system is\nvery often its memory subsystem. This is mainly due to the state-of-the-art\nnetwork links operating at very high speeds and to the fact that in order to\nsupport advanced Quality of Service (QoS), a large number of independent queues\nis desirable. In this paper we analyze the performance bottlenecks of various\ndata memory managers integrated in typical Network Processing Units (NPUs). We\nexpose the performance limitations of software implementations utilizing the\nRISC processing cores typically found in most NPU architectures and we identify\nthe requirements for hardware assisted memory management in order to achieve\nwire-speed operation at gigabit per second rates. Furthermore, we describe the\narchitecture and performance of a hardware memory manager that fulfills those\nrequirements. This memory manager, although it is implemented in a\nreconfigurable technology, it can provide up to 6.2Gbps of aggregate\nthroughput, while handling 32K independent queues.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:00:48 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Papaefstathiou", "I.", ""], ["Orphanoudakis", "T.", ""], ["Kornaros", "G.", ""], ["Kachris", "C.", ""], ["Mavroidis", "I.", ""], ["Nikologiannis", "A.", ""]]}
{"id": "0710.4814", "submitter": "EDA Publishing Association", "authors": "Andrew Duller, Daniel Towner, Gajinder Panesar, Alan Gray, Will\n  Robbins", "title": "picoArray Technology: The Tool's Story", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper briefly describes the picoArray? architecture, and in particular\nthe deterministic internal communication fabric. The methods that have been\ndeveloped for debugging and verifying systems using devices from the picoArray\nfamily are explained. In order to maximize the computational ability of these\ndevices, hardware debugging support has been kept to a minimum and the methods\nand tools developed to take this into account.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:01:15 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Duller", "Andrew", ""], ["Towner", "Daniel", ""], ["Panesar", "Gajinder", ""], ["Gray", "Alan", ""], ["Robbins", "Will", ""]]}
{"id": "0710.4820", "submitter": "EDA Publishing Association", "authors": "Partha Biswas, Sudarshan Banerjee, Nikil Dutt, Laura Pozzi, Paolo\n  Ienne", "title": "ISEGEN: Generation of High-Quality Instruction Set Extensions by\n  Iterative Improvement", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  Customization of processor architectures through Instruction Set Extensions\n(ISEs) is an effective way to meet the growing performance demands of embedded\napplications. A high-quality ISE generation approach needs to obtain results\nclose to those achieved by experienced designers, particularly for complex\napplications that exhibit regularity: expert designers are able to exploit\nmanually such regularity in the data flow graphs to generate high-quality ISEs.\nIn this paper, we present ISEGEN, an approach that identifies high-quality ISEs\nby iterative improvement following the basic principles of the well-known\nKernighan-Lin (K-L) min-cut heuristic. Experimental results on a number of\nMediaBench, EEMBC and cryptographic applications show that our approach matches\nthe quality of the optimal solution obtained by exhaustive search. We also show\nthat our ISEGEN technique is on average 20x faster than a genetic formulation\nthat generates equivalent solutions. Furthermore, the ISEs identified by our\ntechnique exhibit 35% more speedup than the genetic solution on a large\ncryptographic application (AES) by effectively exploiting its regular\nstructure.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:04:11 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Biswas", "Partha", ""], ["Banerjee", "Sudarshan", ""], ["Dutt", "Nikil", ""], ["Pozzi", "Laura", ""], ["Ienne", "Paolo", ""]]}
{"id": "0710.4824", "submitter": "EDA Publishing Association", "authors": "R. Pradeep, S. Vinay, Sanjay Burman, V. Kamakoti", "title": "FPGA based Agile Algorithm-On-Demand Co-Processor", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  With growing computational needs of many real-world applications, frequently\nchanging specifications of standards, and the high design and NRE costs of\nASICs, an algorithm-agile FPGA based co-processor has become a viable\nalternative. In this article, we report about the general design of an\nalgorith-agile co-processor and the proof-of-concept implementation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:04:43 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Pradeep", "R.", ""], ["Vinay", "S.", ""], ["Burman", "Sanjay", ""], ["Kamakoti", "V.", ""]]}
{"id": "0710.4825", "submitter": "EDA Publishing Association", "authors": "Wayne Lyons", "title": "Meeting the Embedded Design Needs of Automotive Applications", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The importance of embedded systems in driving innovation in automotive\napplications continues to grow. Understanding the specific needs of developers\ntargeting this market is also helping to drive innovation in RISC core design.\nThis paper describes how a RISC instruction set architecture has evolved to\nbetter meet those needs, and the key implementation features in two very\ndifferent RISC cores are used to demonstrate the challenges of designing for\nreal-time automotive systems.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:05:33 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Lyons", "Wayne", ""]]}
{"id": "0710.4826", "submitter": "EDA Publishing Association", "authors": "C. Jeffrey, R. Cutajar, S. Prosser, M. Lickess, A. Richardson, S.\n  Riches", "title": "The Integration of On-Line Monitoring and Reconfiguration Functions\n  using EDAA - European design and Automation Association1149.4 Into a Safety\n  Critical Automotive Electronic Control Unit", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents an innovative application of EDAA - European design and\nAutomation Association 1149.4 and the Integrated Diagnostic Reconfiguration\n(IDR) as tools for the implementation of an embedded test solution for an\nAutomotive Electronic Control Unit implemented as a fully integrated mixed\nsignal system. The paper described how the test architecture can be used for\nfault avoidance with results from a hardware prototype presented. The paper\nconcludes that fault avoidance can be integrated into mixed signal electronic\nsystems to handle key failure modes.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:06:43 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Jeffrey", "C.", ""], ["Cutajar", "R.", ""], ["Prosser", "S.", ""], ["Lickess", "M.", ""], ["Richardson", "A.", ""], ["Riches", "S.", ""]]}
{"id": "0710.4827", "submitter": "EDA Publishing Association", "authors": "A. Mayer, H. Siebert, K.D. Mcdonald-Maier", "title": "Debug Support, Calibration and Emulation for Multiple Processor and\n  Powertrain Control SoCs", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The introduction of complex SoCs with multiple processor cores presents new\ndevelopment challenges, such that development support is now a decisive factor\nwhen choosing a System-on-Chip (SoC). The presented developments support\nstrategy addresses the challenges using both architecture and technology\napproaches. The Multi-Core Debug Support (MCDS) architecture provides flexible\ntriggering using cross triggers and a multiple core break and suspend switch.\nTemporal trace ordering is guaranteed down to cycle level by on-chip time\nstamping. The Package Sized-ICE (PSI) approach is a novel method of including\ntrace buffers, overlay memories, processing resources and communication\ninterfaces without changing device behavior. PSI requires no external emulation\nbox, as the debug host interfaces directly with the SoC using a standard\ninterface.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:07:17 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Mayer", "A.", ""], ["Siebert", "H.", ""], ["Mcdonald-Maier", "K. D.", ""]]}
{"id": "0710.4832", "submitter": "EDA Publishing Association", "authors": "Massimo Conti", "title": "SystemC Analysis of a New Dynamic Power Management Architecture", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper presents a new dynamic power management architecture of a System\non Chip. The Power State Machine describing the status of the core follows the\nrecommendations of the ACPI standard. The algorithm controls the power states\nof each block on the basis of battery status, chip temperature and a user\ndefined task priority.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:10:19 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Conti", "Massimo", ""]]}
{"id": "0710.4833", "submitter": "EDA Publishing Association", "authors": "Steve Chappell, Alistair Macarthur, Dan Preston, Dave Olmstead, Bob\n  Flint, Chris Sullivan", "title": "Exploiting Real-Time FPGA Based Adaptive Systems Technology for\n  Real-Time Sensor Fusion in Next Generation Automotive Safety Systems", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  We present a system for the boresighting of sensors using inertial\nmeasurement devices as the basis for developing a range of dynamic real-time\nsensor fusion applications. The proof of concept utilizes a COTS FPGA platform\nfor sensor fusion and real-time correction of a misaligned video sensor. We\nexploit a custom-designed 32-bit soft processor core and C-based design &\nsynthesis for rapid, platform-neutral development. Kalman filter and sensor\nfusion techniques established in advanced aviation systems are applied to\nautomotive vehicles with results exceeding typical industry requirements for\nsensor alignment. Results of the static and the dynamic tests demonstrate that\nusing inexpensive accelerometers mounted on (or during assembly of) a sensor\nand an Inertial Measurement Unit (IMU) fixed to a vehicle can be used to\ncompute the misalignment of the sensor to the IMU and thus vehicle. In some\ncases the model predications and test results exceeded the requirements by an\norder of magnitude with a 3-sigma or 99% confidence.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:11:11 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Chappell", "Steve", ""], ["Macarthur", "Alistair", ""], ["Preston", "Dan", ""], ["Olmstead", "Dave", ""], ["Flint", "Bob", ""], ["Sullivan", "Chris", ""]]}
{"id": "0710.4834", "submitter": "EDA Publishing Association", "authors": "L. Fanucci, A. Giambastiani, F. Iozzi, C. Marino, A. Rocchi", "title": "Platform Based Design for Automotive Sensor Conditioning", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper a general architecture suitable to interface several kinds of\nsensors for automotive applications is presented. A platform based design\napproach is pursued to improve system performance while minimizing\ntime-to-market.. The platform is composed by an analog front-end and a digital\nsection. The latter is based on a microcontroller core (8051 IP by Oregano)\nplus a set of dedicated hardware dedicated to the complex signal processing\nrequired for sensor conditioning. The microcontroller handles also the\ncommunication with external devices (as a PC) for data output and fast\nprototyping. A case study is presented concerning the conditioning of a Gyro\nyaw rate sensor for automotive applications. Measured performance results\noutperform current state-of-the-art commercial devices.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:12:03 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Fanucci", "L.", ""], ["Giambastiani", "A.", ""], ["Iozzi", "F.", ""], ["Marino", "C.", ""], ["Rocchi", "A.", ""]]}
{"id": "0710.4838", "submitter": "EDA Publishing Association", "authors": "Christoph Sandner, Martin Clara, Andreas Santner, Thomas Hartig, Franz\n  Kuttner", "title": "A 6bit, 1.2GSps Low-Power Flash-ADC in 0.13$\\mu$m Digital CMOS", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  A 6bit flash-ADC with 1.2GSps, wide analog bandwidth and low power, realized\nin a standard digital 0.13 $\\mu$m CMOS copper technology is presented.\nEmploying capacitive interpolation gives various advantages when designing for\nlow power: no need for a reference resistor ladder, implicit sample-and-hold\noperation, no edge effects in the interpolation network (as compared to\nresistive interpolation), and a very low input capacitance of only 400fF, which\nleads to an easily drivable analog converter interface. Operating at 1.2GSps\nthe ADC achieves an effective resolution bandwidth (ERBW) of 700MHz, while\nconsuming 160mW of power. At 600MSps we achieve an ERBW of 600MHz with only\n90mW power consumption, both from a 1.5V supply. This corresponds to\noutstanding Figure-of-Merit numbers (FoM) of 2.2 and 1.5pJ/convstep,\nrespectively. The module area is 0.12mm^2.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:15:35 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Sandner", "Christoph", ""], ["Clara", "Martin", ""], ["Santner", "Andreas", ""], ["Hartig", "Thomas", ""], ["Kuttner", "Franz", ""]]}
{"id": "0710.4839", "submitter": "EDA Publishing Association", "authors": "Terje N. Andersen, Atle Briskemyr, Frode Telsto, Johnny Bjornsen,\n  Thomas E. Bonnerud, Bjornar Hernes, Oystein Moldsvor", "title": "A 97mW 110MS/s 12b Pipeline ADC Implemented in 0.18$\\mu$m Digital CMOS", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  A 12 bit Pipeline ADC fabricated in a 0.18 $\\mu$m pure digital CMOS\ntechnology is presented. Its nominal conversion rate is 110MS/s and the nominal\nsupply voltage is 1.8V. The effective number of bits is 10.4 when a 10MHz input\nsignal with 2V_{P-P} signal swing is applied. The occupied silicon area is\n0.86mm^2 and the power consumption equals 97mW. A switched capacitor bias\ncurrent circuit scale the bias current automatically with the conversion rate,\nwhich gives scaleable power consumption and full performance of the ADC from 20\nto 140MS/s.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:16:26 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Andersen", "Terje N.", ""], ["Briskemyr", "Atle", ""], ["Telsto", "Frode", ""], ["Bjornsen", "Johnny", ""], ["Bonnerud", "Thomas E.", ""], ["Hernes", "Bjornar", ""], ["Moldsvor", "Oystein", ""]]}
{"id": "0710.4840", "submitter": "EDA Publishing Association", "authors": "P. Bernardi, G. Masera, F. Quaglio, M. Sonza Reorda", "title": "Testing Logic Cores using a BIST P1500 Compliant Approach: A Case of\n  Study", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper we describe how we applied a BIST-based approach to the test of\na logic core to be included in System-on-a-chip (SoC) environments. The\napproach advantages are the ability to protect the core IP, the simple test\ninterface (thanks also to the adoption of the P1500 standard), the possibility\nto run the test at-speed, the reduced test time, and the good diagnostic\ncapabilities. The paper reports figures about the achieved fault coverage, the\nrequired area overhead, and the performance slowdown, and compares the figures\nwith those for alternative approaches, such as those based on full scan and\nsequential ATPG.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:17:29 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Bernardi", "P.", ""], ["Masera", "G.", ""], ["Quaglio", "F.", ""], ["Reorda", "M. Sonza", ""]]}
{"id": "0710.4842", "submitter": "EDA Publishing Association", "authors": "Dan Hillman", "title": "Using Mobilize Power Management IP for Dynamic & Static Power Reduction\n  in SoC at 130 nm", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  At 130 nm and 90 nm, power consumption (both dynamic and static) has become a\nbarrier in the roadmap for SoC designs targeting battery powered, mobile\napplications. This paper presents the results of dynamic and static power\nreduction achieved implementing Tensilica's 32-bit Xtensa microprocessor core,\nusing Virtual Silicon's Power Management IP. Independent voltage islands are\ncreated using Virtual Silicon's VIP PowerSaver standard cells by using voltage\nlevel shifting cells and voltage isolation cells to implement power islands.\nThe VIP PowerSaver standard cells are characterized at 1.2V, 1.0V and 0.8V, to\naccommodate voltage scaling. Power islands can also be turned off completely.\nDesigners can significantly lower both the dynamic power and the quiescent or\nleakage power of their SoC designs, with very little impact on speed or area\nusing Virtual Silicon's VIP Gate Bias standard cells.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:18:38 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Hillman", "Dan", ""]]}
{"id": "0710.4843", "submitter": "EDA Publishing Association", "authors": "Aline Mello, Leandro Moller, Ney Calazans, Fernando Moraes", "title": "MultiNoC: A Multiprocessing System Enabled by a Network on Chip", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The MultiNoC system implements a programmable on-chip multiprocessing\nplatform built on top of an efficient, low area overhead intra-chip\ninterconnection scheme. The employed interconnection structure is a Network on\nChip, or NoC. NoCs are emerging as a viable alternative to increasing demands\non interconnection architectures, due to the following characteristics: (i)\nenergy efficiency and reliability; (ii) scalability of bandwidth, when compared\nto traditional bus architectures; (iii) reusability; (iv) distributed routing\ndecisions. An external host computer feeds MultiNoC with application\ninstructions and data. After this initialization procedure, MultiNoC executes\nsome algorithm. After finishing execution of the algorithm, output data can be\nread back by the host. Sequential or parallel algorithms conveniently adapted\nto the MultiNoC structure can be executed. The main motivation to propose this\ndesign is to enable the investigation of current trends to increase the number\nof embedded processors in SoCs, leading to the concept of \"sea of processors\"\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:19:07 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Mello", "Aline", ""], ["Moller", "Leandro", ""], ["Calazans", "Ney", ""], ["Moraes", "Fernando", ""]]}
{"id": "0710.4844", "submitter": "EDA Publishing Association", "authors": "M. D. Galanis, A. Milidonis, G. Theodoridis, D. Soudris, C. E. Goutis", "title": "A Partitioning Methodology for Accelerating Applications in Hybrid\n  Reconfigurable Platforms", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper, we propose a methodology for partitioning and mapping\ncomputational intensive applications in reconfigurable hardware blocks of\ndifferent granularity. A generic hybrid reconfigurable architecture is\nconsidered so as the methodology can be applicable to a large number of\nheterogeneous reconfigurable platforms. The methodology mainly consists of two\nstages, the analysis and the mapping of the application onto fine and\ncoarse-grain hardware resources. A prototype framework consisting of analysis,\npartitioning and mapping tools has been also developed. For the coarse-grain\nreconfigurable hardware, we use our previous-developed high-performance\ncoarse-grain data-path. In this work, the methodology is validated using two\nreal-world applications, an OFDM transmitter and a JPEG encoder. In the case of\nthe OFDM transmitter, a maximum clock cycles decrease of 82% relative to the\nones in an all fine-grain mapping solution is achieved. The corresponding\nperformance improvement for the JPEG is 43%.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:20:27 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Galanis", "M. D.", ""], ["Milidonis", "A.", ""], ["Theodoridis", "G.", ""], ["Soudris", "D.", ""], ["Goutis", "C. E.", ""]]}
{"id": "0710.4845", "submitter": "EDA Publishing Association", "authors": "Tero Rissa, Adam Donlin, Wayne Luk", "title": "Evaluation of SystemC Modelling of Reconfigurable Embedded Systems", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This paper evaluates the use of pin and cycle accurate SystemC models for\nembedded system design exploration and early software development. The target\nsystem is MicroBlaze VanillaNet Platform running MicroBlaze uClinux operating\nsystem. The paper compares Register Transfer Level (RTL) Hardware Description\nLanguage (HDL) simulation speed to the simulation speed of several different\nSystemC models. It is shown that simulation speed of pin and cycle accurate\nmodels can go up to 150 kHz, compared to 100 Hz range of HDL simulation.\nFurthermore, utilising techniques that temporarily compromise cycle accuracy,\neffective simulation speed of up to 500 kHz can be obtained.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:21:19 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Rissa", "Tero", ""], ["Donlin", "Adam", ""], ["Luk", "Wayne", ""]]}
{"id": "0710.4850", "submitter": "EDA Publishing Association", "authors": "Michael Ullmann, Wansheng Jin, Jurgen Becker", "title": "Hardware Support for QoS-based Function Allocation in Reconfigurable\n  Systems", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  This contribution presents a new approach for allocating suitable\nfunction-implementation variants depending on given quality-of-service\nfunction-requirements for run-time reconfigurable multi-device systems. Our\napproach adapts methodologies from the domain of knowledge-based systems which\ncan be used for doing run-time hardware/software resource usage optimizations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:24:59 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Ullmann", "Michael", ""], ["Jin", "Wansheng", ""], ["Becker", "Jurgen", ""]]}
{"id": "0710.4975", "submitter": "Yoshiharu Maeno", "authors": "Yoshiharu Maeno", "title": "Node discovery problem for a social network", "comments": null, "journal-ref": "Connections vol.29, pp.62-76 (2009)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods to solve a node discovery problem for a social network are presented.\nCovert nodes refer to the nodes which are not observable directly. They\ntransmit the influence and affect the resulting collaborative activities among\nthe persons in a social network, but do not appear in the surveillance logs\nwhich record the participants of the collaborative activities. Discovering the\ncovert nodes is identifying the suspicious logs where the covert nodes would\nappear if the covert nodes became overt. The performance of the methods is\ndemonstrated with a test dataset generated from computationally synthesized\nnetworks and a real organization.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2007 01:32:47 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2009 04:18:43 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Maeno", "Yoshiharu", ""]]}
{"id": "0710.5116", "submitter": "Taneli Mielik\\\"ainen", "authors": "Matti K\\\"a\\\"ari\\\"ainen, Niels Landwehr, Sampsa Lappalainen and Taneli\n  Mielik\\\"ainen", "title": "Combining haplotypers", "comments": null, "journal-ref": null, "doi": null, "report-no": "C-2007-57", "categories": "cs.LG cs.CE q-bio.QM", "license": null, "abstract": "  Statistically resolving the underlying haplotype pair for a genotype\nmeasurement is an important intermediate step in gene mapping studies, and has\nreceived much attention recently. Consequently, a variety of methods for this\nproblem have been developed. Different methods employ different statistical\nmodels, and thus implicitly encode different assumptions about the nature of\nthe underlying haplotype structure. Depending on the population sample in\nquestion, their relative performance can vary greatly, and it is unclear which\nmethod to choose for a particular sample. Instead of choosing a single method,\nwe explore combining predictions returned by different methods in a principled\nway, and thereby circumvent the problem of method selection.\n  We propose several techniques for combining haplotype reconstructions and\nanalyze their computational properties. In an experimental study on real-world\nhaplotype data we show that such techniques can provide more accurate and\nrobust reconstructions, and are useful for outlier detection. Typically, the\ncombined prediction is at least as accurate as or even more accurate than the\nbest individual method, effectively circumventing the method selection problem.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2007 15:13:21 GMT"}], "update_date": "2007-10-29", "authors_parsed": [["Kääriäinen", "Matti", ""], ["Landwehr", "Niels", ""], ["Lappalainen", "Sampsa", ""], ["Mielikäinen", "Taneli", ""]]}
{"id": "0710.5338", "submitter": "Toshiya Itoh", "authors": "Toshiya Itoh and Osamu Watanabe", "title": "Weighted Random Popular Matchings", "comments": "13 pages, 2 figures", "journal-ref": "Random Structures and Algorithms, 37(4), pp.477-494, 2010", "doi": "10.1002/rsa.20316", "report-no": null, "categories": "cs.DM cs.CC", "license": null, "abstract": "  For a set A of n applicants and a set I of m items, we consider a problem of\ncomputing a matching of applicants to items, i.e., a function M mapping A to I;\nhere we assume that each applicant $x \\in A$ provides a preference list on\nitems in I. We say that an applicant $x \\in A$ prefers an item p than an item q\nif p is located at a higher position than q in its preference list, and we say\nthat x prefers a matching M over a matching M' if x prefers M(x) over M'(x).\nFor a given matching problem A, I, and preference lists, we say that M is more\npopular than M' if the number of applicants preferring M over M' is larger than\nthat of applicants preferring M' over M, and M is called a popular matching if\nthere is no other matching that is more popular than M. Here we consider the\nsituation that A is partitioned into $A_{1},A_{2},...,A_{k}$, and that each\n$A_{i}$ is assigned a weight $w_{i}>0$ such that w_{1}>w_{2}>...>w_{k}>0$. For\nsuch a matching problem, we say that M is more popular than M' if the total\nweight of applicants preferring M over M' is larger than that of applicants\npreferring M' over M, and we call M an k-weighted popular matching if there is\nno other matching that is more popular than M. In this paper, we analyze the\n2-weighted matching problem, and we show that (lower bound) if\n$m/n^{4/3}=o(1)$, then a random instance of the 2-weighted matching problem\nwith $w_{1} \\geq 2w_{2}$ has a 2-weighted popular matching with probability\no(1); and (upper bound) if $n^{4/3}/m = o(1)$, then a random instance of the\n2-weighted matching problem with $w_{1} \\geq 2w_{2}$ has a 2-weighted popular\nmatching with probability 1-o(1).\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2007 04:41:03 GMT"}], "update_date": "2011-09-29", "authors_parsed": [["Itoh", "Toshiya", ""], ["Watanabe", "Osamu", ""]]}
{"id": "0710.5501", "submitter": "Ulrich Sorger", "authors": "Uli Sorger", "title": "Discriminated Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR-CSC-07-01, University of Luxembourg", "categories": "cs.IT cs.AI math.IT", "license": null, "abstract": "  Near optimal decoding of good error control codes is generally a difficult\ntask. However, for a certain type of (sufficiently) good codes an efficient\ndecoding algorithm with near optimal performance exists. These codes are\ndefined via a combination of constituent codes with low complexity trellis\nrepresentations. Their decoding algorithm is an instance of (loopy) belief\npropagation and is based on an iterative transfer of constituent beliefs. The\nbeliefs are thereby given by the symbol probabilities computed in the\nconstituent trellises. Even though weak constituent codes are employed close to\noptimal performance is obtained, i.e., the encoder/decoder pair (almost)\nachieves the information theoretic capacity. However, (loopy) belief\npropagation only performs well for a rather specific set of codes, which limits\nits applicability.\n  In this paper a generalisation of iterative decoding is presented. It is\nproposed to transfer more values than just the constituent beliefs. This is\nachieved by the transfer of beliefs obtained by independently investigating\nparts of the code space. This leads to the concept of discriminators, which are\nused to improve the decoder resolution within certain areas and defines\ndiscriminated symbol beliefs. It is shown that these beliefs approximate the\noverall symbol probabilities. This leads to an iteration rule that (below\nchannel capacity) typically only admits the solution of the overall decoding\nproblem. Via a Gauss approximation a low complexity version of this algorithm\nis derived. Moreover, the approach may then be applied to a wide range of\nchannel maps without significant complexity increase.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2007 19:01:48 GMT"}], "update_date": "2007-10-30", "authors_parsed": [["Sorger", "Uli", ""]]}
{"id": "0710.5512", "submitter": "Santiago Moreno", "authors": "U. Horst, S. Moreno", "title": "Risk Minimization and Optimal Derivative Design in a Principal Agent\n  Game", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  We consider the problem of Adverse Selection and optimal derivative design\nwithin a Principal-Agent framework. The principal's income is exposed to\nnon-hedgeable risk factors arising, for instance, from weather or climate\nphenomena. She evaluates her risk using a coherent and law invariant risk\nmeasure and tries minimize her exposure by selling derivative securities on her\nincome to individual agents. The agents have mean-variance preferences with\nheterogeneous risk aversion coefficients. An agent's degree of risk aversion is\nprivate information and hidden to the principal who only knows the overall\ndistribution. We show that the principal's risk minimization problem has a\nsolution and illustrate the effects of risk transfer on her income by means of\ntwo specific examples. Our model extends earlier work of Barrieu and El Karoui\n(2005) and Carlier, Ekeland and Touzi (2007).\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2007 20:00:15 GMT"}], "update_date": "2007-10-31", "authors_parsed": [["Horst", "U.", ""], ["Moreno", "S.", ""]]}
{"id": "0710.5582", "submitter": "Constantinos Daskalakis", "authors": "Constantinos Daskalakis, Christos Papadimitriou", "title": "Computing Equilibria in Anonymous Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DM", "license": null, "abstract": "  We present efficient approximation algorithms for finding Nash equilibria in\nanonymous games, that is, games in which the players utilities, though\ndifferent, do not differentiate between other players. Our results pertain to\nsuch games with many players but few strategies. We show that any such game has\nan approximate pure Nash equilibrium, computable in polynomial time, with\napproximation O(s^2 L), where s is the number of strategies and L is the\nLipschitz constant of the utilities. Finally, we show that there is a PTAS for\nfinding an epsilon\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2007 07:32:37 GMT"}], "update_date": "2007-10-31", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Papadimitriou", "Christos", ""]]}
{"id": "0711.0086", "submitter": "Sergey Gubin", "authors": "Sergey Gubin", "title": "Convex and linear models of NP-problems", "comments": "In part, the results were presented on WCECS 2007/ICCSA 2007. V2\n  edited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": null, "abstract": "  Reducing the NP-problems to the convex/linear analysis on the Birkhoff\npolytope.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2007 08:33:07 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2007 06:11:22 GMT"}], "update_date": "2007-11-04", "authors_parsed": [["Gubin", "Sergey", ""]]}
{"id": "0711.0110", "submitter": "Florent Krzakala", "authors": "Florent Krzakala and Lenka Zdeborov\\'a", "title": "Phase Transitions and Computational Difficulty in Random Constraint\n  Satisfaction Problems", "comments": "10 pages, Proceedings of the International Workshop on\n  Statistical-Mechanical Informatics 2007, Kyoto (Japan) September 16-19, 2007", "journal-ref": "2008 J. Phys.: Conf. Ser. 95 012012", "doi": "10.1088/1742-6596/95/1/012012", "report-no": null, "categories": "cs.CC cond-mat.stat-mech", "license": null, "abstract": "  We review the understanding of the random constraint satisfaction problems,\nfocusing on the q-coloring of large random graphs, that has been achieved using\nthe cavity method of the physicists. We also discuss the properties of the\nphase diagram in temperature, the connections with the glass transition\nphenomenology in physics, and the related algorithmic issues.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2007 13:42:44 GMT"}], "update_date": "2008-02-04", "authors_parsed": [["Krzakala", "Florent", ""], ["Zdeborová", "Lenka", ""]]}
{"id": "0711.0114", "submitter": "Mathieu Couture", "authors": "Prosenjit Bose, Paz Carmi, Mathieu Couture, Anil Maheshwari, Michiel\n  Smid and Norbert Zeh", "title": "Geometric Spanners With Small Chromatic Number", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR-07-15", "categories": "cs.CG", "license": null, "abstract": "  Given an integer $k \\geq 2$, we consider the problem of computing the\nsmallest real number $t(k)$ such that for each set $P$ of points in the plane,\nthere exists a $t(k)$-spanner for $P$ that has chromatic number at most $k$. We\nprove that $t(2) = 3$, $t(3) = 2$, $t(4) = \\sqrt{2}$, and give upper and lower\nbounds on $t(k)$ for $k>4$. We also show that for any $\\epsilon >0$, there\nexists a $(1+\\epsilon)t(k)$-spanner for $P$ that has $O(|P|)$ edges and\nchromatic number at most $k$. Finally, we consider an on-line variant of the\nproblem where the points of $P$ are given one after another, and the color of a\npoint must be assigned at the moment the point is given. In this setting, we\nprove that $t(2) = 3$, $t(3) = 1+ \\sqrt{3}$, $t(4) = 1+ \\sqrt{2}$, and give\nupper and lower bounds on $t(k)$ for $k>4$.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2007 13:46:14 GMT"}], "update_date": "2007-11-02", "authors_parsed": [["Bose", "Prosenjit", ""], ["Carmi", "Paz", ""], ["Couture", "Mathieu", ""], ["Maheshwari", "Anil", ""], ["Smid", "Michiel", ""], ["Zeh", "Norbert", ""]]}
{"id": "0711.0351", "submitter": "Falk Unger", "authors": "Falk Unger", "title": "Noise threshold for universality of 2-input gates", "comments": "International Symposium on Information Theory, 2007, minor\n  corrections in v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evans and Pippenger showed in 1998 that noisy gates with 2 inputs are\nuniversal for arbitrary computation (i.e. can compute any function with bounded\nerror), if all gates fail independently with probability epsilon and\nepsilon<theta, where theta is roughly 8.856%.\n  We show that formulas built from gates with 2 inputs, in which each gate\nfails with probability at least theta cannot be universal. Hence, there is a\nthreshold on the tolerable noise for formulas with 2-input gates and it is\ntheta. We conjecture that the same threshold also holds for circuits.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2007 16:58:21 GMT"}, {"version": "v2", "created": "Sat, 6 Sep 2008 16:18:09 GMT"}], "update_date": "2008-09-06", "authors_parsed": [["Unger", "Falk", ""]]}
{"id": "0711.0694", "submitter": "Bruno Scherrer", "authors": "Bruno Scherrer (INRIA Lorraine - LORIA)", "title": "Performance Bounds for Lambda Policy Iteration and Application to the\n  Game of Tetris", "comments": "No. RR-6348 (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the discrete-time infinite-horizon optimal control problem\nformalized by Markov Decision Processes. We revisit the work of Bertsekas and\nIoffe, that introduced $\\lambda$ Policy Iteration, a family of algorithms\nparameterized by $\\lambda$ that generalizes the standard algorithms Value\nIteration and Policy Iteration, and has some deep connections with the Temporal\nDifferences algorithm TD($\\lambda$) described by Sutton and Barto. We deepen\nthe original theory developped by the authors by providing convergence rate\nbounds which generalize standard bounds for Value Iteration described for\ninstance by Puterman. Then, the main contribution of this paper is to develop\nthe theory of this algorithm when it is used in an approximate form and show\nthat this is sound. Doing so, we extend and unify the separate analyses\ndevelopped by Munos for Approximate Value Iteration and Approximate Policy\nIteration. Eventually, we revisit the use of this algorithm in the training of\na Tetris playing controller as originally done by Bertsekas and Ioffe. We\nprovide an original performance bound that can be applied to such an\nundiscounted control problem. Our empirical results are different from those of\nBertsekas and Ioffe (which were originally qualified as \"paradoxical\" and\n\"intriguing\"), and much more conform to what one would expect from a learning\nexperiment. We discuss the possible reason for such a difference.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2007 17:07:22 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2007 15:46:43 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2007 12:34:37 GMT"}, {"version": "v4", "created": "Mon, 3 Oct 2011 11:58:38 GMT"}, {"version": "v5", "created": "Tue, 11 Oct 2011 12:42:24 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Scherrer", "Bruno", "", "INRIA Lorraine - LORIA"]]}
{"id": "0711.0784", "submitter": "Philip Baback Alipour", "authors": "Philip B. Alipour", "title": "Addendum to Research MMMCV; A Man/Microbio/Megabio/Computer Vision", "comments": "LaTeX, 10 pages, 4 figures (1 algorithm); An addendum to a research\n  proposal on biovielectroluminescence and MMMCV for postgraduate academic\n  bodies and research departments. The contents of this paper are mostly\n  related and referenced to Article: [arXiv:0710.0410]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CE", "license": null, "abstract": "  In October 2007, a Research Proposal for the University of Sydney, Australia,\nthe author suggested that biovie-physical phenomenon as `electrodynamic\ndependant biological vision', is governed by relativistic quantum laws and\nbiovision. The phenomenon on the basis of `biovielectroluminescence', satisfies\nman/microbio/megabio/computer vision (MMMCV), as a robust candidate for\nphysical and visual sciences. The general aim of this addendum is to present a\nrefined text of Sections 1-3 of that proposal and highlighting the contents of\nits Appendix in form of a `Mechanisms' Section. We then briefly remind in an\narticle aimed for December 2007, by appending two more equations into Section\n3, a theoretical II-time scenario as a time model well-proposed for the\nphenomenon. The time model within the core of the proposal, plays a significant\nrole in emphasizing the principle points on Objectives no. 1-8, Sub-hypothesis\n3.1.2, mentioned in Article [arXiv:0710.0410]. It also expresses the time\nconcept in terms of causing quantized energy f(|E|) of time |t|, emit in regard\nto shortening the probability of particle loci as predictable patterns of\nparticle's un-occurred motion, a solution to Heisenberg's uncertainty principle\n(HUP) into a simplistic manner. We conclude that, practical frames via a time\nalgorithm to this model, fixates such predictable patterns of motion of scenery\nbodies onto recordable observation points of a MMMCV system. It even\nsuppresses/predicts superposition phenomena coming from a human subject and/or\nother bio-subjects for any decision making event, e.g., brainwave quantum\npatterns based on vision. Maintaining the existential probability of Riemann\nsurfaces of II-time scenarios in the context of biovielectroluminescence, makes\nmotion-prediction a possibility.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2007 19:41:22 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Alipour", "Philip B.", ""]]}
{"id": "0711.0838", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "On the operating unit size of load/store architectures", "comments": "23 pages; minor errors corrected, explanations added, references\n  replaced", "journal-ref": "Mathematical Structures in Computer Science, 20(3):395--417, 2010", "doi": "10.1017/S0960129509990314", "report-no": "PRG0703", "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a strict version of the concept of a load/store instruction set\narchitecture in the setting of Maurer machines. We take the view that\ntransformations on the states of a Maurer machine are achieved by applying\nthreads as considered in thread algebra to the Maurer machine. We study how the\ntransformations on the states of the main memory of a strict load/store\ninstruction set architecture that can be achieved by applying threads depend on\nthe operating unit size, the cardinality of the instruction set, and the\nmaximal number of states of the threads.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2007 11:16:34 GMT"}, {"version": "v2", "created": "Tue, 25 Nov 2008 08:46:40 GMT"}], "update_date": "2010-05-12", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}
{"id": "0711.1177", "submitter": "Alfredo von Reckow", "authors": "Alfredo von Reckow", "title": "Considerations on P vs NP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": null, "abstract": "  In order to prove that the P of problems is different to the NP class, we\nconsider the satisfability problem of propositional calculus formulae, which is\nan NP-complete problem. It is shown that, for every search algorithm A, there\nis a set E(A) containing propositional calculus formulae, each of which\nrequires the algorithm A to take non-polynomial time to find the truth-values\nof its propositional letters satisfying it. Moreover, E(A)'s size is an\nexponential function of n, which makes it impossible to detect such formulae in\na polynomial time. Hence, the satisfability problem does not have a polynomial\ncomplexity\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2007 22:32:41 GMT"}], "update_date": "2007-11-09", "authors_parsed": [["von Reckow", "Alfredo", ""]]}
{"id": "0711.1401", "submitter": "Keki Burjorjee", "authors": "Keki Burjorjee", "title": "Towards a Sound Theory of Adaptation for the Simple Genetic Algorithm", "comments": "Typos corrected. No material changes to content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pace of progress in the fields of Evolutionary Computation and Machine\nLearning is currently limited -- in the former field, by the improbability of\nmaking advantageous extensions to evolutionary algorithms when their capacity\nfor adaptation is poorly understood, and in the latter by the difficulty of\nfinding effective semi-principled reductions of hard real-world problems to\nrelatively simple optimization problems. In this paper we explain why a theory\nwhich can accurately explain the simple genetic algorithm's remarkable capacity\nfor adaptation has the potential to address both these limitations. We describe\nwhat we believe to be the impediments -- historic and analytic -- to the\ndiscovery of such a theory and highlight the negative role that the building\nblock hypothesis (BBH) has played. We argue based on experimental results that\na fundamental limitation which is widely believed to constrain the SGA's\nadaptive ability (and is strongly implied by the BBH) is in fact illusionary\nand does not exist. The SGA therefore turns out to be more powerful than it is\ncurrently thought to be. We give conditions under which it becomes feasible to\nnumerically approximate and study the multivariate marginals of the search\ndistribution of an infinite population SGA over multiple generations even when\nits genomes are long, and explain why this analysis is relevant to the riddle\nof the SGA's remarkable adaptive abilities.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2007 02:28:12 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2009 15:28:06 GMT"}], "update_date": "2009-04-03", "authors_parsed": [["Burjorjee", "Keki", ""]]}
{"id": "0711.1466", "submitter": "Yoshiharu Maeno", "authors": "Yoshiharu Maeno and Yukio Ohsawa", "title": "Predicting relevant empty spots in social interaction", "comments": "11 pages, 5 figures, submitted to J. Systems Science and Complexity", "journal-ref": "Journal of Systems Science and Complexity vol.21, pp.161-171\n  (2008)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  An empty spot refers to an empty hard-to-fill space which can be found in the\nrecords of the social interaction, and is the clue to the persons in the\nunderlying social network who do not appear in the records. This contribution\naddresses a problem to predict relevant empty spots in social interaction.\nHomogeneous and inhomogeneous networks are studied as a model underlying the\nsocial interaction. A heuristic predictor function approach is presented as a\nnew method to address the problem. Simulation experiment is demonstrated over a\nhomogeneous network. A test data in the form of baskets is generated from the\nsimulated communication. Precision to predict the empty spots is calculated to\ndemonstrate the performance of the presented approach.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2007 13:54:30 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2008 14:34:55 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2008 05:26:32 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Maeno", "Yoshiharu", ""], ["Ohsawa", "Yukio", ""]]}
{"id": "0711.1723", "submitter": "Jinshan Zhang", "authors": "Jinshan Zhang, Yan Huo, and Fengshan Bai", "title": "An analysis of a random algorithm for estimating all the matchings", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": null, "abstract": "  Counting the number of all the matchings on a bipartite graph has been\ntransformed into calculating the permanent of a matrix obtained from the\nextended bipartite graph by Yan Huo, and Rasmussen presents a simple approach\n(RM) to approximate the permanent, which just yields a critical ratio\nO($n\\omega(n)$) for almost all the 0-1 matrices, provided it's a simple\npromising practical way to compute this #P-complete problem. In this paper, the\nperformance of this method will be shown when it's applied to compute all the\nmatchings based on that transformation. The critical ratio will be proved to be\nvery large with a certain probability, owning an increasing factor larger than\nany polynomial of $n$ even in the sense for almost all the 0-1 matrices. Hence,\nRM fails to work well when counting all the matchings via computing the\npermanent of the matrix. In other words, we must carefully utilize the known\nmethods of estimating the permanent to count all the matchings through that\ntransformation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2007 08:15:39 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2007 15:35:11 GMT"}], "update_date": "2007-11-15", "authors_parsed": [["Zhang", "Jinshan", ""], ["Huo", "Yan", ""], ["Bai", "Fengshan", ""]]}
{"id": "0711.1814", "submitter": "Francesca A. Lisi", "authors": "Francesca A. Lisi", "title": "Building Rules on Top of Ontologies for the Semantic Web with Inductive\n  Logic Programming", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": null, "abstract": "  Building rules on top of ontologies is the ultimate goal of the logical layer\nof the Semantic Web. To this aim an ad-hoc mark-up language for this layer is\ncurrently under discussion. It is intended to follow the tradition of hybrid\nknowledge representation and reasoning systems such as $\\mathcal{AL}$-log that\nintegrates the description logic $\\mathcal{ALC}$ and the function-free Horn\nclausal language \\textsc{Datalog}. In this paper we consider the problem of\nautomating the acquisition of these rules for the Semantic Web. We propose a\ngeneral framework for rule induction that adopts the methodological apparatus\nof Inductive Logic Programming and relies on the expressive and deductive power\nof $\\mathcal{AL}$-log. The framework is valid whatever the scope of induction\n(description vs. prediction) is. Yet, for illustrative purposes, we also\ndiscuss an instantiation of the framework which aims at description and turns\nout to be useful in Ontology Refinement.\n  Keywords: Inductive Logic Programming, Hybrid Knowledge Representation and\nReasoning Systems, Ontologies, Semantic Web.\n  Note: To appear in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2007 17:15:34 GMT"}], "update_date": "2007-11-13", "authors_parsed": [["Lisi", "Francesca A.", ""]]}
{"id": "0711.1827", "submitter": "Joerg Rothe", "authors": "Dorothea Baumeister and Joerg Rothe", "title": "The Three-Color and Two-Color Tantrix(TM) Rotation Puzzle Problems are\n  NP-Complete via Parsimonious Reductions", "comments": "30 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Holzer and Holzer (Discrete Applied Mathematics 144(3):345--358, 2004) proved\nthat the Tantrix(TM) rotation puzzle problem with four colors is NP-complete,\nand they showed that the infinite variant of this problem is undecidable. In\nthis paper, we study the three-color and two-color Tantrix(TM) rotation puzzle\nproblems (3-TRP and 2-TRP) and their variants. Restricting the number of\nallowed colors to three (respectively, to two) reduces the set of available\nTantrix(TM) tiles from 56 to 14 (respectively, to 8). We prove that 3-TRP and\n2-TRP are NP-complete, which answers a question raised by Holzer and Holzer in\nthe affirmative. Since our reductions are parsimonious, it follows that the\nproblems Unique-3-TRP and Unique-2-TRP are DP-complete under randomized\nreductions. We also show that the another-solution problems associated with\n4-TRP, 3-TRP, and 2-TRP are NP-complete. Finally, we prove that the infinite\nvariants of 3-TRP and 2-TRP are undecidable.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2007 17:44:45 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2007 21:22:14 GMT"}, {"version": "v3", "created": "Mon, 9 Jun 2008 12:26:34 GMT"}], "update_date": "2008-06-09", "authors_parsed": [["Baumeister", "Dorothea", ""], ["Rothe", "Joerg", ""]]}
{"id": "0711.2010", "submitter": "Reiner Czerwinski", "authors": "Reiner Czerwinski", "title": "A Polynomial Time Algorithm for Graph Isomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We claimed that there is a polynomial algorithm to test if two graphs are\nisomorphic. But the algorithm is wrong. It only tests if the adjacency matrices\nof two graphs have the same eigenvalues. There is a counterexample of two\nnon-isomorphic graphs with the same eigenvalues.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2007 15:51:33 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2007 20:23:00 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2007 14:51:55 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2008 15:10:16 GMT"}, {"version": "v5", "created": "Sat, 15 Oct 2022 15:56:47 GMT"}], "update_date": "2022-10-18", "authors_parsed": [["Czerwinski", "Reiner", ""]]}
{"id": "0711.2058", "submitter": "Igor M. Suslov", "authors": "I. M. Suslov (P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia)", "title": "Computer Model of a \"Sense of Humour\". I. General Algorithm", "comments": "10 pages, 3 figures included; continuation of this series to appear", "journal-ref": "Biofizika SSSR 37, 318 (1992) [Biophysics 37, 242 (1992)]", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": null, "abstract": "  A computer model of a \"sense of humour\" is proposed. The humorous effect is\ninterpreted as a specific malfunction in the course of information processing\ndue to the need for the rapid deletion of the false version transmitted into\nconsciousness. The biological function of a sense of humour consists in\nspeeding up the bringing of information into consciousness and in fuller use of\nthe resources of the brain.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2007 19:00:32 GMT"}], "update_date": "2007-11-27", "authors_parsed": [["Suslov", "I. M.", "", "P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia"]]}
{"id": "0711.2061", "submitter": "Igor M. Suslov", "authors": "I. M. Suslov (P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia)", "title": "Computer Model of a \"Sense of Humour\". II. Realization in Neural\n  Networks", "comments": "13 pages, 5 figures included; continuation of this series to appear", "journal-ref": "Biofizika SSSR 37, 325 (1992) [Biophysics 37, 249 (1992)]", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": null, "abstract": "  The computer realization of a \"sense of humour\" requires the creation of an\nalgorithm for solving the \"linguistic problem\", i.e. the problem of recognizing\na continuous sequence of polysemantic images. Such algorithm may be realized in\nthe Hopfield model of a neural network after its proper modification.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2007 20:15:10 GMT"}], "update_date": "2007-11-27", "authors_parsed": [["Suslov", "I. M.", "", "P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia"]]}
{"id": "0711.2116", "submitter": "Frederic Vignat", "authors": "Fr\\'ed\\'eric Vignat (LGS), Fran\\c{c}ois Villeneuve (LGS)", "title": "A numerical approach for 3D manufacturing tolerances synthesis", "comments": null, "journal-ref": "Dans Proceedings of the 10th CIRP International Seminar on\n  Computer Aided Tolerancing - 10th CIRP International Seminar on Computer\n  Aided Tolerancing, Erlangen : Allemagne (2007)", "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  Making a product conform to the functional requirements indicated by the\ncustomer suppose to be able to manage the manufacturing process chosen to\nrealise the parts. A simulation step is generally performed to verify that the\nexpected generated deviations fit with these requirements. It is then necessary\nto assess the actual deviations of the process in progress. This is usually\ndone by the verification of the conformity of the workpiece to manufacturing\ntolerances at the end of each set-up. It is thus necessary to determine these\nmanufacturing tolerances. This step is called \"manufacturing tolerance\nsynthesis\". In this paper, a numerical method is proposed to perform 3D\nmanufacturing tolerances synthesis. This method uses the result of the\nnumerical analysis of tolerances to determine influent mall displacement of\nsurfaces. These displacements are described by small displacements torsors. An\nalgorithm is then proposed to determine suitable ISO manufacturing tolerances.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2007 06:21:17 GMT"}], "update_date": "2007-11-15", "authors_parsed": [["Vignat", "Frédéric", "", "LGS"], ["Villeneuve", "François", "", "LGS"]]}
{"id": "0711.2270", "submitter": "Igor M. Suslov", "authors": "I. M. Suslov (P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia)", "title": "Can a Computer Laugh ?", "comments": "English translation of the paper in Russian; 18 pages, 6 figures\n  included", "journal-ref": "Computer Chronicle (Moscow), 1994, issue 1, p.1", "doi": null, "report-no": null, "categories": "cs.CL cs.AI q-bio.NC", "license": null, "abstract": "  A computer model of \"a sense of humour\" suggested previously\n[arXiv:0711.2058,0711.2061], relating the humorous effect with a specific\nmalfunction in information processing, is given in somewhat different\nexposition. Psychological aspects of humour are elaborated more thoroughly. The\nmechanism of laughter is formulated on the more general level. Detailed\ndiscussion is presented for the higher levels of information processing, which\nare responsible for a perception of complex samples of humour. Development of a\nsense of humour in the process of evolution is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2007 18:32:09 GMT"}], "update_date": "2007-11-27", "authors_parsed": [["Suslov", "I. M.", "", "P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia"]]}
{"id": "0711.2383", "submitter": "Barbara Cerato", "authors": "Barbara Cerato, Guido Masera and Emanuele Viterbo", "title": "Decoding the Golden Code: a VLSI design", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  The recently proposed Golden code is an optimal space-time block code for 2 X\n2 multiple-input multiple-output (MIMO) systems. The aim of this work is the\ndesign of a VLSI decoder for a MIMO system coded with the Golden code. The\narchitecture is based on a rearrangement of the sphere decoding algorithm that\nachieves maximum-likelihood (ML) decoding performance. Compared to other\napproaces, the proposed solution exhibits an inherent flexibility in terms of\nmodulation schemes QAM modulation size and this makes our architecture\nparticularly suitable for adaptive modulation schemes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2007 11:55:30 GMT"}], "update_date": "2007-11-16", "authors_parsed": [["Cerato", "Barbara", ""], ["Masera", "Guido", ""], ["Viterbo", "Emanuele", ""]]}
{"id": "0711.2478", "submitter": "Vasileios Barmpoutis", "authors": "Vasileios Barmpoutis, Gary F. Dargush", "title": "A Compact Self-organizing Cellular Automata-based Genetic Algorithm", "comments": "24 pages, 18 figures, Submitted to Evolutionary Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  A Genetic Algorithm (GA) is proposed in which each member of the population\ncan change schemata only with its neighbors according to a rule. The rule\nmethodology and the neighborhood structure employ elements from the Cellular\nAutomata (CA) strategies. Each member of the GA population is assigned to a\ncell and crossover takes place only between adjacent cells, according to the\npredefined rule. Although combinations of CA and GA approaches have appeared\npreviously, here we rely on the inherent self-organizing features of CA, rather\nthan on parallelism. This conceptual shift directs us toward the evolution of\ncompact populations containing only a handful of members. We find that the\nresulting algorithm can search the design space more efficiently than\ntraditional GA strategies due to its ability to exploit mutations within this\ncompact self-organizing population. Consequently, premature convergence is\navoided and the final results often are more accurate. In order to reinforce\nthe superior mutation capability, a re-initialization strategy also is\nimplemented. Ten test functions and two benchmark structural engineering truss\ndesign problems are examined in order to demonstrate the performance of the\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2007 18:19:39 GMT"}], "update_date": "2007-11-16", "authors_parsed": [["Barmpoutis", "Vasileios", ""], ["Dargush", "Gary F.", ""]]}
{"id": "0711.2562", "submitter": "J. Maurice Rojas", "authors": "Ashraf Ibrahim, J. Maurice Rojas, Korben Rusek", "title": "Algorithmic Arithmetic Fewnomial Theory I: One Variable", "comments": "This paper has been withdrawn by the authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Withdrawn by the authors due to an error in the proof of the finite field\nresult (Thm. 1.5): The random primes used in the proof need NOT avoid the\nexceptional primes from Lemma 2.7, thus leaving Thm. 1.5 unproved.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2007 06:15:35 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2010 16:04:36 GMT"}], "update_date": "2010-01-24", "authors_parsed": [["Ibrahim", "Ashraf", ""], ["Rojas", "J. Maurice", ""], ["Rusek", "Korben", ""]]}
{"id": "0711.2605", "submitter": "Gregory Price", "authors": "Gregory N. Price and Erik D. Demaine", "title": "Generalized D-Forms Have No Spurious Creases", "comments": "revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A convex surface that is flat everywhere but on finitely many smooth curves\n(or \"seams\") and points is a seam form. We show that the only creases through\nthe flat components of a seam form are either between vertices or tangent to\nthe seams. As corollaries we resolve open problems about certain special seam\nforms: the flat components of a D-form have no creases at all, and the flat\ncomponent of a pita-form has at most one crease, between the seam's endpoints.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2007 20:58:57 GMT"}, {"version": "v2", "created": "Thu, 7 May 2009 05:45:19 GMT"}], "update_date": "2009-05-07", "authors_parsed": [["Price", "Gregory N.", ""], ["Demaine", "Erik D.", ""]]}
{"id": "0711.2671", "submitter": "Himanshu Thapliyal", "authors": "Himanshu Thapliyal, Hamid R. Arabnia, Rajnish Bajpai, Kamal K. Sharma", "title": "Combined Integer and Variable Precision (CIVP) Floating Point\n  Multiplication Architecture for FPGAs", "comments": "Published in Proceedings of the 2007 International Conference on\n  Parallel and Distributed Processing Techniques and Applications (PDPTA'07),\n  Las Vegas, U.S.A, June 2007, Volume 1, pp. 449-450.(CSREA Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  In this paper, we propose an architecture/methodology for making FPGAs\nsuitable for integer as well as variable precision floating point\nmultiplication. The proposed work will of great importance in applications\nwhich requires variable precision floating point multiplication such as\nmulti-media processing applications. In the proposed architecture/methodology,\nwe propose the replacement of existing 18x18 bit and 25x18 bit dedicated\nmultipliers in FPGAs with dedicated 24x24 bit and 24x9 bit multipliers,\nrespectively. We have proved that our approach of providing the dedicated 24x24\nbit and 24x9 bit multipliers in FPGAs will make them efficient for performing\ninteger as well as single precision, double precision, and Quadruple precision\nfloating point multiplications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2007 20:18:32 GMT"}], "update_date": "2007-11-19", "authors_parsed": [["Thapliyal", "Himanshu", ""], ["Arabnia", "Hamid R.", ""], ["Bajpai", "Rajnish", ""], ["Sharma", "Kamal K.", ""]]}
{"id": "0711.2674", "submitter": "Himanshu Thapliyal", "authors": "Himanshu Thapliyal, Hamid R. Arabnia, Rajnish Bajpai, Kamal K. Sharma", "title": "Partial Reversible Gates(PRG) for Reversible BCD Arithmetic", "comments": "Published in Proceedings of the 2007 International Conference on\n  Computer Design(CDES'07), Las Vegas, U.S.A, June 2007, pp. 90-91(CSREA Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": null, "abstract": "  IEEE 754r is the ongoing revision to the IEEE 754 floating point standard and\na major enhancement to the standard is the addition of decimal format.\nFurthermore, in the recent years reversible logic has emerged as a promising\ncomputing paradigm having its applications in low power CMOS, quantum\ncomputing, nanotechnology, and optical computing. The major goal in reversible\nlogic is to minimize the number of reversible gates and garbage outputs. Thus,\nthis paper proposes the novel concept of partial reversible gates that will\nsatisfy the reversibility criteria for specific cases in BCD arithmetic. The\npartial reversible gate is proposed to minimize the number of reversible gates\nand garbage outputs, while designing the reversible BCD arithmetic circuits.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2007 20:25:20 GMT"}], "update_date": "2007-11-19", "authors_parsed": [["Thapliyal", "Himanshu", ""], ["Arabnia", "Hamid R.", ""], ["Bajpai", "Rajnish", ""], ["Sharma", "Kamal K.", ""]]}
{"id": "0711.2835", "submitter": "Sergey Bereg", "authors": "Sergey Bereg", "title": "Faster Algorithms for Rigidity in the Plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  In [1], a new construction called red-black hierarchy characterizing Laman\ngraphs and an algorithm for computing it were presented. For a Laman graph\nG=(V,E) with n vertices it runs in O(n^2) time assuming that a partition of\n(V,E+e) into two spanning trees is given. We show that a simple modification\nreduces the running time to O(n\\log n). The total running time can be reduced\nO(n\\sqrt{n\\log n}) using the algorithm by Gabow and Westermann [2] for\npartitioning a graph into two forests. The existence of a red-black hierarchy\nis a necessary and sufficient condition for a graph to be a Laman graph. The\nalgorithm for constructing a red-black hierarchy can be then modified to\nrecognize Laman graphs in the same time.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 18:54:32 GMT"}, {"version": "v2", "created": "Fri, 29 Feb 2008 18:38:50 GMT"}], "update_date": "2008-02-29", "authors_parsed": [["Bereg", "Sergey", ""]]}
{"id": "0711.2843", "submitter": "Xueliang Li", "authors": "Xueliang Li, Xiangmei Yao, Wenli Zhou", "title": "Complexity of the conditional colorability of graphs", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": null, "abstract": "  For an integer $r>0$, a conditional $(k,r)$-coloring of a graph $G$ is a\nproper $k$-coloring of the vertices of $G$ such that every vertex $v$ of degree\n$d(v)$ in $G$ is adjacent to vertices with at least $min\\{r, d(v)\\}$ different\ncolors. The smallest integer $k$ for which a graph $G$ has a conditional\n$(k,r)$-coloring is called the $r$th order conditional chromatic number,\ndenoted by $\\chi_r(G)$. It is easy to see that the conditional coloring is a\ngeneralization of the traditional vertex coloring for which $r=1$. In this\npaper, we consider the complexity of the conditional colorings of graphs. The\nmain result is that the conditional $(3,2)$-colorability is $NP$-complete for\ntriangle-free graphs with maximum degree at most 3, which is different from the\nold result that the traditional 3-colorability is polynomial solvable for\ngraphs with maximum degree at most 3. This also implies that it is\n$NP$-complete to determine if a graph of maximum degree 3 is $(3,2)$- or\n$(4,2)$-colorable. Also we have proved that some old complexity results for\ntraditional colorings still hold for the conditional colorings.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 05:41:36 GMT"}], "update_date": "2007-11-20", "authors_parsed": [["Li", "Xueliang", ""], ["Yao", "Xiangmei", ""], ["Zhou", "Wenli", ""]]}
{"id": "0711.2844", "submitter": "Xueliang Li", "authors": "Xueliang Li, Wenli Zhou", "title": "Dynamic 3-Coloring of Claw-free Graphs", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": null, "abstract": "  A {\\it dynamic $k$-coloring} of a graph $G$ is a proper $k$-coloring of the\nvertices of $G$ such that every vertex of degree at least 2 in $G$ will be\nadjacent to vertices with at least 2 different colors. The smallest number $k$\nfor which a graph $G$ can have a dynamic $k$-coloring is the {\\it dynamic\nchromatic number}, denoted by $\\chi_d(G)$. In this paper, we investigate the\ndynamic 3-colorings of claw-free graphs. First, we prove that it is\n$NP$-complete to determine if a claw-free graph with maximum degree 3 is\ndynamically 3-colorable. Second, by forbidding a kind of subgraphs, we find a\nreasonable subclass of claw-free graphs with maximum degree 3, for which the\ndynamically 3-colorable problem can be solved in linear time. Third, we give a\nlinear time algorithm to recognize this subclass of graphs, and a linear time\nalgorithm to determine whether it is dynamically 3-colorable. We also give a\nlinear time algorithm to color the graphs in the subclass by 3 colors.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 05:56:01 GMT"}], "update_date": "2007-11-20", "authors_parsed": [["Li", "Xueliang", ""], ["Zhou", "Wenli", ""]]}
{"id": "0711.2909", "submitter": "Krzysztof R. Apt", "authors": "Krzysztof R. Apt, Francesca Rossi, Kristen Brent Venable", "title": "Comparing the notions of optimality in CP-nets, strategic games and soft\n  constraints", "comments": "39 pages. To appear in Annals of Mathematics and Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": null, "abstract": "  The notion of optimality naturally arises in many areas of applied\nmathematics and computer science concerned with decision making. Here we\nconsider this notion in the context of three formalisms used for different\npurposes in reasoning about multi-agent systems: strategic games, CP-nets, and\nsoft constraints. To relate the notions of optimality in these formalisms we\nintroduce a natural qualitative modification of the notion of a strategic game.\nWe show then that the optimal outcomes of a CP-net are exactly the Nash\nequilibria of such games. This allows us to use the techniques of game theory\nto search for optimal outcomes of CP-nets and vice-versa, to use techniques\ndeveloped for CP-nets to search for Nash equilibria of the considered games.\nThen, we relate the notion of optimality used in the area of soft constraints\nto that used in a generalization of strategic games, called graphical games. In\nparticular we prove that for a natural class of soft constraints that includes\nweighted constraints every optimal solution is both a Nash equilibrium and\nPareto efficient joint strategy. For a natural mapping in the other direction\nwe show that Pareto efficient joint strategies coincide with the optimal\nsolutions of soft constraints.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 12:14:27 GMT"}, {"version": "v2", "created": "Mon, 21 Apr 2008 10:47:41 GMT"}], "update_date": "2008-04-21", "authors_parsed": [["Apt", "Krzysztof R.", ""], ["Rossi", "Francesca", ""], ["Venable", "Kristen Brent", ""]]}
{"id": "0711.2914", "submitter": "Tshilidzi Marwala", "authors": "Gidudu Anthony, Hulley Gregg and Marwala Tshilidzi", "title": "Image Classification Using SVMs: One-against-One Vs One-against-All", "comments": "Proccedings of the 28th Asian Conference on Remote Sensing, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": null, "abstract": "  Support Vector Machines (SVMs) are a relatively new supervised classification\ntechnique to the land cover mapping community. They have their roots in\nStatistical Learning Theory and have gained prominence because they are robust,\naccurate and are effective even when using a small training sample. By their\nnature SVMs are essentially binary classifiers, however, they can be adopted to\nhandle the multiple classification tasks common in remote sensing studies. The\ntwo approaches commonly used are the One-Against-One (1A1) and One-Against-All\n(1AA) techniques. In this paper, these approaches are evaluated in as far as\ntheir impact and implication for land cover mapping. The main finding from this\nresearch is that whereas the 1AA technique is more predisposed to yielding\nunclassified and mixed pixels, the resulting classification accuracy is not\nsignificantly different from 1A1 approach. It is the authors conclusion\ntherefore that ultimately the choice of technique adopted boils down to\npersonal preference and the uniqueness of the dataset at hand.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 12:25:00 GMT"}], "update_date": "2007-11-20", "authors_parsed": [["Anthony", "Gidudu", ""], ["Gregg", "Hulley", ""], ["Tshilidzi", "Marwala", ""]]}
{"id": "0711.2961", "submitter": "Felix Brandt", "authors": "Felix Brandt, Felix Fischer, Paul Harrenstein", "title": "Recognizing Members of the Tournament Equilibrium Set is NP-hard", "comments": "9 pages, 3 figures", "journal-ref": "Social Choice and Welfare 34(4), 2009", "doi": "10.1007/s00355-009-0419-z", "report-no": null, "categories": "cs.CC cs.GT cs.MA", "license": null, "abstract": "  A recurring theme in the mathematical social sciences is how to select the\n\"most desirable\" elements given a binary dominance relation on a set of\nalternatives. Schwartz's tournament equilibrium set (TEQ) ranks among the most\nintriguing, but also among the most enigmatic, tournament solutions that have\nbeen proposed so far in this context. Due to its unwieldy recursive definition,\nlittle is known about TEQ. In particular, its monotonicity remains an open\nproblem up to date. Yet, if TEQ were to satisfy monotonicity, it would be a\nvery attractive tournament solution concept refining both the Banks set and\nDutta's minimal covering set. We show that the problem of deciding whether a\ngiven alternative is contained in TEQ is NP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 15:48:46 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2008 13:47:48 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Brandt", "Felix", ""], ["Fischer", "Felix", ""], ["Harrenstein", "Paul", ""]]}
{"id": "0711.3013", "submitter": "Louis Theran", "authors": "Ileana Streinu and Louis Theran", "title": "Natural realizations of sparsity matroids", "comments": "Corrected some typos from the previous version; to appear in Ars\n  Mathematica Contemporanea", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.AG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hypergraph G with n vertices and m hyperedges with d endpoints each is\n(k,l)-sparse if for all sub-hypergraphs G' on n' vertices and m' edges, m'\\le\nkn'-l. For integers k and l satisfying 0\\le l\\le dk-1, this is known to be a\nlinearly representable matroidal family.\n  Motivated by problems in rigidity theory, we give a new linear representation\ntheorem for the (k,l)-sparse hypergraphs that is natural; i.e., the\nrepresenting matrix captures the vertex-edge incidence structure of the\nunderlying hypergraph G.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 21:02:34 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2007 06:33:13 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2008 18:40:20 GMT"}, {"version": "v4", "created": "Mon, 5 Jul 2010 15:43:57 GMT"}, {"version": "v5", "created": "Mon, 20 Dec 2010 17:06:51 GMT"}], "update_date": "2010-12-21", "authors_parsed": [["Streinu", "Ileana", ""], ["Theran", "Louis", ""]]}
{"id": "0711.3077", "submitter": "Jie Luo", "authors": "Jie Luo", "title": "On Low Complexity Maximum Likelihood Decoding of Convolutional Codes", "comments": "Submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2008.2006461", "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the average complexity of maximum likelihood (ML)\ndecoding of convolutional codes. ML decoding can be modeled as finding the most\nprobable path taken through a Markov graph. Integrated with the Viterbi\nalgorithm (VA), complexity reduction methods such as the sphere decoder often\nuse the sum log likelihood (SLL) of a Markov path as a bound to disprove the\noptimality of other Markov path sets and to consequently avoid exhaustive path\nsearch. In this paper, it is shown that SLL-based optimality tests are\ninefficient if one fixes the coding memory and takes the codeword length to\ninfinity. Alternatively, optimality of a source symbol at a given time index\ncan be testified using bounds derived from log likelihoods of the neighboring\nsymbols. It is demonstrated that such neighboring log likelihood (NLL)-based\noptimality tests, whose efficiency does not depend on the codeword length, can\nbring significant complexity reduction to ML decoding of convolutional codes.\nThe results are generalized to ML sequence detection in a class of\ndiscrete-time hidden Markov systems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2007 07:27:30 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2007 00:15:24 GMT"}, {"version": "v3", "created": "Thu, 31 Jul 2008 17:08:52 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Luo", "Jie", ""]]}
{"id": "0711.3183", "submitter": "Narad Rampersad", "authors": "Terry Anderson, John Loftus, Narad Rampersad, Nicolae Santean, Jeffrey\n  Shallit", "title": "Detecting palindromes, patterns, and borders in regular languages", "comments": "Full version of a paper submitted to LATA 2008. This is a new version\n  with John Loftus added as a co-author and containing new results on\n  unbordered words", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a language L and a nondeterministic finite automaton M, we consider\nwhether we can determine efficiently (in the size of M) if M accepts at least\none word in L, or infinitely many words. Given that M accepts at least one word\nin L, we consider how long a shortest word can be. The languages L that we\nexamine include the palindromes, the non-palindromes, the k-powers, the\nnon-k-powers, the powers, the non-powers (also called primitive words), the\nwords matching a general pattern, the bordered words, and the unbordered words.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2007 17:38:47 GMT"}, {"version": "v2", "created": "Mon, 9 Jun 2008 14:25:57 GMT"}], "update_date": "2009-04-14", "authors_parsed": [["Anderson", "Terry", ""], ["Loftus", "John", ""], ["Rampersad", "Narad", ""], ["Santean", "Nicolae", ""], ["Shallit", "Jeffrey", ""]]}
{"id": "0711.3197", "submitter": "Igor M. Suslov", "authors": "I. M. Suslov (P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia)", "title": "How to realize \"a sense of humour\" in computers ?", "comments": "14 pages, 6 figures included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI q-bio.NC", "license": null, "abstract": "  Computer model of a \"sense of humour\" suggested previously [arXiv:0711.2058,\n0711.2061, 0711.2270] is raised to the level of a realistic algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2007 19:57:23 GMT"}], "update_date": "2007-11-27", "authors_parsed": [["Suslov", "I. M.", "", "P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia"]]}
{"id": "0711.3235", "submitter": "Joseph Y. Halpern", "authors": "Peter D. Grunwald and Joseph Y. Halpern", "title": "A Game-Theoretic Analysis of Updating Sets of Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.ST stat.TH", "license": null, "abstract": "  We consider how an agent should update her uncertainty when it is represented\nby a set $\\P$ of probability distributions and the agent observes that a random\nvariable $X$ takes on value $x$, given that the agent makes decisions using the\nminimax criterion, perhaps the best-studied and most commonly-used criterion in\nthe literature. We adopt a game-theoretic framework, where the agent plays\nagainst a bookie, who chooses some distribution from $\\P$. We consider two\nreasonable games that differ in what the bookie knows when he makes his choice.\nAnomalies that have been observed before, like time inconsistency, can be\nunderstood as arising important because different games are being played,\nagainst bookies with different information. We characterize the important\nspecial cases in which the optimal decision rules according to the minimax\ncriterion amount to either conditioning or simply ignoring the information.\nFinally, we consider the relationship between conditioning and calibration when\nuncertainty is described by sets of probabilities.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2007 23:34:12 GMT"}], "update_date": "2007-11-27", "authors_parsed": [["Grunwald", "Peter D.", ""], ["Halpern", "Joseph Y.", ""]]}
{"id": "0711.3242", "submitter": "Frank Nielsen", "authors": "Frank Nielsen, Richard Nock", "title": "On the Centroids of Symmetrized Bregman Divergences", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  In this paper, we generalize the notions of centroids and barycenters to the\nbroad class of information-theoretic distortion measures called Bregman\ndivergences. Bregman divergences are versatile, and unify quadratic geometric\ndistances with various statistical entropic measures. Because Bregman\ndivergences are typically asymmetric, we consider both the left-sided and\nright-sided centroids and the symmetrized centroids, and prove that all three\nare unique. We give closed-form solutions for the sided centroids that are\ngeneralized means, and design a provably fast and efficient approximation\nalgorithm for the symmetrized centroid based on its exact geometric\ncharacterization that requires solely to walk on the geodesic linking the two\nsided centroids. We report on our generic implementation for computing entropic\ncenters of image clusters and entropic centers of multivariate normals, and\ncompare our results with former ad-hoc methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2007 01:15:19 GMT"}], "update_date": "2007-11-22", "authors_parsed": [["Nielsen", "Frank", ""], ["Nock", "Richard", ""]]}
{"id": "0711.3419", "submitter": "Leo Obrst", "authors": "Ken Samuel, Leo Obrst, Suzette Stoutenberg, Karen Fox, Paul Franklin,\n  Adrian Johnson, Ken Laskey, Deborah Nichols, Steve Lopez, Jason Peterson", "title": "Translating OWL and Semantic Web Rules into Prolog: Moving Toward\n  Description Logic Programs", "comments": "21 pages, 5 figures, 19 tables. To appear in Theory and Practice of\n  Logic Programming (TPLP), 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  To appear in Theory and Practice of Logic Programming (TPLP), 2008.\n  We are researching the interaction between the rule and the ontology layers\nof the Semantic Web, by comparing two options: 1) using OWL and its rule\nextension SWRL to develop an integrated ontology/rule language, and 2) layering\nrules on top of an ontology with RuleML and OWL. Toward this end, we are\ndeveloping the SWORIER system, which enables efficient automated reasoning on\nontologies and rules, by translating all of them into Prolog and adding a set\nof general rules that properly capture the semantics of OWL. We have also\nenabled the user to make dynamic changes on the fly, at run time. This work\naddresses several of the concerns expressed in previous work, such as negation,\ncomplementary classes, disjunctive heads, and cardinality, and it discusses\nalternative approaches for dealing with inconsistencies in the knowledge base.\nIn addition, for efficiency, we implemented techniques called\nextensionalization, avoiding reanalysis, and code minimization.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2007 17:36:50 GMT"}], "update_date": "2007-11-22", "authors_parsed": [["Samuel", "Ken", ""], ["Obrst", "Leo", ""], ["Stoutenberg", "Suzette", ""], ["Fox", "Karen", ""], ["Franklin", "Paul", ""], ["Johnson", "Adrian", ""], ["Laskey", "Ken", ""], ["Nichols", "Deborah", ""], ["Lopez", "Steve", ""], ["Peterson", "Jason", ""]]}
{"id": "0711.3591", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin, Edmund Burke and Jingpeng Li", "title": "An Estimation of Distribution Algorithm with Intelligent Local Search\n  for Rule-based Nurse Rostering", "comments": null, "journal-ref": "Journal of the Operational Research Society, 58 (12), pp\n  1574-1585, 2007", "doi": "10.1057/palgrave.jors.2602308", "report-no": null, "categories": "cs.NE cs.CE", "license": null, "abstract": "  This paper proposes a new memetic evolutionary algorithm to achieve explicit\nlearning in rule-based nurse rostering, which involves applying a set of\nheuristic rules for each nurse's assignment. The main framework of the\nalgorithm is an estimation of distribution algorithm, in which an ant-miner\nmethodology improves the individual solutions produced in each generation.\nUnlike our previous work (where learning is implicit), the learning in the\nmemetic estimation of distribution algorithm is explicit, i.e. we are able to\nidentify building blocks directly. The overall approach learns by building a\nprobabilistic model, i.e. an estimation of the probability distribution of\nindividual nurse-rule pairs that are used to construct schedules. The local\nsearch processor (i.e. the ant-miner) reinforces nurse-rule pairs that receive\nhigher rewards. A challenging real world nurse rostering problem is used as the\ntest problem. Computational results show that the proposed approach outperforms\nmost existing approaches. It is suggested that the learning methodologies\nsuggested in this paper may be applied to other scheduling problems where\nschedules are built systematically according to specific rules\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2007 15:16:21 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:14:51 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""], ["Burke", "Edmund", ""], ["Li", "Jingpeng", ""]]}
{"id": "0711.3628", "submitter": "Francesc Rossell\\'o", "authors": "Gabriel Cardona, Francesc Rossello, Gabriel Valiente", "title": "A Perl Package and an Alignment Tool for Phylogenetic Networks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE", "license": null, "abstract": "  Phylogenetic networks are a generalization of phylogenetic trees that allow\nfor the representation of evolutionary events acting at the population level,\nlike recombination between genes, hybridization between lineages, and lateral\ngene transfer. While most phylogenetics tools implement a wide range of\nalgorithms on phylogenetic trees, there exist only a few applications to work\nwith phylogenetic networks, and there are no open-source libraries either.\n  In order to improve this situation, we have developed a Perl package that\nrelies on the BioPerl bundle and implements many algorithms on phylogenetic\nnetworks. We have also developed a Java applet that makes use of the\naforementioned Perl package and allows the user to make simple experiments with\nphylogenetic networks without having to develop a program or Perl script by\nherself.\n  The Perl package has been accepted as part of the BioPerl bundle. It can be\ndownloaded from http://dmi.uib.es/~gcardona/BioInfo/Bio-PhyloNetwork.tgz. The\nweb-based application is available at http://dmi.uib.es/~gcardona/BioInfo/. The\nPerl package includes full documentation of all its features.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2007 18:05:49 GMT"}], "update_date": "2007-11-26", "authors_parsed": [["Cardona", "Gabriel", ""], ["Rossello", "Francesc", ""], ["Valiente", "Gabriel", ""]]}
{"id": "0711.4309", "submitter": "Giandomenico Sica", "authors": "Ruqian Lu", "title": "Knowware: the third star after Hardware and Software", "comments": "109 pages, ISBN 978-88-7699-095-3 (Printed edition), ISBN\n  978-88-7699-096-0 (Electronic edition), printed edition available on Amazon\n  and on Lulu.com", "journal-ref": "\"Publishing studies\" book series, edited by Giandomenico Sica,\n  ISSN 1973-6061 (Printed edition), ISSN 1973-6053 (Electronic edition)", "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CY", "license": null, "abstract": "  This book proposes to separate knowledge from software and to make it a\ncommodity that is called knowware. The architecture, representation and\nfunction of Knowware are discussed. The principles of knowware engineering and\nits three life cycle models: furnace model, crystallization model and spiral\nmodel are proposed and analyzed. Techniques of software/knowware co-engineering\nare introduced. A software component whose knowledge is replaced by knowware is\ncalled mixware. An object and component oriented development schema of mixware\nis introduced. In particular, the tower model and ladder model for mixware\ndevelopment are proposed and discussed. Finally, knowledge service and knowware\nbased Web service are introduced and compared with Web service. In summary,\nknowware, software and hardware should be considered as three equally important\nunderpinnings of IT industry.\n  Ruqian Lu is a professor of computer science of the Institute of Mathematics,\nAcademy of Mathematics and System Sciences. He is a fellow of Chinese Academy\nof Sciences. His research interests include artificial intelligence, knowledge\nengineering and knowledge based software engineering. He has published more\nthan 100 papers and 10 books. He has won two first class awards from the\nAcademia Sinica and a National second class prize from the Ministry of Science\nand Technology. He has also won the sixth Hua Loo-keng Mathematics Prize.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2007 17:36:35 GMT"}], "update_date": "2007-11-28", "authors_parsed": [["Lu", "Ruqian", ""]]}
{"id": "0711.4324", "submitter": "Jinshan Zhang", "authors": "Jinshan Zhang", "title": "Report on \"American Option Pricing and Hedging Strategies\"", "comments": "14pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DM", "license": null, "abstract": "  This paper mainly discusses the American option's hedging strategies via\nbinomialmodel and the basic idea of pricing and hedging American option.\nAlthough the essential scheme of hedging is almost the same as European option,\nsmall differences may arise when simulating the process for American option\nholder has more rights, spelling that the option can be exercised at anytime\nbefore its maturity. Our method is dynamic-hedging method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2007 18:34:40 GMT"}], "update_date": "2007-11-28", "authors_parsed": [["Zhang", "Jinshan", ""]]}
{"id": "0711.4444", "submitter": "Laurent Hascoet", "authors": "Moulay Hicham Tber (INRIA Sophia Antipolis), Laurent Hascoet (INRIA\n  Sophia Antipolis, SEMA), Arthur Vidard (INRIA Rh\\^one-Alpes / LJK Laboratoire\n  Jean Kuntzmann), Benjamin Dauvergne (INRIA Sophia Antipolis)", "title": "Building the Tangent and Adjoint codes of the Ocean General Circulation\n  Model OPA with the Automatic Differentiation tool TAPENADE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE", "license": null, "abstract": "  The ocean general circulation model OPA is developed by the LODYC team at\nParis VI university. OPA has recently undergone a major rewriting, migrating to\nFORTRAN95, and its adjoint code needs to be rebuilt. For earlier versions, the\nadjoint of OPA was written by hand at a high development cost. We use the\nAutomatic Differentiation tool TAPENADE to build mechanicaly the tangent and\nadjoint codes of OPA. We validate the differentiated codes by comparison with\ndivided differences, and also with an identical twin experiment. We apply\nstate-of-the-art methods to improve the performance of the adjoint code. In\nparticular we implement the Griewank and Walther's binomial checkpointing\nalgorithm which gives us an optimal trade-off between time and memory\nconsumption. We apply a specific strategy to differentiate the iterative linear\nsolver that comes from the implicit time stepping scheme\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2007 08:04:18 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2007 09:09:27 GMT"}], "update_date": "2007-11-29", "authors_parsed": [["Tber", "Moulay Hicham", "", "INRIA Sophia Antipolis"], ["Hascoet", "Laurent", "", "INRIA\n  Sophia Antipolis, SEMA"], ["Vidard", "Arthur", "", "INRIA Rhône-Alpes / LJK Laboratoire\n  Jean Kuntzmann"], ["Dauvergne", "Benjamin", "", "INRIA Sophia Antipolis"]]}
{"id": "0711.4507", "submitter": "Oded Kafri", "authors": "Oded Kafri", "title": "The Second Law as a Cause of the Evolution", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": null, "abstract": "  It is a common belief that in any environment where life is possible, life\nwill be generated. Here it is suggested that the cause for a spontaneous\ngeneration of complex systems is probability driven processes. Based on\nequilibrium thermodynamics, it is argued that in low occupation number\nstatistical systems, the second law of thermodynamics yields an increase of\nthermal entropy and a canonic energy distribution. However, in high occupation\nnumber statistical systems, the same law for the same reasons yields an\nincrease of information and a Benford's law/power-law energy distribution. It\nis therefore, plausible, that eventually the heat death is not necessarily the\nend of the universe.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2007 14:06:19 GMT"}], "update_date": "2007-11-29", "authors_parsed": [["Kafri", "Oded", ""]]}
{"id": "0711.4508", "submitter": "Hiroshi Ishikawa", "authors": "Hiroshi Ishikawa", "title": "Representation and Measure of Structural Information", "comments": "Second version. Revised the Introduction and added more discussion in\n  the last section. The technical content is mostly unchanged. 51 pages, 4\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a uniform representation of general objects that captures the\nregularities with respect to their structure. It allows a representation of a\ngeneral class of objects including geometric patterns and images in a sparse,\nmodular, hierarchical, and recursive manner. The representation can exploit any\ncomputable regularity in objects to compactly describe them, while also being\ncapable of representing random objects as raw data. A set of rules uniformly\ndictates the interpretation of the representation into raw signal, which makes\nit possible to ask what pattern a given raw signal contains. Also, it allows\nsimple separation of the information that we wish to ignore from that which we\nmeasure, by using a set of maps to delineate the a priori parts of the objects,\nleaving only the information in the structure.\n  Using the representation, we introduce a measure of information in general\nobjects relative to structures defined by the set of maps. We point out that\nthe common prescription of encoding objects by strings to use Kolmogorov\ncomplexity is meaningless when, as often is the case, the encoding is not\nspecified in any way other than that it exists. Noting this, we define the\nmeasure directly in terms of the structures of the spaces in which the objects\nreside. As a result, the measure is defined relative to a set of maps that\ncharacterize the structures. It turns out that the measure is equivalent to\nKolmogorov complexity when it is defined relative to the maps characterizing\nthe structure of natural numbers. Thus, the formulation gives the larger class\nof objects a meaningful measure of information that generalizes Kolmogorov\ncomplexity.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2007 18:41:30 GMT"}, {"version": "v2", "created": "Thu, 12 Jun 2008 03:37:52 GMT"}], "update_date": "2008-06-12", "authors_parsed": [["Ishikawa", "Hiroshi", ""]]}
{"id": "0711.4656", "submitter": "Gun Srijuntongsiri", "authors": "Gun Srijuntongsiri, Stephen A. Vavasis", "title": "A condition number analysis of an algorithm for solving a system of\n  polynomial equations with one degree of freedom", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers the problem of solving a system of $n$ real polynomial\nequations in $n+1$ variables. We propose an algorithm based on Newton's method\nand subdivision for this problem. Our algorithm is intended only for\nnondegenerate cases, in which case the solution is a 1-dimensional curve. Our\nfirst main contribution is a definition of a condition number measuring\nreciprocal distance to degeneracy that can distinguish poor and well\nconditioned instances of this problem. (Degenerate problems would be infinitely\nill conditioned in our framework.) Our second contribution, which is the main\nnovelty of our algorithm, is an analysis showing that its running time is\nbounded in terms of the condition number of the problem instance as well as $n$\nand the polynomial degrees.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2007 06:02:16 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2009 04:08:32 GMT"}], "update_date": "2009-12-21", "authors_parsed": [["Srijuntongsiri", "Gun", ""], ["Vavasis", "Stephen A.", ""]]}
{"id": "0711.4759", "submitter": "Piotr Faliszewski", "authors": "Piotr Faliszewski, Edith Hemaspaandra, Lane A. Hemaspaandra, J\\\"org\n  Rothe", "title": "Copeland Voting Fully Resists Constructive Control", "comments": "15 pages, 1 table, 0 figures", "journal-ref": null, "doi": null, "report-no": "URCS-TR-923", "categories": "cs.GT cs.CC cs.MA", "license": null, "abstract": "  Control and bribery are settings in which an external agent seeks to\ninfluence the outcome of an election. Faliszewski et al. [FHHR07] proved that\nLlull voting (which is here denoted by Copeland^1) and a variant (here denoted\nby Copeland^0) of Copeland voting are computationally resistant to many, yet\nnot all, types of constructive control and that they also provide broad\nresistance to bribery. We study a parameterized version of Copeland voting,\ndenoted by Copeland^alpha where the parameter alpha is a rational number\nbetween 0 and 1 that specifies how ties are valued in the pairwise comparisons\nof candidates in Copeland elections. We establish resistance or vulnerability\nresults, in every previously studied control scenario, for Copeland^alpha, for\neach rational alpha, 0 <alpha < 1. In particular, we prove that Copeland^0.5,\nthe system commonly referred to as ``Copeland voting,'' provides full\nresistance to constructive control. Among the systems with a polynomial-time\nwinner problem, this is the first natural election system proven to have full\nresistance to constructive control. Results on bribery and fixed-parameter\ntractability of bounded-case control proven for Copeland^0 and Copeland^1 in\n[FHHR07] are extended to Copeland^alpha for each rational alpha, 0 < alpha < 1;\nwe also give results in more flexible models such as microbribery and extended\ncontrol.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2007 16:12:25 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2007 17:36:39 GMT"}], "update_date": "2007-12-10", "authors_parsed": [["Faliszewski", "Piotr", ""], ["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""], ["Rothe", "Jörg", ""]]}
{"id": "0711.4902", "submitter": "Mikko Alava", "authors": "Mikko Alava, John Ardelius, Erik Aurell, Petteri Kaski, Supriya\n  Krishnamurthy, Pekka Orponen, and Sakari Seitz", "title": "Circumspect descent prevails in solving random constraint satisfaction\n  problems", "comments": "6 figures, about 17 pates", "journal-ref": null, "doi": "10.1073/pnas.0712263105", "report-no": null, "categories": "cs.DS cond-mat.stat-mech cs.AI", "license": null, "abstract": "  We study the performance of stochastic local search algorithms for random\ninstances of the $K$-satisfiability ($K$-SAT) problem. We introduce a new\nstochastic local search algorithm, ChainSAT, which moves in the energy\nlandscape of a problem instance by {\\em never going upwards} in energy.\nChainSAT is a \\emph{focused} algorithm in the sense that it considers only\nvariables occurring in unsatisfied clauses. We show by extensive numerical\ninvestigations that ChainSAT and other focused algorithms solve large $K$-SAT\ninstances almost surely in linear time, up to high clause-to-variable ratios\n$\\alpha$; for example, for K=4 we observe linear-time performance well beyond\nthe recently postulated clustering and condensation transitions in the solution\nspace. The performance of ChainSAT is a surprise given that by design the\nalgorithm gets trapped into the first local energy minimum it encounters, yet\nno such minima are encountered. We also study the geometry of the solution\nspace as accessed by stochastic local search algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2007 11:01:40 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Alava", "Mikko", ""], ["Ardelius", "John", ""], ["Aurell", "Erik", ""], ["Kaski", "Petteri", ""], ["Krishnamurthy", "Supriya", ""], ["Orponen", "Pekka", ""], ["Seitz", "Sakari", ""]]}
{"id": "0711.4924", "submitter": "Piotr Faliszewski", "authors": "Piotr Faliszewski", "title": "Nonuniform Bribery", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": "URCS TR-2007-922", "categories": "cs.GT cs.CC cs.MA", "license": null, "abstract": "  We study the concept of bribery in the situation where voters are willing to\nchange their votes as we ask them, but where their prices depend on the nature\nof the change we request. Our model is an extension of the one of Faliszewski\net al. [FHH06], where each voter has a single price for any change we may ask\nfor. We show polynomial-time algorithms for our version of bribery for a broad\nrange of voting protocols, including plurality, veto, approval, and utility\nbased voting. In addition to our polynomial-time algorithms we provide\nNP-completeness results for a couple of our nonuniform bribery problems for\nweighted voters, and a couple of approximation algorithms for NP-complete\nbribery problems defined in [FHH06] (in particular, an FPTAS for\nplurality-weighted-$bribery problem).\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2007 12:47:35 GMT"}], "update_date": "2007-12-03", "authors_parsed": [["Faliszewski", "Piotr", ""]]}
{"id": "0712.0084", "submitter": "Gilles Champenois", "authors": "Gilles Champenois", "title": "From vectors to mnesors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mnesor theory is the adaptation of vectors to artificial intelligence.\nThe scalar field is replaced by a lattice. Addition becomes idempotent and\nmultiplication is interpreted as a selection operation. We also show that\nmnesors can be the foundation for a linear calculus.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2007 14:37:07 GMT"}, {"version": "v2", "created": "Thu, 8 May 2008 21:26:54 GMT"}, {"version": "v3", "created": "Wed, 23 Jul 2008 07:38:39 GMT"}, {"version": "v4", "created": "Sun, 24 May 2009 17:12:25 GMT"}], "update_date": "2009-05-24", "authors_parsed": [["Champenois", "Gilles", ""]]}
{"id": "0712.0165", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "On the Accepting Power of 2-Tape B\\\"uchi Automata", "comments": null, "journal-ref": "23rd International Symposium on Theoretical Aspects of Computer\n  Science, STACS 2006, France (2006)", "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": null, "abstract": "  We show that, from a topological point of view, 2-tape B\\\"uchi automata have\nthe same accepting power than Turing machines equipped with a B\\\"uchi\nacceptance condition. In particular, we show that for every non null recursive\nordinal alpha, there exist some Sigma^0_alpha-complete and some\nPi^0_alpha-complete infinitary rational relations accepted by 2-tape B\\\"uchi\nautomata. This very surprising result gives answers to questions of W. Thomas\n[Automata and Quantifier Hierarchies, in: Formal Properties of Finite automata\nand Applications, Ramatuelle, 1988, LNCS 386, Springer, 1989, p.104-119], of P.\nSimonnet [Automates et Th\\'eorie Descriptive, Ph. D. Thesis, Universit\\'e Paris\n7, March 1992], and of H. Lescow and W. Thomas [Logical Specifications of\nInfinite Computations, In: \"A Decade of Concurrency\", LNCS 803, Springer, 1994,\np. 583-621].\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2007 18:36:34 GMT"}], "update_date": "2007-12-04", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}
{"id": "0712.0171", "submitter": "Elchanan Mossel", "authors": "Amin Coja-Oghlan and Elchanan Mossel and Dan Vilenchik", "title": "A Spectral Approach to Analyzing Belief Propagation for 3-Coloring", "comments": null, "journal-ref": "Combinatorics, Probability and Computing 18 (2009) 881 - 912", "doi": "10.1017/S096354830900981X", "report-no": null, "categories": "cs.CC cs.AI cs.DM", "license": null, "abstract": "  Contributing to the rigorous understanding of BP, in this paper we relate the\nconvergence of BP to spectral properties of the graph. This encompasses a\nresult for random graphs with a ``planted'' solution; thus, we obtain the first\nrigorous result on BP for graph coloring in the case of a complex graphical\nstructure (as opposed to trees). In particular, the analysis shows how Belief\nPropagation breaks the symmetry between the $3!$ possible permutations of the\ncolor classes.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2007 19:34:59 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Coja-Oghlan", "Amin", ""], ["Mossel", "Elchanan", ""], ["Vilenchik", "Dan", ""]]}
{"id": "0712.0171", "submitter": "Elchanan Mossel", "authors": "Amin Coja-Oghlan and Elchanan Mossel and Dan Vilenchik", "title": "A Spectral Approach to Analyzing Belief Propagation for 3-Coloring", "comments": null, "journal-ref": "Combinatorics, Probability and Computing 18 (2009) 881 - 912", "doi": "10.1017/S096354830900981X", "report-no": null, "categories": "cs.CC cs.AI cs.DM", "license": null, "abstract": "  Contributing to the rigorous understanding of BP, in this paper we relate the\nconvergence of BP to spectral properties of the graph. This encompasses a\nresult for random graphs with a ``planted'' solution; thus, we obtain the first\nrigorous result on BP for graph coloring in the case of a complex graphical\nstructure (as opposed to trees). In particular, the analysis shows how Belief\nPropagation breaks the symmetry between the $3!$ possible permutations of the\ncolor classes.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2007 19:34:59 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Coja-Oghlan", "Amin", ""], ["Mossel", "Elchanan", ""], ["Vilenchik", "Dan", ""]]}
{"id": "0712.0451", "submitter": "Alejandro Chinea Manrique De Lara", "authors": "Alejandro Chinea Manrique De Lara", "title": "A Reactive Tabu Search Algorithm for Stimuli Generation in\n  Psycholinguistics", "comments": "Artificial Intelligence in Science and Technology AISAT 2004\n  Conference. 8 pages, 5 figures, 3 tables", "journal-ref": "Artificial Intelligence in Science and Technology AISAT 2004\n  Conference", "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DM cs.LG", "license": null, "abstract": "  The generation of meaningless \"words\" matching certain statistical and/or\nlinguistic criteria is frequently needed for experimental purposes in\nPsycholinguistics. Such stimuli receive the name of pseudowords or nonwords in\nthe Cognitive Neuroscience literatue. The process for building nonwords\nsometimes has to be based on linguistic units such as syllables or morphemes,\nresulting in a numerical explosion of combinations when the size of the\nnonwords is increased. In this paper, a reactive tabu search scheme is proposed\nto generate nonwords of variables size. The approach builds pseudowords by\nusing a modified Metaheuristic algorithm based on a local search procedure\nenhanced by a feedback-based scheme. Experimental results show that the new\nalgorithm is a practical and effective tool for nonword generation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2007 08:52:46 GMT"}], "update_date": "2007-12-05", "authors_parsed": [["De Lara", "Alejandro Chinea Manrique", ""]]}
{"id": "0712.0451", "submitter": "Alejandro Chinea Manrique De Lara", "authors": "Alejandro Chinea Manrique De Lara", "title": "A Reactive Tabu Search Algorithm for Stimuli Generation in\n  Psycholinguistics", "comments": "Artificial Intelligence in Science and Technology AISAT 2004\n  Conference. 8 pages, 5 figures, 3 tables", "journal-ref": "Artificial Intelligence in Science and Technology AISAT 2004\n  Conference", "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DM cs.LG", "license": null, "abstract": "  The generation of meaningless \"words\" matching certain statistical and/or\nlinguistic criteria is frequently needed for experimental purposes in\nPsycholinguistics. Such stimuli receive the name of pseudowords or nonwords in\nthe Cognitive Neuroscience literatue. The process for building nonwords\nsometimes has to be based on linguistic units such as syllables or morphemes,\nresulting in a numerical explosion of combinations when the size of the\nnonwords is increased. In this paper, a reactive tabu search scheme is proposed\nto generate nonwords of variables size. The approach builds pseudowords by\nusing a modified Metaheuristic algorithm based on a local search procedure\nenhanced by a feedback-based scheme. Experimental results show that the new\nalgorithm is a practical and effective tool for nonword generation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2007 08:52:46 GMT"}], "update_date": "2007-12-05", "authors_parsed": [["De Lara", "Alejandro Chinea Manrique", ""]]}
{"id": "0712.0554", "submitter": "Mathieu Couture", "authors": "Prosenjit Bose, Paz Carmi, Mathieu Couture, Anil Maheshwari, Pat\n  Morin, Michiel Smid", "title": "Spanners of Complete $k$-Partite Geometric Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  We address the following problem: Given a complete $k$-partite geometric\ngraph $K$ whose vertex set is a set of $n$ points in $\\mathbb{R}^d$, compute a\nspanner of $K$ that has a ``small'' stretch factor and ``few'' edges. We\npresent two algorithms for this problem. The first algorithm computes a\n$(5+\\epsilon)$-spanner of $K$ with O(n) edges in $O(n \\log n)$ time. The second\nalgorithm computes a $(3+\\epsilon)$-spanner of $K$ with $O(n \\log n)$ edges in\n$O(n \\log n)$ time. The latter result is optimal: We show that for any $2 \\leq\nk \\leq n - \\Theta(\\sqrt{n \\log n})$, spanners with $O(n \\log n)$ edges and\nstretch factor less than 3 do not exist for all complete $k$-partite geometric\ngraphs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2007 16:14:07 GMT"}], "update_date": "2007-12-05", "authors_parsed": [["Bose", "Prosenjit", ""], ["Carmi", "Paz", ""], ["Couture", "Mathieu", ""], ["Maheshwari", "Anil", ""], ["Morin", "Pat", ""], ["Smid", "Michiel", ""]]}
{"id": "0712.0744", "submitter": "Vitorino Ramos Dr.", "authors": "Vitorino Ramos, C. M. Fernandes, A. C. Rosa, A. Abraham", "title": "Computational Chemotaxis in Ants and Bacteria over Dynamic Environments", "comments": "8 pages, 6 figures, in CEC 07 - IEEE Congress on Evolutionary\n  Computation, ISBN 1-4244-1340-0, pp. 1009-1017, Sep. 2007", "journal-ref": null, "doi": "10.1109/CEC.2007.4424594", "report-no": null, "categories": "cs.MA cs.AI q-bio.PE q-bio.QM", "license": null, "abstract": "  Chemotaxis can be defined as an innate behavioural response by an organism to\na directional stimulus, in which bacteria, and other single-cell or\nmulticellular organisms direct their movements according to certain chemicals\nin their environment. This is important for bacteria to find food (e.g.,\nglucose) by swimming towards the highest concentration of food molecules, or to\nflee from poisons. Based on self-organized computational approaches and similar\nstigmergic concepts we derive a novel swarm intelligent algorithm. What strikes\nfrom these observations is that both eusocial insects as ant colonies and\nbacteria have similar natural mechanisms based on stigmergy in order to emerge\ncoherent and sophisticated patterns of global collective behaviour. Keeping in\nmind the above characteristics we will present a simple model to tackle the\ncollective adaptation of a social swarm based on real ant colony behaviors (SSA\nalgorithm) for tracking extrema in dynamic environments and highly multimodal\ncomplex functions described in the well-know De Jong test suite. Later, for the\npurpose of comparison, a recent model of artificial bacterial foraging (BFOA\nalgorithm) based on similar stigmergic features is described and analyzed.\nFinal results indicate that the SSA collective intelligence is able to cope and\nquickly adapt to unforeseen situations even when over the same cooperative\nforaging period, the community is requested to deal with two different and\ncontradictory purposes, while outperforming BFOA in adaptive speed. Results\nindicate that the present approach deals well in severe Dynamic Optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2007 15:02:19 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Ramos", "Vitorino", ""], ["Fernandes", "C. M.", ""], ["Rosa", "A. C.", ""], ["Abraham", "A.", ""]]}
{"id": "0712.0836", "submitter": "Andrew Adamatzky", "authors": "Andrew Adamatzky, Larry Bull, Pierre Collet, Emmanuel Sapin", "title": "Evolving localizations in reaction-diffusion cellular automata", "comments": "Accepted for publication in Int. J. Modern Physics C", "journal-ref": "International Journal of Modern Physics C (IJMPC) Volume: 19,\n  Issue: 4 (April 2008) pp. 557-567", "doi": "10.1142/S0129183108012376", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  We consider hexagonal cellular automata with immediate cell neighbourhood and\nthree cell-states. Every cell calculates its next state depending on the\nintegral representation of states in its neighbourhood, i.e. how many\nneighbours are in each one state. We employ evolutionary algorithms to breed\nlocal transition functions that support mobile localizations (gliders), and\ncharacterize sets of the functions selected in terms of quasi-chemical systems.\nAnalysis of the set of functions evolved allows to speculate that mobile\nlocalizations are likely to emerge in the quasi-chemical systems with limited\ndiffusion of one reagent, a small number of molecules is required for\namplification of travelling localizations, and reactions leading to stationary\nlocalizations involve relatively equal amount of quasi-chemical species.\nTechniques developed can be applied in cascading signals in nature-inspired\nspatially extended computing devices, and phenomenological studies and\nclassification of non-linear discrete systems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2007 22:07:04 GMT"}], "update_date": "2010-11-23", "authors_parsed": [["Adamatzky", "Andrew", ""], ["Bull", "Larry", ""], ["Collet", "Pierre", ""], ["Sapin", "Emmanuel", ""]]}
{"id": "0712.0932", "submitter": "Kumar Eswaran Dr.", "authors": "Dasika Ratna Deepthi, Sujeet Kuchibhotla and K.Eswaran", "title": "Dimensionality Reduction and Reconstruction using Mirroring Neural\n  Networks and Object Recognition based on Reduced Dimension Characteristic\n  Vector", "comments": "Presented in IEEE International Conference on Advances in Computer\n  Vision and Information Technology (ACVIT-07), Nov. 28-30 2007", "journal-ref": "IEEE International Conference On Advances in Computer Vision and\n  Information Tech. (IEEE, ACVIT-07), pp. 348 - 353 (2007)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": null, "abstract": "  In this paper, we present a Mirroring Neural Network architecture to perform\nnon-linear dimensionality reduction and Object Recognition using a reduced\nlowdimensional characteristic vector. In addition to dimensionality reduction,\nthe network also reconstructs (mirrors) the original high-dimensional input\nvector from the reduced low-dimensional data. The Mirroring Neural Network\narchitecture has more number of processing elements (adalines) in the outer\nlayers and the least number of elements in the central layer to form a\nconverging-diverging shape in its configuration. Since this network is able to\nreconstruct the original image from the output of the innermost layer (which\ncontains all the information about the input pattern), these outputs can be\nused as object signature to classify patterns. The network is trained to\nminimize the discrepancy between actual output and the input by back\npropagating the mean squared error from the output layer to the input layer.\nAfter successfully training the network, it can reduce the dimension of input\nvectors and mirror the patterns fed to it. The Mirroring Neural Network\narchitecture gave very good results on various test patterns.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 14:11:07 GMT"}], "update_date": "2008-12-13", "authors_parsed": [["Deepthi", "Dasika Ratna", ""], ["Kuchibhotla", "Sujeet", ""], ["Eswaran", "K.", ""]]}
{"id": "0712.0938", "submitter": "Kumar Eswaran Dr.", "authors": "Dasika Ratna Deepthi, G.R.Aditya Krishna and K. Eswaran", "title": "Automatic Pattern Classification by Unsupervised Learning Using\n  Dimensionality Reduction of Data with Mirroring Neural Networks", "comments": "Presented in IEEE International Conference on Advances in Computer\n  Vision and Information Technology (ACVIT-07), Nov. 28-30 2007", "journal-ref": "IEEE International Conference on Advances in Computer Vision and\n  Information Tech. (IEEE, ACVIT-07), pp. 354 - 360 (2007)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": null, "abstract": "  This paper proposes an unsupervised learning technique by using Multi-layer\nMirroring Neural Network and Forgy's clustering algorithm. Multi-layer\nMirroring Neural Network is a neural network that can be trained with\ngeneralized data inputs (different categories of image patterns) to perform\nnon-linear dimensionality reduction and the resultant low-dimensional code is\nused for unsupervised pattern classification using Forgy's algorithm. By\nadapting the non-linear activation function (modified sigmoidal function) and\ninitializing the weights and bias terms to small random values, mirroring of\nthe input pattern is initiated. In training, the weights and bias terms are\nchanged in such a way that the input presented is reproduced at the output by\nback propagating the error. The mirroring neural network is capable of reducing\nthe input vector to a great degree (approximately 1/30th the original size) and\nalso able to reconstruct the input pattern at the output layer from this\nreduced code units. The feature set (output of central hidden layer) extracted\nfrom this network is fed to Forgy's algorithm, which classify input data\npatterns into distinguishable classes. In the implementation of Forgy's\nalgorithm, initial seed points are selected in such a way that they are distant\nenough to be perfectly grouped into different categories. Thus a new method of\nunsupervised learning is formulated and demonstrated in this paper. This method\ngave impressive results when applied to classification of different image\npatterns.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 13:52:04 GMT"}], "update_date": "2008-12-15", "authors_parsed": [["Deepthi", "Dasika Ratna", ""], ["Krishna", "G. R. Aditya", ""], ["Eswaran", "K.", ""]]}
{"id": "0712.0948", "submitter": "Stefan Woltran", "authors": "Stefan Woltran", "title": "A Common View on Strong, Uniform, and Other Notions of Equivalence in\n  Answer-Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  Logic programming under the answer-set semantics nowadays deals with numerous\ndifferent notions of program equivalence. This is due to the fact that\nequivalence for substitution (known as strong equivalence) and ordinary\nequivalence are different concepts. The former holds, given programs P and Q,\niff P can be faithfully replaced by Q within any context R, while the latter\nholds iff P and Q provide the same output, that is, they have the same answer\nsets. Notions in between strong and ordinary equivalence have been introduced\nas theoretical tools to compare incomplete programs and are defined by either\nrestricting the syntactic structure of the considered context programs R or by\nbounding the set A of atoms allowed to occur in R (relativized equivalence).For\nthe latter approach, different A yield properly different equivalence notions,\nin general. For the former approach, however, it turned out that any\n``reasonable'' syntactic restriction to R coincides with either ordinary,\nstrong, or uniform equivalence. In this paper, we propose a parameterization\nfor equivalence notions which takes care of both such kinds of restrictions\nsimultaneously by bounding, on the one hand, the atoms which are allowed to\noccur in the rule heads of the context and, on the other hand, the atoms which\nare allowed to occur in the rule bodies of the context. We introduce a general\nsemantical characterization which includes known ones as SE-models (for strong\nequivalence) or UE-models (for uniform equivalence) as special cases.\nMoreover,we provide complexity bounds for the problem in question and sketch a\npossible implementation method.\n  To appear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 14:26:42 GMT"}], "update_date": "2007-12-07", "authors_parsed": [["Woltran", "Stefan", ""]]}
{"id": "0712.1097", "submitter": "Joao Marques-Silva", "authors": "Joao Marques-Silva, Jordi Planes", "title": "On Using Unsatisfiability for Solving Maximum Satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": null, "abstract": "  Maximum Satisfiability (MaxSAT) is a well-known optimization pro- blem, with\nseveral practical applications. The most widely known MAXS AT algorithms are\nineffective at solving hard problems instances from practical application\ndomains. Recent work proposed using efficient Boolean Satisfiability (SAT)\nsolvers for solving the MaxSAT problem, based on identifying and eliminating\nunsatisfiable subformulas. However, these algorithms do not scale in practice.\nThis paper analyzes existing MaxSAT algorithms based on unsatisfiable\nsubformula identification. Moreover, the paper proposes a number of key\noptimizations to these MaxSAT algorithms and a new alternative algorithm. The\nproposed optimizations and the new algorithm provide significant performance\nimprovements on MaxSAT instances from practical applications. Moreover, the\nefficiency of the new generation of unsatisfiability-based MaxSAT solvers\nbecomes effectively indexed to the ability of modern SAT solvers to proving\nunsatisfiability and identifying unsatisfiable subformulas.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 09:21:58 GMT"}], "update_date": "2007-12-10", "authors_parsed": [["Marques-Silva", "Joao", ""], ["Planes", "Jordi", ""]]}
{"id": "0712.1167", "submitter": "Felipe Fran\\c{c}a", "authors": "Leandro A. J. Marzulo, Felipe M. G. Fran\\c{c}a and V\\'itor Santos\n  Costa", "title": "Transactional WaveCache: Towards Speculative and Out-of-Order DataFlow\n  Execution of Memory Operations", "comments": "Submitted to ACM International Conference on Computing Frontiers\n  2008, http://www.computingfrontiers.org/, 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": null, "abstract": "  The WaveScalar is the first DataFlow Architecture that can efficiently\nprovide the sequential memory semantics required by imperative languages. This\nwork presents an alternative memory ordering mechanism for this architecture,\nthe Transaction WaveCache. Our mechanism maintains the execution order of\nmemory operations within blocks of code, called Waves, but adds the ability to\nspeculatively execute, out-of-order, operations from different waves. This\nordering mechanism is inspired by progress in supporting Transactional\nMemories. Waves are considered as atomic regions and executed as nested\ntransactions. If a wave has finished the execution of all its memory\noperations, as soon as the previous waves are committed, it can be committed.\nIf a hazard is detected in a speculative Wave, all the following Waves\n(children) are aborted and re-executed. We evaluate the WaveCache on a set\nartificial benchmarks. If the benchmark does not access memory often, we could\nachieve speedups of around 90%. Speedups of 33.1% and 24% were observed on more\nmemory intensive applications, and slowdowns up to 16% arise if memory\nbandwidth is a bottleneck. For an application full of WAW, WAR and RAW hazards,\na speedup of 139.7% was verified.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 15:59:37 GMT"}], "update_date": "2007-12-10", "authors_parsed": [["Marzulo", "Leandro A. J.", ""], ["França", "Felipe M. G.", ""], ["Costa", "Vítor Santos", ""]]}
{"id": "0712.1182", "submitter": "Audun Josang", "authors": "Audun Josang", "title": "Cumulative and Averaging Fission of Beliefs", "comments": "7 pages, 4 figures, working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  Belief fusion is the principle of combining separate beliefs or bodies of\nevidence originating from different sources. Depending on the situation to be\nmodelled, different belief fusion methods can be applied. Cumulative and\naveraging belief fusion is defined for fusing opinions in subjective logic, and\nfor fusing belief functions in general. The principle of fission is the\nopposite of fusion, namely to eliminate the contribution of a specific belief\nfrom an already fused belief, with the purpose of deriving the remaining\nbelief. This paper describes fission of cumulative belief as well as fission of\naveraging belief in subjective logic. These operators can for example be\napplied to belief revision in Bayesian belief networks, where the belief\ncontribution of a given evidence source can be determined as a function of a\ngiven fused belief and its other contributing beliefs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 16:42:07 GMT"}], "update_date": "2007-12-10", "authors_parsed": [["Josang", "Audun", ""]]}
{"id": "0712.1310", "submitter": "Lev Cherbanski Dr.", "authors": "Lev Cherbanski", "title": "About Algorithm for Transformation of Logic Functions (ATLF)", "comments": "25 pages, in English, German and Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": null, "abstract": "  In this article the algorithm for transformation of logic functions which are\ngiven by truth tables is considered. The suggested algorithm allows the\ntransformation of many-valued logic functions with the required number of\nvariables and can be looked in this sense as universal.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2007 22:36:44 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Cherbanski", "Lev", ""]]}
{"id": "0712.1345", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "Sequential operators in computability logic", "comments": "To appear in \"Information and Computation\"", "journal-ref": "Information and Computation 206 (2008), pp. 1443-1475", "doi": "10.1016/j.ic.2008.10.001", "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computability logic (CL) (see http://www.cis.upenn.edu/~giorgi/cl.html) is a\nsemantical platform and research program for redeveloping logic as a formal\ntheory of computability, as opposed to the formal theory of truth which it has\nmore traditionally been. Formulas in CL stand for (interactive) computational\nproblems, understood as games between a machine and its environment; logical\noperators represent operations on such entities; and \"truth\" is understood as\nexistence of an effective solution, i.e., of an algorithmic winning strategy.\n  The formalism of CL is open-ended, and may undergo series of extensions as\nthe study of the subject advances. The main groups of operators on which CL has\nbeen focused so far are the parallel, choice, branching, and blind operators.\nThe present paper introduces a new important group of operators, called\nsequential. The latter come in the form of sequential conjunction and\ndisjunction, sequential quantifiers, and sequential recurrences. As the name\nmay suggest, the algorithmic intuitions associated with this group are those of\nsequential computations, as opposed to the intuitions of parallel computations\nassociated with the parallel group of operations: playing a sequential\ncombination of games means playing its components in a sequential fashion, one\nafter one.\n  The main technical result of the present paper is a sound and complete\naxiomatization of the propositional fragment of computability logic whose\nvocabulary, together with negation, includes all three -- parallel, choice and\nsequential -- sorts of conjunction and disjunction. An extension of this result\nto the first-order level is also outlined.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2007 16:59:35 GMT"}, {"version": "v2", "created": "Wed, 15 Oct 2008 07:44:55 GMT"}], "update_date": "2011-04-15", "authors_parsed": [["Japaridze", "Giorgi", ""]]}
{"id": "0712.1363", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "Undecidable Problems About Timed Automata", "comments": null, "journal-ref": "Dans Proceedings of the 4th International Conference on Formal\n  Modelling and Analysis of Timed Systems - FORMATS'06, France (2006)", "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": null, "abstract": "  We solve some decision problems for timed automata which were recently raised\nby S. Tripakis in [ Folk Theorems on the Determinization and Minimization of\nTimed Automata, in the Proceedings of the International Workshop FORMATS'2003,\nLNCS, Volume 2791, p. 182-188, 2004 ] and by E. Asarin in [ Challenges in Timed\nLanguages, From Applied Theory to Basic Theory, Bulletin of the EATCS, Volume\n83, p. 106-120, 2004 ]. In particular, we show that one cannot decide whether a\ngiven timed automaton is determinizable or whether the complement of a timed\nregular language is timed regular. We show that the problem of the minimization\nof the number of clocks of a timed automaton is undecidable. It is also\nundecidable whether the shuffle of two timed regular languages is timed\nregular. We show that in the case of timed B\\\"uchi automata accepting infinite\ntimed words some of these problems are Pi^1_1-hard, hence highly undecidable\n(located beyond the arithmetical hierarchy).\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2007 20:11:42 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}
{"id": "0712.1365", "submitter": "Alexei Vazquez", "authors": "Alexei Vazquez", "title": "Population stratification using a statistical model on hypergraphs", "comments": "7 pages, 6 figures", "journal-ref": "Phys. Rev. E 77, 066106 (2008)", "doi": "10.1103/PhysRevE.77.066106", "report-no": null, "categories": "q-bio.PE cs.AI physics.data-an", "license": null, "abstract": "  Population stratification is a problem encountered in several areas of\nbiology and public health. We tackle this problem by mapping a population and\nits elements attributes into a hypergraph, a natural extension of the concept\nof graph or network to encode associations among any number of elements. On\nthis hypergraph, we construct a statistical model reflecting our intuition\nabout how the elements attributes can emerge from a postulated population\nstructure. Finally, we introduce the concept of stratification\nrepresentativeness as a mean to identify the simplest stratification already\ncontaining most of the information about the population structure. We\ndemonstrate the power of this framework stratifying an animal and a human\npopulation based on phenotypic and genotypic properties, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2007 20:53:45 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Vazquez", "Alexei", ""]]}
{"id": "0712.1402", "submitter": "Allan Sly", "authors": "Guy Bresler, Elchanan Mossel, Allan Sly", "title": "Reconstruction of Markov Random Fields from Samples: Some Easy\n  Observations and Algorithms", "comments": "14 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov random fields are used to model high dimensional distributions in a\nnumber of applied areas. Much recent interest has been devoted to the\nreconstruction of the dependency structure from independent samples from the\nMarkov random fields. We analyze a simple algorithm for reconstructing the\nunderlying graph defining a Markov random field on $n$ nodes and maximum degree\n$d$ given observations. We show that under mild non-degeneracy conditions it\nreconstructs the generating graph with high probability using $\\Theta(d\n\\epsilon^{-2}\\delta^{-4} \\log n)$ samples where $\\epsilon,\\delta$ depend on the\nlocal interactions. For most local interaction $\\eps,\\delta$ are of order\n$\\exp(-O(d))$.\n  Our results are optimal as a function of $n$ up to a multiplicative constant\ndepending on $d$ and the strength of the local interactions. Our results seem\nto be the first results for general models that guarantee that {\\em the}\ngenerating model is reconstructed. Furthermore, we provide explicit $O(n^{d+2}\n\\epsilon^{-2}\\delta^{-4} \\log n)$ running time bound. In cases where the\nmeasure on the graph has correlation decay, the running time is $O(n^2 \\log n)$\nfor all fixed $d$. We also discuss the effect of observing noisy samples and\nshow that as long as the noise level is low, our algorithm is effective. On the\nother hand, we construct an example where large noise implies\nnon-identifiability even for generic noise and interactions. Finally, we\nbriefly show that in some simple cases, models with hidden nodes can also be\nrecovered.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 06:50:36 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2010 19:30:26 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Bresler", "Guy", ""], ["Mossel", "Elchanan", ""], ["Sly", "Allan", ""]]}
{"id": "0712.1499", "submitter": "Klaus Aehlig", "authors": "Klaus Aehlig, Arnold Beckmann", "title": "On the computational complexity of cut-reduction", "comments": "41 pages, technical report (CS, Swansea University)", "journal-ref": null, "doi": null, "report-no": "CSR15-2007", "categories": "cs.LO cs.CC", "license": null, "abstract": "  Using appropriate notation systems for proofs, cut-reduction can often be\nrendered feasible on these notations, and explicit bounds can be given.\nDeveloping a suitable notation system for Bounded Arithmetic, and applying\nthese bounds, all the known results on definable functions of certain such\ntheories can be reobtained in a uniform way.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 14:58:27 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Aehlig", "Klaus", ""], ["Beckmann", "Arnold", ""]]}
{"id": "0712.1529", "submitter": "W Saba", "authors": "Walid S. Saba", "title": "Ontology and Formal Semantics - Integration Overdue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": null, "abstract": "  In this note we suggest that difficulties encountered in natural language\nsemantics are, for the most part, due to the use of mere symbol manipulation\nsystems that are devoid of any content. In such systems, where there is hardly\nany link with our common-sense view of the world, and it is quite difficult to\nenvision how one can formally account for the considerable amount of content\nthat is often implicit, but almost never explicitly stated in our everyday\ndiscourse. The solution, in our opinion, is a compositional semantics grounded\nin an ontology that reflects our commonsense view of the world and the way we\ntalk about it in ordinary language. In the compositional logic we envision\nthere are ontological (or first-intension) concepts, and logical (or\nsecond-intension) concepts, and where the ontological concepts include not only\nDavidsonian events, but other abstract objects as well (e.g., states,\nprocesses, properties, activities, attributes, etc.) It will be demonstrated\nhere that in such a framework, a number of challenges in the semantics of\nnatural language (e.g., metonymy, intensionality, metaphor, etc.) can be\nproperly and uniformly addressed.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2007 14:27:12 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2007 20:25:26 GMT"}], "update_date": "2007-12-13", "authors_parsed": [["Saba", "Walid S.", ""]]}
{"id": "0712.1532", "submitter": "Peter Jonsson", "authors": "Peter Jonsson, Andrei Krokhin, Fredrik Kuivinen", "title": "Hard constraint satisfaction problems have hard gaps at location 1", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  An instance of Max CSP is a finite collection of constraints on a set of\nvariables, and the goal is to assign values to the variables that maximises the\nnumber of satisfied constraints. Max CSP captures many well-known problems\n(such as Max k-SAT and Max Cut) and is consequently NP-hard. Thus, it is\nnatural to study how restrictions on the allowed constraint types (or\nconstraint languages) affect the complexity and approximability of Max CSP. The\nPCP theorem is equivalent to the existence of a constraint language for which\nMax CSP has a hard gap at location 1, i.e. it is NP-hard to distinguish between\nsatisfiable instances and instances where at most some constant fraction of the\nconstraints are satisfiable. All constraint languages, for which the CSP\nproblem (i.e., the problem of deciding whether all constraints can be\nsatisfied) is currently known to be NP-hard, have a certain algebraic property.\nWe prove that any constraint language with this algebraic property makes Max\nCSP have a hard gap at location 1 which, in particular, implies that such\nproblems cannot have a PTAS unless P = NP. We then apply this result to Max CSP\nrestricted to a single constraint type; this class of problems contains, for\ninstance, Max Cut and Max DiCut. Assuming P $\\neq$ NP, we show that such\nproblems do not admit PTAS except in some trivial cases. Our results hold even\nif the number of occurrences of each variable is bounded by a constant. We use\nthese results to partially answer open questions and strengthen results by\nEngebretsen et al. [Theor. Comput. Sci., 312 (2004), pp. 17--45], Feder et al.\n[Discrete Math., 307 (2007), pp. 386--392], Krokhin and Larose [Proc.\nPrinciples and Practice of Constraint Programming (2005), pp. 388--402], and\nJonsson and Krokhin [J. Comput. System Sci., 73 (2007), pp. 691--702]\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 16:42:18 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Jonsson", "Peter", ""], ["Krokhin", "Andrei", ""], ["Kuivinen", "Fredrik", ""]]}
{"id": "0712.1959", "submitter": "Tamal Dey", "authors": "Siu-Wing Cheng and Tamal K. Dey", "title": "Delaunay Edge Flips in Dense Surface Triangulations", "comments": "This paper is prelude to \"Maintaining Deforming Surface Meshes\" by\n  Cheng-Dey in SODA 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": null, "abstract": "  Delaunay flip is an elegant, simple tool to convert a triangulation of a\npoint set to its Delaunay triangulation. The technique has been researched\nextensively for full dimensional triangulations of point sets. However, an\nimportant case of triangulations which are not full dimensional is surface\ntriangulations in three dimensions. In this paper we address the question of\nconverting a surface triangulation to a subcomplex of the Delaunay\ntriangulation with edge flips. We show that the surface triangulations which\nclosely approximate a smooth surface with uniform density can be transformed to\na Delaunay triangulation with a simple edge flip algorithm. The condition on\nuniformity becomes less stringent with increasing density of the triangulation.\nIf the condition is dropped completely, the flip algorithm still terminates\nalthough the output surface triangulation becomes \"almost Delaunay\" instead of\nexactly Delaunay.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2007 15:45:53 GMT"}], "update_date": "2007-12-13", "authors_parsed": [["Cheng", "Siu-Wing", ""], ["Dey", "Tamal K.", ""]]}
{"id": "0712.1996", "submitter": "Walied Othman", "authors": "Bart Kuijpers, Walied Othman, Rafael Grimson", "title": "A case study of the difficulty of quantifier elimination in constraint\n  databases: the alibi query in moving object databases", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DB", "license": null, "abstract": "  In the constraint database model, spatial and spatio-temporal data are stored\nby boolean combinations of polynomial equalities and inequalities over the real\nnumbers. The relational calculus augmented with polynomial constraints is the\nstandard first-order query language for constraint databases. Although the\nexpressive power of this query language has been studied extensively, the\ndifficulty of the efficient evaluation of queries, usually involving some form\nof quantifier elimination, has received considerably less attention. The\ninefficiency of existing quantifier-elimination software and the intrinsic\ndifficulty of quantifier elimination have proven to be a bottle-neck for for\nreal-world implementations of constraint database systems. In this paper, we\nfocus on a particular query, called the \\emph{alibi query}, that asks whether\ntwo moving objects whose positions are known at certain moments in time, could\nhave possibly met, given certain speed constraints. This query can be seen as a\nconstraint database query and its evaluation relies on the elimination of a\nblock of three existential quantifiers. Implementations of general purpose\nelimination algorithms are in the specific case, for practical purposes, too\nslow in answering the alibi query and fail completely in the parametric case.\nThe main contribution of this paper is an analytical solution to the parametric\nalibi query, which can be used to answer this query in the specific case in\nconstant time. We also give an analytic solution to the alibi query at a fixed\nmoment in time. The solutions we propose are based on geometric argumentation\nand they illustrate the fact that some practical problems require creative\nsolutions, where at least in theory, existing systems could provide a solution.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2007 18:05:41 GMT"}], "update_date": "2007-12-13", "authors_parsed": [["Kuijpers", "Bart", ""], ["Othman", "Walied", ""], ["Grimson", "Rafael", ""]]}
{"id": "0712.2094", "submitter": "Zachary Abel", "authors": "Timothy G. Abbott, Zachary Abel, David Charlton, Erik D. Demaine,\n  Martin L. Demaine, Scott D. Kominers", "title": "Hinged Dissections Exist", "comments": "22 pages, 14 figures", "journal-ref": "Proceedings of the Twenty-fourth Annual Symposium on Computational\n  Geometry (2008): 110-119.", "doi": "10.1145/1377676.1377695", "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  We prove that any finite collection of polygons of equal area has a common\nhinged dissection. That is, for any such collection of polygons there exists a\nchain of polygons hinged at vertices that can be folded in the plane\ncontinuously without self-intersection to form any polygon in the collection.\nThis result settles the open problem about the existence of hinged dissections\nbetween pairs of polygons that goes back implicitly to 1864 and has been\nstudied extensively in the past ten years. Our result generalizes and indeed\nbuilds upon the result from 1814 that polygons have common dissections (without\nhinges). We also extend our common dissection result to edge-hinged dissections\nof solid 3D polyhedra that have a common (unhinged) dissection, as determined\nby Dehn's 1900 solution to Hilbert's Third Problem. Our proofs are\nconstructive, giving explicit algorithms in all cases. For a constant number of\nplanar polygons, both the number of pieces and running time required by our\nconstruction are pseudopolynomial. This bound is the best possible, even for\nunhinged dissections. Hinged dissections have possible applications to\nreconfigurable robotics, programmable matter, and nanomanufacturing.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 04:43:10 GMT"}], "update_date": "2008-06-12", "authors_parsed": [["Abbott", "Timothy G.", ""], ["Abel", "Zachary", ""], ["Charlton", "David", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Kominers", "Scott D.", ""]]}
{"id": "0712.2141", "submitter": "Sebastien Destercke", "authors": "Eric Chojnacki (IRSN), Jean Baccou (IRSN), S\\'ebastien Destercke\n  (IRSN, IRIT)", "title": "Numerical Sensitivity and Efficiency in the Treatment of Epistemic and\n  Aleatory Uncertainty", "comments": null, "journal-ref": "Fifth International Conference on Sensitivity Analysis of Model\n  Output, Budapest : Hongrie (2007)", "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": null, "abstract": "  The treatment of both aleatory and epistemic uncertainty by recent methods\noften requires an high computational effort. In this abstract, we propose a\nnumerical sampling method allowing to lighten the computational burden of\ntreating the information by means of so-called fuzzy random variables.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 12:49:30 GMT"}], "update_date": "2007-12-14", "authors_parsed": [["Chojnacki", "Eric", "", "IRSN"], ["Baccou", "Jean", "", "IRSN"], ["Destercke", "Sébastien", "", "IRSN, IRIT"]]}
{"id": "0712.2255", "submitter": "Ian T Foster", "authors": "Ian Foster", "title": "Human-Machine Symbiosis, 50 Years On", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.HC", "license": null, "abstract": "  Licklider advocated in 1960 the construction of computers capable of working\nsymbiotically with humans to address problems not easily addressed by humans\nworking alone. Since that time, many of the advances that he envisioned have\nbeen achieved, yet the time spent by human problem solvers in mundane\nactivities remains large. I propose here four areas in which improved tools can\nfurther advance the goal of enhancing human intellect: services, provenance,\nknowledge communities, and automation of problem-solving protocols.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 23:00:37 GMT"}], "update_date": "2007-12-17", "authors_parsed": [["Foster", "Ian", ""]]}
{"id": "0712.2262", "submitter": "Ian T Foster", "authors": "David Bernholdt, Shishir Bharathi, David Brown, Kasidit Chanchio,\n  Meili Chen, Ann Chervenak, Luca Cinquini, Bob Drach, Ian Foster, Peter Fox,\n  Jose Garcia, Carl Kesselman, Rob Markel, Don Middleton, Veronika Nefedova,\n  Line Pouchard, Arie Shoshani, Alex Sim, Gary Strand, Dean Williams", "title": "The Earth System Grid: Supporting the Next Generation of Climate\n  Modeling Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.NI", "license": null, "abstract": "  Understanding the earth's climate system and how it might be changing is a\npreeminent scientific challenge. Global climate models are used to simulate\npast, present, and future climates, and experiments are executed continuously\non an array of distributed supercomputers. The resulting data archive, spread\nover several sites, currently contains upwards of 100 TB of simulation data and\nis growing rapidly. Looking toward mid-decade and beyond, we must anticipate\nand prepare for distributed climate research data holdings of many petabytes.\nThe Earth System Grid (ESG) is a collaborative interdisciplinary project aimed\nat addressing the challenge of enabling management, discovery, access, and\nanalysis of these critically important datasets in a distributed and\nheterogeneous computational environment. The problem is fundamentally a Grid\nproblem. Building upon the Globus toolkit and a variety of other technologies,\nESG is developing an environment that addresses authentication, authorization\nfor data access, large-scale data transport and management, services and\nabstractions for high-performance remote data access, mechanisms for scalable\ndata replication, cataloging with rich semantic and syntactic information, data\ndiscovery, distributed monitoring, and Web-based portals for using the system.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 23:39:04 GMT"}], "update_date": "2007-12-17", "authors_parsed": [["Bernholdt", "David", ""], ["Bharathi", "Shishir", ""], ["Brown", "David", ""], ["Chanchio", "Kasidit", ""], ["Chen", "Meili", ""], ["Chervenak", "Ann", ""], ["Cinquini", "Luca", ""], ["Drach", "Bob", ""], ["Foster", "Ian", ""], ["Fox", "Peter", ""], ["Garcia", "Jose", ""], ["Kesselman", "Carl", ""], ["Markel", "Rob", ""], ["Middleton", "Don", ""], ["Nefedova", "Veronika", ""], ["Pouchard", "Line", ""], ["Shoshani", "Arie", ""], ["Sim", "Alex", ""], ["Strand", "Gary", ""], ["Williams", "Dean", ""]]}
{"id": "0712.2389", "submitter": "Guido Tack", "authors": "Martin Mann and Guido Tack and Sebastian Will", "title": "Decomposition During Search for Propagation-Based Constraint Solvers", "comments": "20 pages, 9 figures, 2 tables; longer, more detailed version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe decomposition during search (DDS), an integration of And/Or tree\nsearch into propagation-based constraint solvers. The presented search\nalgorithm dynamically decomposes sub-problems of a constraint satisfaction\nproblem into independent partial problems, avoiding redundant work.\n  The paper discusses how DDS interacts with key features that make\npropagation-based solvers successful: constraint propagation, especially for\nglobal constraints, and dynamic search heuristics.\n  We have implemented DDS for the Gecode constraint programming library. Two\napplications, solution counting in graph coloring and protein structure\nprediction, exemplify the benefits of DDS in practice.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2007 18:08:26 GMT"}, {"version": "v2", "created": "Wed, 11 Jun 2008 13:00:11 GMT"}], "update_date": "2008-06-11", "authors_parsed": [["Mann", "Martin", ""], ["Tack", "Guido", ""], ["Will", "Sebastian", ""]]}
{"id": "0712.2595", "submitter": "Bill Rosgen", "authors": "Bill Rosgen", "title": "Distinguishing Short Quantum Computations", "comments": "12 pages, 4 figures, to be published in the proceedings of STACS 2008", "journal-ref": null, "doi": "10.4230/LIPIcs.STACS.2008.1322", "report-no": null, "categories": "quant-ph cs.CC", "license": null, "abstract": "  Distinguishing logarithmic depth quantum circuits on mixed states is shown to\nbe complete for QIP, the class of problems having quantum interactive proof\nsystems. Circuits in this model can represent arbitrary quantum processes, and\nthus this result has implications for the verification of implementations of\nquantum algorithms. The distinguishability problem is also complete for QIP on\nconstant depth circuits containing the unbounded fan-out gate. These results\nare shown by reducing a QIP-complete problem to a logarithmic depth version of\nitself using a parallelization technique.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2007 21:40:41 GMT"}], "update_date": "2010-06-02", "authors_parsed": [["Rosgen", "Bill", ""]]}
{"id": "0712.2638", "submitter": "Steve Oudot", "authors": "Fr\\'ed\\'eric Chazal (INRIA Sophia Antipolis), Steve Oudot (INRIA\n  Sophia Antipolis)", "title": "Towards Persistence-Based Reconstruction in Euclidean Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": null, "abstract": "  Manifold reconstruction has been extensively studied for the last decade or\nso, especially in two and three dimensions. Recently, significant improvements\nwere made in higher dimensions, leading to new methods to reconstruct large\nclasses of compact subsets of Euclidean space $\\R^d$. However, the complexities\nof these methods scale up exponentially with d, which makes them impractical in\nmedium or high dimensions, even for handling low-dimensional submanifolds. In\nthis paper, we introduce a novel approach that stands in-between classical\nreconstruction and topological estimation, and whose complexity scales up with\nthe intrinsic dimension of the data. Specifically, when the data points are\nsufficiently densely sampled from a smooth $m$-submanifold of $\\R^d$, our\nmethod retrieves the homology of the submanifold in time at most $c(m)n^5$,\nwhere $n$ is the size of the input and $c(m)$ is a constant depending solely on\n$m$. It can also provably well handle a wide range of compact subsets of\n$\\R^d$, though with worse complexities. Along the way to proving the\ncorrectness of our algorithm, we obtain new results on \\v{C}ech, Rips, and\nwitness complex filtrations in Euclidean spaces.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2007 06:30:08 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2007 10:26:34 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Chazal", "Frédéric", "", "INRIA Sophia Antipolis"], ["Oudot", "Steve", "", "INRIA\n  Sophia Antipolis"]]}
{"id": "0712.2640", "submitter": "Yeow Meng Chee", "authors": "Yeow Meng Chee, Charles J. Colbourn, and Alan C. H. Ling", "title": "Optimal Memoryless Encoding for Low Power Off-Chip Data Buses", "comments": "Proceedings of the 2006 IEEE/ACM international Conference on\n  Computer-Aided Design (San Jose, California, November 05 - 09, 2006). ICCAD\n  '06. ACM, New York, NY, 369-374", "journal-ref": null, "doi": "10.1145/1233501.1233575", "report-no": null, "categories": "cs.AR cs.DM cs.IT math.IT", "license": null, "abstract": "  Off-chip buses account for a significant portion of the total system power\nconsumed in embedded systems. Bus encoding schemes have been proposed to\nminimize power dissipation, but none has been demonstrated to be optimal with\nrespect to any measure. In this paper, we give the first provably optimal and\nexplicit (polynomial-time constructible) families of memoryless codes for\nminimizing bit transitions in off-chip buses. Our results imply that having\naccess to a clock does not make a memoryless encoding scheme that minimizes bit\ntransitions more powerful.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2007 06:37:11 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Chee", "Yeow Meng", ""], ["Colbourn", "Charles J.", ""], ["Ling", "Alan C. H.", ""]]}
{"id": "0712.2643", "submitter": "Cyrille Bertelle", "authors": "Pierrick Tranouez (LITIS), Cyrille Bertelle (LITIS), Damien Olivier\n  (LITIS)", "title": "Changing Levels of Description in a Fluid Flow Simulation", "comments": null, "journal-ref": "Emergent Properties in Natural and Artificial Dynamical Systems,\n  Springer (Ed.) (2006) 87-99", "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": null, "abstract": "  We describe here our perception of complex systems, of how we feel the\ndifferent layers of description are important part of a correct complex system\nsimulation. We describe a rough models categorization between rules based and\nlaw based, of how these categories handled the levels of descriptions or\nscales. We then describe our fluid flow simulation, which combines different\nfineness of grain in a mixed approach of these categories. This simulation is\nbuilt keeping in mind an ulterior use inside a more general aquatic ecosystem.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2007 07:07:06 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Tranouez", "Pierrick", "", "LITIS"], ["Bertelle", "Cyrille", "", "LITIS"], ["Olivier", "Damien", "", "LITIS"]]}
{"id": "0712.2644", "submitter": "Cyrille Bertelle", "authors": "Rawan Ghnemat (LITIS), Saleh Oqeili (IT), Cyrille Bertelle (LITIS),\n  G\\'erard Henry Edmond Duchamp (LIPN)", "title": "Automata-based Adaptive Behavior for Economical Modelling Using Game\n  Theory", "comments": null, "journal-ref": "Emergent Properties in Natural and Artificial Dynamical Systems,\n  Springer (Ed.) (2006) 171-183", "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": null, "abstract": "  In this chapter, we deal with some specific domains of applications to game\ntheory. This is one of the major class of models in the new approaches of\nmodelling in the economic domain. For that, we use genetic automata which allow\nto build adaptive strategies for the players. We explain how the automata-based\nformalism proposed - matrix representation of automata with multiplicities -\nallows to define semi-distance between the strategy behaviors. With that tools,\nwe are able to generate an automatic processus to compute emergent systems of\nentities whose behaviors are represented by these genetic automata.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2007 07:07:54 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Ghnemat", "Rawan", "", "LITIS"], ["Oqeili", "Saleh", "", "IT"], ["Bertelle", "Cyrille", "", "LITIS"], ["Duchamp", "Gérard Henry Edmond", "", "LIPN"]]}
{"id": "0712.2789", "submitter": "Lester Ingber", "authors": "Lester Ingber", "title": "Trading in Risk Dimensions (TRD)", "comments": "This 2005 report has been withdrawn by the author as requested by the\n  publisher of \"Handbook of Technical Trading Analysis\" (Wiley, 2009) in which\n  an updated version appears", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work, mostly published, developed two-shell recursive trading\nsystems. An inner-shell of Canonical Momenta Indicators (CMI) is adaptively fit\nto incoming market data. A parameterized trading-rule outer-shell uses the\nglobal optimization code Adaptive Simulated Annealing (ASA) to fit the trading\nsystem to historical data. A simple fitting algorithm, usually not requiring\nASA, is used for the inner-shell fit. An additional risk-management\nmiddle-shell has been added to create a three-shell recursive\noptimization/sampling/fitting algorithm. Portfolio-level distributions of\ncopula-transformed multivariate distributions (with constituent markets\npossessing different marginal distributions in returns space) are generated by\nMonte Carlo samplings. ASA is used to importance-sample weightings of these\nmarkets.\n  The core code, Trading in Risk Dimensions (TRD), processes Training and\nTesting trading systems on historical data, and consistently interacts with\nRealTime trading platforms at minute resolutions, but this scale can be\nmodified. This approach transforms constituent probability distributions into a\ncommon space where it makes sense to develop correlations to further develop\nprobability distributions and risk/uncertainty analyses of the full portfolio.\nASA is used for importance-sampling these distributions and for optimizing\nsystem parameters.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2007 18:11:52 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2009 03:32:16 GMT"}], "update_date": "2009-11-04", "authors_parsed": [["Ingber", "Lester", ""]]}
{"id": "0712.3137", "submitter": "Lucas Lacasa", "authors": "Lucas Lacasa, Bartolo Luque, Octavio Miramontes", "title": "Phase transition and computational complexity in a stochastic prime\n  number generator", "comments": "Submitted to New Journal of Physics", "journal-ref": "New Journal of Physics 10 (2008) 023009", "doi": "10.1088/1367-2630/10/2/023009", "report-no": null, "categories": "cs.CC physics.comp-ph", "license": null, "abstract": "  We introduce a prime number generator in the form of a stochastic algorithm.\nThe character of such algorithm gives rise to a continuous phase transition\nwhich distinguishes a phase where the algorithm is able to reduce the whole\nsystem of numbers into primes and a phase where the system reaches a frozen\nstate with low prime density. In this paper we firstly pretend to give a broad\ncharacterization of this phase transition, both in terms of analytical and\nnumerical analysis. Critical exponents are calculated, and data collapse is\nprovided. Further on we redefine the model as a search problem, fitting it in\nthe hallmark of computational complexity theory. We suggest that the system\nbelongs to the class NP. The computational cost is maximal around the\nthreshold, as common in many algorithmic phase transitions, revealing the\npresence of an easy-hard-easy pattern. We finally relate the nature of the\nphase transition to an average-case classification of the problem.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2007 10:00:32 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Lacasa", "Lucas", ""], ["Luque", "Bartolo", ""], ["Miramontes", "Octavio", ""]]}
{"id": "0712.3147", "submitter": "Pierre Lescanne", "authors": "Pierre Lescanne (LIP)", "title": "Common knowledge logic in a higher order proof assistant?", "comments": "11 p", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  This paper presents experiments on common knowledge logic, conducted with the\nhelp of the proof assistant Coq. The main feature of common knowledge logic is\nthe eponymous modality that says that a group of agents shares a knowledge\nabout a certain proposition in a inductive way. This modality is specified by\nusing a fixpoint approach. Furthermore, from these experiments, we discuss and\ncompare the structure of theorems that can be proved in specific theories that\nuse common knowledge logic. Those structures manifests the interplay between\nthe theory (as implemented in the proof assistant Coq) and the metatheory.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2007 10:25:34 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2008 16:12:50 GMT"}], "update_date": "2008-01-16", "authors_parsed": [["Lescanne", "Pierre", "", "LIP"]]}
{"id": "0712.3203", "submitter": "Wan ChangLin", "authors": "Changlin Wan, Zhongzhi Shi", "title": "Solving Medium-Density Subset Sum Problems in Expected Polynomial Time:\n  An Enumeration Approach", "comments": "11 pages, 1 figure", "journal-ref": "Changlin Wan, Zhongzhi Shi: Solving Medium-Density Subset Sum\n  Problems in Expected Polynomial Time: An Enumeration Approach. FAW 2008:\n  300-310", "doi": "10.1007/978-3-540-69311-6_31", "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subset sum problem (SSP) can be briefly stated as: given a target integer\n$E$ and a set $A$ containing $n$ positive integer $a_j$, find a subset of $A$\nsumming to $E$. The \\textit{density} $d$ of an SSP instance is defined by the\nratio of $n$ to $m$, where $m$ is the logarithm of the largest integer within\n$A$. Based on the structural and statistical properties of subset sums, we\npresent an improved enumeration scheme for SSP, and implement it as a complete\nand exact algorithm (EnumPlus). The algorithm always equivalently reduces an\ninstance to be low-density, and then solve it by enumeration. Through this\napproach, we show the possibility to design a sole algorithm that can\nefficiently solve arbitrary density instance in a uniform way. Furthermore, our\nalgorithm has considerable performance advantage over previous algorithms.\nFirstly, it extends the density scope, in which SSP can be solved in expected\npolynomial time. Specifically, It solves SSP in expected $O(n\\log{n})$ time\nwhen density $d \\geq c\\cdot \\sqrt{n}/\\log{n}$, while the previously best\ndensity scope is $d \\geq c\\cdot n/(\\log{n})^{2}$. In addition, the overall\nexpected time and space requirement in the average case are proven to be\n$O(n^5\\log n)$ and $O(n^5)$ respectively. Secondly, in the worst case, it\nslightly improves the previously best time complexity of exact algorithms for\nSSP. Specifically, the worst-case time complexity of our algorithm is proved to\nbe $O((n-6)2^{n/2}+n)$, while the previously best result is $O(n2^{n/2})$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2007 14:43:50 GMT"}, {"version": "v2", "created": "Mon, 23 Jun 2008 02:00:12 GMT"}], "update_date": "2008-06-23", "authors_parsed": [["Wan", "Changlin", ""], ["Shi", "Zhongzhi", ""]]}
{"id": "0712.3329", "submitter": "Marcus Hutter", "authors": "Shane Legg and Marcus Hutter", "title": "Universal Intelligence: A Definition of Machine Intelligence", "comments": "50 gentle pages", "journal-ref": "Minds & Machines, 17:4 (2007) pages 391-444", "doi": null, "report-no": "IDSIA-10-07", "categories": "cs.AI", "license": null, "abstract": "  A fundamental problem in artificial intelligence is that nobody really knows\nwhat intelligence is. The problem is especially acute when we need to consider\nartificial systems which are significantly different to humans. In this paper\nwe approach this problem in the following way: We take a number of well known\ninformal definitions of human intelligence that have been given by experts, and\nextract their essential features. These are then mathematically formalised to\nproduce a general measure of intelligence for arbitrary machines. We believe\nthat this equation formally captures the concept of machine intelligence in the\nbroadest reasonable sense. We then show how this formal definition is related\nto the theory of universal optimal learning agents. Finally, we survey the many\nother tests and definitions of intelligence that have been proposed for\nmachines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2007 05:50:54 GMT"}], "update_date": "2008-06-26", "authors_parsed": [["Legg", "Shane", ""], ["Hutter", "Marcus", ""]]}
{"id": "0712.3331", "submitter": "Kunal Talwar", "authors": "Anupam Gupta and Kunal Talwar", "title": "How to Complete a Doubling Metric", "comments": "An extended abstract will appear in proceedings of LATIN 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG", "license": null, "abstract": "  In recent years, considerable advances have been made in the study of\nproperties of metric spaces in terms of their doubling dimension. This line of\nresearch has not only enhanced our understanding of finite metrics, but has\nalso resulted in many algorithmic applications. However, we still do not\nunderstand the interaction between various graph-theoretic (topological)\nproperties of graphs, and the doubling (geometric) properties of the\nshortest-path metrics induced by them. For instance, the following natural\nquestion suggests itself: \\emph{given a finite doubling metric $(V,d)$, is\nthere always an \\underline{unweighted} graph $(V',E')$ with $V\\subseteq V'$\nsuch that the shortest path metric $d'$ on $V'$ is still doubling, and which\nagrees with $d$ on $V$.} This is often useful, given that unweighted graphs are\noften easier to reason about.\n  We show that for any metric space $(V,d)$, there is an \\emph{unweighted}\ngraph $(V',E')$ with shortest-path metric $d':V'\\times V' \\to \\R_{\\geq 0}$ such\nthat\n  -- for all $x,y \\in V$, the distances $d(x,y) \\leq d'(x,y) \\leq (1+\\eps)\n\\cdot d(x,y)$, and\n  -- the doubling dimension for $d'$ is not much more than that of $d$, where\nthis change depends only on $\\e$ and not on the size of the graph.\n  We show a similar result when both $(V,d)$ and $(V',E')$ are restricted to be\ntrees: this gives a simpler proof that doubling trees embed into constant\ndimensional Euclidean space with constant distortion. We also show that our\nresults are tight in terms of the tradeoff between distortion and dimension\nblowup.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2007 06:12:15 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2007 12:32:23 GMT"}], "update_date": "2007-12-27", "authors_parsed": [["Gupta", "Anupam", ""], ["Talwar", "Kunal", ""]]}
{"id": "0712.3348", "submitter": "Xin Li", "authors": "Xin Li, Tian Liu", "title": "On Exponential Time Lower Bound of Knapsack under Backtracking", "comments": "This paper supersedes the result of arXiv:cs/0606064", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  M.Aleknovich et al. have recently proposed a model of algorithms, called BT\nmodel, which generalizes both the priority model of Borodin, Nielson and\nRackoff, as well as a simple dynamic programming model by Woeginger. BT model\ncan be further divided into three kinds of fixed, adaptive and fully adaptive\nones. They have proved exponential time lower bounds of exact and approximation\nalgorithms under adaptive BT model for Knapsack problem. Their exact lower\nbound is $\\Omega(2^{0.5n}/\\sqrt{n})$, in this paper, we slightly improve the\nexact lower bound to about $\\Omega(2^{0.69n}/\\sqrt{n})$, by the same technique,\nwith related parameters optimized.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2007 09:15:17 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2007 13:46:53 GMT"}], "update_date": "2007-12-25", "authors_parsed": [["Li", "Xin", ""], ["Liu", "Tian", ""]]}
{"id": "0712.3423", "submitter": "Alban Ponse", "authors": "J.A. Bergstra, A. Ponse, M.B. van der Zwaag", "title": "Tuplix Calculus", "comments": "22 pages", "journal-ref": "Scientific Annals of Computer Science, 18:35--61, 2008", "doi": null, "report-no": "PRG0713", "categories": "cs.LO cs.CE", "license": null, "abstract": "  We introduce a calculus for tuplices, which are expressions that generalize\nmatrices and vectors. Tuplices have an underlying data type for quantities that\nare taken from a zero-totalized field. We start with the core tuplix calculus\nCTC for entries and tests, which are combined using conjunctive composition. We\ndefine a standard model and prove that CTC is relatively complete with respect\nto it. The core calculus is extended with operators for choice, information\nhiding, scalar multiplication, clearing and encapsulation. We provide two\nexamples of applications; one on incremental financial budgeting, and one on\nmodular financial budget design.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2007 13:58:14 GMT"}], "update_date": "2009-03-03", "authors_parsed": [["Bergstra", "J. A.", ""], ["Ponse", "A.", ""], ["van der Zwaag", "M. B.", ""]]}
{"id": "0712.3617", "submitter": "Erhan Bayraktar", "authors": "Erhan Bayraktar, Bo Yang", "title": "A Unified Framework for Pricing Credit and Equity Derivatives", "comments": "Keywords: Credit Default Swap, Defaultable Bond, Defaultable Stock,\n  Equity Options, Stochastic Interest Rate, Implied Volatility, Multiscale\n  Perturbation Method", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model which can be jointly calibrated to the corporate bond term\nstructure and equity option volatility surface of the same company. Our purpose\nis to obtain explicit bond and equity option pricing formulas that can be\ncalibrated to find a risk neutral model that matches a set of observed market\nprices. This risk neutral model can then be used to price more exotic, illiquid\nor over-the-counter derivatives. We observe that the model implied credit\ndefault swap (CDS) spread matches the market CDS spread and that our model\nproduces a very desirable CDS spread term structure. This is observation is\nworth noticing since without calibrating any parameter to the CDS spread data,\nit is matched by the CDS spread that our model generates using the available\ninformation from the equity options and corporate bond markets. We also observe\nthat our model matches the equity option implied volatility surface well since\nwe properly account for the default risk premium in the implied volatility\nsurface. We demonstrate the importance of accounting for the default risk and\nstochastic interest rate in equity option pricing by comparing our results to\nFouque, Papanicolaou, Sircar and Solna (2003), which only accounts for\nstochastic volatility.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2007 02:53:38 GMT"}, {"version": "v2", "created": "Sat, 20 Sep 2008 21:44:00 GMT"}], "update_date": "2008-09-21", "authors_parsed": [["Bayraktar", "Erhan", ""], ["Yang", "Bo", ""]]}
{"id": "0712.3654", "submitter": "Alejandro Chinea Manrique De Lara", "authors": "Alejandro Chinea Manrique De Lara, Juan Manuel Moreno, Arostegui Jordi\n  Madrenas, Joan Cabestany", "title": "Improving the Performance of PieceWise Linear Separation Incremental\n  Algorithms for Practical Hardware Implementations", "comments": "10 pages, 1 figure, 3 tables", "journal-ref": "Biological and Artificial Computation: From Neuroscience to\n  Technology, J.Mira, R.Moreno-Diaz, J.Cabestany (eds.), pp. 607-616,\n  Springer-Verlag, 1997", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": null, "abstract": "  In this paper we shall review the common problems associated with Piecewise\nLinear Separation incremental algorithms. This kind of neural models yield poor\nperformances when dealing with some classification problems, due to the\nevolving schemes used to construct the resulting networks. So as to avoid this\nundesirable behavior we shall propose a modification criterion. It is based\nupon the definition of a function which will provide information about the\nquality of the network growth process during the learning phase. This function\nis evaluated periodically as the network structure evolves, and will permit, as\nwe shall show through exhaustive benchmarks, to considerably improve the\nperformance(measured in terms of network complexity and generalization\ncapabilities) offered by the networks generated by these incremental models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2007 10:05:52 GMT"}], "update_date": "2007-12-24", "authors_parsed": [["De Lara", "Alejandro Chinea Manrique", ""], ["Moreno", "Juan Manuel", ""], ["Madrenas", "Arostegui Jordi", ""], ["Cabestany", "Joan", ""]]}
{"id": "0712.3825", "submitter": "Marcus Hutter", "authors": "Shane Legg and Marcus Hutter", "title": "Tests of Machine Intelligence", "comments": "12 pages; 1 table. Turing test and derivatives; Compression tests;\n  Linguistic complexity; Multiple cognitive abilities; Competitive games;\n  Psychometric tests; Smith's test; C-test; Universal intelligence", "journal-ref": "50 Years of Artificial Intelligence (2007) pages 232-242", "doi": null, "report-no": "IDSIA-11-07", "categories": "cs.AI", "license": null, "abstract": "  Although the definition and measurement of intelligence is clearly of\nfundamental importance to the field of artificial intelligence, no general\nsurvey of definitions and tests of machine intelligence exists. Indeed few\nresearchers are even aware of alternatives to the Turing test and its many\nderivatives. In this paper we fill this gap by providing a short survey of the\nmany tests of machine intelligence that have been proposed.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2007 01:17:24 GMT"}], "update_date": "2008-06-26", "authors_parsed": [["Legg", "Shane", ""], ["Hutter", "Marcus", ""]]}
{"id": "0712.4027", "submitter": "Olga Holtz", "authors": "James Demmel, Ioana Dumitriu, Olga Holtz, Plamen Koev", "title": "Accurate and Efficient Expression Evaluation and Linear Algebra", "comments": "49 pages, 6 figures, 1 table", "journal-ref": "Acta Numerica, Volume 17, May 2008, pp 87-145", "doi": "10.1017/S0962492906350015", "report-no": null, "categories": "math.NA cs.CC cs.DS math.RA", "license": null, "abstract": "  We survey and unify recent results on the existence of accurate algorithms\nfor evaluating multivariate polynomials, and more generally for accurate\nnumerical linear algebra with structured matrices. By \"accurate\" we mean that\nthe computed answer has relative error less than 1, i.e., has some correct\nleading digits. We also address efficiency, by which we mean algorithms that\nrun in polynomial time in the size of the input. Our results will depend\nstrongly on the model of arithmetic: Most of our results will use the so-called\nTraditional Model (TM). We give a set of necessary and sufficient conditions to\ndecide whether a high accuracy algorithm exists in the TM, and describe\nprogress toward a decision procedure that will take any problem and provide\neither a high accuracy algorithm or a proof that none exists. When no accurate\nalgorithm exists in the TM, it is natural to extend the set of available\naccurate operations by a library of additional operations, such as $x+y+z$, dot\nproducts, or indeed any enumerable set which could then be used to build\nfurther accurate algorithms. We show how our accurate algorithms and decision\nprocedure for finding them extend to this case. Finally, we address other\nmodels of arithmetic, and the relationship between (im)possibility in the TM\nand (in)efficient algorithms operating on numbers represented as bit strings.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2007 20:14:50 GMT"}], "update_date": "2008-05-21", "authors_parsed": [["Demmel", "James", ""], ["Dumitriu", "Ioana", ""], ["Holtz", "Olga", ""], ["Koev", "Plamen", ""]]}
{"id": "0712.4126", "submitter": "Chandan Reddy", "authors": "Chandan K. Reddy", "title": "TRUST-TECH based Methods for Optimization and Learning", "comments": "PHD Thesis", "journal-ref": "Chandan K. Reddy, TRUST-TECH based Methods for Optimization and\n  Learning, PHD Thesis, Cornell University, February 2007", "doi": null, "report-no": null, "categories": "cs.AI cs.CE cs.MS cs.NA cs.NE", "license": null, "abstract": "  Many problems that arise in machine learning domain deal with nonlinearity\nand quite often demand users to obtain global optimal solutions rather than\nlocal optimal ones. Optimization problems are inherent in machine learning\nalgorithms and hence many methods in machine learning were inherited from the\noptimization literature. Popularly known as the initialization problem, the\nideal set of parameters required will significantly depend on the given\ninitialization values. The recently developed TRUST-TECH (TRansformation Under\nSTability-reTaining Equilibria CHaracterization) methodology systematically\nexplores the subspace of the parameters to obtain a complete set of local\noptimal solutions. In this thesis work, we propose TRUST-TECH based methods for\nsolving several optimization and machine learning problems. Two stages namely,\nthe local stage and the neighborhood-search stage, are repeated alternatively\nin the solution space to achieve improvements in the quality of the solutions.\nOur methods were tested on both synthetic and real datasets and the advantages\nof using this novel framework are clearly manifested. This framework not only\nreduces the sensitivity to initialization, but also allows the flexibility for\nthe practitioners to use various global and local methods that work well for a\nparticular problem of interest. Other hierarchical stochastic algorithms like\nevolutionary algorithms and smoothing algorithms are also studied and\nframeworks for combining these methods with TRUST-TECH have been proposed and\nevaluated on several test systems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2007 03:14:32 GMT"}], "update_date": "2007-12-27", "authors_parsed": [["Reddy", "Chandan K.", ""]]}
{"id": "0712.4126", "submitter": "Chandan Reddy", "authors": "Chandan K. Reddy", "title": "TRUST-TECH based Methods for Optimization and Learning", "comments": "PHD Thesis", "journal-ref": "Chandan K. Reddy, TRUST-TECH based Methods for Optimization and\n  Learning, PHD Thesis, Cornell University, February 2007", "doi": null, "report-no": null, "categories": "cs.AI cs.CE cs.MS cs.NA cs.NE", "license": null, "abstract": "  Many problems that arise in machine learning domain deal with nonlinearity\nand quite often demand users to obtain global optimal solutions rather than\nlocal optimal ones. Optimization problems are inherent in machine learning\nalgorithms and hence many methods in machine learning were inherited from the\noptimization literature. Popularly known as the initialization problem, the\nideal set of parameters required will significantly depend on the given\ninitialization values. The recently developed TRUST-TECH (TRansformation Under\nSTability-reTaining Equilibria CHaracterization) methodology systematically\nexplores the subspace of the parameters to obtain a complete set of local\noptimal solutions. In this thesis work, we propose TRUST-TECH based methods for\nsolving several optimization and machine learning problems. Two stages namely,\nthe local stage and the neighborhood-search stage, are repeated alternatively\nin the solution space to achieve improvements in the quality of the solutions.\nOur methods were tested on both synthetic and real datasets and the advantages\nof using this novel framework are clearly manifested. This framework not only\nreduces the sensitivity to initialization, but also allows the flexibility for\nthe practitioners to use various global and local methods that work well for a\nparticular problem of interest. Other hierarchical stochastic algorithms like\nevolutionary algorithms and smoothing algorithms are also studied and\nframeworks for combining these methods with TRUST-TECH have been proposed and\nevaluated on several test systems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2007 03:14:32 GMT"}], "update_date": "2007-12-27", "authors_parsed": [["Reddy", "Chandan K.", ""]]}
{"id": "0712.4279", "submitter": "Troy Lee", "authors": "Troy Lee, Adi Shraibman", "title": "Disjointness is hard in the multi-party number on the forehead model", "comments": "23 pages. Added background to method and references to more recent\n  work. Journal version to appear in Computational Complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that disjointness requires randomized communication\nOmega(n^{1/(k+1)}/2^{2^k}) in the general k-party number-on-the-forehead model\nof complexity. The previous best lower bound for k >= 3 was log(n)/(k-1). Our\nresults give a separation between nondeterministic and randomized multiparty\nnumber-on-the-forehead communication complexity for up to k=log log n - O(log\nlog log n) many players. Also by a reduction of Beame, Pitassi, and Segerlind,\nthese results imply subexponential lower bounds on the size of proofs needed to\nrefute certain unsatisfiable CNFs in a broad class of proof systems, including\ntree-like Lovasz-Schrijver proofs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2007 20:45:53 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2009 12:15:09 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Lee", "Troy", ""], ["Shraibman", "Adi", ""]]}
{"id": "0712.4318", "submitter": "Peter de Blanc", "authors": "Peter de Blanc", "title": "Convergence of Expected Utilities with Algorithmic Probability\n  Distributions", "comments": "2 pages + title page, references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  We consider an agent interacting with an unknown environment. The environment\nis a function which maps natural numbers to natural numbers; the agent's set of\nhypotheses about the environment contains all such functions which are\ncomputable and compatible with a finite set of known input-output pairs, and\nthe agent assigns a positive probability to each such hypothesis. We do not\nrequire that this probability distribution be computable, but it must be\nbounded below by a positive computable function. The agent has a utility\nfunction on outputs from the environment. We show that if this utility function\nis bounded below in absolute value by an unbounded computable function, then\nthe expected utility of any input is undefined. This implies that a computable\nutility function will have convergent expected utilities iff that function is\nbounded.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2007 07:50:00 GMT"}], "update_date": "2007-12-31", "authors_parsed": [["de Blanc", "Peter", ""]]}
{"id": "0712.4402", "submitter": "Ruadhan O'Flanagan", "authors": "Ruadhan O'Flanagan", "title": "Judgment", "comments": "20 pages; minor changes; references added; submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.AI math.LO", "license": null, "abstract": "  The concept of a judgment as a logical action which introduces new\ninformation into a deductive system is examined. This leads to a way of\nmathematically representing implication which is distinct from the familiar\nmaterial implication, according to which \"If A then B\" is considered to be\nequivalent to \"B or not-A\". This leads, in turn, to a resolution of the paradox\nof the raven.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2007 21:00:01 GMT"}, {"version": "v2", "created": "Sat, 29 Dec 2007 03:57:26 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2008 21:30:57 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["O'Flanagan", "Ruadhan", ""]]}
{"id": "0801.0232", "submitter": "Patrizio Frosini", "authors": "Patrizio Frosini", "title": "Does intelligence imply contradiction?", "comments": "39 pages, 6 figures; added Remark 9 (page 19) and Remark 12 (page\n  25); changed some comments after Definition 13 and in Section 5; some minor\n  changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  Contradiction is often seen as a defect of intelligent systems and a\ndangerous limitation on efficiency. In this paper we raise the question of\nwhether, on the contrary, it could be considered a key tool in increasing\nintelligence in biological structures. A possible way of answering this\nquestion in a mathematical context is shown, formulating a proposition that\nsuggests a link between intelligence and contradiction.\n  A concrete approach is presented in the well-defined setting of cellular\nautomata. Here we define the models of ``observer'', ``entity'',\n``environment'', ``intelligence'' and ``contradiction''. These definitions,\nwhich roughly correspond to the common meaning of these words, allow us to\ndeduce a simple but strong result about these concepts in an unbiased,\nmathematical manner. Evidence for a real-world counterpart to the demonstrated\nformal link between intelligence and contradiction is provided by three\ncomputational experiments.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2007 19:07:22 GMT"}, {"version": "v2", "created": "Tue, 18 Mar 2008 11:16:24 GMT"}], "update_date": "2008-03-18", "authors_parsed": [["Frosini", "Patrizio", ""]]}
{"id": "0801.0258", "submitter": "Joseph O'Rourke", "authors": "Nadia Benbernou, Joseph O'Rourke", "title": "On the Maximum Span of Fixed-Angle Chains", "comments": "28 pages, 21 figures. Preliminary version appeared in Proc. 18th\n  Canad. Conf. Comput. Geom., pages 93-96, 2006. This paper has been withdrawn\n  by the authors. Lemma 15 as stated is incorrect, and although we believe the\n  main theorems following (Thms. 17 & 18) are true, the proofs relying on\n  Lem.15 are not valid", "journal-ref": null, "doi": null, "report-no": "Smith Computer Science 088", "categories": "cs.CG", "license": null, "abstract": "  Soss proved that it is NP-hard to find the maximum 2D span of a fixed-angle\npolygonal chain: the largest distance achievable between the endpoints in a\nplanar embedding. These fixed-angle chains can serve as models of protein\nbackbones. The corresponding problem in 3D is open. We show that three special\ncases of particular relevance to the protein model are solvable in polynomial\ntime. When all link lengths and all angles are equal, the maximum 3D span is\nachieved in a flat configuration and can be computed in constant time. When all\nangles are equal and the chain is simple (non-self-crossing), the maximum flat\nspan can be found in linear time. In 3D, when all angles are equal to 90 deg\n(but the link lengths arbitrary), the maximum 3D span is in general nonplanar\nbut can be found in quadratic time.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2008 04:17:20 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2010 12:02:30 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Benbernou", "Nadia", ""], ["O'Rourke", "Joseph", ""]]}
{"id": "0801.0289", "submitter": "Marie Ferbus-Zanda", "authors": "Marie Ferbus-Zanda (LIAFA), Serge Grigorieff (LIAFA)", "title": "Is Randomness \"Native\" to Computer Science?", "comments": "43 pages", "journal-ref": "Current Trends in Theoretical Computer Science. Vol2, World\n  Scientific (Ed.) (2004) 141-180", "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": null, "abstract": "  We survey the Kolmogorov's approach to the notion of randomness through the\nKolmogorov complexity theory. The original motivation of Kolmogorov was to give\nup a quantitative definition of information. In this theory, an object is\nrandomness in the sense that it has a large information content. Afterwards, we\npresent parts of the work of Martin-Lof, Schnorr, Chaitin and Levin which\nsupply a mathematical notion of randomness throughout diverse theories from the\nthe 60' up to recently.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2008 10:26:55 GMT"}], "update_date": "2008-01-03", "authors_parsed": [["Ferbus-Zanda", "Marie", "", "LIAFA"], ["Grigorieff", "Serge", "", "LIAFA"]]}
{"id": "0801.0341", "submitter": "Michael Chertkov", "authors": "Michael Chertkov (Los Alamos)", "title": "Exactness of Belief Propagation for Some Graphical Models with Loops", "comments": "12 pages, 1 figure, submitted to JSTAT", "journal-ref": "J. Stat. Mech. (2008) P10016", "doi": "10.1088/1742-5468/2008/10/P10016", "report-no": "LANL LA-UR-07-8441", "categories": "cond-mat.stat-mech cond-mat.other cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that an arbitrary graphical model of statistical inference\ndefined on a tree, i.e. on a graph without loops, is solved exactly and\nefficiently by an iterative Belief Propagation (BP) algorithm convergent to\nunique minimum of the so-called Bethe free energy functional. For a general\ngraphical model on a loopy graph the functional may show multiple minima, the\niterative BP algorithm may converge to one of the minima or may not converge at\nall, and the global minimum of the Bethe free energy functional is not\nguaranteed to correspond to the optimal Maximum-Likelihood (ML) solution in the\nzero-temperature limit. However, there are exceptions to this general rule,\ndiscussed in \\cite{05KW} and \\cite{08BSS} in two different contexts, where\nzero-temperature version of the BP algorithm finds ML solution for special\nmodels on graphs with loops. These two models share a key feature: their ML\nsolutions can be found by an efficient Linear Programming (LP) algorithm with a\nTotally-Uni-Modular (TUM) matrix of constraints. Generalizing the two models we\nconsider a class of graphical models reducible in the zero temperature limit to\nLP with TUM constraints. Assuming that a gedanken algorithm, g-BP, funding the\nglobal minimum of the Bethe free energy is available we show that in the limit\nof zero temperature g-BP outputs the ML solution. Our consideration is based on\nequivalence established between gapless Linear Programming (LP) relaxation of\nthe graphical model in the $T\\to 0$ limit and respective LP version of the\nBethe-Free energy minimization.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2008 06:07:07 GMT"}, {"version": "v2", "created": "Sun, 15 Jun 2008 15:00:41 GMT"}, {"version": "v3", "created": "Thu, 24 Jul 2008 23:35:51 GMT"}, {"version": "v4", "created": "Tue, 2 Sep 2008 21:25:37 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Chertkov", "Michael", "", "Los Alamos"]]}
{"id": "0801.0349", "submitter": "Marie Ferbus-Zanda", "authors": "Marie Ferbus-Zanda (LIAFA), Serge Grigorieff (LIAFA)", "title": "Church, Cardinal and Ordinal Representations of Integers and Kolmogorov\n  complexity", "comments": "16 pages", "journal-ref": "Dans Denis Richard's 60th Biirthday Conference - Denis Richard's\n  60th Biirthday Conference, France (2002)", "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": null, "abstract": "  We consider classical representations of integers: Church's function\niterators, cardinal equivalence classes of sets, ordinal equivalence classes of\ntotally ordered sets. Since programs do not work on abstract entities and\nrequire formal representations of objects, we effectivize these abstract\nnotions in order to allow them to be computed by programs. To any such\neffectivized representation is then associated a notion of Kolmogorov\ncomplexity. We prove that these Kolmogorov complexities form a strict hierarchy\nwhich coincides with that obtained by relativization to jump oracles and/or\nallowance of infinite computations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2008 08:35:27 GMT"}], "update_date": "2008-01-03", "authors_parsed": [["Ferbus-Zanda", "Marie", "", "LIAFA"], ["Grigorieff", "Serge", "", "LIAFA"]]}
{"id": "0801.0350", "submitter": "Marie Ferbus-Zanda", "authors": "Marie Ferbus-Zanda (LIAFA), Serge Grigorieff (LIAFA)", "title": "Refinment of the \"up to a constant\" ordering using contructive\n  co-immunity and alike. Application to the Min/Max hierarchy of Kolmogorov\n  complexities", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": null, "abstract": "  We introduce orderings between total functions f,g: N -> N which refine the\npointwise \"up to a constant\" ordering <=cte and also insure that f(x) is often\nmuch less thang(x). With such orderings, we prove a strong hierarchy theorem\nfor Kolmogorov complexities obtained with jump oracles and/or Max or Min of\npartial recursive functions. We introduce a notion of second order conditional\nKolmogorov complexity which yields a uniform bound for the \"up to a constant\"\ncomparisons involved in the hierarchy theorem.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2008 08:35:59 GMT"}], "update_date": "2008-01-07", "authors_parsed": [["Ferbus-Zanda", "Marie", "", "LIAFA"], ["Grigorieff", "Serge", "", "LIAFA"]]}
{"id": "0801.0353", "submitter": "Marie Ferbus-Zanda", "authors": "Marie Ferbus-Zanda (LIAFA), Serge Grigorieff (LIAFA)", "title": "Set theoretical Representations of Integers, I", "comments": "56 pages", "journal-ref": "Mathematical Logic Quaterly 52, Number 4 (2006) 375-403", "doi": "10.1002/malq.200510040", "report-no": null, "categories": "math.LO cs.CC", "license": null, "abstract": "  We reconsider some classical natural semantics of integers (namely iterators\nof functions, cardinals of sets, index of equivalence relations), in the\nperspective of Kolmogorov complexity. To each such semantics one can attach a\nsimple representation of integers that we suitably effectivize in order to\ndevelop an associated Kolmogorov theory. Such effectivizations are particular\ninstances of a general notion of \"self-enumerated system\" that we introduce in\nthis paper. Our main result asserts that, with such effectivizations,\nKolmogorov theory allows to quantitatively distinguish the underlying\nsemantics. We characterize the families obtained by such effectivizations and\nprove that the associated Kolmogorov complexities constitute a hierarchy which\ncoincides with that of Kolmogorov complexities defined via jump oracles and/or\ninfinite computations. This contrasts with the well-known fact that usual\nKolmogorov complexity does not depend (up to a constant) on the chosen\narithmetic representation of integers, let it be in any base unary, binary et\nso on. Also, in a conceptual point of view, our result can be seen as a mean to\nmeasure the degree of abstraction of these diverse semantics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2008 08:37:01 GMT"}], "update_date": "2008-01-03", "authors_parsed": [["Ferbus-Zanda", "Marie", "", "LIAFA"], ["Grigorieff", "Serge", "", "LIAFA"]]}
{"id": "0801.0354", "submitter": "Marie Ferbus-Zanda", "authors": "Marie Ferbus-Zanda (LIAFA), Serge Grigorieff (LIAFA)", "title": "Kolmogorov complexity in perspective", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.IT math.IT", "license": null, "abstract": "  We survey the diverse approaches to the notion of information content: from\nShannon entropy to Kolmogorov complexity. The main applications of Kolmogorov\ncomplexity are presented namely, the mathematical notion of randomness (which\ngoes back to the 60's with the work of Martin-Lof, Schnorr, Chaitin, Levin),\nand classification, which is a recent idea with provocative implementation by\nVitanyi and Cilibrasi.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2008 08:38:18 GMT"}], "update_date": "2008-01-03", "authors_parsed": [["Ferbus-Zanda", "Marie", "", "LIAFA"], ["Grigorieff", "Serge", "", "LIAFA"]]}
{"id": "0801.0398", "submitter": "Shmuel Friedland", "authors": "Shmuel Friedland", "title": "On the graph isomorphism problem", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": null, "abstract": "  We relate the graph isomorphism problem to the solvability of certain systems\nof linear equations with nonnegative variables. This version replaces the two\nprevious versions of this paper.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2008 14:40:02 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2008 16:36:12 GMT"}, {"version": "v3", "created": "Thu, 10 Jan 2008 09:41:35 GMT"}], "update_date": "2008-01-10", "authors_parsed": [["Friedland", "Shmuel", ""]]}
{"id": "0801.0474", "submitter": "Christopher Clingerman", "authors": "Christopher Clingerman, Jeremiah Hemphill, Corey Proscia", "title": "Analysis and Counterexamples Regarding Yatsenko's Polynomial-Time\n  Algorithm for Solving the Traveling Salesman Problem", "comments": "10 pages, 8 figures, references arXiv:cs/0702133", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  Yatsenko gives a polynomial-time algorithm for solving the traveling salesman\nproblem. We examine the correctness of the algorithm and its construction. We\nalso comment on Yatsenko's evaluation of the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2008 04:46:16 GMT"}], "update_date": "2008-01-04", "authors_parsed": [["Clingerman", "Christopher", ""], ["Hemphill", "Jeremiah", ""], ["Proscia", "Corey", ""]]}
{"id": "0801.0514", "submitter": "Partha Mukhopadhyay", "authors": "V. Arvind, Partha Mukhopadhyay, and Srikanth Srinivasan", "title": "New results on Noncommutative and Commutative Polynomial Identity\n  Testing", "comments": "23 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  Using ideas from automata theory we design a new efficient (deterministic)\nidentity test for the \\emph{noncommutative} polynomial identity testing problem\n(first introduced and studied in \\cite{RS05,BW05}). We also apply this idea to\nthe reconstruction of black-box noncommuting algebraic branching programs.\nAssuming the black-box model allows us to query the ABP for the output at any\ngiven gate, we can reconstruct an (equivalent) ABP in deterministic polynomial\ntime. Finally, we explore commutative identity testing when the coefficients of\nthe input polynomial come from an arbitrary finite commutative ring with unity.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2008 12:32:41 GMT"}], "update_date": "2008-01-04", "authors_parsed": [["Arvind", "V.", ""], ["Mukhopadhyay", "Partha", ""], ["Srinivasan", "Srikanth", ""]]}
{"id": "0801.0534", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "On the Length of the Wadge Hierarchy of Omega Context Free Languages", "comments": null, "journal-ref": "Journal of Automata, Languages and Combinatorics 10 (4) (2005)\n  439-464", "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.GT math.LO", "license": null, "abstract": "  We prove in this paper that the length of the Wadge hierarchy of omega\ncontext free languages is greater than the Cantor ordinal epsilon_omega, which\nis the omega-th fixed point of the ordinal exponentiation of base omega. The\nsame result holds for the conciliating Wadge hierarchy, defined by J. Duparc,\nof infinitary context free languages, studied by D. Beauquier. We show also\nthat there exist some omega context free languages which are\nSigma^0_omega-complete Borel sets, improving previous results on omega context\nfree languages and the Borel hierarchy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2008 14:48:48 GMT"}], "update_date": "2008-01-04", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}
{"id": "0801.0586", "submitter": "Daniel Perrucci", "authors": "Gabriela Jeronimo, Daniel Perrucci, Juan Sabia", "title": "On sign conditions over real multivariate polynomials", "comments": "extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CG cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new probabilistic algorithm to find a finite set of points\nintersecting the closure of each connected component of the realization of\nevery sign condition over a family of real polynomials defining regular\nhypersurfaces that intersect transversally. This enables us to show a\nprobabilistic procedure to list all feasible sign conditions over the\npolynomials. In addition, we extend these results to the case of closed sign\nconditions over an arbitrary family of real multivariate polynomials. The\ncomplexity bounds for these procedures improve the known ones.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2008 20:03:05 GMT"}, {"version": "v2", "created": "Thu, 18 Dec 2008 19:58:32 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Jeronimo", "Gabriela", ""], ["Perrucci", "Daniel", ""], ["Sabia", "Juan", ""]]}
{"id": "0801.1253", "submitter": "Damiano Mazza", "authors": "Patrick Baillot and Damiano Mazza", "title": "Linear Logic by Levels and Bounded Time Complexity", "comments": "63 pages. To appear in Theoretical Computer Science. This version\n  corrects minor fonts problems from v2", "journal-ref": "Theoretical Computer Science 411 (2010) 470-503", "doi": "10.1016/j.tcs.2009.09.015", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new characterization of elementary and deterministic polynomial\ntime computation in linear logic through the proofs-as-programs correspondence.\nGirard's seminal results, concerning elementary and light linear logic, achieve\nthis characterization by enforcing a stratification principle on proofs, using\nthe notion of depth in proof nets. Here, we propose a more general form of\nstratification, based on inducing levels in proof nets by means of indexes,\nwhich allows us to extend Girard's systems while keeping the same complexity\nproperties. In particular, it turns out that Girard's systems can be recovered\nby forcing depth and level to coincide. A consequence of the higher flexibility\nof levels with respect to depth is the absence of boxes for handling the\nparagraph modality. We use this fact to propose a variant of our polytime\nsystem in which the paragraph modality is only allowed on atoms, and which may\nthus serve as a basis for developing lambda-calculus type assignment systems\nwith more efficient typing algorithms than existing ones.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2008 15:08:20 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2009 19:00:04 GMT"}, {"version": "v3", "created": "Sun, 26 Jul 2009 13:07:48 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Baillot", "Patrick", ""], ["Mazza", "Damiano", ""]]}
{"id": "0801.1275", "submitter": "Christophe Roche", "authors": "Christophe Roche (LISTIC)", "title": "Le terme et le concept : fondements d'une ontoterminologie", "comments": "22 pages", "journal-ref": "Dans TOTh 2007 : Terminologie et Ontologie : Th\\'eories et\n  Applications - TOTh 2007 : Terminologie et Ontologie : Th\\'eories et\n  Applications, Annecy : France (2007)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Most definitions of ontology, viewed as a \"specification of a\nconceptualization\", agree on the fact that if an ontology can take different\nforms, it necessarily includes a vocabulary of terms and some specification of\ntheir meaning in relation to the domain's conceptualization. And as domain\nknowledge is mainly conveyed through scientific and technical texts, we can\nhope to extract some useful information from them for building ontology. But is\nit as simple as this? In this article we shall see that the lexical structure,\ni.e. the network of words linked by linguistic relationships, does not\nnecessarily match the domain conceptualization. We have to bear in mind that\nwriting documents is the concern of textual linguistics, of which one of the\nprinciples is the incompleteness of text, whereas building ontology - viewed as\ntask-independent knowledge - is concerned with conceptualization based on\nformal and not natural languages. Nevertheless, the famous Sapir and Whorf\nhypothesis, concerning the interdependence of thought and language, is also\napplicable to formal languages. This means that the way an ontology is built\nand a concept is defined depends directly on the formal language which is used;\nand the results will not be the same. The introduction of the notion of\nontoterminology allows to take into account epistemological principles for\nformal ontology building.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2008 20:12:02 GMT"}], "update_date": "2008-01-09", "authors_parsed": [["Roche", "Christophe", "", "LISTIC"]]}
{"id": "0801.1300", "submitter": "Igor Razgon", "authors": "Igor Razgon and Barry O'Sullivan", "title": "Almost 2-SAT is Fixed-Parameter Tractable", "comments": "This new version fixes the bug found by Somnath Sikdar in the proof\n  of Claim 8. In the repaired version the modification of the Almost 2-SAT\n  problem called 2-SLASAT is no longer needed and only the modification called\n  2-ASLASAT remains relevant. Hence the whole manuscript is updated so that the\n  2-SLASAT problem is not mentioned there anymore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LO", "license": null, "abstract": "  We consider the following problem. Given a 2-CNF formula, is it possible to\nremove at most $k$ clauses so that the resulting 2-CNF formula is satisfiable?\nThis problem is known to different research communities in Theoretical Computer\nScience under the names 'Almost 2-SAT', 'All-but-$k$ 2-SAT', '2-CNF deletion',\n'2-SAT deletion'. The status of fixed-parameter tractability of this problem is\na long-standing open question in the area of Parameterized Complexity. We\nresolve this open question by proposing an algorithm which solves this problem\nin $O(15^k*k*m^3)$ and thus we show that this problem is fixed-parameter\ntractable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2008 19:04:14 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2008 19:24:05 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2008 15:14:49 GMT"}, {"version": "v4", "created": "Fri, 18 Apr 2008 14:07:04 GMT"}], "update_date": "2008-04-18", "authors_parsed": [["Razgon", "Igor", ""], ["O'Sullivan", "Barry", ""]]}
{"id": "0801.1307", "submitter": "Chris Pollett", "authors": "Chris Pollett and Eric Miles", "title": "Alternating Hierarchies for Time-Space Tradeoffs", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": null, "abstract": "  Nepomnjascii's Theorem states that for all 0 <= \\epsilon < 1 and k > 0 the\nclass of languages recognized in nondeterministic time n^k and space\nn^\\epsilon, NTISP[n^k, n^\\epsilon ], is contained in the linear time hierarchy.\nBy considering restrictions on the size of the universal quantifiers in the\nlinear time hierarchy, this paper refines Nepomnjascii's result to give a sub-\nhierarchy, Eu-LinH, of the linear time hierarchy that is contained in NP and\nwhich contains NTISP[n^k, n^\\epsilon ]. Hence, Eu-LinH contains NL and SC. This\npaper investigates basic structural properties of Eu-LinH. Then the\nrelationships between Eu-LinH and the classes NL, SC, and NP are considered to\nsee if they can shed light on the NL = NP or SC = NP questions. Finally, a new\nhierarchy, zeta -LinH, is defined to reduce the space requirements needed for\nthe upper bound on Eu-LinH.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2008 19:59:05 GMT"}], "update_date": "2008-01-09", "authors_parsed": [["Pollett", "Chris", ""], ["Miles", "Eric", ""]]}
{"id": "0801.1336", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Stream Computing", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Stream computing is the use of multiple autonomic and parallel modules\ntogether with integrative processors at a higher level of abstraction to embody\n\"intelligent\" processing. The biological basis of this computing is sketched\nand the matter of learning is examined.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2008 14:59:31 GMT"}], "update_date": "2008-01-10", "authors_parsed": [["Kak", "Subhash", ""]]}
{"id": "0801.1410", "submitter": "Shmuel Onn", "authors": "Shmuel Onn", "title": "Two graph isomorphism polytopes", "comments": null, "journal-ref": "Discrete Mathematics, 309:2934--2936, 2009", "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO math.OC", "license": null, "abstract": "  The convex hull $\\psi_{n,n}$ of certain $(n!)^2$ tensors was considered\nrecently in connection with graph isomorphism. We consider the convex hull\n$\\psi_n$ of the $n!$ diagonals among these tensors. We show: 1. The polytope\n$\\psi_n$ is a face of $\\psi_{n,n}$. 2. Deciding if a graph $G$ has a subgraph\nisomorphic to $H$ reduces to optimization over $\\psi_n$. 3. Optimization over\n$\\psi_n$ reduces to optimization over $\\psi_{n,n}$. In particular, this implies\nthat the subgraph isomorphism problem reduces to optimization over\n$\\psi_{n,n}$.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2008 13:34:26 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2008 11:25:35 GMT"}], "update_date": "2009-08-22", "authors_parsed": [["Onn", "Shmuel", ""]]}
{"id": "0801.1600", "submitter": "Christian Hoffmann", "authors": "Christian Hoffmann", "title": "A Most General Edge Elimination Polynomial - Thickening of Edges", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": null, "abstract": "  We consider a graph polynomial \\xi(G;x,y,z) introduced by Averbouch, Godlin,\nand Makowsky (2007). This graph polynomial simultaneously generalizes the Tutte\npolynomial as well as a bivariate chromatic polynomial defined by Dohmen,\nPoenitz and Tittmann (2003). We derive an identity which relates the graph\npolynomial of a thicked graph (i.e. a graph with each edge replaced by k copies\nof it) to the graph polynomial of the original graph. As a consequence, we\nobserve that at every point (x,y,z), except for points lying within some set of\ndimension 2, evaluating \\xi is #P-hard.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2008 13:58:45 GMT"}], "update_date": "2008-01-11", "authors_parsed": [["Hoffmann", "Christian", ""]]}
{"id": "0801.1766", "submitter": "Pinyan Lu", "authors": "Jin-Yi Cai, Pinyan Lu and Mingji Xia", "title": "A Family of Counter Examples to an Approach to Graph Isomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": null, "abstract": "  We give a family of counter examples showing that the two sequences of\npolytopes $\\Phi_{n,n}$ and $\\Psi_{n,n}$ are different. These polytopes were\ndefined recently by S. Friedland in an attempt at a polynomial time algorithm\nfor graph isomorphism.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2008 12:28:05 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2008 10:12:53 GMT"}], "update_date": "2008-01-14", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Lu", "Pinyan", ""], ["Xia", "Mingji", ""]]}
{"id": "0801.1783", "submitter": "Olivier Finkel", "authors": "Jacques Duparc (UNIL), Olivier Finkel (LIP)", "title": "An omega-power of a context-free language which is Borel above\n  Delta^0_omega", "comments": "To appear in the Proceedings of the International Conference\n  Foundations of the Formal Sciences V : Infinite Games, November 26th to 29th,\n  2004, Bonn, Germany, Stefan Bold, Benedikt L\\\"owe, Thoralf R\\\"asch, Johan van\n  Benthem (eds.), College Publications at King's College (Studies in Logic),\n  2007", "journal-ref": "Dans Proceedings of the International Conference on Foundations of\n  the Formal Sciences V : Infinite Games - Foundations of the Formal Sciences V\n  : Infinite Games, November 26-29, 2004, Bonn : Allemagne", "doi": null, "report-no": null, "categories": "cs.CC cs.GT cs.LO math.LO", "license": null, "abstract": "  We use erasers-like basic operations on words to construct a set that is both\nBorel and above Delta^0_omega, built as a set V^\\omega where V is a language of\nfinite words accepted by a pushdown automaton. In particular, this gives a\nfirst example of an omega-power of a context free language which is a Borel set\nof infinite rank.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2008 14:20:30 GMT"}], "update_date": "2008-09-10", "authors_parsed": [["Duparc", "Jacques", "", "UNIL"], ["Finkel", "Olivier", "", "LIP"]]}
{"id": "0801.2069", "submitter": "Istvan Szita", "authors": "Istvan Szita and Andras Lorincz", "title": "Factored Value Iteration Converges", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel algorithm, factored value iteration (FVI),\nfor the approximate solution of factored Markov decision processes (fMDPs). The\ntraditional approximate value iteration algorithm is modified in two ways. For\none, the least-squares projection operator is modified so that it does not\nincrease max-norm, and thus preserves convergence. The other modification is\nthat we uniformly sample polynomially many samples from the (exponentially\nlarge) state space. This way, the complexity of our algorithm becomes\npolynomial in the size of the fMDP description length. We prove that the\nalgorithm is convergent. We also derive an upper bound on the difference\nbetween our approximate solution and the optimal one, and also on the error\nintroduced by sampling. We analyze various projection operators with respect to\ntheir computation complexity and their convergence when combined with\napproximate value iteration.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2008 13:09:06 GMT"}, {"version": "v2", "created": "Wed, 13 Aug 2008 15:07:08 GMT"}], "update_date": "2008-08-13", "authors_parsed": [["Szita", "Istvan", ""], ["Lorincz", "Andras", ""]]}
{"id": "0801.2201", "submitter": "Ed Harcourt", "authors": "Ed Harcourt", "title": "Policies of System Level Pipeline Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PL", "license": null, "abstract": "  Pipelining is a well understood and often used implementation technique for\nincreasing the performance of a hardware system. We develop several SystemC/C++\nmodeling techniques that allow us to quickly model, simulate, and evaluate\npipelines. We employ a small domain specific language (DSL) based on resource\nusage patterns that automates the drudgery of boilerplate code needed to\nconfigure connectivity in simulation models. The DSL is embedded directly in\nthe host modeling language SystemC/C++. Additionally we develop several\ntechniques for parameterizing a pipeline's behavior based on policies of\nfunction, communication, and timing (performance modeling).\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2008 15:44:28 GMT"}], "update_date": "2008-01-16", "authors_parsed": [["Harcourt", "Ed", ""]]}
{"id": "0801.2398", "submitter": "Zuoqiang Shi", "authors": "Thomas Y. Hou, Zuoqiang Shi", "title": "Removing the Stiffness of Elastic Force from the Immersed Boundary\n  Method for the 2D Stokes Equations", "comments": "40 pages with 8 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2008.03.002", "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": null, "abstract": "  The Immersed Boundary method has evolved into one of the most useful\ncomputational methods in studying fluid structure interaction. On the other\nhand, the Immersed Boundary method is also known to suffer from a severe\ntimestep stability restriction when using an explicit time discretization. In\nthis paper, we propose several efficient semi-implicit schemes to remove this\nstiffness from the Immersed Boundary method for the two-dimensional Stokes\nflow. First, we obtain a novel unconditionally stable semi-implicit\ndiscretization for the immersed boundary problem. Using this unconditionally\nstable discretization as a building block, we derive several efficient\nsemi-implicit schemes for the immersed boundary problem by applying the Small\nScale Decomposition to this unconditionally stable discretization. Our\nstability analysis and extensive numerical experiments show that our\nsemi-implicit schemes offer much better stability property than the explicit\nscheme. Unlike other implicit or semi-implicit schemes proposed in the\nliterature, our semi-implicit schemes can be solved explicitly in the spectral\nspace. Thus the computational cost of our semi-implicit schemes is comparable\nto that of an explicit scheme, but with a much better stability property.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2008 22:22:25 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2008 21:38:37 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Hou", "Thomas Y.", ""], ["Shi", "Zuoqiang", ""]]}
{"id": "0801.2793", "submitter": "Jeff M Phillips", "authors": "Jeff M. Phillips", "title": "Algorithms for eps-approximations of Terrains", "comments": "24 pages. Long version to supplement conference version to appear in\n  ICALP in May 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  Consider a point set D with a measure function w : D -> R. Let A be the set\nof subsets of D induced by containment in a shape from some geometric family\n(e.g. axis-aligned rectangles, half planes, balls, k-oriented polygons). We say\na range space (D, A) has an eps-approximation P if max {R \\in A} | w(R \\cap\nP)/w(P) - w(R \\cap D)/w(D) | <= eps. We describe algorithms for\ndeterministically constructing discrete eps-approximations for continuous point\nsets such as distributions or terrains. Furthermore, for certain families of\nsubsets A, such as those described by axis-aligned rectangles, we reduce the\nsize of the eps-approximations by almost a square root from O(1/eps^2 log\n1/eps) to O(1/eps polylog 1/eps). This is often the first step in transforming\na continuous problem into a discrete one for which combinatorial techniques can\nbe applied. We describe applications of this result in geo-spatial analysis,\nbiosurveillance, and sensor networks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2008 01:19:44 GMT"}, {"version": "v2", "created": "Fri, 9 May 2008 05:48:55 GMT"}], "update_date": "2008-05-09", "authors_parsed": [["Phillips", "Jeff M.", ""]]}
{"id": "0801.2858", "submitter": "Fabrizio Altarelli", "authors": "Fabrizio Altarelli", "title": "Theoretical analysis of optimization problems - Some properties of\n  random k-SAT and k-XORSAT", "comments": "Ph.D. thesis, 132 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.CC", "license": null, "abstract": "  This thesis is divided in two parts. The first presents an overview of known\nresults in statistical mechanics of disordered systems and its approach to\nrandom combinatorial optimization problems. The second part is a discussion of\ntwo original results.\n  The first result concerns DPLL heuristics for random k-XORSAT, which is\nequivalent to the diluted Ising p-spin model. It is well known that DPLL is\nunable to find the ground states in the clustered phase of the problem, i.e.\nthat it leads to contradictions with probability 1. However, no solid argument\nsupports this is general. A class of heuristics, which includes the well known\nUC and GUC, is introduced and studied. It is shown that any heuristic in this\nclass must fail if the clause to variable ratio is larger than some constant,\nwhich depends on the heuristic but is always smaller than the clustering\nthreshold.\n  The second result concerns the properties of random k-SAT at large clause to\nvariable ratios. In this regime, it is well known that the uniform distribution\nof random instances is dominated by unsatisfiable instances. A general\ntechnique (based on the Replica method) to restrict the distribution to\nsatisfiable instances with uniform weight is introduced, and is used to\ncharacterize their solutions. It is found that in the limit of large clause to\nvariable ratios, the uniform distribution of satisfiable random k-SAT formulas\nis asymptotically equal to the much studied Planted distribution.\n  Both results are already published and available as arXiv:0709.0367 and\narXiv:cs/0609101 . A more detailed and self-contained derivation is presented\nhere.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2008 11:50:32 GMT"}], "update_date": "2008-01-21", "authors_parsed": [["Altarelli", "Fabrizio", ""]]}
{"id": "0801.2890", "submitter": "Abolfazl Ramezanpour", "authors": "L. Dall'Asta, A. Ramezanpour and R. Zecchina", "title": "Entropy landscape and non-Gibbs solutions in constraint satisfaction\n  problems", "comments": "38 pages, 10 figures", "journal-ref": "Phys. Rev. E 77, 031118 (2008)", "doi": "10.1103/PhysRevE.77.031118", "report-no": null, "categories": "cond-mat.stat-mech cs.CC", "license": null, "abstract": "  We study the entropy landscape of solutions for the bicoloring problem in\nrandom graphs, a representative difficult constraint satisfaction problem. Our\ngoal is to classify which type of clusters of solutions are addressed by\ndifferent algorithms. In the first part of the study we use the cavity method\nto obtain the number of clusters with a given internal entropy and determine\nthe phase diagram of the problem, e.g. dynamical, rigidity and SAT-UNSAT\ntransitions. In the second part of the paper we analyze different algorithms\nand locate their behavior in the entropy landscape of the problem. For instance\nwe show that a smoothed version of a decimation strategy based on Belief\nPropagation is able to find solutions belonging to sub-dominant clusters even\nbeyond the so called rigidity transition where the thermodynamically relevant\nclusters become frozen. These non-equilibrium solutions belong to the most\nprobable unfrozen clusters.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2008 14:11:10 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Dall'Asta", "L.", ""], ["Ramezanpour", "A.", ""], ["Zecchina", "R.", ""]]}
{"id": "0801.3046", "submitter": "John Stockie", "authors": "Michael Chapwanya, Wentao Liu and John M. Stockie", "title": "A model for reactive porous transport during re-wetting of hardened\n  concrete", "comments": "30 pages", "journal-ref": "Journal of Engineering Mathematics, 65(1):53-73, 2009", "doi": "10.1007/s10665-009-9268-0", "report-no": null, "categories": "cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mathematical model is developed that captures the transport of liquid water\nin hardened concrete, as well as the chemical reactions that occur between the\nimbibed water and the residual calcium silicate compounds residing in the\nporous concrete matrix. The main hypothesis in this model is that the reaction\nproduct -- calcium silicate hydrate gel -- clogs the pores within the concrete\nthereby hindering water transport. Numerical simulations are employed to\ndetermine the sensitivity of the model solution to changes in various physical\nparameters, and compare to experimental results available in the literature.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2008 18:54:01 GMT"}, {"version": "v2", "created": "Tue, 26 Aug 2008 17:55:14 GMT"}, {"version": "v3", "created": "Fri, 2 Jan 2009 04:15:45 GMT"}], "update_date": "2009-08-12", "authors_parsed": [["Chapwanya", "Michael", ""], ["Liu", "Wentao", ""], ["Stockie", "John M.", ""]]}
{"id": "0801.3111", "submitter": "Martin Pelikan", "authors": "Martin Pelikan", "title": "Analysis of Estimation of Distribution Algorithms and Genetic Algorithms\n  on NK Landscapes", "comments": "Also available at the MEDAL web site, http://medal.cs.umsl.edu/", "journal-ref": "Proceedings of the Genetic and Evolutionary Computation Conference\n  (GECCO-2008), ACM Press, 1033-1040", "doi": null, "report-no": "MEDAL Report No. 2008001", "categories": "cs.NE cs.AI", "license": null, "abstract": "  This study analyzes performance of several genetic and evolutionary\nalgorithms on randomly generated NK fitness landscapes with various values of n\nand k. A large number of NK problem instances are first generated for each n\nand k, and the global optimum of each instance is obtained using the\nbranch-and-bound algorithm. Next, the hierarchical Bayesian optimization\nalgorithm (hBOA), the univariate marginal distribution algorithm (UMDA), and\nthe simple genetic algorithm (GA) with uniform and two-point crossover\noperators are applied to all generated instances. Performance of all algorithms\nis then analyzed and compared, and the results are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2008 00:20:50 GMT"}], "update_date": "2008-07-30", "authors_parsed": [["Pelikan", "Martin", ""]]}
{"id": "0801.3113", "submitter": "Martin Pelikan", "authors": "Martin Pelikan, Kumara Sastry, and David E. Goldberg", "title": "iBOA: The Incremental Bayesian Optimization Algorithm", "comments": "Also available at the MEDAL web site, http://medal.cs.umsl.edu/", "journal-ref": "Proceedings of the Genetic and Evolutionary Computation Conference\n  (GECCO-2008), ACM Press, 455-462", "doi": null, "report-no": "MEDAL Report No. 2008002", "categories": "cs.NE cs.AI", "license": null, "abstract": "  This paper proposes the incremental Bayesian optimization algorithm (iBOA),\nwhich modifies standard BOA by removing the population of solutions and using\nincremental updates of the Bayesian network. iBOA is shown to be able to learn\nand exploit unrestricted Bayesian networks using incremental techniques for\nupdating both the structure as well as the parameters of the probabilistic\nmodel. This represents an important step toward the design of competent\nincremental estimation of distribution algorithms that can solve difficult\nnearly decomposable problems scalably and reliably.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2008 00:34:55 GMT"}], "update_date": "2008-07-30", "authors_parsed": [["Pelikan", "Martin", ""], ["Sastry", "Kumara", ""], ["Goldberg", "David E.", ""]]}
{"id": "0801.3147", "submitter": "Ke Xu", "authors": "Liang Li, Xin Li, Tian Liu, Ke Xu", "title": "From k-SAT to k-CSP: Two Generalized Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": null, "abstract": "  Constraint satisfaction problems (CSPs) models many important intractable\nNP-hard problems such as propositional satisfiability problem (SAT). Algorithms\nwith non-trivial upper bounds on running time for restricted SAT with bounded\nclause length k (k-SAT) can be classified into three styles: DPLL-like,\nPPSZ-like and Local Search, with local search algorithms having already been\ngeneralized to CSP with bounded constraint arity k (k-CSP). We generalize a\nDPLL-like algorithm in its simplest form and a PPSZ-like algorithm from k-SAT\nto k-CSP. As far as we know, this is the first attempt to use PPSZ-like\nstrategy to solve k-CSP, and before little work has been focused on the\nDPLL-like or PPSZ-like strategies for k-CSP.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2008 08:07:33 GMT"}], "update_date": "2008-01-22", "authors_parsed": [["Li", "Liang", ""], ["Li", "Xin", ""], ["Liu", "Tian", ""], ["Xu", "Ke", ""]]}
{"id": "0801.3147", "submitter": "Ke Xu", "authors": "Liang Li, Xin Li, Tian Liu, Ke Xu", "title": "From k-SAT to k-CSP: Two Generalized Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": null, "abstract": "  Constraint satisfaction problems (CSPs) models many important intractable\nNP-hard problems such as propositional satisfiability problem (SAT). Algorithms\nwith non-trivial upper bounds on running time for restricted SAT with bounded\nclause length k (k-SAT) can be classified into three styles: DPLL-like,\nPPSZ-like and Local Search, with local search algorithms having already been\ngeneralized to CSP with bounded constraint arity k (k-CSP). We generalize a\nDPLL-like algorithm in its simplest form and a PPSZ-like algorithm from k-SAT\nto k-CSP. As far as we know, this is the first attempt to use PPSZ-like\nstrategy to solve k-CSP, and before little work has been focused on the\nDPLL-like or PPSZ-like strategies for k-CSP.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2008 08:07:33 GMT"}], "update_date": "2008-01-22", "authors_parsed": [["Li", "Liang", ""], ["Li", "Xin", ""], ["Liu", "Tian", ""], ["Xu", "Ke", ""]]}
{"id": "0801.3209", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin", "title": "A Pyramidal Evolutionary Algorithm with Different Inter-Agent Partnering\n  Strategies for Scheduling Problems", "comments": null, "journal-ref": "Proceedings of the Genetic and Evolutionary Computation Conference\n  (GECCO 2001), late-breaking papers volume, pp 1-8, San Francisco, USA", "doi": null, "report-no": null, "categories": "cs.NE cs.CE", "license": null, "abstract": "  This paper combines the idea of a hierarchical distributed genetic algorithm\nwith different inter-agent partnering strategies. Cascading clusters of\nsub-populations are built from bottom up, with higher-level sub-populations\noptimising larger parts of the problem. Hence higher-level sub-populations\nsearch a larger search space with a lower resolution whilst lower-level\nsub-populations search a smaller search space with a higher resolution. The\neffects of different partner selection schemes amongst the agents on solution\nquality are examined for two multiple-choice optimisation problems. It is shown\nthat partnering strategies that exploit problem-specific knowledge are superior\nand can counter inappropriate (sub-) fitness measurements.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2008 15:55:22 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:10:36 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""]]}
{"id": "0801.3331", "submitter": "Guillaume Hanrot", "authors": "Guillaume Hanrot (INRIA Lorraine - LORIA), Damien Stehl\\'e (INRIA\n  Rh\\^one-Alpes)", "title": "Worst-Case Hermite-Korkine-Zolotarev Reduced Lattice Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC cs.CR", "license": null, "abstract": "  The Hermite-Korkine-Zolotarev reduction plays a central role in strong\nlattice reduction algorithms. By building upon a technique introduced by Ajtai,\nwe show the existence of Hermite-Korkine-Zolotarev reduced bases that are\narguably least reduced. We prove that for such bases, Kannan's algorithm\nsolving the shortest lattice vector problem requires\n$d^{\\frac{d}{2\\e}(1+o(1))}$ bit operations in dimension $d$. This matches the\nbest complexity upper bound known for this algorithm. These bases also provide\nlower bounds on Schnorr's constants $\\alpha_d$ and $\\beta_d$ that are\nessentially equal to the best upper bounds. Finally, we also show the existence\nof particularly bad bases for Schnorr's hierarchy of reductions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2008 09:52:35 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2008 15:13:23 GMT"}], "update_date": "2008-01-24", "authors_parsed": [["Hanrot", "Guillaume", "", "INRIA Lorraine - LORIA"], ["Stehlé", "Damien", "", "INRIA\n  Rhône-Alpes"]]}
{"id": "0801.3539", "submitter": "Uwe Aickelin", "authors": "Steve Cayzer and Uwe Aickelin", "title": "On the Effects of Idiotypic Interactions for Recommendation Communities\n  in Artificial Immune Systems", "comments": null, "journal-ref": "Proceedings of the 1st International Conference on Artificial\n  Immune Systems (ICARIS 2002), pp 154-160, Canterbury, UK, 2001", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  It has previously been shown that a recommender based on immune system\nidiotypic principles can out perform one based on correlation alone. This paper\nreports the results of work in progress, where we undertake some investigations\ninto the nature of this beneficial effect. The initial findings are that the\nimmune system recommender tends to produce different neighbourhoods, and that\nthe superior performance of this recommender is due partly to the different\nneighbourhoods, and partly to the way that the idiotypic effect is used to\nweight each neighbours recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2008 09:59:06 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:10:05 GMT"}, {"version": "v3", "created": "Fri, 16 May 2008 10:42:42 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Cayzer", "Steve", ""], ["Aickelin", "Uwe", ""]]}
{"id": "0801.3547", "submitter": "Uwe Aickelin", "authors": "Steve Cazyer and Uwe Aickelin", "title": "A Recommender System based on the Immune Network", "comments": null, "journal-ref": "Proceedings of the IEEE Congress on Evolutionary Computation (CEC\n  2002), pp 807-813, Honolulu, USA, 2002", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  The immune system is a complex biological system with a highly distributed,\nadaptive and self-organising nature. This paper presents an artificial immune\nsystem (AIS) that exploits some of these characteristics and is applied to the\ntask of film recommendation by collaborative filtering (CF). Natural evolution\nand in particular the immune system have not been designed for classical\noptimisation. However, for this problem, we are not interested in finding a\nsingle optimum. Rather we intend to identify a sub-set of good matches on which\nrecommendations can be based. It is our hypothesis that an AIS built on two\ncentral aspects of the biological immune system will be an ideal candidate to\nachieve this: Antigen - antibody interaction for matching and antibody -\nantibody interaction for diversity. Computational results are presented in\nsupport of this conjecture and compared to those found by other CF techniques.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2008 10:42:49 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:09:24 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Cazyer", "Steve", ""], ["Aickelin", "Uwe", ""]]}
{"id": "0801.3549", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin and Steve Cayzer", "title": "The Danger Theory and Its Application to Artificial Immune Systems", "comments": null, "journal-ref": "Proceedings of the 1st International Conference on Artificial\n  Immune Systems (ICARIS 2002), pp 141-148, Canterbury, Uk, 2002", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CR", "license": null, "abstract": "  Over the last decade, a new idea challenging the classical self-non-self\nviewpoint has become popular amongst immunologists. It is called the Danger\nTheory. In this conceptual paper, we look at this theory from the perspective\nof Artificial Immune System practitioners. An overview of the Danger Theory is\npresented with particular emphasis on analogies in the Artificial Immune\nSystems world. A number of potential application areas are then used to provide\na framing for a critical assessment of the concept, and its relevance for\nArtificial Immune Systems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2008 11:01:31 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:08:46 GMT"}, {"version": "v3", "created": "Fri, 16 May 2008 10:45:49 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""], ["Cayzer", "Steve", ""]]}
{"id": "0801.3550", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin and Larry Bull", "title": "Partnering Strategies for Fitness Evaluation in a Pyramidal Evolutionary\n  Algorithm", "comments": null, "journal-ref": "Proceedings of the Genetic and Evolutionary Computation Conference\n  (GECCO 2002), pp 263-270, New York, USA, 2002", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  This paper combines the idea of a hierarchical distributed genetic algorithm\nwith different inter-agent partnering strategies. Cascading clusters of\nsub-populations are built from bottom up, with higher-level sub-populations\noptimising larger parts of the problem. Hence higher-level sub-populations\nsearch a larger search space with a lower resolution whilst lower-level\nsub-populations search a smaller search space with a higher resolution. The\neffects of different partner selection schemes for (sub-)fitness evaluation\npurposes are examined for two multiple-choice optimisation problems. It is\nshown that random partnering strategies perform best by providing better\nsampling and more diversity.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2008 11:12:39 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:08:00 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""], ["Bull", "Larry", ""]]}
{"id": "0801.3581", "submitter": "Shay Solomon", "authors": "Yefim Dinitz, Michael Elkin, Shay Solomon", "title": "Shallow, Low, and Light Trees, and Tight Lower Bounds for Euclidean\n  Spanners", "comments": "41 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": null, "abstract": "  We show that for every $n$-point metric space $M$ there exists a spanning\ntree $T$ with unweighted diameter $O(\\log n)$ and weight $\\omega(T) = O(\\log n)\n\\cdot \\omega(MST(M))$. Moreover, there is a designated point $rt$ such that for\nevery point $v$, $dist_T(rt,v) \\le (1+\\epsilon) \\cdot dist_M(rt,v)$, for an\narbitrarily small constant $\\epsilon > 0$. We extend this result, and provide a\ntradeoff between unweighted diameter and weight, and prove that this tradeoff\nis \\emph{tight up to constant factors} in the entire range of parameters. These\nresults enable us to settle a long-standing open question in Computational\nGeometry. In STOC'95 Arya et al. devised a construction of Euclidean Spanners\nwith unweighted diameter $O(\\log n)$ and weight $O(\\log n) \\cdot\n\\omega(MST(M))$. Ten years later in SODA'05 Agarwal et al. showed that this\nresult is tight up to a factor of $O(\\log \\log n)$. We close this gap and show\nthat the result of Arya et al. is tight up to constant factors.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2008 13:57:00 GMT"}], "update_date": "2011-08-31", "authors_parsed": [["Dinitz", "Yefim", ""], ["Elkin", "Michael", ""], ["Solomon", "Shay", ""]]}
{"id": "0801.3624", "submitter": "Anil Ada", "authors": "Arkadev Chattopadhyay and Anil Ada", "title": "Multiparty Communication Complexity of Disjointness", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  We obtain a lower bound of n^Omega(1) on the k-party randomized communication\ncomplexity of the Disjointness function in the `Number on the Forehead' model\nof multiparty communication when k is a constant. For k=o(loglog n), the bounds\nremain super-polylogarithmic i.e. (log n)^omega(1). The previous best lower\nbound for three players until recently was Omega(log n).\n  Our bound separates the communication complexity classes NP^{CC}_k and\nBPP^{CC}_k for k=o(loglog n). Furthermore, by the results of Beame, Pitassi and\nSegerlind \\cite{BPS07}, our bound implies proof size lower bounds for\ntree-like, degree k-1 threshold systems and superpolynomial size lower bounds\nfor Lovasz-Schrijver proofs.\n  Sherstov \\cite{She07b} recently developed a novel technique to obtain lower\nbounds on two-party communication using the approximate polynomial degree of\nboolean functions. We obtain our results by extending his technique to the\nmulti-party setting using ideas from Chattopadhyay \\cite{Cha07}.\n  A similar bound for Disjointness has been recently and independently obtained\nby Lee and Shraibman.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2008 16:39:31 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2008 17:39:19 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2008 23:04:00 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Chattopadhyay", "Arkadev", ""], ["Ada", "Anil", ""]]}
{"id": "0801.3669", "submitter": "Mohammad Mahmoody", "authors": "Boaz Barak, Mohammad Mahmoody", "title": "Merkle's Key Agreement Protocol is Optimal: An $O(n^2)$ Attack on any\n  Key Agreement from Random Oracles", "comments": "This version fixes a bug in the proof of the previous version of this\n  paper, see \"Correction of Error\" paragraph and Appendix A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that every key agreement protocol in the random oracle model in\nwhich the honest users make at most $n$ queries to the oracle can be broken by\nan adversary who makes $O(n^2)$ queries to the oracle. This improves on the\nprevious $\\widetilde{\\Omega}(n^6)$ query attack given by Impagliazzo and Rudich\n(STOC '89) and resolves an open question posed by them.\n  Our bound is optimal up to a constant factor since Merkle proposed a key\nagreement protocol in 1974 that can be easily implemented with $n$ queries to a\nrandom oracle and cannot be broken by any adversary who asks $o(n^2)$ queries.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2008 21:01:37 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2008 01:41:04 GMT"}, {"version": "v3", "created": "Thu, 10 Jul 2008 14:14:45 GMT"}, {"version": "v4", "created": "Sun, 31 Mar 2019 00:51:20 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Barak", "Boaz", ""], ["Mahmoody", "Mohammad", ""]]}
{"id": "0801.3680", "submitter": "Mohammad Mahmoody", "authors": "Boaz Barak, Mohammad Mahmoody", "title": "Lower Bounds on Signatures from Symmetric Primitives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every construction of one-time signature schemes from a random\noracle achieves black-box security at most $2^{(1+o(1))q}$, where $q$ is the\ntotal number of oracle queries asked by the key generation, signing, and\nverification algorithms. That is, any such scheme can be broken with\nprobability close to $1$ by a (computationally unbounded) adversary making\n$2^{(1+o(1))q}$ queries to the oracle. This is tight up to a constant factor in\nthe number of queries, since a simple modification of Lamport's one-time\nsignatures (Lamport '79) achieves $2^{(0.812-o(1))q}$ black-box security using\n$q$ queries to the oracle.\n  Our result extends (with a loss of a constant factor in the number of\nqueries) also to the random permutation and ideal-cipher oracles. Since the\nsymmetric primitives (e.g. block ciphers, hash functions, and message\nauthentication codes) can be constructed by a constant number of queries to the\nmentioned oracles, as corollary we get lower bounds on the efficiency of\nsignature schemes from symmetric primitives when the construction is black-box.\nThis can be taken as evidence of an inherent efficiency gap between signature\nschemes and symmetric primitives.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2008 22:16:00 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2008 02:13:43 GMT"}, {"version": "v3", "created": "Sun, 31 Mar 2019 00:40:57 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Barak", "Boaz", ""], ["Mahmoody", "Mohammad", ""]]}
{"id": "0801.3790", "submitter": "Khaled Elbassioni", "authors": "Endre Boros, Khaled Elbassioni, Vladimir Gurvich, Hans Raj Tiwary", "title": "Characterization of the Vertices and Extreme Directions of the Negative\n  Cycles Polyhedron and Hardness of Generating Vertices of 0/1-Polyhedra", "comments": "Title typo fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": null, "abstract": "  Given a graph $G=(V,E)$ and a weight function on the edges $w:E\\mapsto\\RR$,\nwe consider the polyhedron $P(G,w)$ of negative-weight flows on $G$, and get a\ncomplete characterization of the vertices and extreme directions of $P(G,w)$.\nAs a corollary, we show that, unless $P=NP$, there is no output polynomial-time\nalgorithm to generate all the vertices of a 0/1-polyhedron. This strengthens\nthe NP-hardness result of Khachiyan et al. (2006) for non 0/1-polyhedra, and\ncomes in contrast with the polynomiality of vertex enumeration for\n0/1-polytopes \\cite{BL98} [Bussieck and L\\\"ubbecke (1998)].\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2008 16:16:45 GMT"}, {"version": "v2", "created": "Mon, 28 Apr 2008 17:26:09 GMT"}], "update_date": "2008-04-28", "authors_parsed": [["Boros", "Endre", ""], ["Elbassioni", "Khaled", ""], ["Gurvich", "Vladimir", ""], ["Tiwary", "Hans Raj", ""]]}
{"id": "0801.3802", "submitter": "Sven Kosub", "authors": "Sven Kosub", "title": "Dichotomy Results for Fixed-Point Existence Problems for Boolean\n  Dynamical Systems", "comments": "17 pages; this version corrects an error/typo in the 2008/01/24\n  version", "journal-ref": "Mathematics in Computer Science, 1(3):487-505, 2008, special issue\n  on Modeling and Analysis of Complex Systems", "doi": null, "report-no": "TUM-I0701, Institut fuer Informatik, Technische Universitaet\n  Muenchen", "categories": "cs.CC cond-mat.dis-nn cs.DM nlin.AO nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complete classification of the computational complexity of the fixed-point\nexistence problem for boolean dynamical systems, i.e., finite discrete\ndynamical systems over the domain {0, 1}, is presented. For function classes F\nand graph classes G, an (F, G)-system is a boolean dynamical system such that\nall local transition functions lie in F and the underlying graph lies in G. Let\nF be a class of boolean functions which is closed under composition and let G\nbe a class of graphs which is closed under taking minors. The following\ndichotomy theorems are shown: (1) If F contains the self-dual functions and G\ncontains the planar graphs then the fixed-point existence problem for (F,\nG)-systems with local transition function given by truth-tables is NP-complete;\notherwise, it is decidable in polynomial time. (2) If F contains the self-dual\nfunctions and G contains the graphs having vertex covers of size one then the\nfixed-point existence problem for (F, G)-systems with local transition function\ngiven by formulas or circuits is NP-complete; otherwise, it is decidable in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2008 17:10:12 GMT"}, {"version": "v2", "created": "Mon, 1 Dec 2008 16:53:14 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Kosub", "Sven", ""]]}
{"id": "0801.3871", "submitter": "Ke Xu", "authors": "Chunyan Zhao, Ke Xu, Zhiming Zheng", "title": "On the Scaling Window of Model RB", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cond-mat.stat-mech cs.AI", "license": null, "abstract": "  This paper analyzes the scaling window of a random CSP model (i.e. model RB)\nfor which we can identify the threshold points exactly, denoted by $r_{cr}$ or\n$p_{cr}$. For this model, we establish the scaling window\n$W(n,\\delta)=(r_{-}(n,\\delta), r_{+}(n,\\delta))$ such that the probability of a\nrandom instance being satisfiable is greater than $1-\\delta$ for\n$r<r_{-}(n,\\delta)$ and is less than $\\delta$ for $r>r_{+}(n,\\delta)$.\nSpecifically, we obtain the following result\n$$W(n,\\delta)=(r_{cr}-\\Theta(\\frac{1}{n^{1-\\epsilon}\\ln n}), \\\nr_{cr}+\\Theta(\\frac{1}{n\\ln n})),$$ where $0\\leq\\epsilon<1$ is a constant. A\nsimilar result with respect to the other parameter $p$ is also obtained. Since\nthe instances generated by model RB have been shown to be hard at the\nthreshold, this is the first attempt, as far as we know, to analyze the scaling\nwindow of such a model with hard instances.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 02:18:00 GMT"}], "update_date": "2008-01-28", "authors_parsed": [["Zhao", "Chunyan", ""], ["Xu", "Ke", ""], ["Zheng", "Zhiming", ""]]}
{"id": "0801.3871", "submitter": "Ke Xu", "authors": "Chunyan Zhao, Ke Xu, Zhiming Zheng", "title": "On the Scaling Window of Model RB", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cond-mat.stat-mech cs.AI", "license": null, "abstract": "  This paper analyzes the scaling window of a random CSP model (i.e. model RB)\nfor which we can identify the threshold points exactly, denoted by $r_{cr}$ or\n$p_{cr}$. For this model, we establish the scaling window\n$W(n,\\delta)=(r_{-}(n,\\delta), r_{+}(n,\\delta))$ such that the probability of a\nrandom instance being satisfiable is greater than $1-\\delta$ for\n$r<r_{-}(n,\\delta)$ and is less than $\\delta$ for $r>r_{+}(n,\\delta)$.\nSpecifically, we obtain the following result\n$$W(n,\\delta)=(r_{cr}-\\Theta(\\frac{1}{n^{1-\\epsilon}\\ln n}), \\\nr_{cr}+\\Theta(\\frac{1}{n\\ln n})),$$ where $0\\leq\\epsilon<1$ is a constant. A\nsimilar result with respect to the other parameter $p$ is also obtained. Since\nthe instances generated by model RB have been shown to be hard at the\nthreshold, this is the first attempt, as far as we know, to analyze the scaling\nwindow of such a model with hard instances.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 02:18:00 GMT"}], "update_date": "2008-01-28", "authors_parsed": [["Zhao", "Chunyan", ""], ["Xu", "Ke", ""], ["Zheng", "Zhiming", ""]]}
{"id": "0801.3875", "submitter": "Jan Mandel", "authors": "Jan Mandel, Jonathan D. Beezley, Soham Chakraborty, Janice L. Coen,\n  Craig C. Douglas, Anthony Vodacek, Zhen Wang", "title": "Towards a Real-Time Data Driven Wildland Fire Model", "comments": "5 pages, 4 figures", "journal-ref": "IEEE International Symposium on Parallel and Distributed\n  Processing, 2008 (IPDPS 2008), pp. 1-5", "doi": "10.1109/IPDPS.2008.4536414", "report-no": "UCD CCM Report 265", "categories": "physics.ao-ph cs.CE", "license": null, "abstract": "  A wildland fire model based on semi-empirical relations for the spread rate\nof a surface fire and post-frontal heat release is coupled with the Weather\nResearch and Forecasting atmospheric model (WRF). The propagation of the fire\nfront is implemented by a level set method. Data is assimilated by a morphing\nensemble Kalman filter, which provides amplitude as well as position\ncorrections. Thermal images of a fire will provide the observations and will be\ncompared to a synthetic image from the model state.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 04:41:01 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2008 00:40:22 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Mandel", "Jan", ""], ["Beezley", "Jonathan D.", ""], ["Chakraborty", "Soham", ""], ["Coen", "Janice L.", ""], ["Douglas", "Craig C.", ""], ["Vodacek", "Anthony", ""], ["Wang", "Zhen", ""]]}
{"id": "0801.3912", "submitter": "Olivier Finkel", "authors": "Olivier Carton (LIAFA), Olivier Finkel (LIP), Pierre Simonnet (SPE)", "title": "On the Continuity Set of an omega Rational Function", "comments": "Dedicated to Serge Grigorieff on the occasion of his 60th Birthday", "journal-ref": "Theoretical Informatics and Applications (1), 42 (2008) 183-196", "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": null, "abstract": "  In this paper, we study the continuity of rational functions realized by\nB\\\"uchi finite state transducers. It has been shown by Prieur that it can be\ndecided whether such a function is continuous. We prove here that surprisingly,\nit cannot be decided whether such a function F has at least one point of\ncontinuity and that its continuity set C(F) cannot be computed. In the case of\na synchronous rational function, we show that its continuity set is rational\nand that it can be computed. Furthermore we prove that any rational\nPi^0_2-subset of X^omega for some alphabet X is the continuity set C(F) of an\nomega-rational synchronous function F defined on X^omega.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 10:54:05 GMT"}], "update_date": "2008-01-28", "authors_parsed": [["Carton", "Olivier", "", "LIAFA"], ["Finkel", "Olivier", "", "LIP"], ["Simonnet", "Pierre", "", "SPE"]]}
{"id": "0801.3971", "submitter": "Uwe Aickelin", "authors": "Jingpeng Li and Uwe Aickelin", "title": "A Bayesian Optimisation Algorithm for the Nurse Scheduling Problem", "comments": null, "journal-ref": "Proceedings of the IEEE Congress on Evolutionary Computation (CEC\n  2003), pp 2149-2156, Canberra, Australia, 2003", "doi": null, "report-no": null, "categories": "cs.NE cs.CE", "license": null, "abstract": "  A Bayesian optimization algorithm for the nurse scheduling problem is\npresented, which involves choosing a suitable scheduling rule from a set for\neach nurses assignment. Unlike our previous work that used Gas to implement\nimplicit learning, the learning in the proposed algorithm is explicit, ie.\nEventually, we will be able to identify and mix building blocks directly. The\nBayesian optimization algorithm is applied to implement such explicit learning\nby building a Bayesian network of the joint distribution of solutions. The\nconditional probability of each variable in the network is computed according\nto an initial set of promising solutions. Subsequently, each new instance for\neach variable is generated, ie in our case, a new rule string has been\nobtained. Another set of rule strings will be generated in this way, some of\nwhich will replace previous strings based on fitness selection. If stopping\nconditions are not met, the conditional probabilities for all nodes in the\nBayesian network are updated again using the current set of promising rule\nstrings. Computational results from 52 real data instances demonstrate the\nsuccess of this approach. It is also suggested that the learning mechanism in\nthe proposed approach might be suitable for other scheduling problems.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 16:07:25 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:07:17 GMT"}, {"version": "v3", "created": "Fri, 16 May 2008 10:43:52 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Li", "Jingpeng", ""], ["Aickelin", "Uwe", ""]]}
{"id": "0801.4013", "submitter": "Mathieu Couture", "authors": "Prosenjit Bose and Paz Carmi and Mathieu Couture", "title": "Spanners of Additively Weighted Point Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  We study the problem of computing geometric spanners for (additively)\nweighted point sets. A weighted point set is a set of pairs $(p,r)$ where $p$\nis a point in the plane and $r$ is a real number. The distance between two\npoints $(p_i,r_i)$ and $(p_j,r_j)$ is defined as $|p_ip_j|-r_i-r_j$. We show\nthat in the case where all $r_i$ are positive numbers and $|p_ip_j|\\geq\nr_i+r_j$ for all $i,j$ (in which case the points can be seen as\nnon-intersecting disks in the plane), a variant of the Yao graph is a\n$(1+\\epsilon)$-spanner that has a linear number of edges. We also show that the\nAdditively Weighted Delaunay graph (the face-dual of the Additively Weighted\nVoronoi diagram) has constant spanning ratio. The straight line embedding of\nthe Additively Weighted Delaunay graph may not be a plane graph. We show how to\ncompute a plane embedding that also has a constant spanning ratio.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 19:43:09 GMT"}], "update_date": "2008-01-28", "authors_parsed": [["Bose", "Prosenjit", ""], ["Carmi", "Paz", ""], ["Couture", "Mathieu", ""]]}
{"id": "0801.4019", "submitter": "Joseph O'Rourke", "authors": "Alex Benton and Joseph O'Rourke", "title": "A Class of Convex Polyhedra with Few Edge Unfoldings", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": "Smith Computer Science 088", "categories": "cs.CG", "license": null, "abstract": "  We construct a sequence of convex polyhedra on n vertices with the property\nthat, as n -> infinity, the fraction of its edge unfoldings that avoid overlap\napproaches 0, and so the fraction that overlap approaches 1. Nevertheless, each\ndoes have (several) nonoverlapping edge unfoldings.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 20:22:04 GMT"}], "update_date": "2008-01-28", "authors_parsed": [["Benton", "Alex", ""], ["O'Rourke", "Joseph", ""]]}
{"id": "0801.4024", "submitter": "Ilya Shmulevich", "authors": "David J. Galas, Matti Nykter, Gregory W. Carter, Nathan D. Price, Ilya\n  Shmulevich", "title": "Set-based complexity and biological information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT q-bio.QM", "license": null, "abstract": "  It is not obvious what fraction of all the potential information residing in\nthe molecules and structures of living systems is significant or meaningful to\nthe system. Sets of random sequences or identically repeated sequences, for\nexample, would be expected to contribute little or no useful information to a\ncell. This issue of quantitation of information is important since the ebb and\nflow of biologically significant information is essential to our quantitative\nunderstanding of biological function and evolution. Motivated specifically by\nthese problems of biological information, we propose here a class of measures\nto quantify the contextual nature of the information in sets of objects, based\non Kolmogorov's intrinsic complexity. Such measures discount both random and\nredundant information and are inherent in that they do not require a defined\nstate space to quantify the information. The maximization of this new measure,\nwhich can be formulated in terms of the universal information distance, appears\nto have several useful and interesting properties, some of which we illustrate\nwith examples.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 20:58:14 GMT"}], "update_date": "2008-01-28", "authors_parsed": [["Galas", "David J.", ""], ["Nykter", "Matti", ""], ["Carter", "Gregory W.", ""], ["Price", "Nathan D.", ""], ["Shmulevich", "Ilya", ""]]}
{"id": "0801.4105", "submitter": "Steven Perron", "authors": "Steven Perron (University of Toronto)", "title": "Quantified Propositional Logspace Reasoning", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": null, "abstract": "  In this paper, we develop a quantified propositional proof systems that\ncorresponds to logarithmic-space reasoning. We begin by defining a class\nSigmaCNF(2) of quantified formulas that can be evaluated in log space. Then our\nnew proof system GL^* is defined as G_1^* with cuts restricted to SigmaCNF(2)\nformulas and no cut formula that is not quantifier free contains a free\nvariable that does not appear in the final formula.\n  To show that GL^* is strong enough to capture log space reasoning, we\ntranslate theorems of VL into a family of tautologies that have polynomial-size\nGL^* proofs. VL is a theory of bounded arithmetic that is known to correspond\nto logarithmic-space reasoning. To do the translation, we find an appropriate\naxiomatization of VL, and put VL proofs into a new normal form.\n  To show that GL^* is not too strong, we prove the soundness of GL^* in such a\nway that it can be formalized in VL. This is done by giving a logarithmic-space\nalgorithm that witnesses GL^* proofs.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2008 19:53:39 GMT"}], "update_date": "2008-01-29", "authors_parsed": [["Perron", "Steven", "", "University of Toronto"]]}
{"id": "0801.4190", "submitter": "Sebastian Roch", "authors": "Constantinos Daskalakis, Elchanan Mossel, Sebastien Roch", "title": "Phylogenies without Branch Bounds: Contracting the Short, Pruning the\n  Deep", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE cs.DS math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new phylogenetic reconstruction algorithm which, unlike most\nprevious rigorous inference techniques, does not rely on assumptions regarding\nthe branch lengths or the depth of the tree. The algorithm returns a forest\nwhich is guaranteed to contain all edges that are: 1) sufficiently long and 2)\nsufficiently close to the leaves. How much of the true tree is recovered\ndepends on the sequence length provided. The algorithm is distance-based and\nruns in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2008 05:10:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2009 01:48:27 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Mossel", "Elchanan", ""], ["Roch", "Sebastien", ""]]}
{"id": "0801.4194", "submitter": "Kohtaro Tadaki", "authors": "Kohtaro Tadaki", "title": "A statistical mechanical interpretation of algorithmic information\n  theory", "comments": "31 pages, LaTeX2e, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT math.PR quant-ph", "license": null, "abstract": "  We develop a statistical mechanical interpretation of algorithmic information\ntheory by introducing the notion of thermodynamic quantities, such as free\nenergy, energy, statistical mechanical entropy, and specific heat, into\nalgorithmic information theory. We investigate the properties of these\nquantities by means of program-size complexity from the point of view of\nalgorithmic randomness. It is then discovered that, in the interpretation, the\ntemperature plays a role as the compression rate of the values of all these\nthermodynamic quantities, which include the temperature itself. Reflecting this\nself-referential nature of the compression rate of the temperature, we obtain\nfixed point theorems on compression rate.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2008 17:42:27 GMT"}], "update_date": "2009-04-09", "authors_parsed": [["Tadaki", "Kohtaro", ""]]}
{"id": "0801.4287", "submitter": "Uwe Aickelin", "authors": "Qi Chen and Uwe Aickelin", "title": "Movie Recommendation Systems Using An Artificial Immune System", "comments": null, "journal-ref": "6th International Conference in Adaptive Computing in Design and\n  Manufacture (ACDM 2004), Bristol, UK, 2004", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  We apply the Artificial Immune System (AIS) technology to the Collaborative\nFiltering (CF) technology when we build the movie recommendation system. Two\ndifferent affinity measure algorithms of AIS, Kendall tau and Weighted Kappa,\nare used to calculate the correlation coefficients for this movie\nrecommendation system. From the testing we think that Weighted Kappa is more\nsuitable than Kendall tau for movie problems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2008 14:19:12 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:05:58 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Chen", "Qi", ""], ["Aickelin", "Uwe", ""]]}
{"id": "0801.4305", "submitter": "Frank Schweitzer", "authors": "J. Emeterio Navarro Barrientos, Frank E. Walter, Frank Schweitzer", "title": "Risk-Seeking versus Risk-Avoiding Investments in Noisy Periodic\n  Environments", "comments": "27 pp. v2 with minor corrections. See http://www.sg.ethz.ch for more\n  info", "journal-ref": "International Journal of Modern Physics C vol. 19, no. 6 (2008)\n  971-994", "doi": "10.1142/S0129183108012662", "report-no": null, "categories": "q-fin.PM cs.CE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of various agent strategies in an artificial\ninvestment scenario. Agents are equipped with a budget, $x(t)$, and at each\ntime step invest a particular fraction, $q(t)$, of their budget. The return on\ninvestment (RoI), $r(t)$, is characterized by a periodic function with\ndifferent types and levels of noise. Risk-avoiding agents choose their fraction\n$q(t)$ proportional to the expected positive RoI, while risk-seeking agents\nalways choose a maximum value $q_{max}$ if they predict the RoI to be positive\n(\"everything on red\"). In addition to these different strategies, agents have\ndifferent capabilities to predict the future $r(t)$, dependent on their\ninternal complexity. Here, we compare 'zero-intelligent' agents using technical\nanalysis (such as moving least squares) with agents using reinforcement\nlearning or genetic algorithms to predict $r(t)$. The performance of agents is\nmeasured by their average budget growth after a certain number of time steps.\nWe present results of extensive computer simulations, which show that, for our\ngiven artificial environment, (i) the risk-seeking strategy outperforms the\nrisk-avoiding one, and (ii) the genetic algorithm was able to find this optimal\nstrategy itself, and thus outperforms other prediction approaches considered.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2008 15:09:58 GMT"}, {"version": "v2", "created": "Sun, 7 Sep 2008 13:48:45 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Barrientos", "J. Emeterio Navarro", ""], ["Walter", "Frank E.", ""], ["Schweitzer", "Frank", ""]]}
{"id": "0801.4307", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin and Qi Chen", "title": "On Affinity Measures for Artificial Immune System Movie Recommenders", "comments": null, "journal-ref": "Proceedings of the 5th International Conference on Recent Advances\n  in Soft Computing (RASC 2004), Nottingham, UK", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CY", "license": null, "abstract": "  We combine Artificial Immune Systems 'AIS', technology with Collaborative\nFiltering 'CF' and use it to build a movie recommendation system. We already\nknow that Artificial Immune Systems work well as movie recommenders from\nprevious work by Cayzer and Aickelin 3, 4, 5. Here our aim is to investigate\nthe effect of different affinity measure algorithms for the AIS. Two different\naffinity measures, Kendalls Tau and Weighted Kappa, are used to calculate the\ncorrelation coefficients for the movie recommender. We compare the results with\nthose published previously and show that Weighted Kappa is more suitable than\nothers for movie problems. We also show that AIS are generally robust movie\nrecommenders and that, as long as a suitable affinity measure is chosen,\nresults are good.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2008 15:14:45 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:06:30 GMT"}, {"version": "v3", "created": "Fri, 16 May 2008 10:44:44 GMT"}], "update_date": "2008-05-16", "authors_parsed": [["Aickelin", "Uwe", ""], ["Chen", "Qi", ""]]}
{"id": "0801.4312", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin, Edmund Burke and Aniza Din", "title": "Investigating Artificial Immune Systems For Job Shop Rescheduling In\n  Changing Environments", "comments": null, "journal-ref": "6th International Conference in Adaptive Computing in Design and\n  Manufacture (ACDM 2004), Bristol, UK, 2004", "doi": null, "report-no": null, "categories": "cs.NE cs.CE", "license": null, "abstract": "  Artificial immune system can be used to generate schedules in changing\nenvironments and it has been proven to be more robust than schedules developed\nusing a genetic algorithm. Good schedules can be produced especially when the\nnumber of the antigens is increased. However, an increase in the range of the\nantigens had somehow affected the fitness of the immune system. In this\nresearch, we are trying to improve the result of the system by rescheduling the\nsame problem using the same method while at the same time maintaining the\nrobustness of the schedules.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2008 15:26:59 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:03:46 GMT"}, {"version": "v3", "created": "Fri, 16 May 2008 10:43:07 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""], ["Burke", "Edmund", ""], ["Din", "Aniza", ""]]}
{"id": "0801.4314", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin", "title": "Artificial Immune Systems (AIS) - A New Paradigm for Heuristic Decision\n  Making", "comments": null, "journal-ref": "Invited Keynote Talk, Annual Operational Research Conference 46,\n  York, UK, 2004", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": null, "abstract": "  Over the last few years, more and more heuristic decision making techniques\nhave been inspired by nature, e.g. evolutionary algorithms, ant colony\noptimisation and simulated annealing. More recently, a novel computational\nintelligence technique inspired by immunology has emerged, called Artificial\nImmune Systems (AIS). This immune system inspired technique has already been\nuseful in solving some computational problems. In this keynote, we will very\nbriefly describe the immune system metaphors that are relevant to AIS. We will\nthen give some illustrative real-world problems suitable for AIS use and show a\nstep-by-step algorithm walkthrough. A comparison of AIS to other well-known\nalgorithms and areas for future work will round this keynote off. It should be\nnoted that as AIS is still a young and evolving field, there is not yet a fixed\nalgorithm template and hence actual implementations might differ somewhat from\nthe examples given here.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2008 15:32:05 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 17:02:52 GMT"}, {"version": "v3", "created": "Fri, 16 May 2008 10:46:24 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""]]}
{"id": "0801.4405", "submitter": "David Charlton", "authors": "David Charlton, Erik D. Demaine, Martin L. Demaine, Gregory Price,\n  Yaa-Lirng Tu", "title": "A Locked Orthogonal Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  We give a counterexample to a conjecture of Poon [Poo06] that any orthogonal\ntree in two dimensions can always be flattened by a continuous motion that\npreserves edge lengths and avoids self-intersection. We show our example is\nlocked by extending results on strongly locked self-touching linkages due to\nConnelly, Demaine and Rote [CDR02] to allow zero-length edges as defined in\n[ADG07], which may be of independent interest. Our results also yield a locked\ntree with only eleven edges, which is the smallest known example of a locked\ntree.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2008 00:39:37 GMT"}], "update_date": "2008-01-30", "authors_parsed": [["Charlton", "David", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Price", "Gregory", ""], ["Tu", "Yaa-Lirng", ""]]}
{"id": "0801.4585", "submitter": "Piotr Faliszewski", "authors": "Piotr Faliszewski, Lane A. Hemaspaandra", "title": "The Complexity of Power-Index Comparison", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": "URCS TR-2008-929", "categories": "cs.CC cs.GT", "license": null, "abstract": "  We study the complexity of the following problem: Given two weighted voting\ngames G' and G'' that each contain a player p, in which of these games is p's\npower index value higher? We study this problem with respect to both the\nShapley-Shubik power index [SS54] and the Banzhaf power index [Ban65,DS79]. Our\nmain result is that for both of these power indices the problem is complete for\nprobabilistic polynomial time (i.e., is PP-complete). We apply our results to\npartially resolve some recently proposed problems regarding the complexity of\nweighted voting games. We also study the complexity of the raw Shapley-Shubik\npower index. Deng and Papadimitriou [DP94] showed that the raw Shapley-Shubik\npower index is #P-metric-complete. We strengthen this by showing that the raw\nShapley-Shubik power index is many-one complete for #P. And our strengthening\ncannot possibly be further improved to parsimonious completeness, since we\nobserve that, in contrast with the raw Banzhaf power index, the raw\nShapley-Shubik power index is not #P-parsimonious-complete.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2008 00:10:07 GMT"}], "update_date": "2008-01-31", "authors_parsed": [["Faliszewski", "Piotr", ""], ["Hemaspaandra", "Lane A.", ""]]}
{"id": "0801.4714", "submitter": "Miroslava Sotakova", "authors": "Miroslava Sotakova", "title": "Breaking One-Round Key-Agreement Protocols in the Random Oracle Model", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study one-round key-agreement protocols analogous to\nMerkle's puzzles in the random oracle model. The players Alice and Bob are\nallowed to query a random permutation oracle $n$ times and upon their queries\nand communication, they both output the same key with high probability. We\nprove that Eve can always break such a protocol by querying the oracle $O(n^2)$\ntimes. The long-time unproven optimality of the quadratic bound in the fully\ngeneral, multi-round scenario has been shown recently by Barak and\nMahmoody-Ghidary. The results in this paper have been found independently of\ntheir work.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2008 19:34:34 GMT"}, {"version": "v2", "created": "Wed, 12 Mar 2008 21:02:49 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2009 12:17:31 GMT"}], "update_date": "2009-03-24", "authors_parsed": [["Sotakova", "Miroslava", ""]]}
{"id": "0801.4777", "submitter": "Anil Ada", "authors": "Anil Ada", "title": "Non-Deterministic Communication Complexity of Regular Languages", "comments": "Master's thesis, 93 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  In this thesis, we study the place of regular languages within the\ncommunication complexity setting. In particular, we are interested in the\nnon-deterministic communication complexity of regular languages.\n  We show that a regular language has either O(1) or Omega(log n)\nnon-deterministic complexity. We obtain several linear lower bound results\nwhich cover a wide range of regular languages having linear non-deterministic\ncomplexity. These lower bound results also imply a result in semigroup theory:\nwe obtain sufficient conditions for not being in the positive variety Pol(Com).\n  To obtain our results, we use algebraic techniques. In the study of regular\nlanguages, the algebraic point of view pioneered by Eilenberg (\\cite{Eil74})\nhas led to many interesting results. Viewing a semigroup as a computational\ndevice that recognizes languages has proven to be prolific from both semigroup\ntheory and formal languages perspectives. In this thesis, we provide further\ninstances of such mutualism.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2008 21:55:13 GMT"}], "update_date": "2008-02-01", "authors_parsed": [["Ada", "Anil", ""]]}
{"id": "0801.4794", "submitter": "Joel Ratsaby", "authors": "Joel Ratsaby", "title": "On the Complexity of Binary Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.LG", "license": null, "abstract": "  Consider a class $\\mH$ of binary functions $h: X\\to\\{-1, +1\\}$ on a finite\ninterval $X=[0, B]\\subset \\Real$. Define the {\\em sample width} of $h$ on a\nfinite subset (a sample) $S\\subset X$ as $\\w_S(h) \\equiv \\min_{x\\in S}\n|\\w_h(x)|$, where $\\w_h(x) = h(x) \\max\\{a\\geq 0: h(z)=h(x), x-a\\leq z\\leq\nx+a\\}$. Let $\\mathbb{S}_\\ell$ be the space of all samples in $X$ of cardinality\n$\\ell$ and consider sets of wide samples, i.e., {\\em hypersets} which are\ndefined as $A_{\\beta, h} = \\{S\\in \\mathbb{S}_\\ell: \\w_{S}(h) \\geq \\beta\\}$.\nThrough an application of the Sauer-Shelah result on the density of sets an\nupper estimate is obtained on the growth function (or trace) of the class\n$\\{A_{\\beta, h}: h\\in\\mH\\}$, $\\beta>0$, i.e., on the number of possible\ndichotomies obtained by intersecting all hypersets with a fixed collection of\nsamples $S\\in\\mathbb{S}_\\ell$ of cardinality $m$. The estimate is\n$2\\sum_{i=0}^{2\\lfloor B/(2\\beta)\\rfloor}{m-\\ell\\choose i}$.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2008 23:14:19 GMT"}], "update_date": "2008-02-01", "authors_parsed": [["Ratsaby", "Joel", ""]]}
{"id": "0801.4817", "submitter": "Shenghui Su", "authors": "Shenghui Su and Shuwang Lv", "title": "The REESSE2+ Public-key Encryption Scheme", "comments": "11 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives the definitions of an anomalous super-increasing sequence\nand an anomalous subset sum separately, proves the two properties of an\nanomalous super-increasing sequence, and proposes the REESSE2+ public-key\nencryption scheme which includes the three algorithms for key generation,\nencryption and decryption. The paper discusses the necessity and sufficiency of\nthe lever function for preventing the Shamir extremum attack, analyzes the\nsecurity of REESSE2+ against extracting a private key from a public key through\nthe exhaustive search, recovering a plaintext from a ciphertext plus a knapsack\nof high density through the L3 lattice basis reduction method, and\nheuristically obtaining a plaintext through the meet-in-the-middle attack or\nthe adaptive-chosen-ciphertext attack. The authors evaluate the time complexity\nof REESSE2+ encryption and decryption algorithms, compare REESSE2+ with ECC and\nNTRU, and find that the encryption speed of REESSE2+ is ten thousand times\nfaster than ECC and NTRU bearing the equivalent security, and the decryption\nspeed of REESSE2+ is roughly equivalent to ECC and NTRU respectively.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2008 03:50:39 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2008 17:56:47 GMT"}, {"version": "v3", "created": "Sat, 1 Nov 2014 15:57:54 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Su", "Shenghui", ""], ["Lv", "Shuwang", ""]]}
{"id": "0801.4911", "submitter": "Oleg Verbitsky", "authors": "Oleg Verbitsky", "title": "On the Double Coset Membership Problem for Permutation Groups", "comments": "14 pages", "journal-ref": "Algebraic structures and their applications, pp. 351--363 (2002)", "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  We show that the Double Coset Membership problem for permutation groups\npossesses perfect zero-knowledge proofs.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2008 16:19:20 GMT"}], "update_date": "2008-02-01", "authors_parsed": [["Verbitsky", "Oleg", ""]]}
{"id": "0801.4917", "submitter": "Oleg Verbitsky", "authors": "Oleg Verbitsky", "title": "Zero-Knowledge Proofs of the Conjugacy for Permutation Groups", "comments": "12 pages", "journal-ref": "Bulletin of the Lviv University, Series in Mechanics and\n  Mathematics. Vol. 61, pp. 195--205 (2003)", "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  We design a perfect zero-knowledge proof system for recognition if two\npermutation groups are conjugate.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2008 16:33:15 GMT"}], "update_date": "2008-02-01", "authors_parsed": [["Verbitsky", "Oleg", ""]]}
{"id": "0802.0024", "submitter": "Fran\\c{c}ois Nicolas", "authors": "Sylvain Guillemot and Francois Nicolas", "title": "Solving the Maximum Agreement SubTree and the Maximum Compatible Tree\n  problems on many bounded degree trees", "comments": "Revised version of our paper from CPM'06. 14 pages. 3 figures", "journal-ref": "Proceedings of the 17th Annual Symposium on Combinatorial Pattern\n  Matching (CPM'06), volume 4009 of Lecture Notes in Computer Science, pages\n  165--176. Springer-Verlag, 2006", "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of leaf-labeled trees with identical leaf sets, the well-known\n\"Maximum Agreement SubTree\" problem (MAST) consists of finding a subtree\nhomeomorphically included in all input trees and with the largest number of\nleaves. Its variant called \"Maximum Compatible Tree\" (MCT) is less stringent,\nas it allows the input trees to be refined. Both problems are of particular\ninterest in computational biology, where trees encountered have often small\ndegrees.\n  In this paper, we study the parameterized complexity of MAST and MCT with\nrespect to the maximum degree, denoted by D, of the input trees. It is known\nthat MAST is polynomial for bounded D. As a counterpart, we show that the\nproblem is W[1]-hard with respect to parameter D. Moreover, relying on recent\nadvances in parameterized complexity we obtain a tight lower bound: while MAST\ncan be solved in O(N^{O(D)}) time where N denotes the input length, we show\nthat an O(N^{o(D)}) bound is not achievable, unless SNP is contained in SE. We\nalso show that MCT is W[1]-hard with respect to D, and that MCT cannot be\nsolved in O(N^{o(2^{D/2})}) time, SNP is contained in SE.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 16:18:04 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2008 01:54:34 GMT"}, {"version": "v3", "created": "Thu, 10 Jul 2008 10:35:55 GMT"}], "update_date": "2008-07-10", "authors_parsed": [["Guillemot", "Sylvain", ""], ["Nicolas", "Francois", ""]]}
{"id": "0802.0116", "submitter": "Lutz Schr\\\"oder", "authors": "Lutz Schr\\\"oder and Dirk Patinson", "title": "Shallow Models for Non-Iterative Modal Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": "Imperial College TR Computing 2008/3", "categories": "cs.LO cs.AI cs.CC cs.MA", "license": null, "abstract": "  The methods used to establish PSPACE-bounds for modal logics can roughly be\ngrouped into two classes: syntax driven methods establish that exhaustive proof\nsearch can be performed in polynomial space whereas semantic approaches\ndirectly construct shallow models. In this paper, we follow the latter approach\nand establish generic PSPACE-bounds for a large and heterogeneous class of\nmodal logics in a coalgebraic framework. In particular, no complete\naxiomatisation of the logic under scrutiny is needed. This does not only\ncomplement our earlier, syntactic, approach conceptually, but also covers a\nwide variety of new examples which are difficult to harness by purely syntactic\nmeans. Apart from re-proving known complexity bounds for a large variety of\nstructurally different logics, we apply our method to obtain previously unknown\nPSPACE-bounds for Elgesem's logic of agency and for graded modal logic over\nreflexive frames.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 13:11:09 GMT"}, {"version": "v2", "created": "Thu, 20 Mar 2008 20:48:05 GMT"}, {"version": "v3", "created": "Thu, 3 Apr 2008 09:34:18 GMT"}], "update_date": "2008-04-03", "authors_parsed": [["Schröder", "Lutz", ""], ["Patinson", "Dirk", ""]]}
{"id": "0802.0116", "submitter": "Lutz Schr\\\"oder", "authors": "Lutz Schr\\\"oder and Dirk Patinson", "title": "Shallow Models for Non-Iterative Modal Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": "Imperial College TR Computing 2008/3", "categories": "cs.LO cs.AI cs.CC cs.MA", "license": null, "abstract": "  The methods used to establish PSPACE-bounds for modal logics can roughly be\ngrouped into two classes: syntax driven methods establish that exhaustive proof\nsearch can be performed in polynomial space whereas semantic approaches\ndirectly construct shallow models. In this paper, we follow the latter approach\nand establish generic PSPACE-bounds for a large and heterogeneous class of\nmodal logics in a coalgebraic framework. In particular, no complete\naxiomatisation of the logic under scrutiny is needed. This does not only\ncomplement our earlier, syntactic, approach conceptually, but also covers a\nwide variety of new examples which are difficult to harness by purely syntactic\nmeans. Apart from re-proving known complexity bounds for a large variety of\nstructurally different logics, we apply our method to obtain previously unknown\nPSPACE-bounds for Elgesem's logic of agency and for graded modal logic over\nreflexive frames.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 13:11:09 GMT"}, {"version": "v2", "created": "Thu, 20 Mar 2008 20:48:05 GMT"}, {"version": "v3", "created": "Thu, 3 Apr 2008 09:34:18 GMT"}], "update_date": "2008-04-03", "authors_parsed": [["Schröder", "Lutz", ""], ["Patinson", "Dirk", ""]]}
{"id": "0802.0314", "submitter": "Fran\\c{c}ois Nicolas", "authors": "Morris Michael and Francois Nicolas and Esko Ukkonen", "title": "On the complexity of finding gapped motifs", "comments": "Published in Journal of Discrete Algorithms", "journal-ref": null, "doi": "10.1016/j.jda.2009.12.001", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been withdrawn by the corresponding author because the newest\nversion is now published in Journal of Discrete Algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2008 00:08:40 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2008 09:12:24 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2009 14:19:13 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2010 19:26:58 GMT"}, {"version": "v5", "created": "Wed, 18 Aug 2010 01:00:49 GMT"}, {"version": "v6", "created": "Wed, 1 Sep 2010 13:21:53 GMT"}], "update_date": "2010-09-02", "authors_parsed": [["Michael", "Morris", ""], ["Nicolas", "Francois", ""], ["Ukkonen", "Esko", ""]]}
{"id": "0802.0423", "submitter": "Tommy F\\\"arnqvist", "authors": "Tommy F\\\"arnqvist, Peter Jonsson and Johan Thapper", "title": "Approximability Distance in the Space of H-Colourability Problems", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph homomorphism is a vertex map which carries edges from a source graph\nto edges in a target graph. We study the approximability properties of the\nWeighted Maximum H-Colourable Subgraph problem (MAX H-COL). The instances of\nthis problem are edge-weighted graphs G and the objective is to find a subgraph\nof G that has maximal total edge weight, under the condition that the subgraph\nhas a homomorphism to H; note that for H=K_k this problem is equivalent to MAX\nk-CUT. To this end, we introduce a metric structure on the space of graphs\nwhich allows us to extend previously known approximability results to larger\nclasses of graphs. Specifically, the approximation algorithms for MAX CUT by\nGoemans and Williamson and MAX k-CUT by Frieze and Jerrum can be used to yield\nnon-trivial approximation results for MAX H-COL. For a variety of graphs, we\nshow near-optimality results under the Unique Games Conjecture. We also use our\nmethod for comparing the performance of Frieze & Jerrum's algorithm with\nHastad's approximation algorithm for general MAX 2-CSP. This comparison is, in\nmost cases, favourable to Frieze & Jerrum.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2008 14:32:45 GMT"}], "update_date": "2008-02-05", "authors_parsed": [["Färnqvist", "Tommy", ""], ["Jonsson", "Peter", ""], ["Thapper", "Johan", ""]]}
{"id": "0802.0914", "submitter": "Sebastian Roch", "authors": "Elchanan Mossel and Sebastien Roch and Mike Steel", "title": "Shrinkage Effect in Ancestral Maximum Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE math.PR math.ST stat.TH", "license": null, "abstract": "  Ancestral maximum likelihood (AML) is a method that simultaneously\nreconstructs a phylogenetic tree and ancestral sequences from extant data\n(sequences at the leaves). The tree and ancestral sequences maximize the\nprobability of observing the given data under a Markov model of sequence\nevolution, in which branch lengths are also optimized but constrained to take\nthe same value on any edge across all sequence sites. AML differs from the more\nusual form of maximum likelihood (ML) in phylogenetics because ML averages over\nall possible ancestral sequences. ML has long been known to be statistically\nconsistent -- that is, it converges on the correct tree with probability\napproaching 1 as the sequence length grows. However, the statistical\nconsistency of AML has not been formally determined, despite informal remarks\nin a literature that dates back 20 years. In this short note we prove a general\nresult that implies that AML is statistically inconsistent. In particular we\nshow that AML can `shrink' short edges in a tree, resulting in a tree that has\nno internal resolution as the sequence length grows. Our results apply to any\nnumber of taxa.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2008 06:52:44 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Mossel", "Elchanan", ""], ["Roch", "Sebastien", ""], ["Steel", "Mike", ""]]}
{"id": "0802.1306", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic", "title": "Network as a computer: ranking paths to find flows", "comments": "12 pages, CSR 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a simple mathematical model of network computation, based on\nMarkov chains. Similar models apply to a broad range of computational\nphenomena, arising in networks of computers, as well as in genetic, and neural\nnets, in social networks, and so on. The main problem of interaction with such\nspontaneously evolving computational systems is that the data are not uniformly\nstructured. An interesting approach is to try to extract the semantical content\nof the data from their distribution among the nodes. A concept is then\nidentified by finding the community of nodes that share it. The task of data\nstructuring is thus reduced to the task of finding the network communities, as\ngroups of nodes that together perform some non-local data processing. Towards\nthis goal, we extend the ranking methods from nodes to paths. This allows us to\nextract some information about the likely flow biases from the available static\ninformation about the network.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2008 05:33:37 GMT"}], "update_date": "2009-04-18", "authors_parsed": [["Pavlovic", "Dusko", ""]]}
{"id": "0802.1312", "submitter": "Josef Cibulka", "authors": "Josef Cibulka", "title": "Untangling polygons and graphs", "comments": "11 pages, 3 figures", "journal-ref": "Discrete and Computational Geometry 43(2): 402-411 (2010)", "doi": "10.1007/s00454-009-9150-x", "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Untangling is a process in which some vertices of a planar graph are moved to\nobtain a straight-line plane drawing. The aim is to move as few vertices as\npossible. We present an algorithm that untangles the cycle graph C_n while\nkeeping at least \\Omega(n^{2/3}) vertices fixed. For any graph G, we also\npresent an upper bound on the number of fixed vertices in the worst case. The\nbound is a function of the number of vertices, maximum degree and diameter of\nG. One of its consequences is the upper bound O((n log n)^{2/3}) for all\n3-vertex-connected planar graphs.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2008 09:28:15 GMT"}, {"version": "v2", "created": "Wed, 25 Jun 2008 09:45:10 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["Cibulka", "Josef", ""]]}
{"id": "0802.1338", "submitter": "Shai  Gutner", "authors": "Shai Gutner and Michael Tarsi", "title": "Some results on (a:b)-choosability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": null, "abstract": "  A solution to a problem of Erd\\H{o}s, Rubin and Taylor is obtained by showing\nthat if a graph $G$ is $(a:b)$-choosable, and $c/d > a/b$, then $G$ is not\nnecessarily $(c:d)$-choosable. Applying probabilistic methods, an upper bound\nfor the $k^{th}$ choice number of a graph is given. We also prove that a\ndirected graph with maximum outdegree $d$ and no odd directed cycle is\n$(k(d+1):k)$-choosable for every $k \\geq 1$. Other results presented in this\narticle are related to the strong choice number of graphs (a generalization of\nthe strong chromatic number). We conclude with complexity analysis of some\ndecision problems related to graph choosability.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2008 17:46:54 GMT"}], "update_date": "2008-02-12", "authors_parsed": [["Gutner", "Shai", ""], ["Tarsi", "Michael", ""]]}
{"id": "0802.1361", "submitter": "Menelaos Karavelas", "authors": "Menelaos I. Karavelas", "title": "Guarding curvilinear art galleries with edge or mobile guards via\n  2-dominance of triangulation graphs", "comments": "45 pages, 33 figures, short version has appeared in [M. I. Karavelas.\n  Guarding curvilinear art galleries with edge or mobile guards. 2008 ACM\n  Symposium on Solid and Physical Modeling (SPM08), 339-345, 2008.]; v2: new\n  lower bound for the edge 2-dominance problem which now matches the upper\n  bound", "journal-ref": "Comput. Geom. Theory Appl. 44(1):20-51, 2011", "doi": "10.1016/j.comgeo.2010.07.002", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of monitoring an art gallery modeled as a polygon,\nthe edges of which are arcs of curves, with edge or mobile guards. Our focus is\non piecewise-convex polygons, i.e., polygons that are locally convex, except\npossibly at the vertices, and their edges are convex arcs. We transform the\nproblem of monitoring a piecewise-convex polygon to the problem of 2-dominating\na properly defined triangulation graph with edges or diagonals, where\n2-dominance requires that every triangle in the triangulation graph has at\nleast two of its vertices in its 2-dominating set. We show that\n$\\lfloor\\frac{n+1}{3}\\rfloor$ diagonal guards or $\\lfloor\\frac{2n+1}{5}\\rfloor$\nedge guards are always sufficient and sometimes necessary, in order to\n2-dominate a triangulation graph. Furthermore, we show how to compute: a\ndiagonal 2-dominating set of size $\\lfloor\\frac{n+1}{3}\\rfloor$ in linear time,\nan edge 2-dominating set of size $\\lfloor\\frac{2n+1}{5}\\rfloor$ in $O(n^2)$\ntime, and an edge 2-dominating set of size $\\lfloor\\frac{3n}{7}\\rfloor$ in O(n)\ntime. Based on the above-mentioned results, we prove that, for piecewise-convex\npolygons, we can compute: a mobile guard set of size\n$\\lfloor\\frac{n+1}{3}\\rfloor$ in $O(n\\log{}n)$ time, an edge guard set of size\n$\\lfloor\\frac{2n+1}{5}\\rfloor$ in $O(n^2)$ time, and an edge guard set of size\n$\\lfloor\\frac{3n}{7}\\rfloor$ in $O(n\\log{}n)$ time. Finally, we show that\n$\\lfloor\\frac{n}{3}\\rfloor$ mobile or $\\lceil\\frac{n}{3}\\rceil$ edge guards are\nsometimes necessary. When restricting our attention to monotone\npiecewise-convex polygons, the bounds mentioned above drop:\n$\\lceil\\frac{n+1}{4}\\rceil$ edge or mobile guards are always sufficient and\nsometimes necessary; such an edge or mobile guard set, of size at most\n$\\lceil\\frac{n+1}{4}\\rceil$, can be computed in O(n) time.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2008 00:40:37 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2010 19:52:11 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Karavelas", "Menelaos I.", ""]]}
{"id": "0802.1393", "submitter": "Clement Jonquet", "authors": "Cl\\'ement Jonquet (LIRMM), Stefano A. Cerri (LIRMM)", "title": "Les Agents comme des interpr\\'eteurs Scheme : Sp\\'ecification dynamique\n  par la communication", "comments": null, "journal-ref": "Dans 14\\`eme Congr\\`es Francophone AFRIF-AFIA de Reconnaissance\n  des Formes et Intelligence Artificielle - RFIA'04, Toulouse : France (2004)", "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": null, "abstract": "  We proposed in previous papers an extension and an implementation of the\nSTROBE model, which regards the Agents as Scheme interpreters. These Agents are\nable to interpret messages in a dedicated environment including an interpreter\nthat learns from the current conversation therefore representing evolving\nmeta-level Agent's knowledge. When the Agent's interpreter is a\nnondeterministic one, the dialogues may consist of subsequent refinements of\nspecifications in the form of constraint sets. The paper presents a worked out\nexample of dynamic service generation - such as necessary on Grids - by\nexploiting STROBE Agents equipped with a nondeterministic interpreter. It shows\nhow enabling dynamic specification of a problem. Then it illustrates how these\nprinciples could be effective for other applications. Details of the\nimplementation are not provided here, but are available.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2008 08:55:46 GMT"}], "update_date": "2008-02-12", "authors_parsed": [["Jonquet", "Clément", "", "LIRMM"], ["Cerri", "Stefano A.", "", "LIRMM"]]}
{"id": "0802.1465", "submitter": "Cyril Allauzen", "authors": "Cyril Allauzen and Mehryar Mohri", "title": "3-Way Composition of Weighted Finite-State Transducers", "comments": "Added missing acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  Composition of weighted transducers is a fundamental algorithm used in many\napplications, including for computing complex edit-distances between automata,\nor string kernels in machine learning, or to combine different components of a\nspeech recognition, speech synthesis, or information extraction system. We\npresent a generalization of the composition of weighted transducers, 3-way\ncomposition, which is dramatically faster in practice than the standard\ncomposition algorithm when combining more than two transducers. The worst-case\ncomplexity of our algorithm for composing three transducers $T_1$, $T_2$, and\n$T_3$ resulting in $T$, \\ignore{depending on the strategy used, is $O(|T|_Q\nd(T_1) d(T_3) + |T|_E)$ or $(|T|_Q d(T_2) + |T|_E)$,} is $O(|T|_Q \\min(d(T_1)\nd(T_3), d(T_2)) + |T|_E)$, where $|\\cdot|_Q$ denotes the number of states,\n$|\\cdot|_E$ the number of transitions, and $d(\\cdot)$ the maximum out-degree.\nAs in regular composition, the use of perfect hashing requires a pre-processing\nstep with linear-time expected complexity in the size of the input transducers.\nIn many cases, this approach significantly improves on the complexity of\nstandard composition. Our algorithm also leads to a dramatically faster\ncomposition in practice. Furthermore, standard composition can be obtained as a\nspecial case of our algorithm. We report the results of several experiments\ndemonstrating this improvement. These theoretical and empirical improvements\nsignificantly enhance performance in the applications already mentioned.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2008 16:18:40 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2008 18:02:27 GMT"}], "update_date": "2008-02-22", "authors_parsed": [["Allauzen", "Cyril", ""], ["Mohri", "Mehryar", ""]]}
{"id": "0802.1514", "submitter": "Konstantin Kobylkin S.", "authors": "K.S. Kobylkin", "title": "Minimal Committee Problem for Inconsistent Systems of Linear\n  Inequalities on the Plane", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": "10.1134/S1054661806040201", "report-no": null, "categories": "cs.DM cs.CG", "license": null, "abstract": "  A representation of an arbitrary system of strict linear inequalities in R^n\nas a system of points is proposed. The representation is obtained by using a\nso-called polarity. Based on this representation an algorithm for constructing\na committee solution of an inconsistent plane system of linear inequalities is\ngiven. A solution of two problems on minimal committee of a plane system is\nproposed. The obtained solutions to these problems can be found by means of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2008 19:50:56 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2008 07:40:17 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2008 17:15:03 GMT"}], "update_date": "2008-02-15", "authors_parsed": [["Kobylkin", "K. S.", ""]]}
{"id": "0802.1617", "submitter": "Christian Mercat", "authors": "Christian Mercat (I3M)", "title": "Discrete Complex Structure on Surfel Surfaces", "comments": null, "journal-ref": "Dans 14th IAPR International Conference on Discrete Geometry for\n  Computer Imagery - 14th IAPR International Conference on Discrete Geometry\n  for Computer Imagery, Lyon : France (2008)", "doi": null, "report-no": null, "categories": "cs.CG cs.GR math.CV", "license": null, "abstract": "  This paper defines a theory of conformal parametrization of digital surfaces\nmade of surfels equipped with a normal vector. The main idea is to locally\nproject each surfel to the tangent plane, therefore deforming its aspect-ratio.\nIt is a generalization of the theory known for polyhedral surfaces. The main\ndifference is that the conformal ratios that appear are no longer real in\ngeneral. It yields a generalization of the standard Laplacian on weighted\ngraphs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2008 11:06:38 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Mercat", "Christian", "", "I3M"]]}
{"id": "0802.1699", "submitter": "Prajakta Nimbhorkar", "authors": "Nutan Limaye, Meena Mahajan, Prajakta Nimbhorkar", "title": "Longest paths in Planar DAGs in Unambiguous Logspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We show via two different algorithms that finding the length of the longest\npath in planar directed acyclic graph (DAG) is in unambiguous logspace UL, and\nalso in the complement class co-UL. The result extends to toroidal DAGs as\nwell.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2008 20:08:39 GMT"}], "update_date": "2008-02-13", "authors_parsed": [["Limaye", "Nutan", ""], ["Mahajan", "Meena", ""], ["Nimbhorkar", "Prajakta", ""]]}
{"id": "0802.1790", "submitter": "Silvano Di Zenzo", "authors": "Silvano Di Zenzo", "title": "SAT Has No Wizards", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An (encoded) decision problem is a pair (E, F) where E=words that encode\ninstances of the problem, F=words to be accepted. We use \"strings\" in a\ntechnical sense. With an NP problem (E, F) we associate the \"logogram\" of F\nrelative to E, which conveys structural information on E, F, and how F is\nembedded in E. The kernel Ker(P) of a program P that solves (E, F) consists of\nthose strings in the logogram that are used by P. There are relations between\nKer(P) and the complexity of P. We develop an application to SAT that relies\nupon a property of internal independence of SAT. We show that SAT cannot have\nin its logogram strings serving as collective certificates. As consequence, all\nprograms that solve SAT have same kernel.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2008 14:43:40 GMT"}], "update_date": "2008-02-14", "authors_parsed": [["Di Zenzo", "Silvano", ""]]}
{"id": "0802.1829", "submitter": "Francesco Zamponi", "authors": "Fabrizio Altarelli, Remi Monasson, Guilhem Semerjian and Francesco\n  Zamponi", "title": "A review of the Statistical Mechanics approach to Random Optimization\n  Problems", "comments": "26 pages, 8 figures. Contribution to the book \"Handbook of\n  Satisfiability\" to be published in 2008 by IOS press", "journal-ref": "In \"Handbook of Satisfiability\", published by IOS press (2009),\n  Volume 185 of the Series \"Frontiers in Artificial Intelligence and\n  Applications\"", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the connection between statistical mechanics and the analysis of\nrandom optimization problems, with particular emphasis on the random k-SAT\nproblem. We discuss and characterize the different phase transitions that are\nmet in these problems, starting from basic concepts. We also discuss how\nstatistical mechanics methods can be used to investigate the behavior of local\nsearch and decimation based algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2008 13:45:16 GMT"}], "update_date": "2009-01-08", "authors_parsed": [["Altarelli", "Fabrizio", ""], ["Monasson", "Remi", ""], ["Semerjian", "Guilhem", ""], ["Zamponi", "Francesco", ""]]}
{"id": "0802.1884", "submitter": "Henning Schnoor", "authors": "Edith Hemaspaandra and Henning Schnoor", "title": "On the Complexity of Elementary Modal Logics", "comments": "Full version of STACS 2008 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": null, "abstract": "  Modal logics are widely used in computer science. The complexity of modal\nsatisfiability problems has been investigated since the 1970s, usually proving\nresults on a case-by-case basis. We prove a very general classification for a\nwide class of relevant logics: Many important subclasses of modal logics can be\nobtained by restricting the allowed models with first-order Horn formulas. We\nshow that the satisfiability problem for each of these logics is either\nNP-complete or PSPACE-hard, and exhibit a simple classification criterion.\nFurther, we prove matching PSPACE upper bounds for many of the PSPACE-hard\nlogics.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2008 18:57:26 GMT"}], "update_date": "2008-02-14", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Schnoor", "Henning", ""]]}
{"id": "0802.1957", "submitter": "Sudhir Singh", "authors": "Sudhir Kumar Singh, Vwani P. Roychowdhury", "title": "To Broad-Match or Not to Broad-Match : An Auctioneer's Dilemma ?", "comments": "33 pages, 10 figures, new results added, substantially revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of an interesting aspect of sponsored search\nadvertising, namely the consequences of broad match-a feature where an ad of an\nadvertiser can be mapped to a broader range of relevant queries, and not\nnecessarily to the particular keyword(s) that ad is associated with. Starting\nwith a very natural setting for strategies available to the advertisers, and\nvia a careful look through the algorithmic lens, we first propose solution\nconcepts for the game originating from the strategic behavior of advertisers as\nthey try to optimize their budget allocation across various keywords. Next, we\nconsider two broad match scenarios based on factors such as information\nasymmetry between advertisers and the auctioneer, and the extent of\nauctioneer's control on the budget splitting. In the first scenario, the\nadvertisers have the full information about broad match and relevant\nparameters, and can reapportion their own budgets to utilize the extra\ninformation; in particular, the auctioneer has no direct control over budget\nsplitting. We show that, the same broad match may lead to different equilibria,\none leading to a revenue improvement, whereas another to a revenue loss. This\nleaves the auctioneer in a dilemma - whether to broad-match or not. This\nmotivates us to consider another broad match scenario, where the advertisers\nhave information only about the current scenario, and the allocation of the\nbudgets unspent in the current scenario is in the control of the auctioneer. We\nobserve that the auctioneer can always improve his revenue by judiciously using\nbroad match. Thus, information seems to be a double-edged sword for the\nauctioneer.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2008 03:45:07 GMT"}, {"version": "v2", "created": "Mon, 21 Jul 2008 19:40:28 GMT"}], "update_date": "2008-07-21", "authors_parsed": [["Singh", "Sudhir Kumar", ""], ["Roychowdhury", "Vwani P.", ""]]}
{"id": "0802.2001", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin and Kathryn Dowsland", "title": "Exploiting problem structure in a genetic algorithm approach to a nurse\n  rostering problem", "comments": null, "journal-ref": "Journal of Scheduling, 3(3), pp 139-153, 2000", "doi": "10.1002/(SICI)1099-1425(200005/06)3:3<139::AID-JOS41>3.0.CO;2-2", "report-no": null, "categories": "cs.NE cs.CE", "license": null, "abstract": "  There is considerable interest in the use of genetic algorithms to solve\nproblems arising in the areas of scheduling and timetabling. However, the\nclassical genetic algorithm paradigm is not well equipped to handle the\nconflict between objectives and constraints that typically occurs in such\nproblems. In order to overcome this, successful implementations frequently make\nuse of problem specific knowledge. This paper is concerned with the development\nof a GA for a nurse rostering problem at a major UK hospital. The structure of\nthe constraints is used as the basis for a co-evolutionary strategy using\nco-operating sub-populations. Problem specific knowledge is also used to define\na system of incentives and disincentives, and a complementary mutation\noperator. Empirical results based on 52 weeks of live data show how these\nfeatures are able to improve an unsuccessful canonical GA to the point where it\nis able to provide a practical solution to the problem\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2008 11:25:37 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2008 16:56:56 GMT"}, {"version": "v3", "created": "Fri, 16 May 2008 10:44:23 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""], ["Dowsland", "Kathryn", ""]]}
{"id": "0802.2027", "submitter": "Martin Ziegler", "authors": "Martin Ziegler and Wouter M. Koolen", "title": "Kolmogorov Complexity Theory over the Reals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.SC", "license": null, "abstract": "  Kolmogorov Complexity constitutes an integral part of computability theory,\ninformation theory, and computational complexity theory -- in the discrete\nsetting of bits and Turing machines. Over real numbers, on the other hand, the\nBSS-machine (aka real-RAM) has been established as a major model of\ncomputation. This real realm has turned out to exhibit natural counterparts to\nmany notions and results in classical complexity and recursion theory; although\nusually with considerably different proofs. The present work investigates\nsimilarities and differences between discrete and real Kolmogorov Complexity as\nintroduced by Montana and Pardo (1998).\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2008 18:30:55 GMT"}, {"version": "v2", "created": "Fri, 28 Mar 2008 11:04:28 GMT"}], "update_date": "2008-03-28", "authors_parsed": [["Ziegler", "Martin", ""], ["Koolen", "Wouter M.", ""]]}
{"id": "0802.2108", "submitter": "Anil Hirani", "authors": "Evan VanderZee, Anil N. Hirani, Damrong Guoy, Edgar Ramos", "title": "Well-Centered Triangulation", "comments": "Content has been added to experimental results section. Significant\n  edits in introduction and in summary of current and previous results. Minor\n  edits elsewhere", "journal-ref": "SIAM J. Sci. Comput. 31, 6 (2010) 4497-4523", "doi": "10.1137/090748214", "report-no": "UIUCDCS-R-2008-2936", "categories": "cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meshes composed of well-centered simplices have nice orthogonal dual meshes\n(the dual Voronoi diagram). This is useful for certain numerical algorithms\nthat prefer such primal-dual mesh pairs. We prove that well-centered meshes\nalso have optimality properties and relationships to Delaunay and minmax angle\ntriangulations. We present an iterative algorithm that seeks to transform a\ngiven triangulation in two or three dimensions into a well-centered one by\nminimizing a cost function and moving the interior vertices while keeping the\nmesh connectivity and boundary vertices fixed. The cost function is a direct\nresult of a new characterization of well-centeredness in arbitrary dimensions\nthat we present. Ours is the first optimization-based heuristic for\nwell-centeredness, and the first one that applies in both two and three\ndimensions. We show the results of applying our algorithm to small and large\ntwo-dimensional meshes, some with a complex boundary, and obtain a\nwell-centered tetrahedralization of the cube. We also show numerical evidence\nthat our algorithm preserves gradation and that it improves the maximum and\nminimum angles of acute triangulations created by the best known previous\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2008 23:04:07 GMT"}, {"version": "v2", "created": "Fri, 6 Feb 2009 21:21:40 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2009 16:48:13 GMT"}], "update_date": "2010-01-25", "authors_parsed": [["VanderZee", "Evan", ""], ["Hirani", "Anil N.", ""], ["Guoy", "Damrong", ""], ["Ramos", "Edgar", ""]]}
{"id": "0802.2127", "submitter": "Alexandre Riazanov", "authors": "Alexandre Riazanov", "title": "New Implementation Framework for Saturation-Based Reasoning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  The saturation-based reasoning methods are among the most theoretically\ndeveloped ones and are used by most of the state-of-the-art first-order logic\nreasoners. In the last decade there was a sharp increase in performance of such\nsystems, which I attribute to the use of advanced calculi and the intensified\nresearch in implementation techniques. However, nowadays we are witnessing a\nslowdown in performance progress, which may be considered as a sign that the\nsaturation-based technology is reaching its inherent limits. The position I am\ntrying to put forward in this paper is that such scepticism is premature and a\nsharp improvement in performance may potentially be reached by adopting new\narchitectural principles for saturation. The top-level algorithms and\ncorresponding designs used in the state-of-the-art saturation-based theorem\nprovers have (at least) two inherent drawbacks: the insufficient flexibility of\nthe used inference selection mechanisms and the lack of means for intelligent\nprioritising of search directions. In this position paper I analyse these\ndrawbacks and present two ideas on how they could be overcome. In particular, I\npropose a flexible low-cost high-precision mechanism for inference selection,\nintended to overcome problems associated with the currently used instances of\nclause selection-based procedures. I also outline a method for intelligent\nprioritising of search directions, based on probing the search space by\nexploring generalised search directions. I discuss some technical issues\nrelated to implementation of the proposed architectural principles and outline\npossible solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 01:51:29 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Riazanov", "Alexandre", ""]]}
{"id": "0802.2130", "submitter": "Ashkan Aazami", "authors": "Ashkan Aazami", "title": "Domination in graphs with bounded propagation: algorithms, formulations\n  and hardness results", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  We introduce a hierarchy of problems between the \\textsc{Dominating Set}\nproblem and the \\textsc{Power Dominating Set} (PDS) problem called the\n$\\ell$-round power dominating set ($\\ell$-round PDS, for short) problem. For\n$\\ell=1$, this is the \\textsc{Dominating Set} problem, and for $\\ell\\geq n-1$,\nthis is the PDS problem; here $n$ denotes the number of nodes in the input\ngraph. In PDS the goal is to find a minimum size set of nodes $S$ that power\ndominates all the nodes, where a node $v$ is power dominated if (1) $v$ is in\n$S$ or it has a neighbor in $S$, or (2) $v$ has a neighbor $u$ such that $u$\nand all of its neighbors except $v$ are power dominated. Note that rule (1) is\nthe same as for the \\textsc{Dominating Set} problem, and that rule (2) is a\ntype of propagation rule that applies iteratively. The $\\ell$-round PDS problem\nhas the same set of rules as PDS, except we apply rule (2) in ``parallel'' in\nat most $\\ell-1$ rounds. We prove that $\\ell$-round PDS cannot be approximated\nbetter than $2^{\\log^{1-\\epsilon}{n}}$ even for $\\ell=4$ in general graphs. We\nprovide a dynamic programming algorithm to solve $\\ell$-round PDS optimally in\npolynomial time on graphs of bounded tree-width. We present a PTAS (polynomial\ntime approximation scheme) for $\\ell$-round PDS on planar graphs for\n$\\ell=O(\\tfrac{\\log{n}}{\\log{\\log{n}}})$. Finally, we give integer programming\nformulations for $\\ell$-round PDS.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 02:55:52 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Aazami", "Ashkan", ""]]}
{"id": "0802.2134", "submitter": "Kevin Buchin", "authors": "Kevin Buchin", "title": "Minimizing the Maximum Interference is Hard", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following interference model for wireless sensor and ad hoc\nnetworks: the receiver interference of a node is the number of transmission\nranges it lies in. We model transmission ranges as disks. For this case we show\nthat choosing transmission radii which minimize the maximum interference while\nmaintaining a connected symmetric communication graph is NP-complete.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 03:25:37 GMT"}, {"version": "v2", "created": "Sun, 9 Oct 2011 10:12:50 GMT"}], "update_date": "2011-10-11", "authors_parsed": [["Buchin", "Kevin", ""]]}
{"id": "0802.2157", "submitter": "Shai  Gutner", "authors": "Shai Gutner", "title": "Choice numbers of graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": null, "abstract": "  A solution to a problem of Erd\\H{o}s, Rubin and Taylor is obtained by showing\nthat if a graph $G$ is $(a:b)$-choosable, and $c/d > a/b$, then $G$ is not\nnecessarily $(c:d)$-choosable. The simplest case of another problem, stated by\nthe same authors, is settled, proving that every 2-choosable graph is also\n$(4:2)$-choosable. Applying probabilistic methods, an upper bound for the\n$k^{th}$ choice number of a graph is given. We also prove that a directed graph\nwith maximum outdegree $d$ and no odd directed cycle is $(k(d+1):k)$-choosable\nfor every $k \\geq 1$. Other results presented in this article are related to\nthe strong choice number of graphs (a generalization of the strong chromatic\nnumber). We conclude with complexity analysis of some decision problems related\nto graph choosability.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 09:05:54 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Gutner", "Shai", ""]]}
{"id": "0802.2300", "submitter": "Elchanan Mossel", "authors": "Per Austrin and Elchanan Mossel", "title": "Approximation Resistant Predicates From Pairwise Independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximability of predicates on $k$ variables from a domain\n$[q]$, and give a new sufficient condition for such predicates to be\napproximation resistant under the Unique Games Conjecture. Specifically, we\nshow that a predicate $P$ is approximation resistant if there exists a balanced\npairwise independent distribution over $[q]^k$ whose support is contained in\nthe set of satisfying assignments to $P$.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 23:21:05 GMT"}], "update_date": "2008-02-19", "authors_parsed": [["Austrin", "Per", ""], ["Mossel", "Elchanan", ""]]}
{"id": "0802.2305", "submitter": "Ping Li", "authors": "Ping Li", "title": "Compressed Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DM cs.DS cs.LG math.IT", "license": null, "abstract": "  Counting is among the most fundamental operations in computing. For example,\ncounting the pth frequency moment has been a very active area of research, in\ntheoretical computer science, databases, and data mining. When p=1, the task\n(i.e., counting the sum) can be accomplished using a simple counter.\n  Compressed Counting (CC) is proposed for efficiently computing the pth\nfrequency moment of a data stream signal A_t, where 0<p<=2. CC is applicable if\nthe streaming data follow the Turnstile model, with the restriction that at the\ntime t for the evaluation, A_t[i]>= 0, which includes the strict Turnstile\nmodel as a special case. For natural data streams encountered in practice, this\nrestriction is minor.\n  The underly technique for CC is what we call skewed stable random\nprojections, which captures the intuition that, when p=1 a simple counter\nsuffices, and when p = 1+/\\Delta with small \\Delta, the sample complexity of a\ncounter system should be low (continuously as a function of \\Delta). We show at\nsmall \\Delta the sample complexity (number of projections) k = O(1/\\epsilon)\ninstead of O(1/\\epsilon^2).\n  Compressed Counting can serve a basic building block for other tasks in\nstatistics and computing, for example, estimation entropies of data streams,\nparameter estimations using the method of moments and maximum likelihood.\n  Finally, another contribution is an algorithm for approximating the\nlogarithmic norm, \\sum_{i=1}^D\\log A_t[i], and logarithmic distance. The\nlogarithmic distance is useful in machine learning practice with heavy-tailed\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2008 16:42:52 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2008 09:51:09 GMT"}], "update_date": "2008-02-24", "authors_parsed": [["Li", "Ping", ""]]}
{"id": "0802.2429", "submitter": "Sebastien Verel", "authors": "David Simoncini (I3S), S\\'ebastien Verel (I3S), Philippe Collard\n  (I3S), Manuel Clergue (I3S)", "title": "Anisotropic selection in cellular genetic algorithms", "comments": null, "journal-ref": "Dans Proceedings of the 8th annual conference on Genetic and\n  evolutionary computation - Genetic And Evolutionary Computation Conference,\n  Seatle : \\'Etats-Unis d'Am\\'erique (2006)", "doi": "10.1145/1143997.1144098", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  In this paper we introduce a new selection scheme in cellular genetic\nalgorithms (cGAs). Anisotropic Selection (AS) promotes diversity and allows\naccurate control of the selective pressure. First we compare this new scheme\nwith the classical rectangular grid shapes solution according to the selective\npressure: we can obtain the same takeover time with the two techniques although\nthe spreading of the best individual is different. We then give experimental\nresults that show to what extent AS promotes the emergence of niches that\nsupport low coupling and high cohesion. Finally, using a cGA with anisotropic\nselection on a Quadratic Assignment Problem we show the existence of an\nanisotropic optimal value for which the best average performance is observed.\nFurther work will focus on the selective pressure self-adjustment ability\nprovided by this new selection scheme.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2008 07:30:04 GMT"}], "update_date": "2008-02-19", "authors_parsed": [["Simoncini", "David", "", "I3S"], ["Verel", "Sébastien", "", "I3S"], ["Collard", "Philippe", "", "I3S"], ["Clergue", "Manuel", "", "I3S"]]}
{"id": "0802.2432", "submitter": "Andrei Romashchenko", "authors": "Bruno Durand (LIF), Andrei Romashchenko (LIP), Alexander Shen (LIF)", "title": "Fixed Point and Aperiodic Tilings", "comments": "v5: technical revision (positions of figures are shifted)", "journal-ref": "12th International Conference on Developments in Language Theory,\n  Kyoto : Japan (2008)", "doi": "10.1007/978-3-540-85780-8_22", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An aperiodic tile set was first constructed by R.Berger while proving the\nundecidability of the domino problem. It turned out that aperiodic tile sets\nappear in many topics ranging from logic (the Entscheidungsproblem) to physics\n(quasicrystals) We present a new construction of an aperiodic tile set that is\nbased on Kleene's fixed-point construction instead of geometric arguments. This\nconstruction is similar to J. von Neumann self-reproducing automata; similar\nideas were also used by P. Gacs in the context of error-correcting\ncomputations. The flexibility of this construction allows us to construct a\n\"robust\" aperiodic tile set that does not have periodic (or close to periodic)\ntilings even if we allow some (sparse enough) tiling errors. This property was\nnot known for any of the existing aperiodic tile sets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2008 07:50:13 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2008 15:43:21 GMT"}, {"version": "v3", "created": "Mon, 7 Jul 2008 11:16:24 GMT"}, {"version": "v4", "created": "Wed, 13 Jan 2010 13:50:04 GMT"}, {"version": "v5", "created": "Wed, 27 Jan 2010 14:15:07 GMT"}], "update_date": "2010-01-27", "authors_parsed": [["Durand", "Bruno", "", "LIF"], ["Romashchenko", "Andrei", "", "LIP"], ["Shen", "Alexander", "", "LIF"]]}
{"id": "0802.2594", "submitter": "Menelaos Karavelas", "authors": "Menelaos I. Karavelas and Elias P. Tsigaridas", "title": "Guarding curvilinear art galleries with vertex or point guards", "comments": "35 pages, 24 figures", "journal-ref": "Comput. Geom. Theory Appl. 42(6-7):522-535, 2009", "doi": "10.1016/j.comgeo.2008.11.002", "report-no": null, "categories": "cs.CG", "license": null, "abstract": "  One of the earliest and most well known problems in computational geometry is\nthe so-called art gallery problem. The goal is to compute the minimum possible\nnumber guards placed on the vertices of a simple polygon in such a way that\nthey cover the interior of the polygon.\n  In this paper we consider the problem of guarding an art gallery which is\nmodeled as a polygon with curvilinear walls. Our main focus is on polygons the\nedges of which are convex arcs pointing towards the exterior or interior of the\npolygon (but not both), named piecewise-convex and piecewise-concave polygons.\nWe prove that, in the case of piecewise-convex polygons, if we only allow\nvertex guards, $\\lfloor\\frac{4n}{7}\\rfloor-1$ guards are sometimes necessary,\nand $\\lfloor\\frac{2n}{3}\\rfloor$ guards are always sufficient. Moreover, an\n$O(n\\log{}n)$ time and O(n) space algorithm is described that produces a vertex\nguarding set of size at most $\\lfloor\\frac{2n}{3}\\rfloor$. When we allow point\nguards the afore-mentioned lower bound drops down to\n$\\lfloor\\frac{n}{2}\\rfloor$. In the special case of monotone piecewise-convex\npolygons we can show that $\\lfloor\\frac{n}{2}\\rfloor$ vertex guards are always\nsufficient and sometimes necessary; these bounds remain valid even if we allow\npoint guards.\n  In the case of piecewise-concave polygons, we show that $2n-4$ point guards\nare always sufficient and sometimes necessary, whereas it might not be possible\nto guard such polygons by vertex guards. We conclude with bounds for other\ntypes of curvilinear polygons and future work.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2008 06:10:17 GMT"}], "update_date": "2009-11-25", "authors_parsed": [["Karavelas", "Menelaos I.", ""], ["Tsigaridas", "Elias P.", ""]]}
{"id": "0802.2612", "submitter": "Sergey Gubin", "authors": "Sergey Gubin", "title": "On Subgraph Isomorphism", "comments": "Simplified, 6 pages", "journal-ref": "Polynomial size asymmetric linear model for Subgraph Isomorphism,\n  Proceedings WCECS 2008, ISBN: 978-988-98671-0-2, pp.241-246", "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Article explicitly expresses Subgraph Isomorphism by a polynomial size\nasymmetric linear system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2008 09:06:40 GMT"}, {"version": "v2", "created": "Thu, 14 Aug 2008 22:22:49 GMT"}], "update_date": "2008-11-10", "authors_parsed": [["Gubin", "Sergey", ""]]}
{"id": "0802.2668", "submitter": "Shai  Gutner", "authors": "Shai Gutner", "title": "The complexity of planar graph choosability", "comments": null, "journal-ref": "Discrete Math. 159 (1996), 119-130", "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": null, "abstract": "  A graph $G$ is {\\em $k$-choosable} if for every assignment of a set $S(v)$ of\n$k$ colors to every vertex $v$ of $G$, there is a proper coloring of $G$ that\nassigns to each vertex $v$ a color from $S(v)$. We consider the complexity of\ndeciding whether a given graph is $k$-choosable for some constant $k$. In\nparticular, it is shown that deciding whether a given planar graph is\n4-choosable is NP-hard, and so is the problem of deciding whether a given\nplanar triangle-free graph is 3-choosable. We also obtain simple constructions\nof a planar graph which is not 4-choosable and a planar triangle-free graph\nwhich is not 3-choosable.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2008 15:26:19 GMT"}], "update_date": "2008-02-20", "authors_parsed": [["Gutner", "Shai", ""]]}
